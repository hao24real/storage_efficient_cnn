{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(device)  \n",
    "# If 'mps or cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from custom_cifar10 import CustomCIFAR10\n",
    "\n",
    "# Standard transformations for the dataset\n",
    "standard_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Additional focused augmentations\n",
    "focused_augmentations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "])\n",
    "\n",
    "# standard training dataset\n",
    "std_trainset = CustomCIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=standard_transforms\n",
    ")\n",
    "\n",
    "# using custom dataset class to add focused augmentations capability\n",
    "aug_trainset = CustomCIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=standard_transforms,\n",
    "    focused_transform=focused_augmentations\n",
    ")\n",
    "\n",
    "# Combine the two datasets\n",
    "combined_trainset = torch.utils.data.ConcatDataset([std_trainset, aug_trainset])\n",
    "trainloader = torch.utils.data.DataLoader(combined_trainset, batch_size=8,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_cifar_10.models import DenseMax\n",
    "test = DenseMax()\n",
    "test.to(device)\n",
    "# # testing model imported corrected with the right resulting dimensions\n",
    "assert test(torch.randn(4, 3, 32, 32).to(device)).shape == torch.Size([4, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = 0     # Start from epoch 0 or last checkpoint epoch\n",
    "iter_n = len(trainloader)  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 100 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "# a number for computing running validation loss in each iteration.\n",
    "train_per_valid = len(trainloader) / len(validloader)  \n",
    "\n",
    "avg_train_losses, avg_valid_losses = [], []   # Avg. losses.\n",
    "train_accuracies, valid_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "dense_max = DenseMax()     # Create the network instance.\n",
    "# Move the network parameters to the specified device\n",
    "# need to be done before passing to optimizer.\n",
    "dense_max.to(device)  \n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(dense_max.parameters(), lr=5e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "\n",
    "# add scheduling\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(opt, gamma=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest checkpoint file is: models/dense_max/epoch_0039.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "directory_path = Path(\"./models/dense_max_2\")\n",
    "\n",
    "# Make the directory if it doesn't exist\n",
    "directory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Pattern to match the files and extract epoch numbers\n",
    "pattern = r'epoch_(\\d+).pth'\n",
    "\n",
    "# pattern_path = directory_path / 'epoch_*.pth'\n",
    "\n",
    "# Use Path.glob to list all files matching the pattern\n",
    "files = list(directory_path.glob('epoch_*.pth'))\n",
    "\n",
    "# Extract epochs and files into a list of tuples\n",
    "epochs_files = []\n",
    "for file_path in files:\n",
    "    match = re.search(pattern, file_path.name)\n",
    "    if match:\n",
    "        epoch_num = int(match.group(1))\n",
    "        epochs_files.append((epoch_num, file_path))\n",
    "\n",
    "# Sort the list by epoch number in descending order\n",
    "epochs_files.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "latest_file = epochs_files[0][1] if epochs_files else None\n",
    "\n",
    "# latest_file now holds the path to the checkpoint file with the highest epoch number\n",
    "if latest_file:\n",
    "    print(f\"The latest checkpoint file is: {latest_file}\")\n",
    "    PATH = latest_file\n",
    "    checkpoint = torch.load(PATH)\n",
    "    dense_max.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    epoch_start = checkpoint['epoch'] + 1\n",
    "else:\n",
    "    print(\"No checkpoint files found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> [Start of epoch 0]  lr: 0.000500\n",
      "[epoch: 0, i:   124]  train_loss: 2.133  |  valid_loss: 2.091\n",
      "[epoch: 0, i:   249]  train_loss: 1.925  |  valid_loss: 1.909\n",
      "[epoch: 0, i:   374]  train_loss: 1.805  |  valid_loss: 1.832\n",
      "[epoch: 0, i:   499]  train_loss: 1.803  |  valid_loss: 1.631\n",
      "[epoch: 0, i:   624]  train_loss: 1.662  |  valid_loss: 1.654\n",
      "[epoch: 0, i:   749]  train_loss: 1.639  |  valid_loss: 1.551\n",
      "[epoch: 0, i:   874]  train_loss: 1.664  |  valid_loss: 1.578\n",
      "[epoch: 0, i:   999]  train_loss: 1.607  |  valid_loss: 1.565\n",
      "[epoch: 0, i:  1124]  train_loss: 1.620  |  valid_loss: 1.381\n",
      "[epoch: 0, i:  1249]  train_loss: 1.565  |  valid_loss: 1.307\n",
      "[epoch: 0, i:  1374]  train_loss: 1.489  |  valid_loss: 1.335\n",
      "[epoch: 0, i:  1499]  train_loss: 1.515  |  valid_loss: 1.365\n",
      "[epoch: 0, i:  1624]  train_loss: 1.528  |  valid_loss: 1.437\n",
      "[epoch: 0, i:  1749]  train_loss: 1.505  |  valid_loss: 1.357\n",
      "[epoch: 0, i:  1874]  train_loss: 1.464  |  valid_loss: 1.165\n",
      "[epoch: 0, i:  1999]  train_loss: 1.485  |  valid_loss: 1.394\n",
      "[epoch: 0, i:  2124]  train_loss: 1.506  |  valid_loss: 1.279\n",
      "[epoch: 0, i:  2249]  train_loss: 1.390  |  valid_loss: 1.231\n",
      "[epoch: 0, i:  2374]  train_loss: 1.410  |  valid_loss: 1.103\n",
      "[epoch: 0, i:  2499]  train_loss: 1.440  |  valid_loss: 1.435\n",
      "[epoch: 0, i:  2624]  train_loss: 1.396  |  valid_loss: 1.139\n",
      "[epoch: 0, i:  2749]  train_loss: 1.343  |  valid_loss: 1.165\n",
      "[epoch: 0, i:  2874]  train_loss: 1.314  |  valid_loss: 1.154\n",
      "[epoch: 0, i:  2999]  train_loss: 1.476  |  valid_loss: 1.347\n",
      "[epoch: 0, i:  3124]  train_loss: 1.361  |  valid_loss: 1.179\n",
      "[epoch: 0, i:  3249]  train_loss: 1.371  |  valid_loss: 1.494\n",
      "[epoch: 0, i:  3374]  train_loss: 1.286  |  valid_loss: 1.037\n",
      "[epoch: 0, i:  3499]  train_loss: 1.353  |  valid_loss: 1.216\n",
      "[epoch: 0, i:  3624]  train_loss: 1.319  |  valid_loss: 1.203\n",
      "[epoch: 0, i:  3749]  train_loss: 1.342  |  valid_loss: 1.161\n",
      "[epoch: 0, i:  3874]  train_loss: 1.278  |  valid_loss: 1.076\n",
      "[epoch: 0, i:  3999]  train_loss: 1.304  |  valid_loss: 1.029\n",
      "[epoch: 0, i:  4124]  train_loss: 1.353  |  valid_loss: 0.930\n",
      "[epoch: 0, i:  4249]  train_loss: 1.315  |  valid_loss: 1.197\n",
      "[epoch: 0, i:  4374]  train_loss: 1.301  |  valid_loss: 1.164\n",
      "[epoch: 0, i:  4499]  train_loss: 1.268  |  valid_loss: 1.010\n",
      "[epoch: 0, i:  4624]  train_loss: 1.219  |  valid_loss: 1.137\n",
      "[epoch: 0, i:  4749]  train_loss: 1.239  |  valid_loss: 1.112\n",
      "[epoch: 0, i:  4874]  train_loss: 1.258  |  valid_loss: 0.954\n",
      "[epoch: 0, i:  4999]  train_loss: 1.226  |  valid_loss: 1.069\n",
      "[epoch: 0, i:  5124]  train_loss: 1.248  |  valid_loss: 0.970\n",
      "[epoch: 0, i:  5249]  train_loss: 1.235  |  valid_loss: 0.968\n",
      "[epoch: 0, i:  5374]  train_loss: 1.239  |  valid_loss: 0.984\n",
      "[epoch: 0, i:  5499]  train_loss: 1.210  |  valid_loss: 1.003\n",
      "[epoch: 0, i:  5624]  train_loss: 1.216  |  valid_loss: 0.955\n",
      "[epoch: 0, i:  5749]  train_loss: 1.210  |  valid_loss: 1.172\n",
      "[epoch: 0, i:  5874]  train_loss: 1.253  |  valid_loss: 0.950\n",
      "[epoch: 0, i:  5999]  train_loss: 1.146  |  valid_loss: 0.954\n",
      "[epoch: 0, i:  6124]  train_loss: 1.176  |  valid_loss: 0.928\n",
      "[epoch: 0, i:  6249]  train_loss: 1.207  |  valid_loss: 0.990\n",
      "[epoch: 0, i:  6374]  train_loss: 1.188  |  valid_loss: 0.911\n",
      "[epoch: 0, i:  6499]  train_loss: 1.205  |  valid_loss: 0.846\n",
      "[epoch: 0, i:  6624]  train_loss: 1.242  |  valid_loss: 0.945\n",
      "[epoch: 0, i:  6749]  train_loss: 1.187  |  valid_loss: 1.152\n",
      "[epoch: 0, i:  6874]  train_loss: 1.201  |  valid_loss: 0.994\n",
      "[epoch: 0, i:  6999]  train_loss: 1.202  |  valid_loss: 1.097\n",
      "[epoch: 0, i:  7124]  train_loss: 1.173  |  valid_loss: 1.067\n",
      "[epoch: 0, i:  7249]  train_loss: 1.187  |  valid_loss: 0.887\n",
      "[epoch: 0, i:  7374]  train_loss: 1.073  |  valid_loss: 1.171\n",
      "[epoch: 0, i:  7499]  train_loss: 1.149  |  valid_loss: 1.048\n",
      "[epoch: 0, i:  7624]  train_loss: 1.116  |  valid_loss: 1.032\n",
      "[epoch: 0, i:  7749]  train_loss: 1.121  |  valid_loss: 0.985\n",
      "[epoch: 0, i:  7874]  train_loss: 1.136  |  valid_loss: 0.890\n",
      "[epoch: 0, i:  7999]  train_loss: 1.198  |  valid_loss: 0.843\n",
      "[epoch: 0, i:  8124]  train_loss: 1.095  |  valid_loss: 1.013\n",
      "[epoch: 0, i:  8249]  train_loss: 1.125  |  valid_loss: 1.098\n",
      "[epoch: 0, i:  8374]  train_loss: 1.116  |  valid_loss: 0.906\n",
      "[epoch: 0, i:  8499]  train_loss: 1.172  |  valid_loss: 1.050\n",
      "[epoch: 0, i:  8624]  train_loss: 1.093  |  valid_loss: 0.930\n",
      "[epoch: 0, i:  8749]  train_loss: 1.111  |  valid_loss: 1.078\n",
      "[epoch: 0, i:  8874]  train_loss: 1.141  |  valid_loss: 0.998\n",
      "[epoch: 0, i:  8999]  train_loss: 1.155  |  valid_loss: 0.857\n",
      "[epoch: 0, i:  9124]  train_loss: 1.079  |  valid_loss: 0.903\n",
      "[epoch: 0, i:  9249]  train_loss: 1.099  |  valid_loss: 0.723\n",
      "[epoch: 0, i:  9374]  train_loss: 1.144  |  valid_loss: 0.921\n",
      "[epoch: 0, i:  9499]  train_loss: 1.126  |  valid_loss: 0.895\n",
      "[epoch: 0, i:  9624]  train_loss: 1.075  |  valid_loss: 0.866\n",
      "[epoch: 0, i:  9749]  train_loss: 1.071  |  valid_loss: 0.833\n",
      "[epoch: 0, i:  9874]  train_loss: 1.089  |  valid_loss: 0.943\n",
      "[epoch: 0, i:  9999]  train_loss: 1.094  |  valid_loss: 0.951\n",
      "[epoch: 0, i: 10124]  train_loss: 1.046  |  valid_loss: 0.812\n",
      "[epoch: 0, i: 10249]  train_loss: 1.048  |  valid_loss: 0.943\n",
      "[epoch: 0, i: 10374]  train_loss: 1.152  |  valid_loss: 0.868\n",
      "[epoch: 0, i: 10499]  train_loss: 1.139  |  valid_loss: 1.027\n",
      "[epoch: 0, i: 10624]  train_loss: 1.095  |  valid_loss: 0.980\n",
      "[epoch: 0, i: 10749]  train_loss: 1.073  |  valid_loss: 0.807\n",
      "[epoch: 0, i: 10874]  train_loss: 1.109  |  valid_loss: 0.994\n",
      "[epoch: 0, i: 10999]  train_loss: 1.098  |  valid_loss: 1.023\n",
      "[epoch: 0, i: 11124]  train_loss: 1.000  |  valid_loss: 0.854\n",
      "[epoch: 0, i: 11249]  train_loss: 1.049  |  valid_loss: 0.862\n",
      "[epoch: 0, i: 11374]  train_loss: 1.034  |  valid_loss: 0.903\n",
      "[epoch: 0, i: 11499]  train_loss: 1.087  |  valid_loss: 0.776\n",
      "[epoch: 0, i: 11624]  train_loss: 1.045  |  valid_loss: 0.870\n",
      "[epoch: 0, i: 11749]  train_loss: 1.039  |  valid_loss: 0.955\n",
      "[epoch: 0, i: 11874]  train_loss: 1.098  |  valid_loss: 0.804\n",
      "[epoch: 0, i: 11999]  train_loss: 1.050  |  valid_loss: 0.738\n",
      "[epoch: 0, i: 12124]  train_loss: 1.048  |  valid_loss: 0.700\n",
      "[epoch: 0, i: 12249]  train_loss: 1.094  |  valid_loss: 1.069\n",
      "[epoch: 0, i: 12374]  train_loss: 1.082  |  valid_loss: 0.866\n",
      "[epoch: 0, i: 12499]  train_loss: 1.060  |  valid_loss: 0.866\n",
      "--> [End of epoch 0] train_accuracy: 55.51%  |  valid_accuracy: 61.16%\n",
      "--> [Start of epoch 1]  lr: 0.000450\n",
      "[epoch: 1, i:   124]  train_loss: 0.960  |  valid_loss: 0.826\n",
      "[epoch: 1, i:   249]  train_loss: 1.002  |  valid_loss: 0.839\n",
      "[epoch: 1, i:   374]  train_loss: 1.066  |  valid_loss: 0.988\n",
      "[epoch: 1, i:   499]  train_loss: 1.088  |  valid_loss: 0.931\n",
      "[epoch: 1, i:   624]  train_loss: 1.024  |  valid_loss: 0.927\n",
      "[epoch: 1, i:   749]  train_loss: 1.067  |  valid_loss: 0.606\n",
      "[epoch: 1, i:   874]  train_loss: 0.956  |  valid_loss: 0.878\n",
      "[epoch: 1, i:   999]  train_loss: 1.069  |  valid_loss: 0.909\n",
      "[epoch: 1, i:  1124]  train_loss: 1.036  |  valid_loss: 0.917\n",
      "[epoch: 1, i:  1249]  train_loss: 1.028  |  valid_loss: 0.732\n",
      "[epoch: 1, i:  1374]  train_loss: 0.954  |  valid_loss: 0.772\n",
      "[epoch: 1, i:  1499]  train_loss: 0.964  |  valid_loss: 0.867\n",
      "[epoch: 1, i:  1624]  train_loss: 1.062  |  valid_loss: 0.823\n",
      "[epoch: 1, i:  1749]  train_loss: 1.054  |  valid_loss: 0.792\n",
      "[epoch: 1, i:  1874]  train_loss: 1.027  |  valid_loss: 0.690\n",
      "[epoch: 1, i:  1999]  train_loss: 0.978  |  valid_loss: 0.960\n",
      "[epoch: 1, i:  2124]  train_loss: 1.003  |  valid_loss: 0.851\n",
      "[epoch: 1, i:  2249]  train_loss: 1.004  |  valid_loss: 0.806\n",
      "[epoch: 1, i:  2374]  train_loss: 1.039  |  valid_loss: 0.740\n",
      "[epoch: 1, i:  2499]  train_loss: 0.958  |  valid_loss: 1.143\n",
      "[epoch: 1, i:  2624]  train_loss: 1.039  |  valid_loss: 0.873\n",
      "[epoch: 1, i:  2749]  train_loss: 1.029  |  valid_loss: 0.825\n",
      "[epoch: 1, i:  2874]  train_loss: 1.006  |  valid_loss: 0.786\n",
      "[epoch: 1, i:  2999]  train_loss: 0.994  |  valid_loss: 0.898\n",
      "[epoch: 1, i:  3124]  train_loss: 1.017  |  valid_loss: 0.839\n",
      "[epoch: 1, i:  3249]  train_loss: 0.964  |  valid_loss: 1.004\n",
      "[epoch: 1, i:  3374]  train_loss: 1.040  |  valid_loss: 0.755\n",
      "[epoch: 1, i:  3499]  train_loss: 1.033  |  valid_loss: 0.840\n",
      "[epoch: 1, i:  3624]  train_loss: 1.028  |  valid_loss: 0.835\n",
      "[epoch: 1, i:  3749]  train_loss: 1.025  |  valid_loss: 0.786\n",
      "[epoch: 1, i:  3874]  train_loss: 0.984  |  valid_loss: 0.800\n",
      "[epoch: 1, i:  3999]  train_loss: 1.004  |  valid_loss: 0.752\n",
      "[epoch: 1, i:  4124]  train_loss: 1.043  |  valid_loss: 0.716\n",
      "[epoch: 1, i:  4249]  train_loss: 0.992  |  valid_loss: 0.843\n",
      "[epoch: 1, i:  4374]  train_loss: 1.025  |  valid_loss: 0.895\n",
      "[epoch: 1, i:  4499]  train_loss: 0.988  |  valid_loss: 0.778\n",
      "[epoch: 1, i:  4624]  train_loss: 1.002  |  valid_loss: 0.917\n",
      "[epoch: 1, i:  4749]  train_loss: 0.993  |  valid_loss: 0.846\n",
      "[epoch: 1, i:  4874]  train_loss: 0.918  |  valid_loss: 0.737\n",
      "[epoch: 1, i:  4999]  train_loss: 1.027  |  valid_loss: 0.777\n",
      "[epoch: 1, i:  5124]  train_loss: 1.053  |  valid_loss: 0.732\n",
      "[epoch: 1, i:  5249]  train_loss: 0.954  |  valid_loss: 0.786\n",
      "[epoch: 1, i:  5374]  train_loss: 0.971  |  valid_loss: 0.729\n",
      "[epoch: 1, i:  5499]  train_loss: 0.923  |  valid_loss: 0.799\n",
      "[epoch: 1, i:  5624]  train_loss: 0.975  |  valid_loss: 0.785\n",
      "[epoch: 1, i:  5749]  train_loss: 0.958  |  valid_loss: 0.800\n",
      "[epoch: 1, i:  5874]  train_loss: 0.951  |  valid_loss: 0.702\n",
      "[epoch: 1, i:  5999]  train_loss: 0.941  |  valid_loss: 0.724\n",
      "[epoch: 1, i:  6124]  train_loss: 0.998  |  valid_loss: 0.784\n",
      "[epoch: 1, i:  6249]  train_loss: 0.982  |  valid_loss: 0.937\n",
      "[epoch: 1, i:  6374]  train_loss: 1.009  |  valid_loss: 0.732\n",
      "[epoch: 1, i:  6499]  train_loss: 0.938  |  valid_loss: 0.780\n",
      "[epoch: 1, i:  6624]  train_loss: 1.012  |  valid_loss: 0.757\n",
      "[epoch: 1, i:  6749]  train_loss: 1.005  |  valid_loss: 0.917\n",
      "[epoch: 1, i:  6874]  train_loss: 0.918  |  valid_loss: 0.798\n",
      "[epoch: 1, i:  6999]  train_loss: 1.003  |  valid_loss: 0.933\n",
      "[epoch: 1, i:  7124]  train_loss: 0.977  |  valid_loss: 0.817\n",
      "[epoch: 1, i:  7249]  train_loss: 0.978  |  valid_loss: 0.601\n",
      "[epoch: 1, i:  7374]  train_loss: 0.956  |  valid_loss: 0.961\n",
      "[epoch: 1, i:  7499]  train_loss: 0.930  |  valid_loss: 0.818\n",
      "[epoch: 1, i:  7624]  train_loss: 0.963  |  valid_loss: 0.797\n",
      "[epoch: 1, i:  7749]  train_loss: 0.991  |  valid_loss: 0.790\n",
      "[epoch: 1, i:  7874]  train_loss: 0.974  |  valid_loss: 0.739\n",
      "[epoch: 1, i:  7999]  train_loss: 0.968  |  valid_loss: 0.746\n",
      "[epoch: 1, i:  8124]  train_loss: 0.986  |  valid_loss: 0.758\n",
      "[epoch: 1, i:  8249]  train_loss: 0.958  |  valid_loss: 0.877\n",
      "[epoch: 1, i:  8374]  train_loss: 0.957  |  valid_loss: 0.821\n",
      "[epoch: 1, i:  8499]  train_loss: 0.967  |  valid_loss: 0.851\n",
      "[epoch: 1, i:  8624]  train_loss: 0.928  |  valid_loss: 0.751\n",
      "[epoch: 1, i:  8749]  train_loss: 1.009  |  valid_loss: 0.936\n",
      "[epoch: 1, i:  8874]  train_loss: 0.927  |  valid_loss: 0.780\n",
      "[epoch: 1, i:  8999]  train_loss: 0.921  |  valid_loss: 0.740\n",
      "[epoch: 1, i:  9124]  train_loss: 0.925  |  valid_loss: 0.774\n",
      "[epoch: 1, i:  9249]  train_loss: 0.963  |  valid_loss: 0.592\n",
      "[epoch: 1, i:  9374]  train_loss: 0.919  |  valid_loss: 0.767\n",
      "[epoch: 1, i:  9499]  train_loss: 0.937  |  valid_loss: 0.755\n",
      "[epoch: 1, i:  9624]  train_loss: 0.990  |  valid_loss: 0.839\n",
      "[epoch: 1, i:  9749]  train_loss: 0.963  |  valid_loss: 0.745\n",
      "[epoch: 1, i:  9874]  train_loss: 0.932  |  valid_loss: 0.879\n",
      "[epoch: 1, i:  9999]  train_loss: 0.878  |  valid_loss: 0.848\n",
      "[epoch: 1, i: 10124]  train_loss: 0.934  |  valid_loss: 0.609\n",
      "[epoch: 1, i: 10249]  train_loss: 1.003  |  valid_loss: 0.730\n",
      "[epoch: 1, i: 10374]  train_loss: 0.909  |  valid_loss: 0.706\n",
      "[epoch: 1, i: 10499]  train_loss: 0.934  |  valid_loss: 0.893\n",
      "[epoch: 1, i: 10624]  train_loss: 0.934  |  valid_loss: 0.905\n",
      "[epoch: 1, i: 10749]  train_loss: 0.888  |  valid_loss: 0.710\n",
      "[epoch: 1, i: 10874]  train_loss: 0.914  |  valid_loss: 0.850\n",
      "[epoch: 1, i: 10999]  train_loss: 0.952  |  valid_loss: 0.800\n",
      "[epoch: 1, i: 11124]  train_loss: 0.969  |  valid_loss: 0.815\n",
      "[epoch: 1, i: 11249]  train_loss: 0.940  |  valid_loss: 0.834\n",
      "[epoch: 1, i: 11374]  train_loss: 0.944  |  valid_loss: 0.650\n",
      "[epoch: 1, i: 11499]  train_loss: 0.974  |  valid_loss: 0.601\n",
      "[epoch: 1, i: 11624]  train_loss: 0.941  |  valid_loss: 0.731\n",
      "[epoch: 1, i: 11749]  train_loss: 0.974  |  valid_loss: 0.836\n",
      "[epoch: 1, i: 11874]  train_loss: 0.966  |  valid_loss: 0.722\n",
      "[epoch: 1, i: 11999]  train_loss: 0.968  |  valid_loss: 0.714\n",
      "[epoch: 1, i: 12124]  train_loss: 0.871  |  valid_loss: 0.582\n",
      "[epoch: 1, i: 12249]  train_loss: 0.916  |  valid_loss: 0.884\n",
      "[epoch: 1, i: 12374]  train_loss: 0.922  |  valid_loss: 0.786\n",
      "[epoch: 1, i: 12499]  train_loss: 0.935  |  valid_loss: 0.744\n",
      "--> [End of epoch 1] train_accuracy: 66.00%  |  valid_accuracy: 71.88%\n",
      "--> [Start of epoch 2]  lr: 0.000405\n",
      "[epoch: 2, i:   124]  train_loss: 0.944  |  valid_loss: 0.707\n",
      "[epoch: 2, i:   249]  train_loss: 0.911  |  valid_loss: 0.646\n",
      "[epoch: 2, i:   374]  train_loss: 0.861  |  valid_loss: 0.851\n",
      "[epoch: 2, i:   499]  train_loss: 0.940  |  valid_loss: 0.797\n",
      "[epoch: 2, i:   624]  train_loss: 0.983  |  valid_loss: 0.836\n",
      "[epoch: 2, i:   749]  train_loss: 0.890  |  valid_loss: 0.564\n",
      "[epoch: 2, i:   874]  train_loss: 0.936  |  valid_loss: 0.699\n",
      "[epoch: 2, i:   999]  train_loss: 0.821  |  valid_loss: 0.808\n",
      "[epoch: 2, i:  1124]  train_loss: 0.908  |  valid_loss: 0.884\n",
      "[epoch: 2, i:  1249]  train_loss: 0.955  |  valid_loss: 0.699\n",
      "[epoch: 2, i:  1374]  train_loss: 1.014  |  valid_loss: 0.728\n",
      "[epoch: 2, i:  1499]  train_loss: 0.902  |  valid_loss: 0.766\n",
      "[epoch: 2, i:  1624]  train_loss: 0.876  |  valid_loss: 0.713\n",
      "[epoch: 2, i:  1749]  train_loss: 0.888  |  valid_loss: 0.737\n",
      "[epoch: 2, i:  1874]  train_loss: 0.913  |  valid_loss: 0.640\n",
      "[epoch: 2, i:  1999]  train_loss: 0.895  |  valid_loss: 0.806\n",
      "[epoch: 2, i:  2124]  train_loss: 0.884  |  valid_loss: 0.745\n",
      "[epoch: 2, i:  2249]  train_loss: 0.964  |  valid_loss: 0.720\n",
      "[epoch: 2, i:  2374]  train_loss: 0.891  |  valid_loss: 0.701\n",
      "[epoch: 2, i:  2499]  train_loss: 0.911  |  valid_loss: 1.016\n",
      "[epoch: 2, i:  2624]  train_loss: 0.861  |  valid_loss: 0.816\n",
      "[epoch: 2, i:  2749]  train_loss: 0.892  |  valid_loss: 0.728\n",
      "[epoch: 2, i:  2874]  train_loss: 0.888  |  valid_loss: 0.819\n",
      "[epoch: 2, i:  2999]  train_loss: 0.893  |  valid_loss: 0.853\n",
      "[epoch: 2, i:  3124]  train_loss: 0.939  |  valid_loss: 0.775\n",
      "[epoch: 2, i:  3249]  train_loss: 0.972  |  valid_loss: 1.059\n",
      "[epoch: 2, i:  3374]  train_loss: 0.886  |  valid_loss: 0.624\n",
      "[epoch: 2, i:  3499]  train_loss: 0.895  |  valid_loss: 0.812\n",
      "[epoch: 2, i:  3624]  train_loss: 0.937  |  valid_loss: 0.788\n",
      "[epoch: 2, i:  3749]  train_loss: 0.854  |  valid_loss: 0.701\n",
      "[epoch: 2, i:  3874]  train_loss: 0.895  |  valid_loss: 0.727\n",
      "[epoch: 2, i:  3999]  train_loss: 0.912  |  valid_loss: 0.720\n",
      "[epoch: 2, i:  4124]  train_loss: 0.887  |  valid_loss: 0.659\n",
      "[epoch: 2, i:  4249]  train_loss: 0.925  |  valid_loss: 0.805\n",
      "[epoch: 2, i:  4374]  train_loss: 0.969  |  valid_loss: 0.854\n",
      "[epoch: 2, i:  4499]  train_loss: 0.884  |  valid_loss: 0.786\n",
      "[epoch: 2, i:  4624]  train_loss: 0.904  |  valid_loss: 0.856\n",
      "[epoch: 2, i:  4749]  train_loss: 0.903  |  valid_loss: 0.738\n",
      "[epoch: 2, i:  4874]  train_loss: 0.913  |  valid_loss: 0.650\n",
      "[epoch: 2, i:  4999]  train_loss: 0.888  |  valid_loss: 0.624\n",
      "[epoch: 2, i:  5124]  train_loss: 0.882  |  valid_loss: 0.699\n",
      "[epoch: 2, i:  5249]  train_loss: 0.858  |  valid_loss: 0.754\n",
      "[epoch: 2, i:  5374]  train_loss: 0.922  |  valid_loss: 0.559\n",
      "[epoch: 2, i:  5499]  train_loss: 0.873  |  valid_loss: 0.695\n",
      "[epoch: 2, i:  5624]  train_loss: 0.867  |  valid_loss: 0.726\n",
      "[epoch: 2, i:  5749]  train_loss: 0.900  |  valid_loss: 0.751\n",
      "[epoch: 2, i:  5874]  train_loss: 0.828  |  valid_loss: 0.632\n",
      "[epoch: 2, i:  5999]  train_loss: 0.899  |  valid_loss: 0.663\n",
      "[epoch: 2, i:  6124]  train_loss: 0.900  |  valid_loss: 0.609\n",
      "[epoch: 2, i:  6249]  train_loss: 0.928  |  valid_loss: 0.861\n",
      "[epoch: 2, i:  6374]  train_loss: 0.914  |  valid_loss: 0.714\n",
      "[epoch: 2, i:  6499]  train_loss: 0.904  |  valid_loss: 0.717\n",
      "[epoch: 2, i:  6624]  train_loss: 0.902  |  valid_loss: 0.673\n",
      "[epoch: 2, i:  6749]  train_loss: 0.859  |  valid_loss: 0.759\n",
      "[epoch: 2, i:  6874]  train_loss: 0.882  |  valid_loss: 0.722\n",
      "[epoch: 2, i:  6999]  train_loss: 0.896  |  valid_loss: 0.792\n",
      "[epoch: 2, i:  7124]  train_loss: 0.868  |  valid_loss: 0.818\n",
      "[epoch: 2, i:  7249]  train_loss: 0.830  |  valid_loss: 0.519\n",
      "[epoch: 2, i:  7374]  train_loss: 0.908  |  valid_loss: 0.812\n",
      "[epoch: 2, i:  7499]  train_loss: 0.840  |  valid_loss: 0.760\n",
      "[epoch: 2, i:  7624]  train_loss: 0.832  |  valid_loss: 0.661\n",
      "[epoch: 2, i:  7749]  train_loss: 0.885  |  valid_loss: 0.823\n",
      "[epoch: 2, i:  7874]  train_loss: 0.939  |  valid_loss: 0.717\n",
      "[epoch: 2, i:  7999]  train_loss: 0.888  |  valid_loss: 0.651\n",
      "[epoch: 2, i:  8124]  train_loss: 0.838  |  valid_loss: 0.675\n",
      "[epoch: 2, i:  8249]  train_loss: 0.902  |  valid_loss: 0.753\n",
      "[epoch: 2, i:  8374]  train_loss: 0.926  |  valid_loss: 0.678\n",
      "[epoch: 2, i:  8499]  train_loss: 0.882  |  valid_loss: 0.826\n",
      "[epoch: 2, i:  8624]  train_loss: 0.862  |  valid_loss: 0.588\n",
      "[epoch: 2, i:  8749]  train_loss: 0.840  |  valid_loss: 0.842\n",
      "[epoch: 2, i:  8874]  train_loss: 0.913  |  valid_loss: 0.725\n",
      "[epoch: 2, i:  8999]  train_loss: 0.924  |  valid_loss: 0.691\n",
      "[epoch: 2, i:  9124]  train_loss: 0.922  |  valid_loss: 0.662\n",
      "[epoch: 2, i:  9249]  train_loss: 0.894  |  valid_loss: 0.594\n",
      "[epoch: 2, i:  9374]  train_loss: 0.879  |  valid_loss: 0.822\n",
      "[epoch: 2, i:  9499]  train_loss: 0.957  |  valid_loss: 0.640\n",
      "[epoch: 2, i:  9624]  train_loss: 0.905  |  valid_loss: 0.795\n",
      "[epoch: 2, i:  9749]  train_loss: 0.934  |  valid_loss: 0.706\n",
      "[epoch: 2, i:  9874]  train_loss: 0.859  |  valid_loss: 0.791\n",
      "[epoch: 2, i:  9999]  train_loss: 0.852  |  valid_loss: 0.767\n",
      "[epoch: 2, i: 10124]  train_loss: 0.925  |  valid_loss: 0.563\n",
      "[epoch: 2, i: 10249]  train_loss: 0.893  |  valid_loss: 0.666\n",
      "[epoch: 2, i: 10374]  train_loss: 0.866  |  valid_loss: 0.670\n",
      "[epoch: 2, i: 10499]  train_loss: 0.833  |  valid_loss: 0.782\n",
      "[epoch: 2, i: 10624]  train_loss: 0.892  |  valid_loss: 0.873\n",
      "[epoch: 2, i: 10749]  train_loss: 0.858  |  valid_loss: 0.713\n",
      "[epoch: 2, i: 10874]  train_loss: 0.881  |  valid_loss: 0.761\n",
      "[epoch: 2, i: 10999]  train_loss: 0.871  |  valid_loss: 0.780\n",
      "[epoch: 2, i: 11124]  train_loss: 0.864  |  valid_loss: 0.770\n",
      "[epoch: 2, i: 11249]  train_loss: 0.878  |  valid_loss: 0.753\n",
      "[epoch: 2, i: 11374]  train_loss: 0.869  |  valid_loss: 0.666\n",
      "[epoch: 2, i: 11499]  train_loss: 0.920  |  valid_loss: 0.572\n",
      "[epoch: 2, i: 11624]  train_loss: 0.880  |  valid_loss: 0.770\n",
      "[epoch: 2, i: 11749]  train_loss: 0.955  |  valid_loss: 0.919\n",
      "[epoch: 2, i: 11874]  train_loss: 0.868  |  valid_loss: 0.663\n",
      "[epoch: 2, i: 11999]  train_loss: 0.816  |  valid_loss: 0.572\n",
      "[epoch: 2, i: 12124]  train_loss: 0.848  |  valid_loss: 0.559\n",
      "[epoch: 2, i: 12249]  train_loss: 0.899  |  valid_loss: 0.933\n",
      "[epoch: 2, i: 12374]  train_loss: 0.838  |  valid_loss: 0.706\n",
      "[epoch: 2, i: 12499]  train_loss: 0.892  |  valid_loss: 0.715\n",
      "--> [End of epoch 2] train_accuracy: 69.27%  |  valid_accuracy: 74.34%\n",
      "--> [Start of epoch 3]  lr: 0.000365\n",
      "[epoch: 3, i:   124]  train_loss: 0.832  |  valid_loss: 0.664\n",
      "[epoch: 3, i:   249]  train_loss: 0.889  |  valid_loss: 0.670\n",
      "[epoch: 3, i:   374]  train_loss: 0.853  |  valid_loss: 0.766\n",
      "[epoch: 3, i:   499]  train_loss: 0.837  |  valid_loss: 0.763\n",
      "[epoch: 3, i:   624]  train_loss: 0.845  |  valid_loss: 0.861\n",
      "[epoch: 3, i:   749]  train_loss: 0.884  |  valid_loss: 0.519\n",
      "[epoch: 3, i:   874]  train_loss: 0.826  |  valid_loss: 0.739\n",
      "[epoch: 3, i:   999]  train_loss: 0.871  |  valid_loss: 0.738\n",
      "[epoch: 3, i:  1124]  train_loss: 0.868  |  valid_loss: 0.802\n",
      "[epoch: 3, i:  1249]  train_loss: 0.832  |  valid_loss: 0.607\n",
      "[epoch: 3, i:  1374]  train_loss: 0.869  |  valid_loss: 0.622\n",
      "[epoch: 3, i:  1499]  train_loss: 0.901  |  valid_loss: 0.725\n",
      "[epoch: 3, i:  1624]  train_loss: 0.823  |  valid_loss: 0.610\n",
      "[epoch: 3, i:  1749]  train_loss: 0.844  |  valid_loss: 0.656\n",
      "[epoch: 3, i:  1874]  train_loss: 0.815  |  valid_loss: 0.652\n",
      "[epoch: 3, i:  1999]  train_loss: 0.822  |  valid_loss: 0.812\n",
      "[epoch: 3, i:  2124]  train_loss: 0.868  |  valid_loss: 0.702\n",
      "[epoch: 3, i:  2249]  train_loss: 0.834  |  valid_loss: 0.714\n",
      "[epoch: 3, i:  2374]  train_loss: 0.823  |  valid_loss: 0.661\n",
      "[epoch: 3, i:  2499]  train_loss: 0.841  |  valid_loss: 0.867\n",
      "[epoch: 3, i:  2624]  train_loss: 0.842  |  valid_loss: 0.741\n",
      "[epoch: 3, i:  2749]  train_loss: 0.901  |  valid_loss: 0.704\n",
      "[epoch: 3, i:  2874]  train_loss: 0.886  |  valid_loss: 0.749\n",
      "[epoch: 3, i:  2999]  train_loss: 0.831  |  valid_loss: 0.745\n",
      "[epoch: 3, i:  3124]  train_loss: 0.860  |  valid_loss: 0.711\n",
      "[epoch: 3, i:  3249]  train_loss: 0.826  |  valid_loss: 0.984\n",
      "[epoch: 3, i:  3374]  train_loss: 0.854  |  valid_loss: 0.586\n",
      "[epoch: 3, i:  3499]  train_loss: 0.899  |  valid_loss: 0.716\n",
      "[epoch: 3, i:  3624]  train_loss: 0.841  |  valid_loss: 0.729\n",
      "[epoch: 3, i:  3749]  train_loss: 0.878  |  valid_loss: 0.674\n",
      "[epoch: 3, i:  3874]  train_loss: 0.871  |  valid_loss: 0.669\n",
      "[epoch: 3, i:  3999]  train_loss: 0.842  |  valid_loss: 0.655\n",
      "[epoch: 3, i:  4124]  train_loss: 0.850  |  valid_loss: 0.650\n",
      "[epoch: 3, i:  4249]  train_loss: 0.821  |  valid_loss: 0.764\n",
      "[epoch: 3, i:  4374]  train_loss: 0.847  |  valid_loss: 0.830\n",
      "[epoch: 3, i:  4499]  train_loss: 0.828  |  valid_loss: 0.659\n",
      "[epoch: 3, i:  4624]  train_loss: 0.812  |  valid_loss: 0.846\n",
      "[epoch: 3, i:  4749]  train_loss: 0.890  |  valid_loss: 0.699\n",
      "[epoch: 3, i:  4874]  train_loss: 0.834  |  valid_loss: 0.588\n",
      "[epoch: 3, i:  4999]  train_loss: 0.845  |  valid_loss: 0.637\n",
      "[epoch: 3, i:  5124]  train_loss: 0.843  |  valid_loss: 0.645\n",
      "[epoch: 3, i:  5249]  train_loss: 0.891  |  valid_loss: 0.667\n",
      "[epoch: 3, i:  5374]  train_loss: 0.871  |  valid_loss: 0.527\n",
      "[epoch: 3, i:  5499]  train_loss: 0.867  |  valid_loss: 0.683\n",
      "[epoch: 3, i:  5624]  train_loss: 0.896  |  valid_loss: 0.617\n",
      "[epoch: 3, i:  5749]  train_loss: 0.803  |  valid_loss: 0.770\n",
      "[epoch: 3, i:  5874]  train_loss: 0.848  |  valid_loss: 0.607\n",
      "[epoch: 3, i:  5999]  train_loss: 0.812  |  valid_loss: 0.688\n",
      "[epoch: 3, i:  6124]  train_loss: 0.830  |  valid_loss: 0.607\n",
      "[epoch: 3, i:  6249]  train_loss: 0.786  |  valid_loss: 0.880\n",
      "[epoch: 3, i:  6374]  train_loss: 0.865  |  valid_loss: 0.639\n",
      "[epoch: 3, i:  6499]  train_loss: 0.783  |  valid_loss: 0.710\n",
      "[epoch: 3, i:  6624]  train_loss: 0.797  |  valid_loss: 0.582\n",
      "[epoch: 3, i:  6749]  train_loss: 0.870  |  valid_loss: 0.667\n",
      "[epoch: 3, i:  6874]  train_loss: 0.882  |  valid_loss: 0.716\n",
      "[epoch: 3, i:  6999]  train_loss: 0.897  |  valid_loss: 0.796\n",
      "[epoch: 3, i:  7124]  train_loss: 0.846  |  valid_loss: 0.825\n",
      "[epoch: 3, i:  7249]  train_loss: 0.858  |  valid_loss: 0.524\n",
      "[epoch: 3, i:  7374]  train_loss: 0.849  |  valid_loss: 0.830\n",
      "[epoch: 3, i:  7499]  train_loss: 0.825  |  valid_loss: 0.737\n",
      "[epoch: 3, i:  7624]  train_loss: 0.828  |  valid_loss: 0.646\n",
      "[epoch: 3, i:  7749]  train_loss: 0.829  |  valid_loss: 0.767\n",
      "[epoch: 3, i:  7874]  train_loss: 0.903  |  valid_loss: 0.606\n",
      "[epoch: 3, i:  7999]  train_loss: 0.786  |  valid_loss: 0.599\n",
      "[epoch: 3, i:  8124]  train_loss: 0.821  |  valid_loss: 0.682\n",
      "[epoch: 3, i:  8249]  train_loss: 0.846  |  valid_loss: 0.772\n",
      "[epoch: 3, i:  8374]  train_loss: 0.850  |  valid_loss: 0.690\n",
      "[epoch: 3, i:  8499]  train_loss: 0.857  |  valid_loss: 0.878\n",
      "[epoch: 3, i:  8624]  train_loss: 0.801  |  valid_loss: 0.651\n",
      "[epoch: 3, i:  8749]  train_loss: 0.831  |  valid_loss: 0.871\n",
      "[epoch: 3, i:  8874]  train_loss: 0.797  |  valid_loss: 0.667\n",
      "[epoch: 3, i:  8999]  train_loss: 0.826  |  valid_loss: 0.617\n",
      "[epoch: 3, i:  9124]  train_loss: 0.869  |  valid_loss: 0.662\n",
      "[epoch: 3, i:  9249]  train_loss: 0.834  |  valid_loss: 0.531\n",
      "[epoch: 3, i:  9374]  train_loss: 0.858  |  valid_loss: 0.688\n",
      "[epoch: 3, i:  9499]  train_loss: 0.826  |  valid_loss: 0.629\n",
      "[epoch: 3, i:  9624]  train_loss: 0.918  |  valid_loss: 0.724\n",
      "[epoch: 3, i:  9749]  train_loss: 0.853  |  valid_loss: 0.704\n",
      "[epoch: 3, i:  9874]  train_loss: 0.849  |  valid_loss: 0.770\n",
      "[epoch: 3, i:  9999]  train_loss: 0.828  |  valid_loss: 0.680\n",
      "[epoch: 3, i: 10124]  train_loss: 0.801  |  valid_loss: 0.554\n",
      "[epoch: 3, i: 10249]  train_loss: 0.823  |  valid_loss: 0.627\n",
      "[epoch: 3, i: 10374]  train_loss: 0.833  |  valid_loss: 0.612\n",
      "[epoch: 3, i: 10499]  train_loss: 0.809  |  valid_loss: 0.721\n",
      "[epoch: 3, i: 10624]  train_loss: 0.856  |  valid_loss: 0.756\n",
      "[epoch: 3, i: 10749]  train_loss: 0.869  |  valid_loss: 0.703\n",
      "[epoch: 3, i: 10874]  train_loss: 0.840  |  valid_loss: 0.754\n",
      "[epoch: 3, i: 10999]  train_loss: 0.773  |  valid_loss: 0.675\n",
      "[epoch: 3, i: 11124]  train_loss: 0.818  |  valid_loss: 0.750\n",
      "[epoch: 3, i: 11249]  train_loss: 0.877  |  valid_loss: 0.772\n",
      "[epoch: 3, i: 11374]  train_loss: 0.830  |  valid_loss: 0.662\n",
      "[epoch: 3, i: 11499]  train_loss: 0.774  |  valid_loss: 0.502\n",
      "[epoch: 3, i: 11624]  train_loss: 0.823  |  valid_loss: 0.748\n",
      "[epoch: 3, i: 11749]  train_loss: 0.849  |  valid_loss: 0.703\n",
      "[epoch: 3, i: 11874]  train_loss: 0.839  |  valid_loss: 0.669\n",
      "[epoch: 3, i: 11999]  train_loss: 0.800  |  valid_loss: 0.527\n",
      "[epoch: 3, i: 12124]  train_loss: 0.871  |  valid_loss: 0.478\n",
      "[epoch: 3, i: 12249]  train_loss: 0.744  |  valid_loss: 0.847\n",
      "[epoch: 3, i: 12374]  train_loss: 0.864  |  valid_loss: 0.651\n",
      "[epoch: 3, i: 12499]  train_loss: 0.819  |  valid_loss: 0.606\n",
      "--> [End of epoch 3] train_accuracy: 71.23%  |  valid_accuracy: 76.16%\n",
      "--> [Start of epoch 4]  lr: 0.000328\n",
      "[epoch: 4, i:   124]  train_loss: 0.743  |  valid_loss: 0.619\n",
      "[epoch: 4, i:   249]  train_loss: 0.804  |  valid_loss: 0.627\n",
      "[epoch: 4, i:   374]  train_loss: 0.795  |  valid_loss: 0.728\n",
      "[epoch: 4, i:   499]  train_loss: 0.786  |  valid_loss: 0.713\n",
      "[epoch: 4, i:   624]  train_loss: 0.823  |  valid_loss: 0.718\n",
      "[epoch: 4, i:   749]  train_loss: 0.879  |  valid_loss: 0.499\n",
      "[epoch: 4, i:   874]  train_loss: 0.812  |  valid_loss: 0.690\n",
      "[epoch: 4, i:   999]  train_loss: 0.793  |  valid_loss: 0.757\n",
      "[epoch: 4, i:  1124]  train_loss: 0.826  |  valid_loss: 0.789\n",
      "[epoch: 4, i:  1249]  train_loss: 0.790  |  valid_loss: 0.524\n",
      "[epoch: 4, i:  1374]  train_loss: 0.727  |  valid_loss: 0.666\n",
      "[epoch: 4, i:  1499]  train_loss: 0.761  |  valid_loss: 0.774\n",
      "[epoch: 4, i:  1624]  train_loss: 0.862  |  valid_loss: 0.643\n",
      "[epoch: 4, i:  1749]  train_loss: 0.738  |  valid_loss: 0.630\n",
      "[epoch: 4, i:  1874]  train_loss: 0.795  |  valid_loss: 0.598\n",
      "[epoch: 4, i:  1999]  train_loss: 0.772  |  valid_loss: 0.814\n",
      "[epoch: 4, i:  2124]  train_loss: 0.759  |  valid_loss: 0.664\n",
      "[epoch: 4, i:  2249]  train_loss: 0.765  |  valid_loss: 0.661\n",
      "[epoch: 4, i:  2374]  train_loss: 0.807  |  valid_loss: 0.649\n",
      "[epoch: 4, i:  2499]  train_loss: 0.797  |  valid_loss: 0.921\n",
      "[epoch: 4, i:  2624]  train_loss: 0.834  |  valid_loss: 0.708\n",
      "[epoch: 4, i:  2749]  train_loss: 0.791  |  valid_loss: 0.736\n",
      "[epoch: 4, i:  2874]  train_loss: 0.785  |  valid_loss: 0.748\n",
      "[epoch: 4, i:  2999]  train_loss: 0.894  |  valid_loss: 0.681\n",
      "[epoch: 4, i:  3124]  train_loss: 0.930  |  valid_loss: 0.710\n",
      "[epoch: 4, i:  3249]  train_loss: 0.828  |  valid_loss: 0.904\n",
      "[epoch: 4, i:  3374]  train_loss: 0.795  |  valid_loss: 0.577\n",
      "[epoch: 4, i:  3499]  train_loss: 0.794  |  valid_loss: 0.675\n",
      "[epoch: 4, i:  3624]  train_loss: 0.816  |  valid_loss: 0.706\n",
      "[epoch: 4, i:  3749]  train_loss: 0.838  |  valid_loss: 0.637\n",
      "[epoch: 4, i:  3874]  train_loss: 0.775  |  valid_loss: 0.708\n",
      "[epoch: 4, i:  3999]  train_loss: 0.773  |  valid_loss: 0.656\n",
      "[epoch: 4, i:  4124]  train_loss: 0.852  |  valid_loss: 0.580\n",
      "[epoch: 4, i:  4249]  train_loss: 0.826  |  valid_loss: 0.790\n",
      "[epoch: 4, i:  4374]  train_loss: 0.822  |  valid_loss: 0.812\n",
      "[epoch: 4, i:  4499]  train_loss: 0.800  |  valid_loss: 0.653\n",
      "[epoch: 4, i:  4624]  train_loss: 0.893  |  valid_loss: 0.824\n",
      "[epoch: 4, i:  4749]  train_loss: 0.822  |  valid_loss: 0.743\n",
      "[epoch: 4, i:  4874]  train_loss: 0.818  |  valid_loss: 0.606\n",
      "[epoch: 4, i:  4999]  train_loss: 0.785  |  valid_loss: 0.592\n",
      "[epoch: 4, i:  5124]  train_loss: 0.871  |  valid_loss: 0.621\n",
      "[epoch: 4, i:  5249]  train_loss: 0.841  |  valid_loss: 0.648\n",
      "[epoch: 4, i:  5374]  train_loss: 0.768  |  valid_loss: 0.488\n",
      "[epoch: 4, i:  5499]  train_loss: 0.783  |  valid_loss: 0.670\n",
      "[epoch: 4, i:  5624]  train_loss: 0.849  |  valid_loss: 0.686\n",
      "[epoch: 4, i:  5749]  train_loss: 0.809  |  valid_loss: 0.637\n",
      "[epoch: 4, i:  5874]  train_loss: 0.815  |  valid_loss: 0.564\n",
      "[epoch: 4, i:  5999]  train_loss: 0.770  |  valid_loss: 0.576\n",
      "[epoch: 4, i:  6124]  train_loss: 0.814  |  valid_loss: 0.513\n",
      "[epoch: 4, i:  6249]  train_loss: 0.876  |  valid_loss: 0.902\n",
      "[epoch: 4, i:  6374]  train_loss: 0.805  |  valid_loss: 0.611\n",
      "[epoch: 4, i:  6499]  train_loss: 0.828  |  valid_loss: 0.661\n",
      "[epoch: 4, i:  6624]  train_loss: 0.784  |  valid_loss: 0.564\n",
      "[epoch: 4, i:  6749]  train_loss: 0.789  |  valid_loss: 0.668\n",
      "[epoch: 4, i:  6874]  train_loss: 0.753  |  valid_loss: 0.741\n",
      "[epoch: 4, i:  6999]  train_loss: 0.772  |  valid_loss: 0.697\n",
      "[epoch: 4, i:  7124]  train_loss: 0.833  |  valid_loss: 0.733\n",
      "[epoch: 4, i:  7249]  train_loss: 0.835  |  valid_loss: 0.518\n",
      "[epoch: 4, i:  7374]  train_loss: 0.772  |  valid_loss: 0.713\n",
      "[epoch: 4, i:  7499]  train_loss: 0.790  |  valid_loss: 0.742\n",
      "[epoch: 4, i:  7624]  train_loss: 0.859  |  valid_loss: 0.627\n",
      "[epoch: 4, i:  7749]  train_loss: 0.789  |  valid_loss: 0.669\n",
      "[epoch: 4, i:  7874]  train_loss: 0.781  |  valid_loss: 0.607\n",
      "[epoch: 4, i:  7999]  train_loss: 0.790  |  valid_loss: 0.610\n",
      "[epoch: 4, i:  8124]  train_loss: 0.839  |  valid_loss: 0.655\n",
      "[epoch: 4, i:  8249]  train_loss: 0.781  |  valid_loss: 0.739\n",
      "[epoch: 4, i:  8374]  train_loss: 0.794  |  valid_loss: 0.691\n",
      "[epoch: 4, i:  8499]  train_loss: 0.823  |  valid_loss: 0.804\n",
      "[epoch: 4, i:  8624]  train_loss: 0.853  |  valid_loss: 0.552\n",
      "[epoch: 4, i:  8749]  train_loss: 0.803  |  valid_loss: 0.816\n",
      "[epoch: 4, i:  8874]  train_loss: 0.809  |  valid_loss: 0.593\n",
      "[epoch: 4, i:  8999]  train_loss: 0.834  |  valid_loss: 0.588\n",
      "[epoch: 4, i:  9124]  train_loss: 0.788  |  valid_loss: 0.591\n",
      "[epoch: 4, i:  9249]  train_loss: 0.844  |  valid_loss: 0.543\n",
      "[epoch: 4, i:  9374]  train_loss: 0.800  |  valid_loss: 0.651\n",
      "[epoch: 4, i:  9499]  train_loss: 0.773  |  valid_loss: 0.604\n",
      "[epoch: 4, i:  9624]  train_loss: 0.780  |  valid_loss: 0.667\n",
      "[epoch: 4, i:  9749]  train_loss: 0.831  |  valid_loss: 0.714\n",
      "[epoch: 4, i:  9874]  train_loss: 0.843  |  valid_loss: 0.729\n",
      "[epoch: 4, i:  9999]  train_loss: 0.846  |  valid_loss: 0.637\n",
      "[epoch: 4, i: 10124]  train_loss: 0.863  |  valid_loss: 0.592\n",
      "[epoch: 4, i: 10249]  train_loss: 0.689  |  valid_loss: 0.573\n",
      "[epoch: 4, i: 10374]  train_loss: 0.805  |  valid_loss: 0.613\n",
      "[epoch: 4, i: 10499]  train_loss: 0.783  |  valid_loss: 0.707\n",
      "[epoch: 4, i: 10624]  train_loss: 0.767  |  valid_loss: 0.653\n",
      "[epoch: 4, i: 10749]  train_loss: 0.800  |  valid_loss: 0.606\n",
      "[epoch: 4, i: 10874]  train_loss: 0.806  |  valid_loss: 0.678\n",
      "[epoch: 4, i: 10999]  train_loss: 0.810  |  valid_loss: 0.664\n",
      "[epoch: 4, i: 11124]  train_loss: 0.825  |  valid_loss: 0.721\n",
      "[epoch: 4, i: 11249]  train_loss: 0.815  |  valid_loss: 0.694\n",
      "[epoch: 4, i: 11374]  train_loss: 0.852  |  valid_loss: 0.596\n",
      "[epoch: 4, i: 11499]  train_loss: 0.789  |  valid_loss: 0.487\n",
      "[epoch: 4, i: 11624]  train_loss: 0.747  |  valid_loss: 0.713\n",
      "[epoch: 4, i: 11749]  train_loss: 0.826  |  valid_loss: 0.691\n",
      "[epoch: 4, i: 11874]  train_loss: 0.822  |  valid_loss: 0.669\n",
      "[epoch: 4, i: 11999]  train_loss: 0.718  |  valid_loss: 0.601\n",
      "[epoch: 4, i: 12124]  train_loss: 0.752  |  valid_loss: 0.459\n",
      "[epoch: 4, i: 12249]  train_loss: 0.765  |  valid_loss: 0.820\n",
      "[epoch: 4, i: 12374]  train_loss: 0.864  |  valid_loss: 0.651\n",
      "[epoch: 4, i: 12499]  train_loss: 0.742  |  valid_loss: 0.596\n",
      "--> [End of epoch 4] train_accuracy: 72.42%  |  valid_accuracy: 77.16%\n",
      "--> [Start of epoch 5]  lr: 0.000295\n",
      "[epoch: 5, i:   124]  train_loss: 0.748  |  valid_loss: 0.643\n",
      "[epoch: 5, i:   249]  train_loss: 0.793  |  valid_loss: 0.607\n",
      "[epoch: 5, i:   374]  train_loss: 0.772  |  valid_loss: 0.664\n",
      "[epoch: 5, i:   499]  train_loss: 0.707  |  valid_loss: 0.735\n",
      "[epoch: 5, i:   624]  train_loss: 0.758  |  valid_loss: 0.744\n",
      "[epoch: 5, i:   749]  train_loss: 0.786  |  valid_loss: 0.509\n",
      "[epoch: 5, i:   874]  train_loss: 0.770  |  valid_loss: 0.581\n",
      "[epoch: 5, i:   999]  train_loss: 0.807  |  valid_loss: 0.698\n",
      "[epoch: 5, i:  1124]  train_loss: 0.781  |  valid_loss: 0.719\n",
      "[epoch: 5, i:  1249]  train_loss: 0.731  |  valid_loss: 0.492\n",
      "[epoch: 5, i:  1374]  train_loss: 0.769  |  valid_loss: 0.576\n",
      "[epoch: 5, i:  1499]  train_loss: 0.712  |  valid_loss: 0.706\n",
      "[epoch: 5, i:  1624]  train_loss: 0.794  |  valid_loss: 0.546\n",
      "[epoch: 5, i:  1749]  train_loss: 0.822  |  valid_loss: 0.651\n",
      "[epoch: 5, i:  1874]  train_loss: 0.854  |  valid_loss: 0.606\n",
      "[epoch: 5, i:  1999]  train_loss: 0.803  |  valid_loss: 0.708\n",
      "[epoch: 5, i:  2124]  train_loss: 0.821  |  valid_loss: 0.612\n",
      "[epoch: 5, i:  2249]  train_loss: 0.758  |  valid_loss: 0.676\n",
      "[epoch: 5, i:  2374]  train_loss: 0.777  |  valid_loss: 0.632\n",
      "[epoch: 5, i:  2499]  train_loss: 0.759  |  valid_loss: 0.908\n",
      "[epoch: 5, i:  2624]  train_loss: 0.726  |  valid_loss: 0.751\n",
      "[epoch: 5, i:  2749]  train_loss: 0.802  |  valid_loss: 0.643\n",
      "[epoch: 5, i:  2874]  train_loss: 0.832  |  valid_loss: 0.735\n",
      "[epoch: 5, i:  2999]  train_loss: 0.800  |  valid_loss: 0.663\n",
      "[epoch: 5, i:  3124]  train_loss: 0.757  |  valid_loss: 0.655\n",
      "[epoch: 5, i:  3249]  train_loss: 0.762  |  valid_loss: 0.967\n",
      "[epoch: 5, i:  3374]  train_loss: 0.741  |  valid_loss: 0.535\n",
      "[epoch: 5, i:  3499]  train_loss: 0.792  |  valid_loss: 0.649\n",
      "[epoch: 5, i:  3624]  train_loss: 0.740  |  valid_loss: 0.722\n",
      "[epoch: 5, i:  3749]  train_loss: 0.755  |  valid_loss: 0.719\n",
      "[epoch: 5, i:  3874]  train_loss: 0.815  |  valid_loss: 0.663\n",
      "[epoch: 5, i:  3999]  train_loss: 0.742  |  valid_loss: 0.658\n",
      "[epoch: 5, i:  4124]  train_loss: 0.738  |  valid_loss: 0.603\n",
      "[epoch: 5, i:  4249]  train_loss: 0.764  |  valid_loss: 0.690\n",
      "[epoch: 5, i:  4374]  train_loss: 0.807  |  valid_loss: 0.745\n",
      "[epoch: 5, i:  4499]  train_loss: 0.773  |  valid_loss: 0.611\n",
      "[epoch: 5, i:  4624]  train_loss: 0.671  |  valid_loss: 0.807\n",
      "[epoch: 5, i:  4749]  train_loss: 0.727  |  valid_loss: 0.680\n",
      "[epoch: 5, i:  4874]  train_loss: 0.788  |  valid_loss: 0.505\n",
      "[epoch: 5, i:  4999]  train_loss: 0.768  |  valid_loss: 0.550\n",
      "[epoch: 5, i:  5124]  train_loss: 0.768  |  valid_loss: 0.613\n",
      "[epoch: 5, i:  5249]  train_loss: 0.792  |  valid_loss: 0.642\n",
      "[epoch: 5, i:  5374]  train_loss: 0.813  |  valid_loss: 0.482\n",
      "[epoch: 5, i:  5499]  train_loss: 0.766  |  valid_loss: 0.646\n",
      "[epoch: 5, i:  5624]  train_loss: 0.719  |  valid_loss: 0.711\n",
      "[epoch: 5, i:  5749]  train_loss: 0.762  |  valid_loss: 0.612\n",
      "[epoch: 5, i:  5874]  train_loss: 0.752  |  valid_loss: 0.535\n",
      "[epoch: 5, i:  5999]  train_loss: 0.796  |  valid_loss: 0.655\n",
      "[epoch: 5, i:  6124]  train_loss: 0.780  |  valid_loss: 0.529\n",
      "[epoch: 5, i:  6249]  train_loss: 0.821  |  valid_loss: 0.769\n",
      "[epoch: 5, i:  6374]  train_loss: 0.765  |  valid_loss: 0.625\n",
      "[epoch: 5, i:  6499]  train_loss: 0.749  |  valid_loss: 0.665\n",
      "[epoch: 5, i:  6624]  train_loss: 0.719  |  valid_loss: 0.536\n",
      "[epoch: 5, i:  6749]  train_loss: 0.845  |  valid_loss: 0.616\n",
      "[epoch: 5, i:  6874]  train_loss: 0.724  |  valid_loss: 0.678\n",
      "[epoch: 5, i:  6999]  train_loss: 0.812  |  valid_loss: 0.754\n",
      "[epoch: 5, i:  7124]  train_loss: 0.753  |  valid_loss: 0.684\n",
      "[epoch: 5, i:  7249]  train_loss: 0.786  |  valid_loss: 0.487\n",
      "[epoch: 5, i:  7374]  train_loss: 0.819  |  valid_loss: 0.755\n",
      "[epoch: 5, i:  7499]  train_loss: 0.816  |  valid_loss: 0.675\n",
      "[epoch: 5, i:  7624]  train_loss: 0.825  |  valid_loss: 0.638\n",
      "[epoch: 5, i:  7749]  train_loss: 0.799  |  valid_loss: 0.638\n",
      "[epoch: 5, i:  7874]  train_loss: 0.834  |  valid_loss: 0.590\n",
      "[epoch: 5, i:  7999]  train_loss: 0.744  |  valid_loss: 0.541\n",
      "[epoch: 5, i:  8124]  train_loss: 0.727  |  valid_loss: 0.632\n",
      "[epoch: 5, i:  8249]  train_loss: 0.776  |  valid_loss: 0.625\n",
      "[epoch: 5, i:  8374]  train_loss: 0.736  |  valid_loss: 0.652\n",
      "[epoch: 5, i:  8499]  train_loss: 0.820  |  valid_loss: 0.744\n",
      "[epoch: 5, i:  8624]  train_loss: 0.782  |  valid_loss: 0.611\n",
      "[epoch: 5, i:  8749]  train_loss: 0.787  |  valid_loss: 0.789\n",
      "[epoch: 5, i:  8874]  train_loss: 0.822  |  valid_loss: 0.588\n",
      "[epoch: 5, i:  8999]  train_loss: 0.827  |  valid_loss: 0.487\n",
      "[epoch: 5, i:  9124]  train_loss: 0.708  |  valid_loss: 0.536\n",
      "[epoch: 5, i:  9249]  train_loss: 0.821  |  valid_loss: 0.488\n",
      "[epoch: 5, i:  9374]  train_loss: 0.791  |  valid_loss: 0.632\n",
      "[epoch: 5, i:  9499]  train_loss: 0.841  |  valid_loss: 0.582\n",
      "[epoch: 5, i:  9624]  train_loss: 0.711  |  valid_loss: 0.632\n",
      "[epoch: 5, i:  9749]  train_loss: 0.795  |  valid_loss: 0.700\n",
      "[epoch: 5, i:  9874]  train_loss: 0.730  |  valid_loss: 0.740\n",
      "[epoch: 5, i:  9999]  train_loss: 0.766  |  valid_loss: 0.680\n",
      "[epoch: 5, i: 10124]  train_loss: 0.792  |  valid_loss: 0.492\n",
      "[epoch: 5, i: 10249]  train_loss: 0.756  |  valid_loss: 0.529\n",
      "[epoch: 5, i: 10374]  train_loss: 0.745  |  valid_loss: 0.577\n",
      "[epoch: 5, i: 10499]  train_loss: 0.754  |  valid_loss: 0.696\n",
      "[epoch: 5, i: 10624]  train_loss: 0.763  |  valid_loss: 0.664\n",
      "[epoch: 5, i: 10749]  train_loss: 0.781  |  valid_loss: 0.640\n",
      "[epoch: 5, i: 10874]  train_loss: 0.833  |  valid_loss: 0.686\n",
      "[epoch: 5, i: 10999]  train_loss: 0.731  |  valid_loss: 0.597\n",
      "[epoch: 5, i: 11124]  train_loss: 0.740  |  valid_loss: 0.764\n",
      "[epoch: 5, i: 11249]  train_loss: 0.771  |  valid_loss: 0.681\n",
      "[epoch: 5, i: 11374]  train_loss: 0.682  |  valid_loss: 0.587\n",
      "[epoch: 5, i: 11499]  train_loss: 0.753  |  valid_loss: 0.445\n",
      "[epoch: 5, i: 11624]  train_loss: 0.791  |  valid_loss: 0.638\n",
      "[epoch: 5, i: 11749]  train_loss: 0.778  |  valid_loss: 0.722\n",
      "[epoch: 5, i: 11874]  train_loss: 0.770  |  valid_loss: 0.644\n",
      "[epoch: 5, i: 11999]  train_loss: 0.804  |  valid_loss: 0.532\n",
      "[epoch: 5, i: 12124]  train_loss: 0.734  |  valid_loss: 0.483\n",
      "[epoch: 5, i: 12249]  train_loss: 0.747  |  valid_loss: 0.766\n",
      "[epoch: 5, i: 12374]  train_loss: 0.770  |  valid_loss: 0.626\n",
      "[epoch: 5, i: 12499]  train_loss: 0.754  |  valid_loss: 0.589\n",
      "--> [End of epoch 5] train_accuracy: 73.60%  |  valid_accuracy: 77.61%\n",
      "--> [Start of epoch 6]  lr: 0.000266\n",
      "[epoch: 6, i:   124]  train_loss: 0.725  |  valid_loss: 0.585\n",
      "[epoch: 6, i:   249]  train_loss: 0.752  |  valid_loss: 0.608\n",
      "[epoch: 6, i:   374]  train_loss: 0.739  |  valid_loss: 0.660\n",
      "[epoch: 6, i:   499]  train_loss: 0.769  |  valid_loss: 0.712\n",
      "[epoch: 6, i:   624]  train_loss: 0.749  |  valid_loss: 0.686\n",
      "[epoch: 6, i:   749]  train_loss: 0.781  |  valid_loss: 0.499\n",
      "[epoch: 6, i:   874]  train_loss: 0.761  |  valid_loss: 0.592\n",
      "[epoch: 6, i:   999]  train_loss: 0.717  |  valid_loss: 0.642\n",
      "[epoch: 6, i:  1124]  train_loss: 0.697  |  valid_loss: 0.726\n",
      "[epoch: 6, i:  1249]  train_loss: 0.801  |  valid_loss: 0.486\n",
      "[epoch: 6, i:  1374]  train_loss: 0.690  |  valid_loss: 0.592\n",
      "[epoch: 6, i:  1499]  train_loss: 0.781  |  valid_loss: 0.669\n",
      "[epoch: 6, i:  1624]  train_loss: 0.760  |  valid_loss: 0.619\n",
      "[epoch: 6, i:  1749]  train_loss: 0.736  |  valid_loss: 0.585\n",
      "[epoch: 6, i:  1874]  train_loss: 0.768  |  valid_loss: 0.547\n",
      "[epoch: 6, i:  1999]  train_loss: 0.754  |  valid_loss: 0.683\n",
      "[epoch: 6, i:  2124]  train_loss: 0.743  |  valid_loss: 0.593\n",
      "[epoch: 6, i:  2249]  train_loss: 0.758  |  valid_loss: 0.704\n",
      "[epoch: 6, i:  2374]  train_loss: 0.725  |  valid_loss: 0.564\n",
      "[epoch: 6, i:  2499]  train_loss: 0.778  |  valid_loss: 0.801\n",
      "[epoch: 6, i:  2624]  train_loss: 0.792  |  valid_loss: 0.779\n",
      "[epoch: 6, i:  2749]  train_loss: 0.749  |  valid_loss: 0.639\n",
      "[epoch: 6, i:  2874]  train_loss: 0.800  |  valid_loss: 0.727\n",
      "[epoch: 6, i:  2999]  train_loss: 0.798  |  valid_loss: 0.705\n",
      "[epoch: 6, i:  3124]  train_loss: 0.748  |  valid_loss: 0.642\n",
      "[epoch: 6, i:  3249]  train_loss: 0.724  |  valid_loss: 0.968\n",
      "[epoch: 6, i:  3374]  train_loss: 0.753  |  valid_loss: 0.522\n",
      "[epoch: 6, i:  3499]  train_loss: 0.734  |  valid_loss: 0.597\n",
      "[epoch: 6, i:  3624]  train_loss: 0.760  |  valid_loss: 0.635\n",
      "[epoch: 6, i:  3749]  train_loss: 0.752  |  valid_loss: 0.622\n",
      "[epoch: 6, i:  3874]  train_loss: 0.796  |  valid_loss: 0.633\n",
      "[epoch: 6, i:  3999]  train_loss: 0.714  |  valid_loss: 0.666\n",
      "[epoch: 6, i:  4124]  train_loss: 0.761  |  valid_loss: 0.516\n",
      "[epoch: 6, i:  4249]  train_loss: 0.837  |  valid_loss: 0.726\n",
      "[epoch: 6, i:  4374]  train_loss: 0.766  |  valid_loss: 0.746\n",
      "[epoch: 6, i:  4499]  train_loss: 0.717  |  valid_loss: 0.598\n",
      "[epoch: 6, i:  4624]  train_loss: 0.804  |  valid_loss: 0.781\n",
      "[epoch: 6, i:  4749]  train_loss: 0.781  |  valid_loss: 0.676\n",
      "[epoch: 6, i:  4874]  train_loss: 0.717  |  valid_loss: 0.547\n",
      "[epoch: 6, i:  4999]  train_loss: 0.732  |  valid_loss: 0.540\n",
      "[epoch: 6, i:  5124]  train_loss: 0.745  |  valid_loss: 0.628\n",
      "[epoch: 6, i:  5249]  train_loss: 0.798  |  valid_loss: 0.592\n",
      "[epoch: 6, i:  5374]  train_loss: 0.729  |  valid_loss: 0.432\n",
      "[epoch: 6, i:  5499]  train_loss: 0.832  |  valid_loss: 0.618\n",
      "[epoch: 6, i:  5624]  train_loss: 0.757  |  valid_loss: 0.707\n",
      "[epoch: 6, i:  5749]  train_loss: 0.712  |  valid_loss: 0.621\n",
      "[epoch: 6, i:  5874]  train_loss: 0.825  |  valid_loss: 0.503\n",
      "[epoch: 6, i:  5999]  train_loss: 0.799  |  valid_loss: 0.628\n",
      "[epoch: 6, i:  6124]  train_loss: 0.735  |  valid_loss: 0.559\n",
      "[epoch: 6, i:  6249]  train_loss: 0.706  |  valid_loss: 0.857\n",
      "[epoch: 6, i:  6374]  train_loss: 0.736  |  valid_loss: 0.557\n",
      "[epoch: 6, i:  6499]  train_loss: 0.764  |  valid_loss: 0.652\n",
      "[epoch: 6, i:  6624]  train_loss: 0.752  |  valid_loss: 0.569\n",
      "[epoch: 6, i:  6749]  train_loss: 0.734  |  valid_loss: 0.590\n",
      "[epoch: 6, i:  6874]  train_loss: 0.728  |  valid_loss: 0.690\n",
      "[epoch: 6, i:  6999]  train_loss: 0.741  |  valid_loss: 0.690\n",
      "[epoch: 6, i:  7124]  train_loss: 0.814  |  valid_loss: 0.746\n",
      "[epoch: 6, i:  7249]  train_loss: 0.735  |  valid_loss: 0.479\n",
      "[epoch: 6, i:  7374]  train_loss: 0.757  |  valid_loss: 0.667\n",
      "[epoch: 6, i:  7499]  train_loss: 0.766  |  valid_loss: 0.629\n",
      "[epoch: 6, i:  7624]  train_loss: 0.772  |  valid_loss: 0.522\n",
      "[epoch: 6, i:  7749]  train_loss: 0.748  |  valid_loss: 0.672\n",
      "[epoch: 6, i:  7874]  train_loss: 0.701  |  valid_loss: 0.537\n",
      "[epoch: 6, i:  7999]  train_loss: 0.750  |  valid_loss: 0.506\n",
      "[epoch: 6, i:  8124]  train_loss: 0.801  |  valid_loss: 0.601\n",
      "[epoch: 6, i:  8249]  train_loss: 0.749  |  valid_loss: 0.623\n",
      "[epoch: 6, i:  8374]  train_loss: 0.700  |  valid_loss: 0.646\n",
      "[epoch: 6, i:  8499]  train_loss: 0.744  |  valid_loss: 0.747\n",
      "[epoch: 6, i:  8624]  train_loss: 0.736  |  valid_loss: 0.605\n",
      "[epoch: 6, i:  8749]  train_loss: 0.755  |  valid_loss: 0.802\n",
      "[epoch: 6, i:  8874]  train_loss: 0.765  |  valid_loss: 0.580\n",
      "[epoch: 6, i:  8999]  train_loss: 0.694  |  valid_loss: 0.501\n",
      "[epoch: 6, i:  9124]  train_loss: 0.693  |  valid_loss: 0.563\n",
      "[epoch: 6, i:  9249]  train_loss: 0.782  |  valid_loss: 0.490\n",
      "[epoch: 6, i:  9374]  train_loss: 0.721  |  valid_loss: 0.577\n",
      "[epoch: 6, i:  9499]  train_loss: 0.711  |  valid_loss: 0.515\n",
      "[epoch: 6, i:  9624]  train_loss: 0.756  |  valid_loss: 0.660\n",
      "[epoch: 6, i:  9749]  train_loss: 0.786  |  valid_loss: 0.644\n",
      "[epoch: 6, i:  9874]  train_loss: 0.723  |  valid_loss: 0.666\n",
      "[epoch: 6, i:  9999]  train_loss: 0.754  |  valid_loss: 0.647\n",
      "[epoch: 6, i: 10124]  train_loss: 0.785  |  valid_loss: 0.497\n",
      "[epoch: 6, i: 10249]  train_loss: 0.759  |  valid_loss: 0.519\n",
      "[epoch: 6, i: 10374]  train_loss: 0.759  |  valid_loss: 0.579\n",
      "[epoch: 6, i: 10499]  train_loss: 0.771  |  valid_loss: 0.692\n",
      "[epoch: 6, i: 10624]  train_loss: 0.701  |  valid_loss: 0.749\n",
      "[epoch: 6, i: 10749]  train_loss: 0.762  |  valid_loss: 0.615\n",
      "[epoch: 6, i: 10874]  train_loss: 0.765  |  valid_loss: 0.670\n",
      "[epoch: 6, i: 10999]  train_loss: 0.753  |  valid_loss: 0.593\n",
      "[epoch: 6, i: 11124]  train_loss: 0.747  |  valid_loss: 0.706\n",
      "[epoch: 6, i: 11249]  train_loss: 0.761  |  valid_loss: 0.657\n",
      "[epoch: 6, i: 11374]  train_loss: 0.784  |  valid_loss: 0.592\n",
      "[epoch: 6, i: 11499]  train_loss: 0.788  |  valid_loss: 0.418\n",
      "[epoch: 6, i: 11624]  train_loss: 0.793  |  valid_loss: 0.675\n",
      "[epoch: 6, i: 11749]  train_loss: 0.747  |  valid_loss: 0.695\n",
      "[epoch: 6, i: 11874]  train_loss: 0.772  |  valid_loss: 0.593\n",
      "[epoch: 6, i: 11999]  train_loss: 0.784  |  valid_loss: 0.497\n",
      "[epoch: 6, i: 12124]  train_loss: 0.776  |  valid_loss: 0.496\n",
      "[epoch: 6, i: 12249]  train_loss: 0.735  |  valid_loss: 0.739\n",
      "[epoch: 6, i: 12374]  train_loss: 0.795  |  valid_loss: 0.597\n",
      "[epoch: 6, i: 12499]  train_loss: 0.810  |  valid_loss: 0.584\n",
      "--> [End of epoch 6] train_accuracy: 73.99%  |  valid_accuracy: 78.29%\n",
      "--> [Start of epoch 7]  lr: 0.000239\n",
      "[epoch: 7, i:   124]  train_loss: 0.750  |  valid_loss: 0.632\n",
      "[epoch: 7, i:   249]  train_loss: 0.732  |  valid_loss: 0.597\n",
      "[epoch: 7, i:   374]  train_loss: 0.705  |  valid_loss: 0.673\n",
      "[epoch: 7, i:   499]  train_loss: 0.690  |  valid_loss: 0.609\n",
      "[epoch: 7, i:   624]  train_loss: 0.709  |  valid_loss: 0.678\n",
      "[epoch: 7, i:   749]  train_loss: 0.763  |  valid_loss: 0.433\n",
      "[epoch: 7, i:   874]  train_loss: 0.716  |  valid_loss: 0.614\n",
      "[epoch: 7, i:   999]  train_loss: 0.770  |  valid_loss: 0.674\n",
      "[epoch: 7, i:  1124]  train_loss: 0.789  |  valid_loss: 0.640\n",
      "[epoch: 7, i:  1249]  train_loss: 0.738  |  valid_loss: 0.525\n",
      "[epoch: 7, i:  1374]  train_loss: 0.721  |  valid_loss: 0.589\n",
      "[epoch: 7, i:  1499]  train_loss: 0.753  |  valid_loss: 0.700\n",
      "[epoch: 7, i:  1624]  train_loss: 0.763  |  valid_loss: 0.540\n",
      "[epoch: 7, i:  1749]  train_loss: 0.732  |  valid_loss: 0.659\n",
      "[epoch: 7, i:  1874]  train_loss: 0.709  |  valid_loss: 0.529\n",
      "[epoch: 7, i:  1999]  train_loss: 0.747  |  valid_loss: 0.670\n",
      "[epoch: 7, i:  2124]  train_loss: 0.786  |  valid_loss: 0.665\n",
      "[epoch: 7, i:  2249]  train_loss: 0.697  |  valid_loss: 0.660\n",
      "[epoch: 7, i:  2374]  train_loss: 0.704  |  valid_loss: 0.610\n",
      "[epoch: 7, i:  2499]  train_loss: 0.789  |  valid_loss: 0.864\n",
      "[epoch: 7, i:  2624]  train_loss: 0.756  |  valid_loss: 0.698\n",
      "[epoch: 7, i:  2749]  train_loss: 0.731  |  valid_loss: 0.594\n",
      "[epoch: 7, i:  2874]  train_loss: 0.728  |  valid_loss: 0.689\n",
      "[epoch: 7, i:  2999]  train_loss: 0.694  |  valid_loss: 0.646\n",
      "[epoch: 7, i:  3124]  train_loss: 0.708  |  valid_loss: 0.673\n",
      "[epoch: 7, i:  3249]  train_loss: 0.734  |  valid_loss: 0.980\n",
      "[epoch: 7, i:  3374]  train_loss: 0.767  |  valid_loss: 0.584\n",
      "[epoch: 7, i:  3499]  train_loss: 0.728  |  valid_loss: 0.615\n",
      "[epoch: 7, i:  3624]  train_loss: 0.758  |  valid_loss: 0.632\n",
      "[epoch: 7, i:  3749]  train_loss: 0.726  |  valid_loss: 0.635\n",
      "[epoch: 7, i:  3874]  train_loss: 0.723  |  valid_loss: 0.607\n",
      "[epoch: 7, i:  3999]  train_loss: 0.722  |  valid_loss: 0.603\n",
      "[epoch: 7, i:  4124]  train_loss: 0.718  |  valid_loss: 0.651\n",
      "[epoch: 7, i:  4249]  train_loss: 0.792  |  valid_loss: 0.677\n",
      "[epoch: 7, i:  4374]  train_loss: 0.698  |  valid_loss: 0.722\n",
      "[epoch: 7, i:  4499]  train_loss: 0.774  |  valid_loss: 0.569\n",
      "[epoch: 7, i:  4624]  train_loss: 0.761  |  valid_loss: 0.835\n",
      "[epoch: 7, i:  4749]  train_loss: 0.737  |  valid_loss: 0.596\n",
      "[epoch: 7, i:  4874]  train_loss: 0.754  |  valid_loss: 0.485\n",
      "[epoch: 7, i:  4999]  train_loss: 0.742  |  valid_loss: 0.474\n",
      "[epoch: 7, i:  5124]  train_loss: 0.695  |  valid_loss: 0.586\n",
      "[epoch: 7, i:  5249]  train_loss: 0.726  |  valid_loss: 0.580\n",
      "[epoch: 7, i:  5374]  train_loss: 0.706  |  valid_loss: 0.468\n",
      "[epoch: 7, i:  5499]  train_loss: 0.771  |  valid_loss: 0.594\n",
      "[epoch: 7, i:  5624]  train_loss: 0.719  |  valid_loss: 0.619\n",
      "[epoch: 7, i:  5749]  train_loss: 0.687  |  valid_loss: 0.595\n",
      "[epoch: 7, i:  5874]  train_loss: 0.772  |  valid_loss: 0.455\n",
      "[epoch: 7, i:  5999]  train_loss: 0.708  |  valid_loss: 0.602\n",
      "[epoch: 7, i:  6124]  train_loss: 0.698  |  valid_loss: 0.509\n",
      "[epoch: 7, i:  6249]  train_loss: 0.746  |  valid_loss: 0.862\n",
      "[epoch: 7, i:  6374]  train_loss: 0.815  |  valid_loss: 0.552\n",
      "[epoch: 7, i:  6499]  train_loss: 0.782  |  valid_loss: 0.637\n",
      "[epoch: 7, i:  6624]  train_loss: 0.727  |  valid_loss: 0.588\n",
      "[epoch: 7, i:  6749]  train_loss: 0.724  |  valid_loss: 0.610\n",
      "[epoch: 7, i:  6874]  train_loss: 0.798  |  valid_loss: 0.683\n",
      "[epoch: 7, i:  6999]  train_loss: 0.736  |  valid_loss: 0.723\n",
      "[epoch: 7, i:  7124]  train_loss: 0.709  |  valid_loss: 0.752\n",
      "[epoch: 7, i:  7249]  train_loss: 0.753  |  valid_loss: 0.492\n",
      "[epoch: 7, i:  7374]  train_loss: 0.760  |  valid_loss: 0.703\n",
      "[epoch: 7, i:  7499]  train_loss: 0.728  |  valid_loss: 0.601\n",
      "[epoch: 7, i:  7624]  train_loss: 0.717  |  valid_loss: 0.542\n",
      "[epoch: 7, i:  7749]  train_loss: 0.809  |  valid_loss: 0.636\n",
      "[epoch: 7, i:  7874]  train_loss: 0.764  |  valid_loss: 0.548\n",
      "[epoch: 7, i:  7999]  train_loss: 0.687  |  valid_loss: 0.554\n",
      "[epoch: 7, i:  8124]  train_loss: 0.737  |  valid_loss: 0.571\n",
      "[epoch: 7, i:  8249]  train_loss: 0.742  |  valid_loss: 0.678\n",
      "[epoch: 7, i:  8374]  train_loss: 0.664  |  valid_loss: 0.602\n",
      "[epoch: 7, i:  8499]  train_loss: 0.697  |  valid_loss: 0.695\n",
      "[epoch: 7, i:  8624]  train_loss: 0.707  |  valid_loss: 0.530\n",
      "[epoch: 7, i:  8749]  train_loss: 0.768  |  valid_loss: 0.838\n",
      "[epoch: 7, i:  8874]  train_loss: 0.767  |  valid_loss: 0.623\n",
      "[epoch: 7, i:  8999]  train_loss: 0.687  |  valid_loss: 0.544\n",
      "[epoch: 7, i:  9124]  train_loss: 0.731  |  valid_loss: 0.521\n",
      "[epoch: 7, i:  9249]  train_loss: 0.757  |  valid_loss: 0.452\n",
      "[epoch: 7, i:  9374]  train_loss: 0.666  |  valid_loss: 0.606\n",
      "[epoch: 7, i:  9499]  train_loss: 0.767  |  valid_loss: 0.556\n",
      "[epoch: 7, i:  9624]  train_loss: 0.750  |  valid_loss: 0.615\n",
      "[epoch: 7, i:  9749]  train_loss: 0.783  |  valid_loss: 0.658\n",
      "[epoch: 7, i:  9874]  train_loss: 0.736  |  valid_loss: 0.654\n",
      "[epoch: 7, i:  9999]  train_loss: 0.684  |  valid_loss: 0.648\n",
      "[epoch: 7, i: 10124]  train_loss: 0.744  |  valid_loss: 0.496\n",
      "[epoch: 7, i: 10249]  train_loss: 0.723  |  valid_loss: 0.518\n",
      "[epoch: 7, i: 10374]  train_loss: 0.716  |  valid_loss: 0.594\n",
      "[epoch: 7, i: 10499]  train_loss: 0.665  |  valid_loss: 0.576\n",
      "[epoch: 7, i: 10624]  train_loss: 0.722  |  valid_loss: 0.667\n",
      "[epoch: 7, i: 10749]  train_loss: 0.722  |  valid_loss: 0.606\n",
      "[epoch: 7, i: 10874]  train_loss: 0.735  |  valid_loss: 0.687\n",
      "[epoch: 7, i: 10999]  train_loss: 0.810  |  valid_loss: 0.629\n",
      "[epoch: 7, i: 11124]  train_loss: 0.759  |  valid_loss: 0.719\n",
      "[epoch: 7, i: 11249]  train_loss: 0.753  |  valid_loss: 0.621\n",
      "[epoch: 7, i: 11374]  train_loss: 0.717  |  valid_loss: 0.557\n",
      "[epoch: 7, i: 11499]  train_loss: 0.773  |  valid_loss: 0.418\n",
      "[epoch: 7, i: 11624]  train_loss: 0.752  |  valid_loss: 0.707\n",
      "[epoch: 7, i: 11749]  train_loss: 0.765  |  valid_loss: 0.645\n",
      "[epoch: 7, i: 11874]  train_loss: 0.726  |  valid_loss: 0.581\n",
      "[epoch: 7, i: 11999]  train_loss: 0.722  |  valid_loss: 0.514\n",
      "[epoch: 7, i: 12124]  train_loss: 0.769  |  valid_loss: 0.493\n",
      "[epoch: 7, i: 12249]  train_loss: 0.713  |  valid_loss: 0.759\n",
      "[epoch: 7, i: 12374]  train_loss: 0.730  |  valid_loss: 0.574\n",
      "[epoch: 7, i: 12499]  train_loss: 0.763  |  valid_loss: 0.527\n",
      "--> [End of epoch 7] train_accuracy: 74.71%  |  valid_accuracy: 78.72%\n",
      "--> [Start of epoch 8]  lr: 0.000215\n",
      "[epoch: 8, i:   124]  train_loss: 0.704  |  valid_loss: 0.655\n",
      "[epoch: 8, i:   249]  train_loss: 0.748  |  valid_loss: 0.640\n",
      "[epoch: 8, i:   374]  train_loss: 0.699  |  valid_loss: 0.690\n",
      "[epoch: 8, i:   499]  train_loss: 0.717  |  valid_loss: 0.683\n",
      "[epoch: 8, i:   624]  train_loss: 0.762  |  valid_loss: 0.657\n",
      "[epoch: 8, i:   749]  train_loss: 0.715  |  valid_loss: 0.416\n",
      "[epoch: 8, i:   874]  train_loss: 0.757  |  valid_loss: 0.601\n",
      "[epoch: 8, i:   999]  train_loss: 0.741  |  valid_loss: 0.589\n",
      "[epoch: 8, i:  1124]  train_loss: 0.737  |  valid_loss: 0.683\n",
      "[epoch: 8, i:  1249]  train_loss: 0.726  |  valid_loss: 0.463\n",
      "[epoch: 8, i:  1374]  train_loss: 0.728  |  valid_loss: 0.559\n",
      "[epoch: 8, i:  1499]  train_loss: 0.696  |  valid_loss: 0.626\n",
      "[epoch: 8, i:  1624]  train_loss: 0.711  |  valid_loss: 0.544\n",
      "[epoch: 8, i:  1749]  train_loss: 0.735  |  valid_loss: 0.537\n",
      "[epoch: 8, i:  1874]  train_loss: 0.734  |  valid_loss: 0.513\n",
      "[epoch: 8, i:  1999]  train_loss: 0.745  |  valid_loss: 0.656\n",
      "[epoch: 8, i:  2124]  train_loss: 0.641  |  valid_loss: 0.630\n",
      "[epoch: 8, i:  2249]  train_loss: 0.710  |  valid_loss: 0.653\n",
      "[epoch: 8, i:  2374]  train_loss: 0.691  |  valid_loss: 0.637\n",
      "[epoch: 8, i:  2499]  train_loss: 0.737  |  valid_loss: 0.833\n",
      "[epoch: 8, i:  2624]  train_loss: 0.753  |  valid_loss: 0.750\n",
      "[epoch: 8, i:  2749]  train_loss: 0.767  |  valid_loss: 0.598\n",
      "[epoch: 8, i:  2874]  train_loss: 0.792  |  valid_loss: 0.683\n",
      "[epoch: 8, i:  2999]  train_loss: 0.690  |  valid_loss: 0.658\n",
      "[epoch: 8, i:  3124]  train_loss: 0.701  |  valid_loss: 0.596\n",
      "[epoch: 8, i:  3249]  train_loss: 0.749  |  valid_loss: 0.924\n",
      "[epoch: 8, i:  3374]  train_loss: 0.733  |  valid_loss: 0.549\n",
      "[epoch: 8, i:  3499]  train_loss: 0.765  |  valid_loss: 0.590\n",
      "[epoch: 8, i:  3624]  train_loss: 0.648  |  valid_loss: 0.627\n",
      "[epoch: 8, i:  3749]  train_loss: 0.726  |  valid_loss: 0.606\n",
      "[epoch: 8, i:  3874]  train_loss: 0.720  |  valid_loss: 0.619\n",
      "[epoch: 8, i:  3999]  train_loss: 0.685  |  valid_loss: 0.663\n",
      "[epoch: 8, i:  4124]  train_loss: 0.743  |  valid_loss: 0.615\n",
      "[epoch: 8, i:  4249]  train_loss: 0.730  |  valid_loss: 0.658\n",
      "[epoch: 8, i:  4374]  train_loss: 0.682  |  valid_loss: 0.737\n",
      "[epoch: 8, i:  4499]  train_loss: 0.757  |  valid_loss: 0.500\n",
      "[epoch: 8, i:  4624]  train_loss: 0.658  |  valid_loss: 0.779\n",
      "[epoch: 8, i:  4749]  train_loss: 0.710  |  valid_loss: 0.670\n",
      "[epoch: 8, i:  4874]  train_loss: 0.762  |  valid_loss: 0.504\n",
      "[epoch: 8, i:  4999]  train_loss: 0.662  |  valid_loss: 0.566\n",
      "[epoch: 8, i:  5124]  train_loss: 0.815  |  valid_loss: 0.571\n",
      "[epoch: 8, i:  5249]  train_loss: 0.716  |  valid_loss: 0.596\n",
      "[epoch: 8, i:  5374]  train_loss: 0.733  |  valid_loss: 0.385\n",
      "[epoch: 8, i:  5499]  train_loss: 0.709  |  valid_loss: 0.634\n",
      "[epoch: 8, i:  5624]  train_loss: 0.666  |  valid_loss: 0.620\n",
      "[epoch: 8, i:  5749]  train_loss: 0.659  |  valid_loss: 0.584\n",
      "[epoch: 8, i:  5874]  train_loss: 0.717  |  valid_loss: 0.500\n",
      "[epoch: 8, i:  5999]  train_loss: 0.746  |  valid_loss: 0.630\n",
      "[epoch: 8, i:  6124]  train_loss: 0.733  |  valid_loss: 0.532\n",
      "[epoch: 8, i:  6249]  train_loss: 0.691  |  valid_loss: 0.807\n",
      "[epoch: 8, i:  6374]  train_loss: 0.679  |  valid_loss: 0.553\n",
      "[epoch: 8, i:  6499]  train_loss: 0.722  |  valid_loss: 0.591\n",
      "[epoch: 8, i:  6624]  train_loss: 0.758  |  valid_loss: 0.544\n",
      "[epoch: 8, i:  6749]  train_loss: 0.763  |  valid_loss: 0.529\n",
      "[epoch: 8, i:  6874]  train_loss: 0.650  |  valid_loss: 0.647\n",
      "[epoch: 8, i:  6999]  train_loss: 0.684  |  valid_loss: 0.673\n",
      "[epoch: 8, i:  7124]  train_loss: 0.721  |  valid_loss: 0.722\n",
      "[epoch: 8, i:  7249]  train_loss: 0.724  |  valid_loss: 0.480\n",
      "[epoch: 8, i:  7374]  train_loss: 0.784  |  valid_loss: 0.697\n",
      "[epoch: 8, i:  7499]  train_loss: 0.689  |  valid_loss: 0.622\n",
      "[epoch: 8, i:  7624]  train_loss: 0.733  |  valid_loss: 0.514\n",
      "[epoch: 8, i:  7749]  train_loss: 0.696  |  valid_loss: 0.589\n",
      "[epoch: 8, i:  7874]  train_loss: 0.721  |  valid_loss: 0.508\n",
      "[epoch: 8, i:  7999]  train_loss: 0.725  |  valid_loss: 0.480\n",
      "[epoch: 8, i:  8124]  train_loss: 0.689  |  valid_loss: 0.584\n",
      "[epoch: 8, i:  8249]  train_loss: 0.692  |  valid_loss: 0.620\n",
      "[epoch: 8, i:  8374]  train_loss: 0.731  |  valid_loss: 0.562\n",
      "[epoch: 8, i:  8499]  train_loss: 0.645  |  valid_loss: 0.636\n",
      "[epoch: 8, i:  8624]  train_loss: 0.725  |  valid_loss: 0.512\n",
      "[epoch: 8, i:  8749]  train_loss: 0.663  |  valid_loss: 0.766\n",
      "[epoch: 8, i:  8874]  train_loss: 0.712  |  valid_loss: 0.592\n",
      "[epoch: 8, i:  8999]  train_loss: 0.678  |  valid_loss: 0.491\n",
      "[epoch: 8, i:  9124]  train_loss: 0.690  |  valid_loss: 0.535\n",
      "[epoch: 8, i:  9249]  train_loss: 0.687  |  valid_loss: 0.470\n",
      "[epoch: 8, i:  9374]  train_loss: 0.699  |  valid_loss: 0.607\n",
      "[epoch: 8, i:  9499]  train_loss: 0.718  |  valid_loss: 0.576\n",
      "[epoch: 8, i:  9624]  train_loss: 0.797  |  valid_loss: 0.644\n",
      "[epoch: 8, i:  9749]  train_loss: 0.735  |  valid_loss: 0.624\n",
      "[epoch: 8, i:  9874]  train_loss: 0.727  |  valid_loss: 0.681\n",
      "[epoch: 8, i:  9999]  train_loss: 0.746  |  valid_loss: 0.640\n",
      "[epoch: 8, i: 10124]  train_loss: 0.715  |  valid_loss: 0.493\n",
      "[epoch: 8, i: 10249]  train_loss: 0.735  |  valid_loss: 0.510\n",
      "[epoch: 8, i: 10374]  train_loss: 0.720  |  valid_loss: 0.559\n",
      "[epoch: 8, i: 10499]  train_loss: 0.671  |  valid_loss: 0.580\n",
      "[epoch: 8, i: 10624]  train_loss: 0.704  |  valid_loss: 0.687\n",
      "[epoch: 8, i: 10749]  train_loss: 0.658  |  valid_loss: 0.598\n",
      "[epoch: 8, i: 10874]  train_loss: 0.706  |  valid_loss: 0.610\n",
      "[epoch: 8, i: 10999]  train_loss: 0.738  |  valid_loss: 0.538\n",
      "[epoch: 8, i: 11124]  train_loss: 0.704  |  valid_loss: 0.749\n",
      "[epoch: 8, i: 11249]  train_loss: 0.677  |  valid_loss: 0.656\n",
      "[epoch: 8, i: 11374]  train_loss: 0.736  |  valid_loss: 0.566\n",
      "[epoch: 8, i: 11499]  train_loss: 0.712  |  valid_loss: 0.408\n",
      "[epoch: 8, i: 11624]  train_loss: 0.714  |  valid_loss: 0.687\n",
      "[epoch: 8, i: 11749]  train_loss: 0.692  |  valid_loss: 0.684\n",
      "[epoch: 8, i: 11874]  train_loss: 0.703  |  valid_loss: 0.632\n",
      "[epoch: 8, i: 11999]  train_loss: 0.754  |  valid_loss: 0.543\n",
      "[epoch: 8, i: 12124]  train_loss: 0.724  |  valid_loss: 0.452\n",
      "[epoch: 8, i: 12249]  train_loss: 0.752  |  valid_loss: 0.778\n",
      "[epoch: 8, i: 12374]  train_loss: 0.763  |  valid_loss: 0.565\n",
      "[epoch: 8, i: 12499]  train_loss: 0.729  |  valid_loss: 0.501\n",
      "--> [End of epoch 8] train_accuracy: 75.47%  |  valid_accuracy: 79.45%\n",
      "--> [Start of epoch 9]  lr: 0.000194\n",
      "[epoch: 9, i:   124]  train_loss: 0.666  |  valid_loss: 0.616\n",
      "[epoch: 9, i:   249]  train_loss: 0.720  |  valid_loss: 0.607\n",
      "[epoch: 9, i:   374]  train_loss: 0.720  |  valid_loss: 0.617\n",
      "[epoch: 9, i:   499]  train_loss: 0.656  |  valid_loss: 0.677\n",
      "[epoch: 9, i:   624]  train_loss: 0.690  |  valid_loss: 0.643\n",
      "[epoch: 9, i:   749]  train_loss: 0.690  |  valid_loss: 0.389\n",
      "[epoch: 9, i:   874]  train_loss: 0.658  |  valid_loss: 0.565\n",
      "[epoch: 9, i:   999]  train_loss: 0.660  |  valid_loss: 0.649\n",
      "[epoch: 9, i:  1124]  train_loss: 0.700  |  valid_loss: 0.679\n",
      "[epoch: 9, i:  1249]  train_loss: 0.674  |  valid_loss: 0.475\n",
      "[epoch: 9, i:  1374]  train_loss: 0.653  |  valid_loss: 0.567\n",
      "[epoch: 9, i:  1499]  train_loss: 0.721  |  valid_loss: 0.664\n",
      "[epoch: 9, i:  1624]  train_loss: 0.656  |  valid_loss: 0.515\n",
      "[epoch: 9, i:  1749]  train_loss: 0.691  |  valid_loss: 0.544\n",
      "[epoch: 9, i:  1874]  train_loss: 0.677  |  valid_loss: 0.538\n",
      "[epoch: 9, i:  1999]  train_loss: 0.700  |  valid_loss: 0.645\n",
      "[epoch: 9, i:  2124]  train_loss: 0.695  |  valid_loss: 0.618\n",
      "[epoch: 9, i:  2249]  train_loss: 0.698  |  valid_loss: 0.620\n",
      "[epoch: 9, i:  2374]  train_loss: 0.684  |  valid_loss: 0.619\n",
      "[epoch: 9, i:  2499]  train_loss: 0.704  |  valid_loss: 0.867\n",
      "[epoch: 9, i:  2624]  train_loss: 0.681  |  valid_loss: 0.744\n",
      "[epoch: 9, i:  2749]  train_loss: 0.719  |  valid_loss: 0.566\n",
      "[epoch: 9, i:  2874]  train_loss: 0.705  |  valid_loss: 0.695\n",
      "[epoch: 9, i:  2999]  train_loss: 0.668  |  valid_loss: 0.675\n",
      "[epoch: 9, i:  3124]  train_loss: 0.706  |  valid_loss: 0.666\n",
      "[epoch: 9, i:  3249]  train_loss: 0.701  |  valid_loss: 0.958\n",
      "[epoch: 9, i:  3374]  train_loss: 0.679  |  valid_loss: 0.522\n",
      "[epoch: 9, i:  3499]  train_loss: 0.733  |  valid_loss: 0.584\n",
      "[epoch: 9, i:  3624]  train_loss: 0.763  |  valid_loss: 0.647\n",
      "[epoch: 9, i:  3749]  train_loss: 0.721  |  valid_loss: 0.634\n",
      "[epoch: 9, i:  3874]  train_loss: 0.758  |  valid_loss: 0.597\n",
      "[epoch: 9, i:  3999]  train_loss: 0.677  |  valid_loss: 0.578\n",
      "[epoch: 9, i:  4124]  train_loss: 0.720  |  valid_loss: 0.557\n",
      "[epoch: 9, i:  4249]  train_loss: 0.661  |  valid_loss: 0.631\n",
      "[epoch: 9, i:  4374]  train_loss: 0.730  |  valid_loss: 0.825\n",
      "[epoch: 9, i:  4499]  train_loss: 0.725  |  valid_loss: 0.522\n",
      "[epoch: 9, i:  4624]  train_loss: 0.682  |  valid_loss: 0.776\n",
      "[epoch: 9, i:  4749]  train_loss: 0.743  |  valid_loss: 0.622\n",
      "[epoch: 9, i:  4874]  train_loss: 0.717  |  valid_loss: 0.479\n",
      "[epoch: 9, i:  4999]  train_loss: 0.637  |  valid_loss: 0.519\n",
      "[epoch: 9, i:  5124]  train_loss: 0.691  |  valid_loss: 0.564\n",
      "[epoch: 9, i:  5249]  train_loss: 0.752  |  valid_loss: 0.558\n",
      "[epoch: 9, i:  5374]  train_loss: 0.729  |  valid_loss: 0.407\n",
      "[epoch: 9, i:  5499]  train_loss: 0.702  |  valid_loss: 0.567\n",
      "[epoch: 9, i:  5624]  train_loss: 0.747  |  valid_loss: 0.627\n",
      "[epoch: 9, i:  5749]  train_loss: 0.669  |  valid_loss: 0.589\n",
      "[epoch: 9, i:  5874]  train_loss: 0.710  |  valid_loss: 0.506\n",
      "[epoch: 9, i:  5999]  train_loss: 0.756  |  valid_loss: 0.615\n",
      "[epoch: 9, i:  6124]  train_loss: 0.617  |  valid_loss: 0.468\n",
      "[epoch: 9, i:  6249]  train_loss: 0.720  |  valid_loss: 0.729\n",
      "[epoch: 9, i:  6374]  train_loss: 0.693  |  valid_loss: 0.573\n",
      "[epoch: 9, i:  6499]  train_loss: 0.702  |  valid_loss: 0.615\n",
      "[epoch: 9, i:  6624]  train_loss: 0.754  |  valid_loss: 0.552\n",
      "[epoch: 9, i:  6749]  train_loss: 0.673  |  valid_loss: 0.511\n",
      "[epoch: 9, i:  6874]  train_loss: 0.695  |  valid_loss: 0.661\n",
      "[epoch: 9, i:  6999]  train_loss: 0.676  |  valid_loss: 0.658\n",
      "[epoch: 9, i:  7124]  train_loss: 0.680  |  valid_loss: 0.707\n",
      "[epoch: 9, i:  7249]  train_loss: 0.726  |  valid_loss: 0.522\n",
      "[epoch: 9, i:  7374]  train_loss: 0.720  |  valid_loss: 0.658\n",
      "[epoch: 9, i:  7499]  train_loss: 0.698  |  valid_loss: 0.603\n",
      "[epoch: 9, i:  7624]  train_loss: 0.643  |  valid_loss: 0.477\n",
      "[epoch: 9, i:  7749]  train_loss: 0.675  |  valid_loss: 0.547\n",
      "[epoch: 9, i:  7874]  train_loss: 0.733  |  valid_loss: 0.542\n",
      "[epoch: 9, i:  7999]  train_loss: 0.694  |  valid_loss: 0.452\n",
      "[epoch: 9, i:  8124]  train_loss: 0.741  |  valid_loss: 0.568\n",
      "[epoch: 9, i:  8249]  train_loss: 0.760  |  valid_loss: 0.643\n",
      "[epoch: 9, i:  8374]  train_loss: 0.673  |  valid_loss: 0.551\n",
      "[epoch: 9, i:  8499]  train_loss: 0.728  |  valid_loss: 0.677\n",
      "[epoch: 9, i:  8624]  train_loss: 0.715  |  valid_loss: 0.552\n",
      "[epoch: 9, i:  8749]  train_loss: 0.734  |  valid_loss: 0.767\n",
      "[epoch: 9, i:  8874]  train_loss: 0.687  |  valid_loss: 0.593\n",
      "[epoch: 9, i:  8999]  train_loss: 0.647  |  valid_loss: 0.528\n",
      "[epoch: 9, i:  9124]  train_loss: 0.667  |  valid_loss: 0.534\n",
      "[epoch: 9, i:  9249]  train_loss: 0.779  |  valid_loss: 0.425\n",
      "[epoch: 9, i:  9374]  train_loss: 0.717  |  valid_loss: 0.564\n",
      "[epoch: 9, i:  9499]  train_loss: 0.705  |  valid_loss: 0.544\n",
      "[epoch: 9, i:  9624]  train_loss: 0.690  |  valid_loss: 0.598\n",
      "[epoch: 9, i:  9749]  train_loss: 0.677  |  valid_loss: 0.601\n",
      "[epoch: 9, i:  9874]  train_loss: 0.704  |  valid_loss: 0.654\n",
      "[epoch: 9, i:  9999]  train_loss: 0.742  |  valid_loss: 0.600\n",
      "[epoch: 9, i: 10124]  train_loss: 0.732  |  valid_loss: 0.462\n",
      "[epoch: 9, i: 10249]  train_loss: 0.732  |  valid_loss: 0.488\n",
      "[epoch: 9, i: 10374]  train_loss: 0.703  |  valid_loss: 0.527\n",
      "[epoch: 9, i: 10499]  train_loss: 0.716  |  valid_loss: 0.565\n",
      "[epoch: 9, i: 10624]  train_loss: 0.694  |  valid_loss: 0.634\n",
      "[epoch: 9, i: 10749]  train_loss: 0.745  |  valid_loss: 0.572\n",
      "[epoch: 9, i: 10874]  train_loss: 0.665  |  valid_loss: 0.598\n",
      "[epoch: 9, i: 10999]  train_loss: 0.707  |  valid_loss: 0.564\n",
      "[epoch: 9, i: 11124]  train_loss: 0.733  |  valid_loss: 0.658\n",
      "[epoch: 9, i: 11249]  train_loss: 0.756  |  valid_loss: 0.648\n",
      "[epoch: 9, i: 11374]  train_loss: 0.732  |  valid_loss: 0.546\n",
      "[epoch: 9, i: 11499]  train_loss: 0.687  |  valid_loss: 0.404\n",
      "[epoch: 9, i: 11624]  train_loss: 0.698  |  valid_loss: 0.670\n",
      "[epoch: 9, i: 11749]  train_loss: 0.665  |  valid_loss: 0.629\n",
      "[epoch: 9, i: 11874]  train_loss: 0.764  |  valid_loss: 0.587\n",
      "[epoch: 9, i: 11999]  train_loss: 0.790  |  valid_loss: 0.528\n",
      "[epoch: 9, i: 12124]  train_loss: 0.696  |  valid_loss: 0.470\n",
      "[epoch: 9, i: 12249]  train_loss: 0.764  |  valid_loss: 0.611\n",
      "[epoch: 9, i: 12374]  train_loss: 0.689  |  valid_loss: 0.590\n",
      "[epoch: 9, i: 12499]  train_loss: 0.685  |  valid_loss: 0.521\n",
      "--> [End of epoch 9] train_accuracy: 75.94%  |  valid_accuracy: 79.57%\n",
      "--> [Start of epoch 10]  lr: 0.000174\n",
      "[epoch: 10, i:   124]  train_loss: 0.692  |  valid_loss: 0.676\n",
      "[epoch: 10, i:   249]  train_loss: 0.696  |  valid_loss: 0.622\n",
      "[epoch: 10, i:   374]  train_loss: 0.708  |  valid_loss: 0.675\n",
      "[epoch: 10, i:   499]  train_loss: 0.678  |  valid_loss: 0.660\n",
      "[epoch: 10, i:   624]  train_loss: 0.671  |  valid_loss: 0.642\n",
      "[epoch: 10, i:   749]  train_loss: 0.733  |  valid_loss: 0.425\n",
      "[epoch: 10, i:   874]  train_loss: 0.683  |  valid_loss: 0.610\n",
      "[epoch: 10, i:   999]  train_loss: 0.702  |  valid_loss: 0.560\n",
      "[epoch: 10, i:  1124]  train_loss: 0.705  |  valid_loss: 0.702\n",
      "[epoch: 10, i:  1249]  train_loss: 0.724  |  valid_loss: 0.497\n",
      "[epoch: 10, i:  1374]  train_loss: 0.694  |  valid_loss: 0.580\n",
      "[epoch: 10, i:  1499]  train_loss: 0.697  |  valid_loss: 0.695\n",
      "[epoch: 10, i:  1624]  train_loss: 0.668  |  valid_loss: 0.560\n",
      "[epoch: 10, i:  1749]  train_loss: 0.690  |  valid_loss: 0.509\n",
      "[epoch: 10, i:  1874]  train_loss: 0.686  |  valid_loss: 0.535\n",
      "[epoch: 10, i:  1999]  train_loss: 0.689  |  valid_loss: 0.624\n",
      "[epoch: 10, i:  2124]  train_loss: 0.667  |  valid_loss: 0.542\n",
      "[epoch: 10, i:  2249]  train_loss: 0.716  |  valid_loss: 0.596\n",
      "[epoch: 10, i:  2374]  train_loss: 0.691  |  valid_loss: 0.588\n",
      "[epoch: 10, i:  2499]  train_loss: 0.635  |  valid_loss: 0.889\n",
      "[epoch: 10, i:  2624]  train_loss: 0.712  |  valid_loss: 0.718\n",
      "[epoch: 10, i:  2749]  train_loss: 0.707  |  valid_loss: 0.588\n",
      "[epoch: 10, i:  2874]  train_loss: 0.659  |  valid_loss: 0.690\n",
      "[epoch: 10, i:  2999]  train_loss: 0.651  |  valid_loss: 0.594\n",
      "[epoch: 10, i:  3124]  train_loss: 0.689  |  valid_loss: 0.602\n",
      "[epoch: 10, i:  3249]  train_loss: 0.699  |  valid_loss: 0.873\n",
      "[epoch: 10, i:  3374]  train_loss: 0.666  |  valid_loss: 0.487\n",
      "[epoch: 10, i:  3499]  train_loss: 0.723  |  valid_loss: 0.588\n",
      "[epoch: 10, i:  3624]  train_loss: 0.675  |  valid_loss: 0.631\n",
      "[epoch: 10, i:  3749]  train_loss: 0.740  |  valid_loss: 0.622\n",
      "[epoch: 10, i:  3874]  train_loss: 0.739  |  valid_loss: 0.645\n",
      "[epoch: 10, i:  3999]  train_loss: 0.670  |  valid_loss: 0.621\n",
      "[epoch: 10, i:  4124]  train_loss: 0.656  |  valid_loss: 0.558\n",
      "[epoch: 10, i:  4249]  train_loss: 0.726  |  valid_loss: 0.635\n",
      "[epoch: 10, i:  4374]  train_loss: 0.701  |  valid_loss: 0.769\n",
      "[epoch: 10, i:  4499]  train_loss: 0.727  |  valid_loss: 0.499\n",
      "[epoch: 10, i:  4624]  train_loss: 0.690  |  valid_loss: 0.801\n",
      "[epoch: 10, i:  4749]  train_loss: 0.706  |  valid_loss: 0.611\n",
      "[epoch: 10, i:  4874]  train_loss: 0.666  |  valid_loss: 0.485\n",
      "[epoch: 10, i:  4999]  train_loss: 0.687  |  valid_loss: 0.505\n",
      "[epoch: 10, i:  5124]  train_loss: 0.696  |  valid_loss: 0.537\n",
      "[epoch: 10, i:  5249]  train_loss: 0.713  |  valid_loss: 0.598\n",
      "[epoch: 10, i:  5374]  train_loss: 0.715  |  valid_loss: 0.383\n",
      "[epoch: 10, i:  5499]  train_loss: 0.690  |  valid_loss: 0.601\n",
      "[epoch: 10, i:  5624]  train_loss: 0.724  |  valid_loss: 0.648\n",
      "[epoch: 10, i:  5749]  train_loss: 0.633  |  valid_loss: 0.577\n",
      "[epoch: 10, i:  5874]  train_loss: 0.727  |  valid_loss: 0.521\n",
      "[epoch: 10, i:  5999]  train_loss: 0.709  |  valid_loss: 0.611\n",
      "[epoch: 10, i:  6124]  train_loss: 0.649  |  valid_loss: 0.458\n",
      "[epoch: 10, i:  6249]  train_loss: 0.807  |  valid_loss: 0.754\n",
      "[epoch: 10, i:  6374]  train_loss: 0.709  |  valid_loss: 0.523\n",
      "[epoch: 10, i:  6499]  train_loss: 0.653  |  valid_loss: 0.605\n",
      "[epoch: 10, i:  6624]  train_loss: 0.627  |  valid_loss: 0.510\n",
      "[epoch: 10, i:  6749]  train_loss: 0.672  |  valid_loss: 0.528\n",
      "[epoch: 10, i:  6874]  train_loss: 0.716  |  valid_loss: 0.608\n",
      "[epoch: 10, i:  6999]  train_loss: 0.679  |  valid_loss: 0.724\n",
      "[epoch: 10, i:  7124]  train_loss: 0.676  |  valid_loss: 0.755\n",
      "[epoch: 10, i:  7249]  train_loss: 0.721  |  valid_loss: 0.468\n",
      "[epoch: 10, i:  7374]  train_loss: 0.730  |  valid_loss: 0.683\n",
      "[epoch: 10, i:  7499]  train_loss: 0.676  |  valid_loss: 0.561\n",
      "[epoch: 10, i:  7624]  train_loss: 0.716  |  valid_loss: 0.476\n",
      "[epoch: 10, i:  7749]  train_loss: 0.739  |  valid_loss: 0.552\n",
      "[epoch: 10, i:  7874]  train_loss: 0.655  |  valid_loss: 0.510\n",
      "[epoch: 10, i:  7999]  train_loss: 0.690  |  valid_loss: 0.486\n",
      "[epoch: 10, i:  8124]  train_loss: 0.732  |  valid_loss: 0.573\n",
      "[epoch: 10, i:  8249]  train_loss: 0.747  |  valid_loss: 0.612\n",
      "[epoch: 10, i:  8374]  train_loss: 0.675  |  valid_loss: 0.615\n",
      "[epoch: 10, i:  8499]  train_loss: 0.711  |  valid_loss: 0.680\n",
      "[epoch: 10, i:  8624]  train_loss: 0.708  |  valid_loss: 0.540\n",
      "[epoch: 10, i:  8749]  train_loss: 0.676  |  valid_loss: 0.676\n",
      "[epoch: 10, i:  8874]  train_loss: 0.723  |  valid_loss: 0.538\n",
      "[epoch: 10, i:  8999]  train_loss: 0.678  |  valid_loss: 0.510\n",
      "[epoch: 10, i:  9124]  train_loss: 0.716  |  valid_loss: 0.529\n",
      "[epoch: 10, i:  9249]  train_loss: 0.723  |  valid_loss: 0.445\n",
      "[epoch: 10, i:  9374]  train_loss: 0.718  |  valid_loss: 0.563\n",
      "[epoch: 10, i:  9499]  train_loss: 0.679  |  valid_loss: 0.505\n",
      "[epoch: 10, i:  9624]  train_loss: 0.658  |  valid_loss: 0.597\n",
      "[epoch: 10, i:  9749]  train_loss: 0.685  |  valid_loss: 0.629\n",
      "[epoch: 10, i:  9874]  train_loss: 0.690  |  valid_loss: 0.650\n",
      "[epoch: 10, i:  9999]  train_loss: 0.672  |  valid_loss: 0.620\n",
      "[epoch: 10, i: 10124]  train_loss: 0.661  |  valid_loss: 0.474\n",
      "[epoch: 10, i: 10249]  train_loss: 0.667  |  valid_loss: 0.548\n",
      "[epoch: 10, i: 10374]  train_loss: 0.701  |  valid_loss: 0.537\n",
      "[epoch: 10, i: 10499]  train_loss: 0.736  |  valid_loss: 0.533\n",
      "[epoch: 10, i: 10624]  train_loss: 0.709  |  valid_loss: 0.638\n",
      "[epoch: 10, i: 10749]  train_loss: 0.668  |  valid_loss: 0.571\n",
      "[epoch: 10, i: 10874]  train_loss: 0.686  |  valid_loss: 0.631\n",
      "[epoch: 10, i: 10999]  train_loss: 0.721  |  valid_loss: 0.581\n",
      "[epoch: 10, i: 11124]  train_loss: 0.726  |  valid_loss: 0.683\n",
      "[epoch: 10, i: 11249]  train_loss: 0.706  |  valid_loss: 0.631\n",
      "[epoch: 10, i: 11374]  train_loss: 0.651  |  valid_loss: 0.487\n",
      "[epoch: 10, i: 11499]  train_loss: 0.688  |  valid_loss: 0.371\n",
      "[epoch: 10, i: 11624]  train_loss: 0.667  |  valid_loss: 0.629\n",
      "[epoch: 10, i: 11749]  train_loss: 0.667  |  valid_loss: 0.664\n",
      "[epoch: 10, i: 11874]  train_loss: 0.767  |  valid_loss: 0.657\n",
      "[epoch: 10, i: 11999]  train_loss: 0.679  |  valid_loss: 0.476\n",
      "[epoch: 10, i: 12124]  train_loss: 0.690  |  valid_loss: 0.442\n",
      "[epoch: 10, i: 12249]  train_loss: 0.747  |  valid_loss: 0.681\n",
      "[epoch: 10, i: 12374]  train_loss: 0.730  |  valid_loss: 0.578\n",
      "[epoch: 10, i: 12499]  train_loss: 0.616  |  valid_loss: 0.509\n",
      "--> [End of epoch 10] train_accuracy: 76.13%  |  valid_accuracy: 79.99%\n",
      "--> [Start of epoch 11]  lr: 0.000157\n",
      "[epoch: 11, i:   124]  train_loss: 0.726  |  valid_loss: 0.605\n",
      "[epoch: 11, i:   249]  train_loss: 0.694  |  valid_loss: 0.671\n",
      "[epoch: 11, i:   374]  train_loss: 0.705  |  valid_loss: 0.659\n",
      "[epoch: 11, i:   499]  train_loss: 0.688  |  valid_loss: 0.669\n",
      "[epoch: 11, i:   624]  train_loss: 0.732  |  valid_loss: 0.643\n",
      "[epoch: 11, i:   749]  train_loss: 0.701  |  valid_loss: 0.391\n",
      "[epoch: 11, i:   874]  train_loss: 0.722  |  valid_loss: 0.547\n",
      "[epoch: 11, i:   999]  train_loss: 0.686  |  valid_loss: 0.590\n",
      "[epoch: 11, i:  1124]  train_loss: 0.634  |  valid_loss: 0.692\n",
      "[epoch: 11, i:  1249]  train_loss: 0.674  |  valid_loss: 0.472\n",
      "[epoch: 11, i:  1374]  train_loss: 0.655  |  valid_loss: 0.569\n",
      "[epoch: 11, i:  1499]  train_loss: 0.682  |  valid_loss: 0.717\n",
      "[epoch: 11, i:  1624]  train_loss: 0.675  |  valid_loss: 0.554\n",
      "[epoch: 11, i:  1749]  train_loss: 0.667  |  valid_loss: 0.568\n",
      "[epoch: 11, i:  1874]  train_loss: 0.668  |  valid_loss: 0.551\n",
      "[epoch: 11, i:  1999]  train_loss: 0.707  |  valid_loss: 0.654\n",
      "[epoch: 11, i:  2124]  train_loss: 0.679  |  valid_loss: 0.550\n",
      "[epoch: 11, i:  2249]  train_loss: 0.675  |  valid_loss: 0.638\n",
      "[epoch: 11, i:  2374]  train_loss: 0.677  |  valid_loss: 0.596\n",
      "[epoch: 11, i:  2499]  train_loss: 0.629  |  valid_loss: 0.838\n",
      "[epoch: 11, i:  2624]  train_loss: 0.680  |  valid_loss: 0.704\n",
      "[epoch: 11, i:  2749]  train_loss: 0.700  |  valid_loss: 0.584\n",
      "[epoch: 11, i:  2874]  train_loss: 0.657  |  valid_loss: 0.685\n",
      "[epoch: 11, i:  2999]  train_loss: 0.706  |  valid_loss: 0.629\n",
      "[epoch: 11, i:  3124]  train_loss: 0.657  |  valid_loss: 0.624\n",
      "[epoch: 11, i:  3249]  train_loss: 0.682  |  valid_loss: 0.842\n",
      "[epoch: 11, i:  3374]  train_loss: 0.667  |  valid_loss: 0.517\n",
      "[epoch: 11, i:  3499]  train_loss: 0.670  |  valid_loss: 0.585\n",
      "[epoch: 11, i:  3624]  train_loss: 0.680  |  valid_loss: 0.651\n",
      "[epoch: 11, i:  3749]  train_loss: 0.665  |  valid_loss: 0.639\n",
      "[epoch: 11, i:  3874]  train_loss: 0.709  |  valid_loss: 0.620\n",
      "[epoch: 11, i:  3999]  train_loss: 0.732  |  valid_loss: 0.571\n",
      "[epoch: 11, i:  4124]  train_loss: 0.734  |  valid_loss: 0.564\n",
      "[epoch: 11, i:  4249]  train_loss: 0.624  |  valid_loss: 0.666\n",
      "[epoch: 11, i:  4374]  train_loss: 0.649  |  valid_loss: 0.739\n",
      "[epoch: 11, i:  4499]  train_loss: 0.656  |  valid_loss: 0.482\n",
      "[epoch: 11, i:  4624]  train_loss: 0.758  |  valid_loss: 0.828\n",
      "[epoch: 11, i:  4749]  train_loss: 0.643  |  valid_loss: 0.615\n",
      "[epoch: 11, i:  4874]  train_loss: 0.646  |  valid_loss: 0.523\n",
      "[epoch: 11, i:  4999]  train_loss: 0.739  |  valid_loss: 0.488\n",
      "[epoch: 11, i:  5124]  train_loss: 0.635  |  valid_loss: 0.550\n",
      "[epoch: 11, i:  5249]  train_loss: 0.740  |  valid_loss: 0.583\n",
      "[epoch: 11, i:  5374]  train_loss: 0.648  |  valid_loss: 0.390\n",
      "[epoch: 11, i:  5499]  train_loss: 0.646  |  valid_loss: 0.572\n",
      "[epoch: 11, i:  5624]  train_loss: 0.639  |  valid_loss: 0.642\n",
      "[epoch: 11, i:  5749]  train_loss: 0.727  |  valid_loss: 0.535\n",
      "[epoch: 11, i:  5874]  train_loss: 0.721  |  valid_loss: 0.495\n",
      "[epoch: 11, i:  5999]  train_loss: 0.638  |  valid_loss: 0.642\n",
      "[epoch: 11, i:  6124]  train_loss: 0.674  |  valid_loss: 0.473\n",
      "[epoch: 11, i:  6249]  train_loss: 0.651  |  valid_loss: 0.750\n",
      "[epoch: 11, i:  6374]  train_loss: 0.685  |  valid_loss: 0.522\n",
      "[epoch: 11, i:  6499]  train_loss: 0.642  |  valid_loss: 0.606\n",
      "[epoch: 11, i:  6624]  train_loss: 0.617  |  valid_loss: 0.538\n",
      "[epoch: 11, i:  6749]  train_loss: 0.712  |  valid_loss: 0.519\n",
      "[epoch: 11, i:  6874]  train_loss: 0.708  |  valid_loss: 0.654\n",
      "[epoch: 11, i:  6999]  train_loss: 0.698  |  valid_loss: 0.716\n",
      "[epoch: 11, i:  7124]  train_loss: 0.659  |  valid_loss: 0.723\n",
      "[epoch: 11, i:  7249]  train_loss: 0.696  |  valid_loss: 0.500\n",
      "[epoch: 11, i:  7374]  train_loss: 0.626  |  valid_loss: 0.653\n",
      "[epoch: 11, i:  7499]  train_loss: 0.668  |  valid_loss: 0.548\n",
      "[epoch: 11, i:  7624]  train_loss: 0.632  |  valid_loss: 0.465\n",
      "[epoch: 11, i:  7749]  train_loss: 0.654  |  valid_loss: 0.560\n",
      "[epoch: 11, i:  7874]  train_loss: 0.740  |  valid_loss: 0.505\n",
      "[epoch: 11, i:  7999]  train_loss: 0.707  |  valid_loss: 0.448\n",
      "[epoch: 11, i:  8124]  train_loss: 0.658  |  valid_loss: 0.575\n",
      "[epoch: 11, i:  8249]  train_loss: 0.678  |  valid_loss: 0.649\n",
      "[epoch: 11, i:  8374]  train_loss: 0.721  |  valid_loss: 0.572\n",
      "[epoch: 11, i:  8499]  train_loss: 0.691  |  valid_loss: 0.631\n",
      "[epoch: 11, i:  8624]  train_loss: 0.684  |  valid_loss: 0.543\n",
      "[epoch: 11, i:  8749]  train_loss: 0.652  |  valid_loss: 0.762\n",
      "[epoch: 11, i:  8874]  train_loss: 0.705  |  valid_loss: 0.591\n",
      "[epoch: 11, i:  8999]  train_loss: 0.636  |  valid_loss: 0.493\n",
      "[epoch: 11, i:  9124]  train_loss: 0.705  |  valid_loss: 0.504\n",
      "[epoch: 11, i:  9249]  train_loss: 0.657  |  valid_loss: 0.451\n",
      "[epoch: 11, i:  9374]  train_loss: 0.694  |  valid_loss: 0.586\n",
      "[epoch: 11, i:  9499]  train_loss: 0.660  |  valid_loss: 0.500\n",
      "[epoch: 11, i:  9624]  train_loss: 0.638  |  valid_loss: 0.611\n",
      "[epoch: 11, i:  9749]  train_loss: 0.634  |  valid_loss: 0.629\n",
      "[epoch: 11, i:  9874]  train_loss: 0.665  |  valid_loss: 0.649\n",
      "[epoch: 11, i:  9999]  train_loss: 0.682  |  valid_loss: 0.639\n",
      "[epoch: 11, i: 10124]  train_loss: 0.749  |  valid_loss: 0.524\n",
      "[epoch: 11, i: 10249]  train_loss: 0.709  |  valid_loss: 0.532\n",
      "[epoch: 11, i: 10374]  train_loss: 0.680  |  valid_loss: 0.601\n",
      "[epoch: 11, i: 10499]  train_loss: 0.710  |  valid_loss: 0.539\n",
      "[epoch: 11, i: 10624]  train_loss: 0.647  |  valid_loss: 0.637\n",
      "[epoch: 11, i: 10749]  train_loss: 0.703  |  valid_loss: 0.555\n",
      "[epoch: 11, i: 10874]  train_loss: 0.700  |  valid_loss: 0.591\n",
      "[epoch: 11, i: 10999]  train_loss: 0.646  |  valid_loss: 0.589\n",
      "[epoch: 11, i: 11124]  train_loss: 0.695  |  valid_loss: 0.620\n",
      "[epoch: 11, i: 11249]  train_loss: 0.724  |  valid_loss: 0.598\n",
      "[epoch: 11, i: 11374]  train_loss: 0.676  |  valid_loss: 0.526\n",
      "[epoch: 11, i: 11499]  train_loss: 0.707  |  valid_loss: 0.399\n",
      "[epoch: 11, i: 11624]  train_loss: 0.692  |  valid_loss: 0.637\n",
      "[epoch: 11, i: 11749]  train_loss: 0.678  |  valid_loss: 0.641\n",
      "[epoch: 11, i: 11874]  train_loss: 0.697  |  valid_loss: 0.579\n",
      "[epoch: 11, i: 11999]  train_loss: 0.658  |  valid_loss: 0.540\n",
      "[epoch: 11, i: 12124]  train_loss: 0.685  |  valid_loss: 0.440\n",
      "[epoch: 11, i: 12249]  train_loss: 0.678  |  valid_loss: 0.742\n",
      "[epoch: 11, i: 12374]  train_loss: 0.692  |  valid_loss: 0.596\n",
      "[epoch: 11, i: 12499]  train_loss: 0.672  |  valid_loss: 0.441\n",
      "--> [End of epoch 11] train_accuracy: 76.76%  |  valid_accuracy: 79.84%\n",
      "--> [Start of epoch 12]  lr: 0.000141\n",
      "[epoch: 12, i:   124]  train_loss: 0.621  |  valid_loss: 0.642\n",
      "[epoch: 12, i:   249]  train_loss: 0.699  |  valid_loss: 0.662\n",
      "[epoch: 12, i:   374]  train_loss: 0.682  |  valid_loss: 0.614\n",
      "[epoch: 12, i:   499]  train_loss: 0.618  |  valid_loss: 0.678\n",
      "[epoch: 12, i:   624]  train_loss: 0.699  |  valid_loss: 0.630\n",
      "[epoch: 12, i:   749]  train_loss: 0.706  |  valid_loss: 0.391\n",
      "[epoch: 12, i:   874]  train_loss: 0.693  |  valid_loss: 0.600\n",
      "[epoch: 12, i:   999]  train_loss: 0.683  |  valid_loss: 0.607\n",
      "[epoch: 12, i:  1124]  train_loss: 0.665  |  valid_loss: 0.692\n",
      "[epoch: 12, i:  1249]  train_loss: 0.712  |  valid_loss: 0.517\n",
      "[epoch: 12, i:  1374]  train_loss: 0.633  |  valid_loss: 0.551\n",
      "[epoch: 12, i:  1499]  train_loss: 0.703  |  valid_loss: 0.693\n",
      "[epoch: 12, i:  1624]  train_loss: 0.623  |  valid_loss: 0.553\n",
      "[epoch: 12, i:  1749]  train_loss: 0.705  |  valid_loss: 0.564\n",
      "[epoch: 12, i:  1874]  train_loss: 0.668  |  valid_loss: 0.516\n",
      "[epoch: 12, i:  1999]  train_loss: 0.684  |  valid_loss: 0.664\n",
      "[epoch: 12, i:  2124]  train_loss: 0.678  |  valid_loss: 0.585\n",
      "[epoch: 12, i:  2249]  train_loss: 0.677  |  valid_loss: 0.638\n",
      "[epoch: 12, i:  2374]  train_loss: 0.649  |  valid_loss: 0.533\n",
      "[epoch: 12, i:  2499]  train_loss: 0.679  |  valid_loss: 0.896\n",
      "[epoch: 12, i:  2624]  train_loss: 0.675  |  valid_loss: 0.678\n",
      "[epoch: 12, i:  2749]  train_loss: 0.665  |  valid_loss: 0.576\n",
      "[epoch: 12, i:  2874]  train_loss: 0.679  |  valid_loss: 0.682\n",
      "[epoch: 12, i:  2999]  train_loss: 0.673  |  valid_loss: 0.633\n",
      "[epoch: 12, i:  3124]  train_loss: 0.692  |  valid_loss: 0.643\n",
      "[epoch: 12, i:  3249]  train_loss: 0.658  |  valid_loss: 0.813\n",
      "[epoch: 12, i:  3374]  train_loss: 0.644  |  valid_loss: 0.493\n",
      "[epoch: 12, i:  3499]  train_loss: 0.681  |  valid_loss: 0.577\n",
      "[epoch: 12, i:  3624]  train_loss: 0.634  |  valid_loss: 0.656\n",
      "[epoch: 12, i:  3749]  train_loss: 0.712  |  valid_loss: 0.643\n",
      "[epoch: 12, i:  3874]  train_loss: 0.711  |  valid_loss: 0.546\n",
      "[epoch: 12, i:  3999]  train_loss: 0.660  |  valid_loss: 0.568\n",
      "[epoch: 12, i:  4124]  train_loss: 0.690  |  valid_loss: 0.550\n",
      "[epoch: 12, i:  4249]  train_loss: 0.709  |  valid_loss: 0.626\n",
      "[epoch: 12, i:  4374]  train_loss: 0.605  |  valid_loss: 0.698\n",
      "[epoch: 12, i:  4499]  train_loss: 0.687  |  valid_loss: 0.518\n",
      "[epoch: 12, i:  4624]  train_loss: 0.675  |  valid_loss: 0.834\n",
      "[epoch: 12, i:  4749]  train_loss: 0.655  |  valid_loss: 0.580\n",
      "[epoch: 12, i:  4874]  train_loss: 0.652  |  valid_loss: 0.505\n",
      "[epoch: 12, i:  4999]  train_loss: 0.655  |  valid_loss: 0.544\n",
      "[epoch: 12, i:  5124]  train_loss: 0.616  |  valid_loss: 0.560\n",
      "[epoch: 12, i:  5249]  train_loss: 0.621  |  valid_loss: 0.615\n",
      "[epoch: 12, i:  5374]  train_loss: 0.664  |  valid_loss: 0.387\n",
      "[epoch: 12, i:  5499]  train_loss: 0.652  |  valid_loss: 0.564\n",
      "[epoch: 12, i:  5624]  train_loss: 0.671  |  valid_loss: 0.606\n",
      "[epoch: 12, i:  5749]  train_loss: 0.625  |  valid_loss: 0.540\n",
      "[epoch: 12, i:  5874]  train_loss: 0.656  |  valid_loss: 0.459\n",
      "[epoch: 12, i:  5999]  train_loss: 0.714  |  valid_loss: 0.601\n",
      "[epoch: 12, i:  6124]  train_loss: 0.670  |  valid_loss: 0.454\n",
      "[epoch: 12, i:  6249]  train_loss: 0.637  |  valid_loss: 0.707\n",
      "[epoch: 12, i:  6374]  train_loss: 0.730  |  valid_loss: 0.545\n",
      "[epoch: 12, i:  6499]  train_loss: 0.667  |  valid_loss: 0.539\n",
      "[epoch: 12, i:  6624]  train_loss: 0.732  |  valid_loss: 0.475\n",
      "[epoch: 12, i:  6749]  train_loss: 0.658  |  valid_loss: 0.508\n",
      "[epoch: 12, i:  6874]  train_loss: 0.714  |  valid_loss: 0.590\n",
      "[epoch: 12, i:  6999]  train_loss: 0.683  |  valid_loss: 0.665\n",
      "[epoch: 12, i:  7124]  train_loss: 0.671  |  valid_loss: 0.690\n",
      "[epoch: 12, i:  7249]  train_loss: 0.690  |  valid_loss: 0.467\n",
      "[epoch: 12, i:  7374]  train_loss: 0.672  |  valid_loss: 0.666\n",
      "[epoch: 12, i:  7499]  train_loss: 0.684  |  valid_loss: 0.610\n",
      "[epoch: 12, i:  7624]  train_loss: 0.636  |  valid_loss: 0.489\n",
      "[epoch: 12, i:  7749]  train_loss: 0.653  |  valid_loss: 0.543\n",
      "[epoch: 12, i:  7874]  train_loss: 0.700  |  valid_loss: 0.493\n",
      "[epoch: 12, i:  7999]  train_loss: 0.713  |  valid_loss: 0.458\n",
      "[epoch: 12, i:  8124]  train_loss: 0.719  |  valid_loss: 0.530\n",
      "[epoch: 12, i:  8249]  train_loss: 0.683  |  valid_loss: 0.613\n",
      "[epoch: 12, i:  8374]  train_loss: 0.635  |  valid_loss: 0.560\n",
      "[epoch: 12, i:  8499]  train_loss: 0.655  |  valid_loss: 0.701\n",
      "[epoch: 12, i:  8624]  train_loss: 0.646  |  valid_loss: 0.544\n",
      "[epoch: 12, i:  8749]  train_loss: 0.684  |  valid_loss: 0.738\n",
      "[epoch: 12, i:  8874]  train_loss: 0.698  |  valid_loss: 0.585\n",
      "[epoch: 12, i:  8999]  train_loss: 0.637  |  valid_loss: 0.491\n",
      "[epoch: 12, i:  9124]  train_loss: 0.674  |  valid_loss: 0.498\n",
      "[epoch: 12, i:  9249]  train_loss: 0.677  |  valid_loss: 0.426\n",
      "[epoch: 12, i:  9374]  train_loss: 0.670  |  valid_loss: 0.596\n",
      "[epoch: 12, i:  9499]  train_loss: 0.693  |  valid_loss: 0.525\n",
      "[epoch: 12, i:  9624]  train_loss: 0.708  |  valid_loss: 0.622\n",
      "[epoch: 12, i:  9749]  train_loss: 0.678  |  valid_loss: 0.628\n",
      "[epoch: 12, i:  9874]  train_loss: 0.659  |  valid_loss: 0.642\n",
      "[epoch: 12, i:  9999]  train_loss: 0.700  |  valid_loss: 0.608\n",
      "[epoch: 12, i: 10124]  train_loss: 0.646  |  valid_loss: 0.459\n",
      "[epoch: 12, i: 10249]  train_loss: 0.722  |  valid_loss: 0.544\n",
      "[epoch: 12, i: 10374]  train_loss: 0.641  |  valid_loss: 0.513\n",
      "[epoch: 12, i: 10499]  train_loss: 0.693  |  valid_loss: 0.536\n",
      "[epoch: 12, i: 10624]  train_loss: 0.633  |  valid_loss: 0.655\n",
      "[epoch: 12, i: 10749]  train_loss: 0.642  |  valid_loss: 0.572\n",
      "[epoch: 12, i: 10874]  train_loss: 0.668  |  valid_loss: 0.566\n",
      "[epoch: 12, i: 10999]  train_loss: 0.690  |  valid_loss: 0.595\n",
      "[epoch: 12, i: 11124]  train_loss: 0.691  |  valid_loss: 0.676\n",
      "[epoch: 12, i: 11249]  train_loss: 0.666  |  valid_loss: 0.667\n",
      "[epoch: 12, i: 11374]  train_loss: 0.684  |  valid_loss: 0.526\n",
      "[epoch: 12, i: 11499]  train_loss: 0.700  |  valid_loss: 0.360\n",
      "[epoch: 12, i: 11624]  train_loss: 0.651  |  valid_loss: 0.640\n",
      "[epoch: 12, i: 11749]  train_loss: 0.679  |  valid_loss: 0.637\n",
      "[epoch: 12, i: 11874]  train_loss: 0.715  |  valid_loss: 0.579\n",
      "[epoch: 12, i: 11999]  train_loss: 0.637  |  valid_loss: 0.477\n",
      "[epoch: 12, i: 12124]  train_loss: 0.671  |  valid_loss: 0.482\n",
      "[epoch: 12, i: 12249]  train_loss: 0.657  |  valid_loss: 0.710\n",
      "[epoch: 12, i: 12374]  train_loss: 0.714  |  valid_loss: 0.558\n",
      "[epoch: 12, i: 12499]  train_loss: 0.739  |  valid_loss: 0.542\n",
      "--> [End of epoch 12] train_accuracy: 77.00%  |  valid_accuracy: 80.04%\n",
      "--> [Start of epoch 13]  lr: 0.000127\n",
      "[epoch: 13, i:   124]  train_loss: 0.674  |  valid_loss: 0.586\n",
      "[epoch: 13, i:   249]  train_loss: 0.682  |  valid_loss: 0.661\n",
      "[epoch: 13, i:   374]  train_loss: 0.699  |  valid_loss: 0.607\n",
      "[epoch: 13, i:   499]  train_loss: 0.618  |  valid_loss: 0.623\n",
      "[epoch: 13, i:   624]  train_loss: 0.588  |  valid_loss: 0.605\n",
      "[epoch: 13, i:   749]  train_loss: 0.713  |  valid_loss: 0.351\n",
      "[epoch: 13, i:   874]  train_loss: 0.689  |  valid_loss: 0.618\n",
      "[epoch: 13, i:   999]  train_loss: 0.609  |  valid_loss: 0.660\n",
      "[epoch: 13, i:  1124]  train_loss: 0.643  |  valid_loss: 0.655\n",
      "[epoch: 13, i:  1249]  train_loss: 0.684  |  valid_loss: 0.517\n",
      "[epoch: 13, i:  1374]  train_loss: 0.646  |  valid_loss: 0.561\n",
      "[epoch: 13, i:  1499]  train_loss: 0.654  |  valid_loss: 0.699\n",
      "[epoch: 13, i:  1624]  train_loss: 0.677  |  valid_loss: 0.554\n",
      "[epoch: 13, i:  1749]  train_loss: 0.612  |  valid_loss: 0.574\n",
      "[epoch: 13, i:  1874]  train_loss: 0.664  |  valid_loss: 0.496\n",
      "[epoch: 13, i:  1999]  train_loss: 0.684  |  valid_loss: 0.646\n",
      "[epoch: 13, i:  2124]  train_loss: 0.602  |  valid_loss: 0.563\n",
      "[epoch: 13, i:  2249]  train_loss: 0.683  |  valid_loss: 0.612\n",
      "[epoch: 13, i:  2374]  train_loss: 0.614  |  valid_loss: 0.580\n",
      "[epoch: 13, i:  2499]  train_loss: 0.661  |  valid_loss: 0.843\n",
      "[epoch: 13, i:  2624]  train_loss: 0.644  |  valid_loss: 0.738\n",
      "[epoch: 13, i:  2749]  train_loss: 0.667  |  valid_loss: 0.551\n",
      "[epoch: 13, i:  2874]  train_loss: 0.633  |  valid_loss: 0.656\n",
      "[epoch: 13, i:  2999]  train_loss: 0.641  |  valid_loss: 0.613\n",
      "[epoch: 13, i:  3124]  train_loss: 0.610  |  valid_loss: 0.635\n",
      "[epoch: 13, i:  3249]  train_loss: 0.695  |  valid_loss: 0.837\n",
      "[epoch: 13, i:  3374]  train_loss: 0.676  |  valid_loss: 0.557\n",
      "[epoch: 13, i:  3499]  train_loss: 0.664  |  valid_loss: 0.626\n",
      "[epoch: 13, i:  3624]  train_loss: 0.633  |  valid_loss: 0.703\n",
      "[epoch: 13, i:  3749]  train_loss: 0.626  |  valid_loss: 0.641\n",
      "[epoch: 13, i:  3874]  train_loss: 0.622  |  valid_loss: 0.584\n",
      "[epoch: 13, i:  3999]  train_loss: 0.686  |  valid_loss: 0.598\n",
      "[epoch: 13, i:  4124]  train_loss: 0.666  |  valid_loss: 0.533\n",
      "[epoch: 13, i:  4249]  train_loss: 0.665  |  valid_loss: 0.639\n",
      "[epoch: 13, i:  4374]  train_loss: 0.632  |  valid_loss: 0.756\n",
      "[epoch: 13, i:  4499]  train_loss: 0.640  |  valid_loss: 0.514\n",
      "[epoch: 13, i:  4624]  train_loss: 0.657  |  valid_loss: 0.804\n",
      "[epoch: 13, i:  4749]  train_loss: 0.660  |  valid_loss: 0.593\n",
      "[epoch: 13, i:  4874]  train_loss: 0.665  |  valid_loss: 0.460\n",
      "[epoch: 13, i:  4999]  train_loss: 0.612  |  valid_loss: 0.549\n",
      "[epoch: 13, i:  5124]  train_loss: 0.642  |  valid_loss: 0.509\n",
      "[epoch: 13, i:  5249]  train_loss: 0.693  |  valid_loss: 0.592\n",
      "[epoch: 13, i:  5374]  train_loss: 0.648  |  valid_loss: 0.404\n",
      "[epoch: 13, i:  5499]  train_loss: 0.642  |  valid_loss: 0.603\n",
      "[epoch: 13, i:  5624]  train_loss: 0.658  |  valid_loss: 0.648\n",
      "[epoch: 13, i:  5749]  train_loss: 0.649  |  valid_loss: 0.536\n",
      "[epoch: 13, i:  5874]  train_loss: 0.694  |  valid_loss: 0.457\n",
      "[epoch: 13, i:  5999]  train_loss: 0.624  |  valid_loss: 0.642\n",
      "[epoch: 13, i:  6124]  train_loss: 0.665  |  valid_loss: 0.432\n",
      "[epoch: 13, i:  6249]  train_loss: 0.681  |  valid_loss: 0.758\n",
      "[epoch: 13, i:  6374]  train_loss: 0.664  |  valid_loss: 0.535\n",
      "[epoch: 13, i:  6499]  train_loss: 0.676  |  valid_loss: 0.565\n",
      "[epoch: 13, i:  6624]  train_loss: 0.675  |  valid_loss: 0.509\n",
      "[epoch: 13, i:  6749]  train_loss: 0.685  |  valid_loss: 0.481\n",
      "[epoch: 13, i:  6874]  train_loss: 0.668  |  valid_loss: 0.610\n",
      "[epoch: 13, i:  6999]  train_loss: 0.691  |  valid_loss: 0.665\n",
      "[epoch: 13, i:  7124]  train_loss: 0.681  |  valid_loss: 0.713\n",
      "[epoch: 13, i:  7249]  train_loss: 0.652  |  valid_loss: 0.516\n",
      "[epoch: 13, i:  7374]  train_loss: 0.631  |  valid_loss: 0.633\n",
      "[epoch: 13, i:  7499]  train_loss: 0.680  |  valid_loss: 0.624\n",
      "[epoch: 13, i:  7624]  train_loss: 0.682  |  valid_loss: 0.484\n",
      "[epoch: 13, i:  7749]  train_loss: 0.659  |  valid_loss: 0.528\n",
      "[epoch: 13, i:  7874]  train_loss: 0.603  |  valid_loss: 0.538\n",
      "[epoch: 13, i:  7999]  train_loss: 0.689  |  valid_loss: 0.452\n",
      "[epoch: 13, i:  8124]  train_loss: 0.671  |  valid_loss: 0.576\n",
      "[epoch: 13, i:  8249]  train_loss: 0.693  |  valid_loss: 0.619\n",
      "[epoch: 13, i:  8374]  train_loss: 0.660  |  valid_loss: 0.542\n",
      "[epoch: 13, i:  8499]  train_loss: 0.668  |  valid_loss: 0.673\n",
      "[epoch: 13, i:  8624]  train_loss: 0.677  |  valid_loss: 0.540\n",
      "[epoch: 13, i:  8749]  train_loss: 0.615  |  valid_loss: 0.755\n",
      "[epoch: 13, i:  8874]  train_loss: 0.649  |  valid_loss: 0.539\n",
      "[epoch: 13, i:  8999]  train_loss: 0.711  |  valid_loss: 0.471\n",
      "[epoch: 13, i:  9124]  train_loss: 0.744  |  valid_loss: 0.525\n",
      "[epoch: 13, i:  9249]  train_loss: 0.670  |  valid_loss: 0.421\n",
      "[epoch: 13, i:  9374]  train_loss: 0.719  |  valid_loss: 0.559\n",
      "[epoch: 13, i:  9499]  train_loss: 0.730  |  valid_loss: 0.527\n",
      "[epoch: 13, i:  9624]  train_loss: 0.673  |  valid_loss: 0.609\n",
      "[epoch: 13, i:  9749]  train_loss: 0.654  |  valid_loss: 0.600\n",
      "[epoch: 13, i:  9874]  train_loss: 0.668  |  valid_loss: 0.672\n",
      "[epoch: 13, i:  9999]  train_loss: 0.652  |  valid_loss: 0.590\n",
      "[epoch: 13, i: 10124]  train_loss: 0.636  |  valid_loss: 0.446\n",
      "[epoch: 13, i: 10249]  train_loss: 0.698  |  valid_loss: 0.531\n",
      "[epoch: 13, i: 10374]  train_loss: 0.671  |  valid_loss: 0.518\n",
      "[epoch: 13, i: 10499]  train_loss: 0.695  |  valid_loss: 0.549\n",
      "[epoch: 13, i: 10624]  train_loss: 0.648  |  valid_loss: 0.631\n",
      "[epoch: 13, i: 10749]  train_loss: 0.665  |  valid_loss: 0.582\n",
      "[epoch: 13, i: 10874]  train_loss: 0.667  |  valid_loss: 0.573\n",
      "[epoch: 13, i: 10999]  train_loss: 0.670  |  valid_loss: 0.557\n",
      "[epoch: 13, i: 11124]  train_loss: 0.699  |  valid_loss: 0.677\n",
      "[epoch: 13, i: 11249]  train_loss: 0.714  |  valid_loss: 0.578\n",
      "[epoch: 13, i: 11374]  train_loss: 0.670  |  valid_loss: 0.511\n",
      "[epoch: 13, i: 11499]  train_loss: 0.727  |  valid_loss: 0.381\n",
      "[epoch: 13, i: 11624]  train_loss: 0.694  |  valid_loss: 0.587\n",
      "[epoch: 13, i: 11749]  train_loss: 0.728  |  valid_loss: 0.630\n",
      "[epoch: 13, i: 11874]  train_loss: 0.670  |  valid_loss: 0.596\n",
      "[epoch: 13, i: 11999]  train_loss: 0.591  |  valid_loss: 0.502\n",
      "[epoch: 13, i: 12124]  train_loss: 0.629  |  valid_loss: 0.455\n",
      "[epoch: 13, i: 12249]  train_loss: 0.672  |  valid_loss: 0.684\n",
      "[epoch: 13, i: 12374]  train_loss: 0.722  |  valid_loss: 0.539\n",
      "[epoch: 13, i: 12499]  train_loss: 0.683  |  valid_loss: 0.486\n",
      "--> [End of epoch 13] train_accuracy: 77.31%  |  valid_accuracy: 80.17%\n",
      "--> [Start of epoch 14]  lr: 0.000114\n",
      "[epoch: 14, i:   124]  train_loss: 0.624  |  valid_loss: 0.653\n",
      "[epoch: 14, i:   249]  train_loss: 0.664  |  valid_loss: 0.641\n",
      "[epoch: 14, i:   374]  train_loss: 0.644  |  valid_loss: 0.608\n",
      "[epoch: 14, i:   499]  train_loss: 0.616  |  valid_loss: 0.631\n",
      "[epoch: 14, i:   624]  train_loss: 0.649  |  valid_loss: 0.573\n",
      "[epoch: 14, i:   749]  train_loss: 0.716  |  valid_loss: 0.383\n",
      "[epoch: 14, i:   874]  train_loss: 0.635  |  valid_loss: 0.566\n",
      "[epoch: 14, i:   999]  train_loss: 0.655  |  valid_loss: 0.607\n",
      "[epoch: 14, i:  1124]  train_loss: 0.629  |  valid_loss: 0.620\n",
      "[epoch: 14, i:  1249]  train_loss: 0.677  |  valid_loss: 0.492\n",
      "[epoch: 14, i:  1374]  train_loss: 0.570  |  valid_loss: 0.563\n",
      "[epoch: 14, i:  1499]  train_loss: 0.663  |  valid_loss: 0.708\n",
      "[epoch: 14, i:  1624]  train_loss: 0.674  |  valid_loss: 0.540\n",
      "[epoch: 14, i:  1749]  train_loss: 0.640  |  valid_loss: 0.554\n",
      "[epoch: 14, i:  1874]  train_loss: 0.682  |  valid_loss: 0.506\n",
      "[epoch: 14, i:  1999]  train_loss: 0.608  |  valid_loss: 0.652\n",
      "[epoch: 14, i:  2124]  train_loss: 0.590  |  valid_loss: 0.558\n",
      "[epoch: 14, i:  2249]  train_loss: 0.642  |  valid_loss: 0.649\n",
      "[epoch: 14, i:  2374]  train_loss: 0.670  |  valid_loss: 0.626\n",
      "[epoch: 14, i:  2499]  train_loss: 0.695  |  valid_loss: 0.825\n",
      "[epoch: 14, i:  2624]  train_loss: 0.641  |  valid_loss: 0.703\n",
      "[epoch: 14, i:  2749]  train_loss: 0.664  |  valid_loss: 0.563\n",
      "[epoch: 14, i:  2874]  train_loss: 0.620  |  valid_loss: 0.634\n",
      "[epoch: 14, i:  2999]  train_loss: 0.704  |  valid_loss: 0.593\n",
      "[epoch: 14, i:  3124]  train_loss: 0.737  |  valid_loss: 0.692\n",
      "[epoch: 14, i:  3249]  train_loss: 0.697  |  valid_loss: 0.871\n",
      "[epoch: 14, i:  3374]  train_loss: 0.671  |  valid_loss: 0.507\n",
      "[epoch: 14, i:  3499]  train_loss: 0.652  |  valid_loss: 0.613\n",
      "[epoch: 14, i:  3624]  train_loss: 0.608  |  valid_loss: 0.656\n",
      "[epoch: 14, i:  3749]  train_loss: 0.637  |  valid_loss: 0.609\n",
      "[epoch: 14, i:  3874]  train_loss: 0.678  |  valid_loss: 0.593\n",
      "[epoch: 14, i:  3999]  train_loss: 0.612  |  valid_loss: 0.593\n",
      "[epoch: 14, i:  4124]  train_loss: 0.600  |  valid_loss: 0.560\n",
      "[epoch: 14, i:  4249]  train_loss: 0.652  |  valid_loss: 0.652\n",
      "[epoch: 14, i:  4374]  train_loss: 0.640  |  valid_loss: 0.734\n",
      "[epoch: 14, i:  4499]  train_loss: 0.643  |  valid_loss: 0.454\n",
      "[epoch: 14, i:  4624]  train_loss: 0.641  |  valid_loss: 0.801\n",
      "[epoch: 14, i:  4749]  train_loss: 0.713  |  valid_loss: 0.589\n",
      "[epoch: 14, i:  4874]  train_loss: 0.599  |  valid_loss: 0.474\n",
      "[epoch: 14, i:  4999]  train_loss: 0.668  |  valid_loss: 0.480\n",
      "[epoch: 14, i:  5124]  train_loss: 0.615  |  valid_loss: 0.534\n",
      "[epoch: 14, i:  5249]  train_loss: 0.705  |  valid_loss: 0.576\n",
      "[epoch: 14, i:  5374]  train_loss: 0.665  |  valid_loss: 0.381\n",
      "[epoch: 14, i:  5499]  train_loss: 0.673  |  valid_loss: 0.582\n",
      "[epoch: 14, i:  5624]  train_loss: 0.623  |  valid_loss: 0.588\n",
      "[epoch: 14, i:  5749]  train_loss: 0.639  |  valid_loss: 0.532\n",
      "[epoch: 14, i:  5874]  train_loss: 0.690  |  valid_loss: 0.445\n",
      "[epoch: 14, i:  5999]  train_loss: 0.690  |  valid_loss: 0.571\n",
      "[epoch: 14, i:  6124]  train_loss: 0.680  |  valid_loss: 0.420\n",
      "[epoch: 14, i:  6249]  train_loss: 0.643  |  valid_loss: 0.746\n",
      "[epoch: 14, i:  6374]  train_loss: 0.648  |  valid_loss: 0.523\n",
      "[epoch: 14, i:  6499]  train_loss: 0.695  |  valid_loss: 0.572\n",
      "[epoch: 14, i:  6624]  train_loss: 0.676  |  valid_loss: 0.543\n",
      "[epoch: 14, i:  6749]  train_loss: 0.665  |  valid_loss: 0.502\n",
      "[epoch: 14, i:  6874]  train_loss: 0.643  |  valid_loss: 0.582\n",
      "[epoch: 14, i:  6999]  train_loss: 0.709  |  valid_loss: 0.682\n",
      "[epoch: 14, i:  7124]  train_loss: 0.622  |  valid_loss: 0.691\n",
      "[epoch: 14, i:  7249]  train_loss: 0.674  |  valid_loss: 0.489\n",
      "[epoch: 14, i:  7374]  train_loss: 0.627  |  valid_loss: 0.582\n",
      "[epoch: 14, i:  7499]  train_loss: 0.661  |  valid_loss: 0.573\n",
      "[epoch: 14, i:  7624]  train_loss: 0.656  |  valid_loss: 0.436\n",
      "[epoch: 14, i:  7749]  train_loss: 0.647  |  valid_loss: 0.523\n",
      "[epoch: 14, i:  7874]  train_loss: 0.674  |  valid_loss: 0.520\n",
      "[epoch: 14, i:  7999]  train_loss: 0.645  |  valid_loss: 0.437\n",
      "[epoch: 14, i:  8124]  train_loss: 0.657  |  valid_loss: 0.520\n",
      "[epoch: 14, i:  8249]  train_loss: 0.639  |  valid_loss: 0.612\n",
      "[epoch: 14, i:  8374]  train_loss: 0.603  |  valid_loss: 0.525\n",
      "[epoch: 14, i:  8499]  train_loss: 0.725  |  valid_loss: 0.622\n",
      "[epoch: 14, i:  8624]  train_loss: 0.645  |  valid_loss: 0.490\n",
      "[epoch: 14, i:  8749]  train_loss: 0.715  |  valid_loss: 0.710\n",
      "[epoch: 14, i:  8874]  train_loss: 0.660  |  valid_loss: 0.561\n",
      "[epoch: 14, i:  8999]  train_loss: 0.633  |  valid_loss: 0.479\n",
      "[epoch: 14, i:  9124]  train_loss: 0.692  |  valid_loss: 0.515\n",
      "[epoch: 14, i:  9249]  train_loss: 0.641  |  valid_loss: 0.430\n",
      "[epoch: 14, i:  9374]  train_loss: 0.667  |  valid_loss: 0.583\n",
      "[epoch: 14, i:  9499]  train_loss: 0.721  |  valid_loss: 0.525\n",
      "[epoch: 14, i:  9624]  train_loss: 0.662  |  valid_loss: 0.540\n",
      "[epoch: 14, i:  9749]  train_loss: 0.598  |  valid_loss: 0.611\n",
      "[epoch: 14, i:  9874]  train_loss: 0.652  |  valid_loss: 0.621\n",
      "[epoch: 14, i:  9999]  train_loss: 0.624  |  valid_loss: 0.562\n",
      "[epoch: 14, i: 10124]  train_loss: 0.698  |  valid_loss: 0.476\n",
      "[epoch: 14, i: 10249]  train_loss: 0.679  |  valid_loss: 0.543\n",
      "[epoch: 14, i: 10374]  train_loss: 0.673  |  valid_loss: 0.507\n",
      "[epoch: 14, i: 10499]  train_loss: 0.647  |  valid_loss: 0.521\n",
      "[epoch: 14, i: 10624]  train_loss: 0.700  |  valid_loss: 0.641\n",
      "[epoch: 14, i: 10749]  train_loss: 0.669  |  valid_loss: 0.533\n",
      "[epoch: 14, i: 10874]  train_loss: 0.656  |  valid_loss: 0.578\n",
      "[epoch: 14, i: 10999]  train_loss: 0.708  |  valid_loss: 0.538\n",
      "[epoch: 14, i: 11124]  train_loss: 0.615  |  valid_loss: 0.632\n",
      "[epoch: 14, i: 11249]  train_loss: 0.656  |  valid_loss: 0.598\n",
      "[epoch: 14, i: 11374]  train_loss: 0.641  |  valid_loss: 0.465\n",
      "[epoch: 14, i: 11499]  train_loss: 0.684  |  valid_loss: 0.396\n",
      "[epoch: 14, i: 11624]  train_loss: 0.634  |  valid_loss: 0.648\n",
      "[epoch: 14, i: 11749]  train_loss: 0.669  |  valid_loss: 0.647\n",
      "[epoch: 14, i: 11874]  train_loss: 0.626  |  valid_loss: 0.556\n",
      "[epoch: 14, i: 11999]  train_loss: 0.726  |  valid_loss: 0.506\n",
      "[epoch: 14, i: 12124]  train_loss: 0.647  |  valid_loss: 0.494\n",
      "[epoch: 14, i: 12249]  train_loss: 0.705  |  valid_loss: 0.670\n",
      "[epoch: 14, i: 12374]  train_loss: 0.711  |  valid_loss: 0.570\n",
      "[epoch: 14, i: 12499]  train_loss: 0.676  |  valid_loss: 0.467\n",
      "--> [End of epoch 14] train_accuracy: 77.58%  |  valid_accuracy: 80.58%\n",
      "--> [Start of epoch 15]  lr: 0.000103\n",
      "[epoch: 15, i:   124]  train_loss: 0.589  |  valid_loss: 0.667\n",
      "[epoch: 15, i:   249]  train_loss: 0.614  |  valid_loss: 0.592\n",
      "[epoch: 15, i:   374]  train_loss: 0.616  |  valid_loss: 0.610\n",
      "[epoch: 15, i:   499]  train_loss: 0.635  |  valid_loss: 0.645\n",
      "[epoch: 15, i:   624]  train_loss: 0.684  |  valid_loss: 0.581\n",
      "[epoch: 15, i:   749]  train_loss: 0.644  |  valid_loss: 0.357\n",
      "[epoch: 15, i:   874]  train_loss: 0.606  |  valid_loss: 0.561\n",
      "[epoch: 15, i:   999]  train_loss: 0.666  |  valid_loss: 0.583\n",
      "[epoch: 15, i:  1124]  train_loss: 0.635  |  valid_loss: 0.671\n",
      "[epoch: 15, i:  1249]  train_loss: 0.660  |  valid_loss: 0.511\n",
      "[epoch: 15, i:  1374]  train_loss: 0.650  |  valid_loss: 0.574\n",
      "[epoch: 15, i:  1499]  train_loss: 0.632  |  valid_loss: 0.641\n",
      "[epoch: 15, i:  1624]  train_loss: 0.667  |  valid_loss: 0.528\n",
      "[epoch: 15, i:  1749]  train_loss: 0.598  |  valid_loss: 0.583\n",
      "[epoch: 15, i:  1874]  train_loss: 0.676  |  valid_loss: 0.486\n",
      "[epoch: 15, i:  1999]  train_loss: 0.621  |  valid_loss: 0.690\n",
      "[epoch: 15, i:  2124]  train_loss: 0.569  |  valid_loss: 0.528\n",
      "[epoch: 15, i:  2249]  train_loss: 0.659  |  valid_loss: 0.646\n",
      "[epoch: 15, i:  2374]  train_loss: 0.626  |  valid_loss: 0.595\n",
      "[epoch: 15, i:  2499]  train_loss: 0.557  |  valid_loss: 0.821\n",
      "[epoch: 15, i:  2624]  train_loss: 0.639  |  valid_loss: 0.722\n",
      "[epoch: 15, i:  2749]  train_loss: 0.688  |  valid_loss: 0.557\n",
      "[epoch: 15, i:  2874]  train_loss: 0.699  |  valid_loss: 0.692\n",
      "[epoch: 15, i:  2999]  train_loss: 0.589  |  valid_loss: 0.631\n",
      "[epoch: 15, i:  3124]  train_loss: 0.610  |  valid_loss: 0.652\n",
      "[epoch: 15, i:  3249]  train_loss: 0.660  |  valid_loss: 0.856\n",
      "[epoch: 15, i:  3374]  train_loss: 0.663  |  valid_loss: 0.495\n",
      "[epoch: 15, i:  3499]  train_loss: 0.629  |  valid_loss: 0.594\n",
      "[epoch: 15, i:  3624]  train_loss: 0.614  |  valid_loss: 0.658\n",
      "[epoch: 15, i:  3749]  train_loss: 0.675  |  valid_loss: 0.622\n",
      "[epoch: 15, i:  3874]  train_loss: 0.654  |  valid_loss: 0.619\n",
      "[epoch: 15, i:  3999]  train_loss: 0.632  |  valid_loss: 0.623\n",
      "[epoch: 15, i:  4124]  train_loss: 0.625  |  valid_loss: 0.563\n",
      "[epoch: 15, i:  4249]  train_loss: 0.619  |  valid_loss: 0.652\n",
      "[epoch: 15, i:  4374]  train_loss: 0.660  |  valid_loss: 0.790\n",
      "[epoch: 15, i:  4499]  train_loss: 0.659  |  valid_loss: 0.483\n",
      "[epoch: 15, i:  4624]  train_loss: 0.617  |  valid_loss: 0.817\n",
      "[epoch: 15, i:  4749]  train_loss: 0.701  |  valid_loss: 0.626\n",
      "[epoch: 15, i:  4874]  train_loss: 0.644  |  valid_loss: 0.475\n",
      "[epoch: 15, i:  4999]  train_loss: 0.671  |  valid_loss: 0.537\n",
      "[epoch: 15, i:  5124]  train_loss: 0.609  |  valid_loss: 0.523\n",
      "[epoch: 15, i:  5249]  train_loss: 0.699  |  valid_loss: 0.587\n",
      "[epoch: 15, i:  5374]  train_loss: 0.672  |  valid_loss: 0.376\n",
      "[epoch: 15, i:  5499]  train_loss: 0.642  |  valid_loss: 0.590\n",
      "[epoch: 15, i:  5624]  train_loss: 0.644  |  valid_loss: 0.622\n",
      "[epoch: 15, i:  5749]  train_loss: 0.649  |  valid_loss: 0.497\n",
      "[epoch: 15, i:  5874]  train_loss: 0.681  |  valid_loss: 0.458\n",
      "[epoch: 15, i:  5999]  train_loss: 0.606  |  valid_loss: 0.593\n",
      "[epoch: 15, i:  6124]  train_loss: 0.676  |  valid_loss: 0.463\n",
      "[epoch: 15, i:  6249]  train_loss: 0.634  |  valid_loss: 0.775\n",
      "[epoch: 15, i:  6374]  train_loss: 0.629  |  valid_loss: 0.505\n",
      "[epoch: 15, i:  6499]  train_loss: 0.677  |  valid_loss: 0.550\n",
      "[epoch: 15, i:  6624]  train_loss: 0.673  |  valid_loss: 0.506\n",
      "[epoch: 15, i:  6749]  train_loss: 0.628  |  valid_loss: 0.489\n",
      "[epoch: 15, i:  6874]  train_loss: 0.669  |  valid_loss: 0.547\n",
      "[epoch: 15, i:  6999]  train_loss: 0.622  |  valid_loss: 0.689\n",
      "[epoch: 15, i:  7124]  train_loss: 0.648  |  valid_loss: 0.721\n",
      "[epoch: 15, i:  7249]  train_loss: 0.638  |  valid_loss: 0.464\n",
      "[epoch: 15, i:  7374]  train_loss: 0.651  |  valid_loss: 0.632\n",
      "[epoch: 15, i:  7499]  train_loss: 0.618  |  valid_loss: 0.552\n",
      "[epoch: 15, i:  7624]  train_loss: 0.705  |  valid_loss: 0.472\n",
      "[epoch: 15, i:  7749]  train_loss: 0.618  |  valid_loss: 0.498\n",
      "[epoch: 15, i:  7874]  train_loss: 0.670  |  valid_loss: 0.515\n",
      "[epoch: 15, i:  7999]  train_loss: 0.625  |  valid_loss: 0.428\n",
      "[epoch: 15, i:  8124]  train_loss: 0.609  |  valid_loss: 0.523\n",
      "[epoch: 15, i:  8249]  train_loss: 0.570  |  valid_loss: 0.640\n",
      "[epoch: 15, i:  8374]  train_loss: 0.709  |  valid_loss: 0.567\n",
      "[epoch: 15, i:  8499]  train_loss: 0.651  |  valid_loss: 0.640\n",
      "[epoch: 15, i:  8624]  train_loss: 0.652  |  valid_loss: 0.570\n",
      "[epoch: 15, i:  8749]  train_loss: 0.619  |  valid_loss: 0.818\n",
      "[epoch: 15, i:  8874]  train_loss: 0.606  |  valid_loss: 0.559\n",
      "[epoch: 15, i:  8999]  train_loss: 0.632  |  valid_loss: 0.487\n",
      "[epoch: 15, i:  9124]  train_loss: 0.630  |  valid_loss: 0.483\n",
      "[epoch: 15, i:  9249]  train_loss: 0.649  |  valid_loss: 0.427\n",
      "[epoch: 15, i:  9374]  train_loss: 0.706  |  valid_loss: 0.530\n",
      "[epoch: 15, i:  9499]  train_loss: 0.689  |  valid_loss: 0.502\n",
      "[epoch: 15, i:  9624]  train_loss: 0.609  |  valid_loss: 0.538\n",
      "[epoch: 15, i:  9749]  train_loss: 0.616  |  valid_loss: 0.653\n",
      "[epoch: 15, i:  9874]  train_loss: 0.687  |  valid_loss: 0.635\n",
      "[epoch: 15, i:  9999]  train_loss: 0.665  |  valid_loss: 0.631\n",
      "[epoch: 15, i: 10124]  train_loss: 0.679  |  valid_loss: 0.476\n",
      "[epoch: 15, i: 10249]  train_loss: 0.668  |  valid_loss: 0.520\n",
      "[epoch: 15, i: 10374]  train_loss: 0.700  |  valid_loss: 0.504\n",
      "[epoch: 15, i: 10499]  train_loss: 0.693  |  valid_loss: 0.491\n",
      "[epoch: 15, i: 10624]  train_loss: 0.652  |  valid_loss: 0.612\n",
      "[epoch: 15, i: 10749]  train_loss: 0.661  |  valid_loss: 0.557\n",
      "[epoch: 15, i: 10874]  train_loss: 0.648  |  valid_loss: 0.564\n",
      "[epoch: 15, i: 10999]  train_loss: 0.684  |  valid_loss: 0.568\n",
      "[epoch: 15, i: 11124]  train_loss: 0.678  |  valid_loss: 0.679\n",
      "[epoch: 15, i: 11249]  train_loss: 0.688  |  valid_loss: 0.655\n",
      "[epoch: 15, i: 11374]  train_loss: 0.695  |  valid_loss: 0.501\n",
      "[epoch: 15, i: 11499]  train_loss: 0.677  |  valid_loss: 0.385\n",
      "[epoch: 15, i: 11624]  train_loss: 0.612  |  valid_loss: 0.624\n",
      "[epoch: 15, i: 11749]  train_loss: 0.645  |  valid_loss: 0.639\n",
      "[epoch: 15, i: 11874]  train_loss: 0.715  |  valid_loss: 0.609\n",
      "[epoch: 15, i: 11999]  train_loss: 0.692  |  valid_loss: 0.510\n",
      "[epoch: 15, i: 12124]  train_loss: 0.625  |  valid_loss: 0.422\n",
      "[epoch: 15, i: 12249]  train_loss: 0.657  |  valid_loss: 0.710\n",
      "[epoch: 15, i: 12374]  train_loss: 0.602  |  valid_loss: 0.570\n",
      "[epoch: 15, i: 12499]  train_loss: 0.611  |  valid_loss: 0.427\n",
      "--> [End of epoch 15] train_accuracy: 77.86%  |  valid_accuracy: 80.51%\n",
      "--> [Start of epoch 16]  lr: 0.000093\n",
      "[epoch: 16, i:   124]  train_loss: 0.706  |  valid_loss: 0.667\n",
      "[epoch: 16, i:   249]  train_loss: 0.628  |  valid_loss: 0.556\n",
      "[epoch: 16, i:   374]  train_loss: 0.628  |  valid_loss: 0.618\n",
      "[epoch: 16, i:   499]  train_loss: 0.627  |  valid_loss: 0.625\n",
      "[epoch: 16, i:   624]  train_loss: 0.660  |  valid_loss: 0.605\n",
      "[epoch: 16, i:   749]  train_loss: 0.634  |  valid_loss: 0.337\n",
      "[epoch: 16, i:   874]  train_loss: 0.607  |  valid_loss: 0.553\n",
      "[epoch: 16, i:   999]  train_loss: 0.675  |  valid_loss: 0.598\n",
      "[epoch: 16, i:  1124]  train_loss: 0.642  |  valid_loss: 0.584\n",
      "[epoch: 16, i:  1249]  train_loss: 0.618  |  valid_loss: 0.507\n",
      "[epoch: 16, i:  1374]  train_loss: 0.655  |  valid_loss: 0.571\n",
      "[epoch: 16, i:  1499]  train_loss: 0.680  |  valid_loss: 0.663\n",
      "[epoch: 16, i:  1624]  train_loss: 0.658  |  valid_loss: 0.536\n",
      "[epoch: 16, i:  1749]  train_loss: 0.608  |  valid_loss: 0.557\n",
      "[epoch: 16, i:  1874]  train_loss: 0.733  |  valid_loss: 0.510\n",
      "[epoch: 16, i:  1999]  train_loss: 0.631  |  valid_loss: 0.664\n",
      "[epoch: 16, i:  2124]  train_loss: 0.645  |  valid_loss: 0.513\n",
      "[epoch: 16, i:  2249]  train_loss: 0.660  |  valid_loss: 0.661\n",
      "[epoch: 16, i:  2374]  train_loss: 0.621  |  valid_loss: 0.556\n",
      "[epoch: 16, i:  2499]  train_loss: 0.669  |  valid_loss: 0.836\n",
      "[epoch: 16, i:  2624]  train_loss: 0.649  |  valid_loss: 0.698\n",
      "[epoch: 16, i:  2749]  train_loss: 0.686  |  valid_loss: 0.541\n",
      "[epoch: 16, i:  2874]  train_loss: 0.693  |  valid_loss: 0.673\n",
      "[epoch: 16, i:  2999]  train_loss: 0.619  |  valid_loss: 0.644\n",
      "[epoch: 16, i:  3124]  train_loss: 0.608  |  valid_loss: 0.685\n",
      "[epoch: 16, i:  3249]  train_loss: 0.667  |  valid_loss: 0.800\n",
      "[epoch: 16, i:  3374]  train_loss: 0.601  |  valid_loss: 0.496\n",
      "[epoch: 16, i:  3499]  train_loss: 0.597  |  valid_loss: 0.547\n",
      "[epoch: 16, i:  3624]  train_loss: 0.669  |  valid_loss: 0.671\n",
      "[epoch: 16, i:  3749]  train_loss: 0.636  |  valid_loss: 0.612\n",
      "[epoch: 16, i:  3874]  train_loss: 0.612  |  valid_loss: 0.604\n",
      "[epoch: 16, i:  3999]  train_loss: 0.648  |  valid_loss: 0.562\n",
      "[epoch: 16, i:  4124]  train_loss: 0.617  |  valid_loss: 0.526\n",
      "[epoch: 16, i:  4249]  train_loss: 0.604  |  valid_loss: 0.637\n",
      "[epoch: 16, i:  4374]  train_loss: 0.627  |  valid_loss: 0.740\n",
      "[epoch: 16, i:  4499]  train_loss: 0.610  |  valid_loss: 0.482\n",
      "[epoch: 16, i:  4624]  train_loss: 0.593  |  valid_loss: 0.762\n",
      "[epoch: 16, i:  4749]  train_loss: 0.635  |  valid_loss: 0.596\n",
      "[epoch: 16, i:  4874]  train_loss: 0.595  |  valid_loss: 0.460\n",
      "[epoch: 16, i:  4999]  train_loss: 0.638  |  valid_loss: 0.495\n",
      "[epoch: 16, i:  5124]  train_loss: 0.589  |  valid_loss: 0.510\n",
      "[epoch: 16, i:  5249]  train_loss: 0.589  |  valid_loss: 0.558\n",
      "[epoch: 16, i:  5374]  train_loss: 0.611  |  valid_loss: 0.412\n",
      "[epoch: 16, i:  5499]  train_loss: 0.619  |  valid_loss: 0.563\n",
      "[epoch: 16, i:  5624]  train_loss: 0.615  |  valid_loss: 0.630\n",
      "[epoch: 16, i:  5749]  train_loss: 0.692  |  valid_loss: 0.488\n",
      "[epoch: 16, i:  5874]  train_loss: 0.675  |  valid_loss: 0.468\n",
      "[epoch: 16, i:  5999]  train_loss: 0.622  |  valid_loss: 0.625\n",
      "[epoch: 16, i:  6124]  train_loss: 0.617  |  valid_loss: 0.434\n",
      "[epoch: 16, i:  6249]  train_loss: 0.668  |  valid_loss: 0.751\n",
      "[epoch: 16, i:  6374]  train_loss: 0.666  |  valid_loss: 0.501\n",
      "[epoch: 16, i:  6499]  train_loss: 0.629  |  valid_loss: 0.598\n",
      "[epoch: 16, i:  6624]  train_loss: 0.623  |  valid_loss: 0.479\n",
      "[epoch: 16, i:  6749]  train_loss: 0.641  |  valid_loss: 0.485\n",
      "[epoch: 16, i:  6874]  train_loss: 0.623  |  valid_loss: 0.552\n",
      "[epoch: 16, i:  6999]  train_loss: 0.613  |  valid_loss: 0.633\n",
      "[epoch: 16, i:  7124]  train_loss: 0.642  |  valid_loss: 0.706\n",
      "[epoch: 16, i:  7249]  train_loss: 0.590  |  valid_loss: 0.483\n",
      "[epoch: 16, i:  7374]  train_loss: 0.657  |  valid_loss: 0.616\n",
      "[epoch: 16, i:  7499]  train_loss: 0.587  |  valid_loss: 0.557\n",
      "[epoch: 16, i:  7624]  train_loss: 0.686  |  valid_loss: 0.463\n",
      "[epoch: 16, i:  7749]  train_loss: 0.691  |  valid_loss: 0.519\n",
      "[epoch: 16, i:  7874]  train_loss: 0.653  |  valid_loss: 0.500\n",
      "[epoch: 16, i:  7999]  train_loss: 0.652  |  valid_loss: 0.415\n",
      "[epoch: 16, i:  8124]  train_loss: 0.675  |  valid_loss: 0.540\n",
      "[epoch: 16, i:  8249]  train_loss: 0.620  |  valid_loss: 0.597\n",
      "[epoch: 16, i:  8374]  train_loss: 0.635  |  valid_loss: 0.534\n",
      "[epoch: 16, i:  8499]  train_loss: 0.618  |  valid_loss: 0.654\n",
      "[epoch: 16, i:  8624]  train_loss: 0.602  |  valid_loss: 0.525\n",
      "[epoch: 16, i:  8749]  train_loss: 0.680  |  valid_loss: 0.735\n",
      "[epoch: 16, i:  8874]  train_loss: 0.660  |  valid_loss: 0.531\n",
      "[epoch: 16, i:  8999]  train_loss: 0.615  |  valid_loss: 0.495\n",
      "[epoch: 16, i:  9124]  train_loss: 0.599  |  valid_loss: 0.503\n",
      "[epoch: 16, i:  9249]  train_loss: 0.623  |  valid_loss: 0.434\n",
      "[epoch: 16, i:  9374]  train_loss: 0.698  |  valid_loss: 0.518\n",
      "[epoch: 16, i:  9499]  train_loss: 0.679  |  valid_loss: 0.509\n",
      "[epoch: 16, i:  9624]  train_loss: 0.627  |  valid_loss: 0.602\n",
      "[epoch: 16, i:  9749]  train_loss: 0.628  |  valid_loss: 0.634\n",
      "[epoch: 16, i:  9874]  train_loss: 0.686  |  valid_loss: 0.662\n",
      "[epoch: 16, i:  9999]  train_loss: 0.647  |  valid_loss: 0.599\n",
      "[epoch: 16, i: 10124]  train_loss: 0.570  |  valid_loss: 0.506\n",
      "[epoch: 16, i: 10249]  train_loss: 0.691  |  valid_loss: 0.523\n",
      "[epoch: 16, i: 10374]  train_loss: 0.616  |  valid_loss: 0.479\n",
      "[epoch: 16, i: 10499]  train_loss: 0.696  |  valid_loss: 0.502\n",
      "[epoch: 16, i: 10624]  train_loss: 0.688  |  valid_loss: 0.633\n",
      "[epoch: 16, i: 10749]  train_loss: 0.629  |  valid_loss: 0.566\n",
      "[epoch: 16, i: 10874]  train_loss: 0.638  |  valid_loss: 0.605\n",
      "[epoch: 16, i: 10999]  train_loss: 0.707  |  valid_loss: 0.512\n",
      "[epoch: 16, i: 11124]  train_loss: 0.668  |  valid_loss: 0.630\n",
      "[epoch: 16, i: 11249]  train_loss: 0.605  |  valid_loss: 0.602\n",
      "[epoch: 16, i: 11374]  train_loss: 0.641  |  valid_loss: 0.480\n",
      "[epoch: 16, i: 11499]  train_loss: 0.647  |  valid_loss: 0.381\n",
      "[epoch: 16, i: 11624]  train_loss: 0.625  |  valid_loss: 0.610\n",
      "[epoch: 16, i: 11749]  train_loss: 0.616  |  valid_loss: 0.619\n",
      "[epoch: 16, i: 11874]  train_loss: 0.634  |  valid_loss: 0.597\n",
      "[epoch: 16, i: 11999]  train_loss: 0.631  |  valid_loss: 0.462\n",
      "[epoch: 16, i: 12124]  train_loss: 0.665  |  valid_loss: 0.474\n",
      "[epoch: 16, i: 12249]  train_loss: 0.600  |  valid_loss: 0.664\n",
      "[epoch: 16, i: 12374]  train_loss: 0.651  |  valid_loss: 0.566\n",
      "[epoch: 16, i: 12499]  train_loss: 0.655  |  valid_loss: 0.453\n",
      "--> [End of epoch 16] train_accuracy: 78.28%  |  valid_accuracy: 80.41%\n",
      "--> [Start of epoch 17]  lr: 0.000083\n",
      "[epoch: 17, i:   124]  train_loss: 0.652  |  valid_loss: 0.636\n",
      "[epoch: 17, i:   249]  train_loss: 0.595  |  valid_loss: 0.595\n",
      "[epoch: 17, i:   374]  train_loss: 0.624  |  valid_loss: 0.626\n",
      "[epoch: 17, i:   499]  train_loss: 0.687  |  valid_loss: 0.670\n",
      "[epoch: 17, i:   624]  train_loss: 0.621  |  valid_loss: 0.564\n",
      "[epoch: 17, i:   749]  train_loss: 0.645  |  valid_loss: 0.374\n",
      "[epoch: 17, i:   874]  train_loss: 0.629  |  valid_loss: 0.616\n",
      "[epoch: 17, i:   999]  train_loss: 0.647  |  valid_loss: 0.600\n",
      "[epoch: 17, i:  1124]  train_loss: 0.647  |  valid_loss: 0.579\n",
      "[epoch: 17, i:  1249]  train_loss: 0.675  |  valid_loss: 0.491\n",
      "[epoch: 17, i:  1374]  train_loss: 0.643  |  valid_loss: 0.525\n",
      "[epoch: 17, i:  1499]  train_loss: 0.579  |  valid_loss: 0.645\n",
      "[epoch: 17, i:  1624]  train_loss: 0.629  |  valid_loss: 0.520\n",
      "[epoch: 17, i:  1749]  train_loss: 0.607  |  valid_loss: 0.549\n",
      "[epoch: 17, i:  1874]  train_loss: 0.623  |  valid_loss: 0.505\n",
      "[epoch: 17, i:  1999]  train_loss: 0.629  |  valid_loss: 0.645\n",
      "[epoch: 17, i:  2124]  train_loss: 0.629  |  valid_loss: 0.506\n",
      "[epoch: 17, i:  2249]  train_loss: 0.588  |  valid_loss: 0.619\n",
      "[epoch: 17, i:  2374]  train_loss: 0.618  |  valid_loss: 0.569\n",
      "[epoch: 17, i:  2499]  train_loss: 0.683  |  valid_loss: 0.814\n",
      "[epoch: 17, i:  2624]  train_loss: 0.611  |  valid_loss: 0.704\n",
      "[epoch: 17, i:  2749]  train_loss: 0.619  |  valid_loss: 0.533\n",
      "[epoch: 17, i:  2874]  train_loss: 0.612  |  valid_loss: 0.694\n",
      "[epoch: 17, i:  2999]  train_loss: 0.641  |  valid_loss: 0.618\n",
      "[epoch: 17, i:  3124]  train_loss: 0.670  |  valid_loss: 0.613\n",
      "[epoch: 17, i:  3249]  train_loss: 0.660  |  valid_loss: 0.833\n",
      "[epoch: 17, i:  3374]  train_loss: 0.668  |  valid_loss: 0.557\n",
      "[epoch: 17, i:  3499]  train_loss: 0.641  |  valid_loss: 0.556\n",
      "[epoch: 17, i:  3624]  train_loss: 0.635  |  valid_loss: 0.712\n",
      "[epoch: 17, i:  3749]  train_loss: 0.559  |  valid_loss: 0.575\n",
      "[epoch: 17, i:  3874]  train_loss: 0.646  |  valid_loss: 0.582\n",
      "[epoch: 17, i:  3999]  train_loss: 0.620  |  valid_loss: 0.608\n",
      "[epoch: 17, i:  4124]  train_loss: 0.645  |  valid_loss: 0.524\n",
      "[epoch: 17, i:  4249]  train_loss: 0.570  |  valid_loss: 0.642\n",
      "[epoch: 17, i:  4374]  train_loss: 0.652  |  valid_loss: 0.716\n",
      "[epoch: 17, i:  4499]  train_loss: 0.639  |  valid_loss: 0.471\n",
      "[epoch: 17, i:  4624]  train_loss: 0.627  |  valid_loss: 0.778\n",
      "[epoch: 17, i:  4749]  train_loss: 0.625  |  valid_loss: 0.566\n",
      "[epoch: 17, i:  4874]  train_loss: 0.587  |  valid_loss: 0.488\n",
      "[epoch: 17, i:  4999]  train_loss: 0.646  |  valid_loss: 0.495\n",
      "[epoch: 17, i:  5124]  train_loss: 0.702  |  valid_loss: 0.497\n",
      "[epoch: 17, i:  5249]  train_loss: 0.639  |  valid_loss: 0.556\n",
      "[epoch: 17, i:  5374]  train_loss: 0.605  |  valid_loss: 0.407\n",
      "[epoch: 17, i:  5499]  train_loss: 0.629  |  valid_loss: 0.569\n",
      "[epoch: 17, i:  5624]  train_loss: 0.645  |  valid_loss: 0.609\n",
      "[epoch: 17, i:  5749]  train_loss: 0.601  |  valid_loss: 0.519\n",
      "[epoch: 17, i:  5874]  train_loss: 0.583  |  valid_loss: 0.444\n",
      "[epoch: 17, i:  5999]  train_loss: 0.653  |  valid_loss: 0.626\n",
      "[epoch: 17, i:  6124]  train_loss: 0.583  |  valid_loss: 0.456\n",
      "[epoch: 17, i:  6249]  train_loss: 0.640  |  valid_loss: 0.758\n",
      "[epoch: 17, i:  6374]  train_loss: 0.624  |  valid_loss: 0.492\n",
      "[epoch: 17, i:  6499]  train_loss: 0.634  |  valid_loss: 0.574\n",
      "[epoch: 17, i:  6624]  train_loss: 0.573  |  valid_loss: 0.497\n",
      "[epoch: 17, i:  6749]  train_loss: 0.615  |  valid_loss: 0.516\n",
      "[epoch: 17, i:  6874]  train_loss: 0.708  |  valid_loss: 0.558\n",
      "[epoch: 17, i:  6999]  train_loss: 0.632  |  valid_loss: 0.643\n",
      "[epoch: 17, i:  7124]  train_loss: 0.632  |  valid_loss: 0.688\n",
      "[epoch: 17, i:  7249]  train_loss: 0.628  |  valid_loss: 0.457\n",
      "[epoch: 17, i:  7374]  train_loss: 0.580  |  valid_loss: 0.621\n",
      "[epoch: 17, i:  7499]  train_loss: 0.607  |  valid_loss: 0.526\n",
      "[epoch: 17, i:  7624]  train_loss: 0.635  |  valid_loss: 0.486\n",
      "[epoch: 17, i:  7749]  train_loss: 0.623  |  valid_loss: 0.539\n",
      "[epoch: 17, i:  7874]  train_loss: 0.675  |  valid_loss: 0.520\n",
      "[epoch: 17, i:  7999]  train_loss: 0.672  |  valid_loss: 0.438\n",
      "[epoch: 17, i:  8124]  train_loss: 0.653  |  valid_loss: 0.508\n",
      "[epoch: 17, i:  8249]  train_loss: 0.636  |  valid_loss: 0.552\n",
      "[epoch: 17, i:  8374]  train_loss: 0.632  |  valid_loss: 0.528\n",
      "[epoch: 17, i:  8499]  train_loss: 0.665  |  valid_loss: 0.609\n",
      "[epoch: 17, i:  8624]  train_loss: 0.650  |  valid_loss: 0.598\n",
      "[epoch: 17, i:  8749]  train_loss: 0.669  |  valid_loss: 0.747\n",
      "[epoch: 17, i:  8874]  train_loss: 0.619  |  valid_loss: 0.559\n",
      "[epoch: 17, i:  8999]  train_loss: 0.570  |  valid_loss: 0.455\n",
      "[epoch: 17, i:  9124]  train_loss: 0.627  |  valid_loss: 0.476\n",
      "[epoch: 17, i:  9249]  train_loss: 0.654  |  valid_loss: 0.452\n",
      "[epoch: 17, i:  9374]  train_loss: 0.581  |  valid_loss: 0.505\n",
      "[epoch: 17, i:  9499]  train_loss: 0.703  |  valid_loss: 0.505\n",
      "[epoch: 17, i:  9624]  train_loss: 0.623  |  valid_loss: 0.570\n",
      "[epoch: 17, i:  9749]  train_loss: 0.712  |  valid_loss: 0.599\n",
      "[epoch: 17, i:  9874]  train_loss: 0.645  |  valid_loss: 0.649\n",
      "[epoch: 17, i:  9999]  train_loss: 0.672  |  valid_loss: 0.609\n",
      "[epoch: 17, i: 10124]  train_loss: 0.708  |  valid_loss: 0.442\n",
      "[epoch: 17, i: 10249]  train_loss: 0.670  |  valid_loss: 0.531\n",
      "[epoch: 17, i: 10374]  train_loss: 0.701  |  valid_loss: 0.497\n",
      "[epoch: 17, i: 10499]  train_loss: 0.632  |  valid_loss: 0.510\n",
      "[epoch: 17, i: 10624]  train_loss: 0.645  |  valid_loss: 0.625\n",
      "[epoch: 17, i: 10749]  train_loss: 0.657  |  valid_loss: 0.532\n",
      "[epoch: 17, i: 10874]  train_loss: 0.626  |  valid_loss: 0.565\n",
      "[epoch: 17, i: 10999]  train_loss: 0.683  |  valid_loss: 0.582\n",
      "[epoch: 17, i: 11124]  train_loss: 0.573  |  valid_loss: 0.625\n",
      "[epoch: 17, i: 11249]  train_loss: 0.635  |  valid_loss: 0.621\n",
      "[epoch: 17, i: 11374]  train_loss: 0.651  |  valid_loss: 0.487\n",
      "[epoch: 17, i: 11499]  train_loss: 0.593  |  valid_loss: 0.363\n",
      "[epoch: 17, i: 11624]  train_loss: 0.684  |  valid_loss: 0.640\n",
      "[epoch: 17, i: 11749]  train_loss: 0.640  |  valid_loss: 0.594\n",
      "[epoch: 17, i: 11874]  train_loss: 0.681  |  valid_loss: 0.611\n",
      "[epoch: 17, i: 11999]  train_loss: 0.604  |  valid_loss: 0.504\n",
      "[epoch: 17, i: 12124]  train_loss: 0.653  |  valid_loss: 0.433\n",
      "[epoch: 17, i: 12249]  train_loss: 0.547  |  valid_loss: 0.707\n",
      "[epoch: 17, i: 12374]  train_loss: 0.629  |  valid_loss: 0.554\n",
      "[epoch: 17, i: 12499]  train_loss: 0.650  |  valid_loss: 0.463\n",
      "--> [End of epoch 17] train_accuracy: 78.44%  |  valid_accuracy: 80.57%\n",
      "--> [Start of epoch 18]  lr: 0.000075\n",
      "[epoch: 18, i:   124]  train_loss: 0.619  |  valid_loss: 0.643\n",
      "[epoch: 18, i:   249]  train_loss: 0.657  |  valid_loss: 0.560\n",
      "[epoch: 18, i:   374]  train_loss: 0.630  |  valid_loss: 0.601\n",
      "[epoch: 18, i:   499]  train_loss: 0.591  |  valid_loss: 0.643\n",
      "[epoch: 18, i:   624]  train_loss: 0.578  |  valid_loss: 0.603\n",
      "[epoch: 18, i:   749]  train_loss: 0.664  |  valid_loss: 0.349\n",
      "[epoch: 18, i:   874]  train_loss: 0.625  |  valid_loss: 0.590\n",
      "[epoch: 18, i:   999]  train_loss: 0.626  |  valid_loss: 0.657\n",
      "[epoch: 18, i:  1124]  train_loss: 0.585  |  valid_loss: 0.623\n",
      "[epoch: 18, i:  1249]  train_loss: 0.578  |  valid_loss: 0.523\n",
      "[epoch: 18, i:  1374]  train_loss: 0.606  |  valid_loss: 0.528\n",
      "[epoch: 18, i:  1499]  train_loss: 0.625  |  valid_loss: 0.689\n",
      "[epoch: 18, i:  1624]  train_loss: 0.589  |  valid_loss: 0.501\n",
      "[epoch: 18, i:  1749]  train_loss: 0.661  |  valid_loss: 0.518\n",
      "[epoch: 18, i:  1874]  train_loss: 0.582  |  valid_loss: 0.499\n",
      "[epoch: 18, i:  1999]  train_loss: 0.623  |  valid_loss: 0.640\n",
      "[epoch: 18, i:  2124]  train_loss: 0.564  |  valid_loss: 0.538\n",
      "[epoch: 18, i:  2249]  train_loss: 0.666  |  valid_loss: 0.626\n",
      "[epoch: 18, i:  2374]  train_loss: 0.598  |  valid_loss: 0.571\n",
      "[epoch: 18, i:  2499]  train_loss: 0.663  |  valid_loss: 0.832\n",
      "[epoch: 18, i:  2624]  train_loss: 0.615  |  valid_loss: 0.718\n",
      "[epoch: 18, i:  2749]  train_loss: 0.666  |  valid_loss: 0.572\n",
      "[epoch: 18, i:  2874]  train_loss: 0.622  |  valid_loss: 0.631\n",
      "[epoch: 18, i:  2999]  train_loss: 0.646  |  valid_loss: 0.587\n",
      "[epoch: 18, i:  3124]  train_loss: 0.611  |  valid_loss: 0.643\n",
      "[epoch: 18, i:  3249]  train_loss: 0.647  |  valid_loss: 0.811\n",
      "[epoch: 18, i:  3374]  train_loss: 0.631  |  valid_loss: 0.501\n",
      "[epoch: 18, i:  3499]  train_loss: 0.614  |  valid_loss: 0.606\n",
      "[epoch: 18, i:  3624]  train_loss: 0.595  |  valid_loss: 0.732\n",
      "[epoch: 18, i:  3749]  train_loss: 0.629  |  valid_loss: 0.601\n",
      "[epoch: 18, i:  3874]  train_loss: 0.660  |  valid_loss: 0.609\n",
      "[epoch: 18, i:  3999]  train_loss: 0.671  |  valid_loss: 0.592\n",
      "[epoch: 18, i:  4124]  train_loss: 0.625  |  valid_loss: 0.569\n",
      "[epoch: 18, i:  4249]  train_loss: 0.637  |  valid_loss: 0.650\n",
      "[epoch: 18, i:  4374]  train_loss: 0.590  |  valid_loss: 0.755\n",
      "[epoch: 18, i:  4499]  train_loss: 0.633  |  valid_loss: 0.488\n",
      "[epoch: 18, i:  4624]  train_loss: 0.639  |  valid_loss: 0.810\n",
      "[epoch: 18, i:  4749]  train_loss: 0.617  |  valid_loss: 0.556\n",
      "[epoch: 18, i:  4874]  train_loss: 0.562  |  valid_loss: 0.455\n",
      "[epoch: 18, i:  4999]  train_loss: 0.625  |  valid_loss: 0.493\n",
      "[epoch: 18, i:  5124]  train_loss: 0.651  |  valid_loss: 0.489\n",
      "[epoch: 18, i:  5249]  train_loss: 0.612  |  valid_loss: 0.574\n",
      "[epoch: 18, i:  5374]  train_loss: 0.665  |  valid_loss: 0.427\n",
      "[epoch: 18, i:  5499]  train_loss: 0.631  |  valid_loss: 0.564\n",
      "[epoch: 18, i:  5624]  train_loss: 0.600  |  valid_loss: 0.603\n",
      "[epoch: 18, i:  5749]  train_loss: 0.615  |  valid_loss: 0.507\n",
      "[epoch: 18, i:  5874]  train_loss: 0.630  |  valid_loss: 0.450\n",
      "[epoch: 18, i:  5999]  train_loss: 0.599  |  valid_loss: 0.597\n",
      "[epoch: 18, i:  6124]  train_loss: 0.584  |  valid_loss: 0.446\n",
      "[epoch: 18, i:  6249]  train_loss: 0.614  |  valid_loss: 0.745\n",
      "[epoch: 18, i:  6374]  train_loss: 0.611  |  valid_loss: 0.546\n",
      "[epoch: 18, i:  6499]  train_loss: 0.696  |  valid_loss: 0.558\n",
      "[epoch: 18, i:  6624]  train_loss: 0.608  |  valid_loss: 0.504\n",
      "[epoch: 18, i:  6749]  train_loss: 0.618  |  valid_loss: 0.502\n",
      "[epoch: 18, i:  6874]  train_loss: 0.690  |  valid_loss: 0.595\n",
      "[epoch: 18, i:  6999]  train_loss: 0.594  |  valid_loss: 0.706\n",
      "[epoch: 18, i:  7124]  train_loss: 0.555  |  valid_loss: 0.732\n",
      "[epoch: 18, i:  7249]  train_loss: 0.578  |  valid_loss: 0.471\n",
      "[epoch: 18, i:  7374]  train_loss: 0.603  |  valid_loss: 0.632\n",
      "[epoch: 18, i:  7499]  train_loss: 0.631  |  valid_loss: 0.558\n",
      "[epoch: 18, i:  7624]  train_loss: 0.636  |  valid_loss: 0.496\n",
      "[epoch: 18, i:  7749]  train_loss: 0.658  |  valid_loss: 0.516\n",
      "[epoch: 18, i:  7874]  train_loss: 0.625  |  valid_loss: 0.503\n",
      "[epoch: 18, i:  7999]  train_loss: 0.638  |  valid_loss: 0.422\n",
      "[epoch: 18, i:  8124]  train_loss: 0.642  |  valid_loss: 0.486\n",
      "[epoch: 18, i:  8249]  train_loss: 0.618  |  valid_loss: 0.519\n",
      "[epoch: 18, i:  8374]  train_loss: 0.611  |  valid_loss: 0.530\n",
      "[epoch: 18, i:  8499]  train_loss: 0.665  |  valid_loss: 0.644\n",
      "[epoch: 18, i:  8624]  train_loss: 0.642  |  valid_loss: 0.531\n",
      "[epoch: 18, i:  8749]  train_loss: 0.599  |  valid_loss: 0.753\n",
      "[epoch: 18, i:  8874]  train_loss: 0.642  |  valid_loss: 0.517\n",
      "[epoch: 18, i:  8999]  train_loss: 0.626  |  valid_loss: 0.436\n",
      "[epoch: 18, i:  9124]  train_loss: 0.622  |  valid_loss: 0.455\n",
      "[epoch: 18, i:  9249]  train_loss: 0.635  |  valid_loss: 0.418\n",
      "[epoch: 18, i:  9374]  train_loss: 0.667  |  valid_loss: 0.464\n",
      "[epoch: 18, i:  9499]  train_loss: 0.654  |  valid_loss: 0.525\n",
      "[epoch: 18, i:  9624]  train_loss: 0.578  |  valid_loss: 0.580\n",
      "[epoch: 18, i:  9749]  train_loss: 0.627  |  valid_loss: 0.622\n",
      "[epoch: 18, i:  9874]  train_loss: 0.682  |  valid_loss: 0.632\n",
      "[epoch: 18, i:  9999]  train_loss: 0.574  |  valid_loss: 0.608\n",
      "[epoch: 18, i: 10124]  train_loss: 0.663  |  valid_loss: 0.414\n",
      "[epoch: 18, i: 10249]  train_loss: 0.656  |  valid_loss: 0.548\n",
      "[epoch: 18, i: 10374]  train_loss: 0.621  |  valid_loss: 0.505\n",
      "[epoch: 18, i: 10499]  train_loss: 0.614  |  valid_loss: 0.525\n",
      "[epoch: 18, i: 10624]  train_loss: 0.668  |  valid_loss: 0.599\n",
      "[epoch: 18, i: 10749]  train_loss: 0.691  |  valid_loss: 0.525\n",
      "[epoch: 18, i: 10874]  train_loss: 0.671  |  valid_loss: 0.554\n",
      "[epoch: 18, i: 10999]  train_loss: 0.646  |  valid_loss: 0.511\n",
      "[epoch: 18, i: 11124]  train_loss: 0.622  |  valid_loss: 0.635\n",
      "[epoch: 18, i: 11249]  train_loss: 0.567  |  valid_loss: 0.620\n",
      "[epoch: 18, i: 11374]  train_loss: 0.657  |  valid_loss: 0.481\n",
      "[epoch: 18, i: 11499]  train_loss: 0.627  |  valid_loss: 0.397\n",
      "[epoch: 18, i: 11624]  train_loss: 0.629  |  valid_loss: 0.659\n",
      "[epoch: 18, i: 11749]  train_loss: 0.594  |  valid_loss: 0.620\n",
      "[epoch: 18, i: 11874]  train_loss: 0.620  |  valid_loss: 0.601\n",
      "[epoch: 18, i: 11999]  train_loss: 0.654  |  valid_loss: 0.511\n",
      "[epoch: 18, i: 12124]  train_loss: 0.637  |  valid_loss: 0.481\n",
      "[epoch: 18, i: 12249]  train_loss: 0.669  |  valid_loss: 0.687\n",
      "[epoch: 18, i: 12374]  train_loss: 0.664  |  valid_loss: 0.567\n",
      "[epoch: 18, i: 12499]  train_loss: 0.662  |  valid_loss: 0.478\n",
      "--> [End of epoch 18] train_accuracy: 78.53%  |  valid_accuracy: 80.64%\n",
      "--> [Start of epoch 19]  lr: 0.000068\n",
      "[epoch: 19, i:   124]  train_loss: 0.693  |  valid_loss: 0.648\n",
      "[epoch: 19, i:   249]  train_loss: 0.665  |  valid_loss: 0.591\n",
      "[epoch: 19, i:   374]  train_loss: 0.626  |  valid_loss: 0.553\n",
      "[epoch: 19, i:   499]  train_loss: 0.634  |  valid_loss: 0.662\n",
      "[epoch: 19, i:   624]  train_loss: 0.675  |  valid_loss: 0.605\n",
      "[epoch: 19, i:   749]  train_loss: 0.623  |  valid_loss: 0.349\n",
      "[epoch: 19, i:   874]  train_loss: 0.653  |  valid_loss: 0.573\n",
      "[epoch: 19, i:   999]  train_loss: 0.621  |  valid_loss: 0.616\n",
      "[epoch: 19, i:  1124]  train_loss: 0.652  |  valid_loss: 0.609\n",
      "[epoch: 19, i:  1249]  train_loss: 0.605  |  valid_loss: 0.498\n",
      "[epoch: 19, i:  1374]  train_loss: 0.596  |  valid_loss: 0.515\n",
      "[epoch: 19, i:  1499]  train_loss: 0.585  |  valid_loss: 0.659\n",
      "[epoch: 19, i:  1624]  train_loss: 0.621  |  valid_loss: 0.530\n",
      "[epoch: 19, i:  1749]  train_loss: 0.624  |  valid_loss: 0.562\n",
      "[epoch: 19, i:  1874]  train_loss: 0.533  |  valid_loss: 0.506\n",
      "[epoch: 19, i:  1999]  train_loss: 0.637  |  valid_loss: 0.656\n",
      "[epoch: 19, i:  2124]  train_loss: 0.628  |  valid_loss: 0.561\n",
      "[epoch: 19, i:  2249]  train_loss: 0.628  |  valid_loss: 0.623\n",
      "[epoch: 19, i:  2374]  train_loss: 0.637  |  valid_loss: 0.592\n",
      "[epoch: 19, i:  2499]  train_loss: 0.620  |  valid_loss: 0.816\n",
      "[epoch: 19, i:  2624]  train_loss: 0.565  |  valid_loss: 0.703\n",
      "[epoch: 19, i:  2749]  train_loss: 0.565  |  valid_loss: 0.534\n",
      "[epoch: 19, i:  2874]  train_loss: 0.643  |  valid_loss: 0.664\n",
      "[epoch: 19, i:  2999]  train_loss: 0.636  |  valid_loss: 0.583\n",
      "[epoch: 19, i:  3124]  train_loss: 0.621  |  valid_loss: 0.629\n",
      "[epoch: 19, i:  3249]  train_loss: 0.649  |  valid_loss: 0.804\n",
      "[epoch: 19, i:  3374]  train_loss: 0.623  |  valid_loss: 0.487\n",
      "[epoch: 19, i:  3499]  train_loss: 0.619  |  valid_loss: 0.593\n",
      "[epoch: 19, i:  3624]  train_loss: 0.639  |  valid_loss: 0.731\n",
      "[epoch: 19, i:  3749]  train_loss: 0.669  |  valid_loss: 0.597\n",
      "[epoch: 19, i:  3874]  train_loss: 0.602  |  valid_loss: 0.589\n",
      "[epoch: 19, i:  3999]  train_loss: 0.573  |  valid_loss: 0.599\n",
      "[epoch: 19, i:  4124]  train_loss: 0.631  |  valid_loss: 0.572\n",
      "[epoch: 19, i:  4249]  train_loss: 0.649  |  valid_loss: 0.639\n",
      "[epoch: 19, i:  4374]  train_loss: 0.620  |  valid_loss: 0.725\n",
      "[epoch: 19, i:  4499]  train_loss: 0.619  |  valid_loss: 0.448\n",
      "[epoch: 19, i:  4624]  train_loss: 0.625  |  valid_loss: 0.797\n",
      "[epoch: 19, i:  4749]  train_loss: 0.607  |  valid_loss: 0.572\n",
      "[epoch: 19, i:  4874]  train_loss: 0.605  |  valid_loss: 0.480\n",
      "[epoch: 19, i:  4999]  train_loss: 0.667  |  valid_loss: 0.479\n",
      "[epoch: 19, i:  5124]  train_loss: 0.630  |  valid_loss: 0.522\n",
      "[epoch: 19, i:  5249]  train_loss: 0.631  |  valid_loss: 0.548\n",
      "[epoch: 19, i:  5374]  train_loss: 0.636  |  valid_loss: 0.413\n",
      "[epoch: 19, i:  5499]  train_loss: 0.576  |  valid_loss: 0.559\n",
      "[epoch: 19, i:  5624]  train_loss: 0.634  |  valid_loss: 0.602\n",
      "[epoch: 19, i:  5749]  train_loss: 0.646  |  valid_loss: 0.531\n",
      "[epoch: 19, i:  5874]  train_loss: 0.693  |  valid_loss: 0.455\n",
      "[epoch: 19, i:  5999]  train_loss: 0.626  |  valid_loss: 0.565\n",
      "[epoch: 19, i:  6124]  train_loss: 0.645  |  valid_loss: 0.467\n",
      "[epoch: 19, i:  6249]  train_loss: 0.644  |  valid_loss: 0.735\n",
      "[epoch: 19, i:  6374]  train_loss: 0.586  |  valid_loss: 0.507\n",
      "[epoch: 19, i:  6499]  train_loss: 0.607  |  valid_loss: 0.530\n",
      "[epoch: 19, i:  6624]  train_loss: 0.605  |  valid_loss: 0.503\n",
      "[epoch: 19, i:  6749]  train_loss: 0.684  |  valid_loss: 0.475\n",
      "[epoch: 19, i:  6874]  train_loss: 0.616  |  valid_loss: 0.563\n",
      "[epoch: 19, i:  6999]  train_loss: 0.644  |  valid_loss: 0.653\n",
      "[epoch: 19, i:  7124]  train_loss: 0.668  |  valid_loss: 0.629\n",
      "[epoch: 19, i:  7249]  train_loss: 0.600  |  valid_loss: 0.446\n",
      "[epoch: 19, i:  7374]  train_loss: 0.605  |  valid_loss: 0.640\n",
      "[epoch: 19, i:  7499]  train_loss: 0.644  |  valid_loss: 0.565\n",
      "[epoch: 19, i:  7624]  train_loss: 0.655  |  valid_loss: 0.433\n",
      "[epoch: 19, i:  7749]  train_loss: 0.643  |  valid_loss: 0.501\n",
      "[epoch: 19, i:  7874]  train_loss: 0.652  |  valid_loss: 0.464\n",
      "[epoch: 19, i:  7999]  train_loss: 0.662  |  valid_loss: 0.407\n",
      "[epoch: 19, i:  8124]  train_loss: 0.615  |  valid_loss: 0.524\n",
      "[epoch: 19, i:  8249]  train_loss: 0.601  |  valid_loss: 0.580\n",
      "[epoch: 19, i:  8374]  train_loss: 0.617  |  valid_loss: 0.546\n",
      "[epoch: 19, i:  8499]  train_loss: 0.636  |  valid_loss: 0.673\n",
      "[epoch: 19, i:  8624]  train_loss: 0.651  |  valid_loss: 0.527\n",
      "[epoch: 19, i:  8749]  train_loss: 0.610  |  valid_loss: 0.765\n",
      "[epoch: 19, i:  8874]  train_loss: 0.681  |  valid_loss: 0.512\n",
      "[epoch: 19, i:  8999]  train_loss: 0.676  |  valid_loss: 0.472\n",
      "[epoch: 19, i:  9124]  train_loss: 0.557  |  valid_loss: 0.455\n",
      "[epoch: 19, i:  9249]  train_loss: 0.606  |  valid_loss: 0.444\n",
      "[epoch: 19, i:  9374]  train_loss: 0.633  |  valid_loss: 0.499\n",
      "[epoch: 19, i:  9499]  train_loss: 0.650  |  valid_loss: 0.534\n",
      "[epoch: 19, i:  9624]  train_loss: 0.629  |  valid_loss: 0.576\n",
      "[epoch: 19, i:  9749]  train_loss: 0.610  |  valid_loss: 0.604\n",
      "[epoch: 19, i:  9874]  train_loss: 0.653  |  valid_loss: 0.621\n",
      "[epoch: 19, i:  9999]  train_loss: 0.618  |  valid_loss: 0.611\n",
      "[epoch: 19, i: 10124]  train_loss: 0.643  |  valid_loss: 0.475\n",
      "[epoch: 19, i: 10249]  train_loss: 0.668  |  valid_loss: 0.524\n",
      "[epoch: 19, i: 10374]  train_loss: 0.640  |  valid_loss: 0.502\n",
      "[epoch: 19, i: 10499]  train_loss: 0.636  |  valid_loss: 0.520\n",
      "[epoch: 19, i: 10624]  train_loss: 0.585  |  valid_loss: 0.623\n",
      "[epoch: 19, i: 10749]  train_loss: 0.636  |  valid_loss: 0.573\n",
      "[epoch: 19, i: 10874]  train_loss: 0.624  |  valid_loss: 0.540\n",
      "[epoch: 19, i: 10999]  train_loss: 0.640  |  valid_loss: 0.572\n",
      "[epoch: 19, i: 11124]  train_loss: 0.600  |  valid_loss: 0.623\n",
      "[epoch: 19, i: 11249]  train_loss: 0.653  |  valid_loss: 0.595\n",
      "[epoch: 19, i: 11374]  train_loss: 0.603  |  valid_loss: 0.438\n",
      "[epoch: 19, i: 11499]  train_loss: 0.615  |  valid_loss: 0.376\n",
      "[epoch: 19, i: 11624]  train_loss: 0.543  |  valid_loss: 0.643\n",
      "[epoch: 19, i: 11749]  train_loss: 0.602  |  valid_loss: 0.654\n",
      "[epoch: 19, i: 11874]  train_loss: 0.626  |  valid_loss: 0.586\n",
      "[epoch: 19, i: 11999]  train_loss: 0.637  |  valid_loss: 0.476\n",
      "[epoch: 19, i: 12124]  train_loss: 0.649  |  valid_loss: 0.464\n",
      "[epoch: 19, i: 12249]  train_loss: 0.631  |  valid_loss: 0.683\n",
      "[epoch: 19, i: 12374]  train_loss: 0.595  |  valid_loss: 0.583\n",
      "[epoch: 19, i: 12499]  train_loss: 0.551  |  valid_loss: 0.457\n",
      "--> [End of epoch 19] train_accuracy: 78.62%  |  valid_accuracy: 80.43%\n",
      "--> [Start of epoch 20]  lr: 0.000061\n",
      "[epoch: 20, i:   124]  train_loss: 0.667  |  valid_loss: 0.624\n",
      "[epoch: 20, i:   249]  train_loss: 0.646  |  valid_loss: 0.594\n",
      "[epoch: 20, i:   374]  train_loss: 0.688  |  valid_loss: 0.571\n",
      "[epoch: 20, i:   499]  train_loss: 0.636  |  valid_loss: 0.625\n",
      "[epoch: 20, i:   624]  train_loss: 0.630  |  valid_loss: 0.587\n",
      "[epoch: 20, i:   749]  train_loss: 0.629  |  valid_loss: 0.375\n",
      "[epoch: 20, i:   874]  train_loss: 0.559  |  valid_loss: 0.589\n",
      "[epoch: 20, i:   999]  train_loss: 0.640  |  valid_loss: 0.631\n",
      "[epoch: 20, i:  1124]  train_loss: 0.667  |  valid_loss: 0.600\n",
      "[epoch: 20, i:  1249]  train_loss: 0.625  |  valid_loss: 0.488\n",
      "[epoch: 20, i:  1374]  train_loss: 0.578  |  valid_loss: 0.507\n",
      "[epoch: 20, i:  1499]  train_loss: 0.568  |  valid_loss: 0.709\n",
      "[epoch: 20, i:  1624]  train_loss: 0.634  |  valid_loss: 0.517\n",
      "[epoch: 20, i:  1749]  train_loss: 0.597  |  valid_loss: 0.519\n",
      "[epoch: 20, i:  1874]  train_loss: 0.679  |  valid_loss: 0.512\n",
      "[epoch: 20, i:  1999]  train_loss: 0.619  |  valid_loss: 0.673\n",
      "[epoch: 20, i:  2124]  train_loss: 0.641  |  valid_loss: 0.577\n",
      "[epoch: 20, i:  2249]  train_loss: 0.572  |  valid_loss: 0.684\n",
      "[epoch: 20, i:  2374]  train_loss: 0.630  |  valid_loss: 0.621\n",
      "[epoch: 20, i:  2499]  train_loss: 0.651  |  valid_loss: 0.809\n",
      "[epoch: 20, i:  2624]  train_loss: 0.603  |  valid_loss: 0.712\n",
      "[epoch: 20, i:  2749]  train_loss: 0.591  |  valid_loss: 0.523\n",
      "[epoch: 20, i:  2874]  train_loss: 0.603  |  valid_loss: 0.704\n",
      "[epoch: 20, i:  2999]  train_loss: 0.631  |  valid_loss: 0.592\n",
      "[epoch: 20, i:  3124]  train_loss: 0.673  |  valid_loss: 0.626\n",
      "[epoch: 20, i:  3249]  train_loss: 0.648  |  valid_loss: 0.821\n",
      "[epoch: 20, i:  3374]  train_loss: 0.593  |  valid_loss: 0.486\n",
      "[epoch: 20, i:  3499]  train_loss: 0.584  |  valid_loss: 0.585\n",
      "[epoch: 20, i:  3624]  train_loss: 0.599  |  valid_loss: 0.683\n",
      "[epoch: 20, i:  3749]  train_loss: 0.567  |  valid_loss: 0.651\n",
      "[epoch: 20, i:  3874]  train_loss: 0.635  |  valid_loss: 0.576\n",
      "[epoch: 20, i:  3999]  train_loss: 0.590  |  valid_loss: 0.593\n",
      "[epoch: 20, i:  4124]  train_loss: 0.665  |  valid_loss: 0.553\n",
      "[epoch: 20, i:  4249]  train_loss: 0.617  |  valid_loss: 0.642\n",
      "[epoch: 20, i:  4374]  train_loss: 0.580  |  valid_loss: 0.725\n",
      "[epoch: 20, i:  4499]  train_loss: 0.654  |  valid_loss: 0.445\n",
      "[epoch: 20, i:  4624]  train_loss: 0.645  |  valid_loss: 0.780\n",
      "[epoch: 20, i:  4749]  train_loss: 0.615  |  valid_loss: 0.555\n",
      "[epoch: 20, i:  4874]  train_loss: 0.622  |  valid_loss: 0.459\n",
      "[epoch: 20, i:  4999]  train_loss: 0.624  |  valid_loss: 0.506\n",
      "[epoch: 20, i:  5124]  train_loss: 0.610  |  valid_loss: 0.500\n",
      "[epoch: 20, i:  5249]  train_loss: 0.586  |  valid_loss: 0.550\n",
      "[epoch: 20, i:  5374]  train_loss: 0.540  |  valid_loss: 0.401\n",
      "[epoch: 20, i:  5499]  train_loss: 0.654  |  valid_loss: 0.590\n",
      "[epoch: 20, i:  5624]  train_loss: 0.591  |  valid_loss: 0.601\n",
      "[epoch: 20, i:  5749]  train_loss: 0.583  |  valid_loss: 0.472\n",
      "[epoch: 20, i:  5874]  train_loss: 0.644  |  valid_loss: 0.446\n",
      "[epoch: 20, i:  5999]  train_loss: 0.587  |  valid_loss: 0.585\n",
      "[epoch: 20, i:  6124]  train_loss: 0.577  |  valid_loss: 0.438\n",
      "[epoch: 20, i:  6249]  train_loss: 0.632  |  valid_loss: 0.751\n",
      "[epoch: 20, i:  6374]  train_loss: 0.601  |  valid_loss: 0.519\n",
      "[epoch: 20, i:  6499]  train_loss: 0.627  |  valid_loss: 0.570\n",
      "[epoch: 20, i:  6624]  train_loss: 0.617  |  valid_loss: 0.482\n",
      "[epoch: 20, i:  6749]  train_loss: 0.712  |  valid_loss: 0.480\n",
      "[epoch: 20, i:  6874]  train_loss: 0.612  |  valid_loss: 0.592\n",
      "[epoch: 20, i:  6999]  train_loss: 0.625  |  valid_loss: 0.686\n",
      "[epoch: 20, i:  7124]  train_loss: 0.661  |  valid_loss: 0.683\n",
      "[epoch: 20, i:  7249]  train_loss: 0.645  |  valid_loss: 0.448\n",
      "[epoch: 20, i:  7374]  train_loss: 0.627  |  valid_loss: 0.591\n",
      "[epoch: 20, i:  7499]  train_loss: 0.710  |  valid_loss: 0.572\n",
      "[epoch: 20, i:  7624]  train_loss: 0.660  |  valid_loss: 0.444\n",
      "[epoch: 20, i:  7749]  train_loss: 0.610  |  valid_loss: 0.528\n",
      "[epoch: 20, i:  7874]  train_loss: 0.657  |  valid_loss: 0.484\n",
      "[epoch: 20, i:  7999]  train_loss: 0.616  |  valid_loss: 0.409\n",
      "[epoch: 20, i:  8124]  train_loss: 0.630  |  valid_loss: 0.538\n",
      "[epoch: 20, i:  8249]  train_loss: 0.604  |  valid_loss: 0.533\n",
      "[epoch: 20, i:  8374]  train_loss: 0.650  |  valid_loss: 0.543\n",
      "[epoch: 20, i:  8499]  train_loss: 0.614  |  valid_loss: 0.600\n",
      "[epoch: 20, i:  8624]  train_loss: 0.618  |  valid_loss: 0.521\n",
      "[epoch: 20, i:  8749]  train_loss: 0.614  |  valid_loss: 0.768\n",
      "[epoch: 20, i:  8874]  train_loss: 0.616  |  valid_loss: 0.521\n",
      "[epoch: 20, i:  8999]  train_loss: 0.625  |  valid_loss: 0.481\n",
      "[epoch: 20, i:  9124]  train_loss: 0.583  |  valid_loss: 0.445\n",
      "[epoch: 20, i:  9249]  train_loss: 0.641  |  valid_loss: 0.420\n",
      "[epoch: 20, i:  9374]  train_loss: 0.617  |  valid_loss: 0.466\n",
      "[epoch: 20, i:  9499]  train_loss: 0.623  |  valid_loss: 0.554\n",
      "[epoch: 20, i:  9624]  train_loss: 0.608  |  valid_loss: 0.562\n",
      "[epoch: 20, i:  9749]  train_loss: 0.646  |  valid_loss: 0.567\n",
      "[epoch: 20, i:  9874]  train_loss: 0.602  |  valid_loss: 0.628\n",
      "[epoch: 20, i:  9999]  train_loss: 0.611  |  valid_loss: 0.591\n",
      "[epoch: 20, i: 10124]  train_loss: 0.624  |  valid_loss: 0.471\n",
      "[epoch: 20, i: 10249]  train_loss: 0.565  |  valid_loss: 0.540\n",
      "[epoch: 20, i: 10374]  train_loss: 0.650  |  valid_loss: 0.506\n",
      "[epoch: 20, i: 10499]  train_loss: 0.670  |  valid_loss: 0.509\n",
      "[epoch: 20, i: 10624]  train_loss: 0.624  |  valid_loss: 0.646\n",
      "[epoch: 20, i: 10749]  train_loss: 0.637  |  valid_loss: 0.568\n",
      "[epoch: 20, i: 10874]  train_loss: 0.611  |  valid_loss: 0.548\n",
      "[epoch: 20, i: 10999]  train_loss: 0.641  |  valid_loss: 0.558\n",
      "[epoch: 20, i: 11124]  train_loss: 0.681  |  valid_loss: 0.670\n",
      "[epoch: 20, i: 11249]  train_loss: 0.705  |  valid_loss: 0.609\n",
      "[epoch: 20, i: 11374]  train_loss: 0.647  |  valid_loss: 0.460\n",
      "[epoch: 20, i: 11499]  train_loss: 0.609  |  valid_loss: 0.370\n",
      "[epoch: 20, i: 11624]  train_loss: 0.621  |  valid_loss: 0.643\n",
      "[epoch: 20, i: 11749]  train_loss: 0.641  |  valid_loss: 0.646\n",
      "[epoch: 20, i: 11874]  train_loss: 0.594  |  valid_loss: 0.587\n",
      "[epoch: 20, i: 11999]  train_loss: 0.571  |  valid_loss: 0.506\n",
      "[epoch: 20, i: 12124]  train_loss: 0.624  |  valid_loss: 0.448\n",
      "[epoch: 20, i: 12249]  train_loss: 0.634  |  valid_loss: 0.682\n",
      "[epoch: 20, i: 12374]  train_loss: 0.578  |  valid_loss: 0.571\n",
      "[epoch: 20, i: 12499]  train_loss: 0.647  |  valid_loss: 0.471\n",
      "--> [End of epoch 20] train_accuracy: 78.92%  |  valid_accuracy: 80.67%\n",
      "--> [Start of epoch 21]  lr: 0.000055\n",
      "[epoch: 21, i:   124]  train_loss: 0.572  |  valid_loss: 0.638\n",
      "[epoch: 21, i:   249]  train_loss: 0.635  |  valid_loss: 0.577\n",
      "[epoch: 21, i:   374]  train_loss: 0.637  |  valid_loss: 0.579\n",
      "[epoch: 21, i:   499]  train_loss: 0.668  |  valid_loss: 0.638\n",
      "[epoch: 21, i:   624]  train_loss: 0.630  |  valid_loss: 0.594\n",
      "[epoch: 21, i:   749]  train_loss: 0.595  |  valid_loss: 0.347\n",
      "[epoch: 21, i:   874]  train_loss: 0.673  |  valid_loss: 0.573\n",
      "[epoch: 21, i:   999]  train_loss: 0.609  |  valid_loss: 0.611\n",
      "[epoch: 21, i:  1124]  train_loss: 0.630  |  valid_loss: 0.572\n",
      "[epoch: 21, i:  1249]  train_loss: 0.696  |  valid_loss: 0.491\n",
      "[epoch: 21, i:  1374]  train_loss: 0.599  |  valid_loss: 0.506\n",
      "[epoch: 21, i:  1499]  train_loss: 0.638  |  valid_loss: 0.650\n",
      "[epoch: 21, i:  1624]  train_loss: 0.604  |  valid_loss: 0.486\n",
      "[epoch: 21, i:  1749]  train_loss: 0.678  |  valid_loss: 0.544\n",
      "[epoch: 21, i:  1874]  train_loss: 0.632  |  valid_loss: 0.517\n",
      "[epoch: 21, i:  1999]  train_loss: 0.645  |  valid_loss: 0.644\n",
      "[epoch: 21, i:  2124]  train_loss: 0.577  |  valid_loss: 0.513\n",
      "[epoch: 21, i:  2249]  train_loss: 0.572  |  valid_loss: 0.665\n",
      "[epoch: 21, i:  2374]  train_loss: 0.627  |  valid_loss: 0.586\n",
      "[epoch: 21, i:  2499]  train_loss: 0.577  |  valid_loss: 0.845\n",
      "[epoch: 21, i:  2624]  train_loss: 0.602  |  valid_loss: 0.701\n",
      "[epoch: 21, i:  2749]  train_loss: 0.611  |  valid_loss: 0.533\n",
      "[epoch: 21, i:  2874]  train_loss: 0.625  |  valid_loss: 0.685\n",
      "[epoch: 21, i:  2999]  train_loss: 0.642  |  valid_loss: 0.566\n",
      "[epoch: 21, i:  3124]  train_loss: 0.595  |  valid_loss: 0.661\n",
      "[epoch: 21, i:  3249]  train_loss: 0.625  |  valid_loss: 0.827\n",
      "[epoch: 21, i:  3374]  train_loss: 0.692  |  valid_loss: 0.494\n",
      "[epoch: 21, i:  3499]  train_loss: 0.626  |  valid_loss: 0.603\n",
      "[epoch: 21, i:  3624]  train_loss: 0.626  |  valid_loss: 0.705\n",
      "[epoch: 21, i:  3749]  train_loss: 0.664  |  valid_loss: 0.614\n",
      "[epoch: 21, i:  3874]  train_loss: 0.599  |  valid_loss: 0.591\n",
      "[epoch: 21, i:  3999]  train_loss: 0.677  |  valid_loss: 0.596\n",
      "[epoch: 21, i:  4124]  train_loss: 0.540  |  valid_loss: 0.606\n",
      "[epoch: 21, i:  4249]  train_loss: 0.604  |  valid_loss: 0.597\n",
      "[epoch: 21, i:  4374]  train_loss: 0.635  |  valid_loss: 0.760\n",
      "[epoch: 21, i:  4499]  train_loss: 0.623  |  valid_loss: 0.501\n",
      "[epoch: 21, i:  4624]  train_loss: 0.635  |  valid_loss: 0.805\n",
      "[epoch: 21, i:  4749]  train_loss: 0.661  |  valid_loss: 0.561\n",
      "[epoch: 21, i:  4874]  train_loss: 0.609  |  valid_loss: 0.426\n",
      "[epoch: 21, i:  4999]  train_loss: 0.635  |  valid_loss: 0.458\n",
      "[epoch: 21, i:  5124]  train_loss: 0.627  |  valid_loss: 0.537\n",
      "[epoch: 21, i:  5249]  train_loss: 0.561  |  valid_loss: 0.565\n",
      "[epoch: 21, i:  5374]  train_loss: 0.606  |  valid_loss: 0.396\n",
      "[epoch: 21, i:  5499]  train_loss: 0.631  |  valid_loss: 0.546\n",
      "[epoch: 21, i:  5624]  train_loss: 0.597  |  valid_loss: 0.592\n",
      "[epoch: 21, i:  5749]  train_loss: 0.635  |  valid_loss: 0.503\n",
      "[epoch: 21, i:  5874]  train_loss: 0.592  |  valid_loss: 0.466\n",
      "[epoch: 21, i:  5999]  train_loss: 0.626  |  valid_loss: 0.572\n",
      "[epoch: 21, i:  6124]  train_loss: 0.658  |  valid_loss: 0.395\n",
      "[epoch: 21, i:  6249]  train_loss: 0.647  |  valid_loss: 0.744\n",
      "[epoch: 21, i:  6374]  train_loss: 0.614  |  valid_loss: 0.523\n",
      "[epoch: 21, i:  6499]  train_loss: 0.571  |  valid_loss: 0.546\n",
      "[epoch: 21, i:  6624]  train_loss: 0.638  |  valid_loss: 0.539\n",
      "[epoch: 21, i:  6749]  train_loss: 0.595  |  valid_loss: 0.455\n",
      "[epoch: 21, i:  6874]  train_loss: 0.561  |  valid_loss: 0.540\n",
      "[epoch: 21, i:  6999]  train_loss: 0.631  |  valid_loss: 0.632\n",
      "[epoch: 21, i:  7124]  train_loss: 0.614  |  valid_loss: 0.661\n",
      "[epoch: 21, i:  7249]  train_loss: 0.600  |  valid_loss: 0.450\n",
      "[epoch: 21, i:  7374]  train_loss: 0.620  |  valid_loss: 0.609\n",
      "[epoch: 21, i:  7499]  train_loss: 0.589  |  valid_loss: 0.541\n",
      "[epoch: 21, i:  7624]  train_loss: 0.609  |  valid_loss: 0.440\n",
      "[epoch: 21, i:  7749]  train_loss: 0.645  |  valid_loss: 0.535\n",
      "[epoch: 21, i:  7874]  train_loss: 0.601  |  valid_loss: 0.493\n",
      "[epoch: 21, i:  7999]  train_loss: 0.583  |  valid_loss: 0.408\n",
      "[epoch: 21, i:  8124]  train_loss: 0.588  |  valid_loss: 0.489\n",
      "[epoch: 21, i:  8249]  train_loss: 0.619  |  valid_loss: 0.532\n",
      "[epoch: 21, i:  8374]  train_loss: 0.614  |  valid_loss: 0.520\n",
      "[epoch: 21, i:  8499]  train_loss: 0.618  |  valid_loss: 0.640\n",
      "[epoch: 21, i:  8624]  train_loss: 0.634  |  valid_loss: 0.535\n",
      "[epoch: 21, i:  8749]  train_loss: 0.575  |  valid_loss: 0.755\n",
      "[epoch: 21, i:  8874]  train_loss: 0.669  |  valid_loss: 0.511\n",
      "[epoch: 21, i:  8999]  train_loss: 0.644  |  valid_loss: 0.459\n",
      "[epoch: 21, i:  9124]  train_loss: 0.652  |  valid_loss: 0.469\n",
      "[epoch: 21, i:  9249]  train_loss: 0.565  |  valid_loss: 0.433\n",
      "[epoch: 21, i:  9374]  train_loss: 0.688  |  valid_loss: 0.524\n",
      "[epoch: 21, i:  9499]  train_loss: 0.570  |  valid_loss: 0.568\n",
      "[epoch: 21, i:  9624]  train_loss: 0.713  |  valid_loss: 0.559\n",
      "[epoch: 21, i:  9749]  train_loss: 0.597  |  valid_loss: 0.596\n",
      "[epoch: 21, i:  9874]  train_loss: 0.562  |  valid_loss: 0.615\n",
      "[epoch: 21, i:  9999]  train_loss: 0.650  |  valid_loss: 0.619\n",
      "[epoch: 21, i: 10124]  train_loss: 0.642  |  valid_loss: 0.452\n",
      "[epoch: 21, i: 10249]  train_loss: 0.606  |  valid_loss: 0.548\n",
      "[epoch: 21, i: 10374]  train_loss: 0.623  |  valid_loss: 0.472\n",
      "[epoch: 21, i: 10499]  train_loss: 0.649  |  valid_loss: 0.506\n",
      "[epoch: 21, i: 10624]  train_loss: 0.621  |  valid_loss: 0.667\n",
      "[epoch: 21, i: 10749]  train_loss: 0.566  |  valid_loss: 0.557\n",
      "[epoch: 21, i: 10874]  train_loss: 0.667  |  valid_loss: 0.565\n",
      "[epoch: 21, i: 10999]  train_loss: 0.624  |  valid_loss: 0.546\n",
      "[epoch: 21, i: 11124]  train_loss: 0.607  |  valid_loss: 0.634\n",
      "[epoch: 21, i: 11249]  train_loss: 0.602  |  valid_loss: 0.590\n",
      "[epoch: 21, i: 11374]  train_loss: 0.621  |  valid_loss: 0.468\n",
      "[epoch: 21, i: 11499]  train_loss: 0.643  |  valid_loss: 0.393\n",
      "[epoch: 21, i: 11624]  train_loss: 0.559  |  valid_loss: 0.626\n",
      "[epoch: 21, i: 11749]  train_loss: 0.629  |  valid_loss: 0.654\n",
      "[epoch: 21, i: 11874]  train_loss: 0.615  |  valid_loss: 0.619\n",
      "[epoch: 21, i: 11999]  train_loss: 0.616  |  valid_loss: 0.461\n",
      "[epoch: 21, i: 12124]  train_loss: 0.679  |  valid_loss: 0.452\n",
      "[epoch: 21, i: 12249]  train_loss: 0.680  |  valid_loss: 0.680\n",
      "[epoch: 21, i: 12374]  train_loss: 0.607  |  valid_loss: 0.543\n",
      "[epoch: 21, i: 12499]  train_loss: 0.662  |  valid_loss: 0.481\n",
      "--> [End of epoch 21] train_accuracy: 78.85%  |  valid_accuracy: 80.49%\n",
      "--> [Start of epoch 22]  lr: 0.000049\n",
      "[epoch: 22, i:   124]  train_loss: 0.595  |  valid_loss: 0.620\n",
      "[epoch: 22, i:   249]  train_loss: 0.615  |  valid_loss: 0.595\n",
      "[epoch: 22, i:   374]  train_loss: 0.665  |  valid_loss: 0.616\n",
      "[epoch: 22, i:   499]  train_loss: 0.613  |  valid_loss: 0.679\n",
      "[epoch: 22, i:   624]  train_loss: 0.607  |  valid_loss: 0.593\n",
      "[epoch: 22, i:   749]  train_loss: 0.587  |  valid_loss: 0.344\n",
      "[epoch: 22, i:   874]  train_loss: 0.579  |  valid_loss: 0.570\n",
      "[epoch: 22, i:   999]  train_loss: 0.628  |  valid_loss: 0.623\n",
      "[epoch: 22, i:  1124]  train_loss: 0.598  |  valid_loss: 0.558\n",
      "[epoch: 22, i:  1249]  train_loss: 0.563  |  valid_loss: 0.501\n",
      "[epoch: 22, i:  1374]  train_loss: 0.604  |  valid_loss: 0.510\n",
      "[epoch: 22, i:  1499]  train_loss: 0.577  |  valid_loss: 0.653\n",
      "[epoch: 22, i:  1624]  train_loss: 0.589  |  valid_loss: 0.505\n",
      "[epoch: 22, i:  1749]  train_loss: 0.634  |  valid_loss: 0.548\n",
      "[epoch: 22, i:  1874]  train_loss: 0.579  |  valid_loss: 0.504\n",
      "[epoch: 22, i:  1999]  train_loss: 0.599  |  valid_loss: 0.649\n",
      "[epoch: 22, i:  2124]  train_loss: 0.621  |  valid_loss: 0.559\n",
      "[epoch: 22, i:  2249]  train_loss: 0.643  |  valid_loss: 0.630\n",
      "[epoch: 22, i:  2374]  train_loss: 0.583  |  valid_loss: 0.592\n",
      "[epoch: 22, i:  2499]  train_loss: 0.629  |  valid_loss: 0.819\n",
      "[epoch: 22, i:  2624]  train_loss: 0.613  |  valid_loss: 0.720\n",
      "[epoch: 22, i:  2749]  train_loss: 0.601  |  valid_loss: 0.517\n",
      "[epoch: 22, i:  2874]  train_loss: 0.561  |  valid_loss: 0.686\n",
      "[epoch: 22, i:  2999]  train_loss: 0.568  |  valid_loss: 0.571\n",
      "[epoch: 22, i:  3124]  train_loss: 0.585  |  valid_loss: 0.610\n",
      "[epoch: 22, i:  3249]  train_loss: 0.663  |  valid_loss: 0.848\n",
      "[epoch: 22, i:  3374]  train_loss: 0.641  |  valid_loss: 0.505\n",
      "[epoch: 22, i:  3499]  train_loss: 0.639  |  valid_loss: 0.602\n",
      "[epoch: 22, i:  3624]  train_loss: 0.598  |  valid_loss: 0.699\n",
      "[epoch: 22, i:  3749]  train_loss: 0.590  |  valid_loss: 0.588\n",
      "[epoch: 22, i:  3874]  train_loss: 0.641  |  valid_loss: 0.585\n",
      "[epoch: 22, i:  3999]  train_loss: 0.621  |  valid_loss: 0.585\n",
      "[epoch: 22, i:  4124]  train_loss: 0.695  |  valid_loss: 0.550\n",
      "[epoch: 22, i:  4249]  train_loss: 0.646  |  valid_loss: 0.591\n",
      "[epoch: 22, i:  4374]  train_loss: 0.595  |  valid_loss: 0.793\n",
      "[epoch: 22, i:  4499]  train_loss: 0.637  |  valid_loss: 0.427\n",
      "[epoch: 22, i:  4624]  train_loss: 0.653  |  valid_loss: 0.794\n",
      "[epoch: 22, i:  4749]  train_loss: 0.643  |  valid_loss: 0.548\n",
      "[epoch: 22, i:  4874]  train_loss: 0.604  |  valid_loss: 0.473\n",
      "[epoch: 22, i:  4999]  train_loss: 0.597  |  valid_loss: 0.482\n",
      "[epoch: 22, i:  5124]  train_loss: 0.603  |  valid_loss: 0.509\n",
      "[epoch: 22, i:  5249]  train_loss: 0.686  |  valid_loss: 0.601\n",
      "[epoch: 22, i:  5374]  train_loss: 0.682  |  valid_loss: 0.384\n",
      "[epoch: 22, i:  5499]  train_loss: 0.650  |  valid_loss: 0.566\n",
      "[epoch: 22, i:  5624]  train_loss: 0.632  |  valid_loss: 0.599\n",
      "[epoch: 22, i:  5749]  train_loss: 0.598  |  valid_loss: 0.506\n",
      "[epoch: 22, i:  5874]  train_loss: 0.646  |  valid_loss: 0.444\n",
      "[epoch: 22, i:  5999]  train_loss: 0.600  |  valid_loss: 0.568\n",
      "[epoch: 22, i:  6124]  train_loss: 0.579  |  valid_loss: 0.449\n",
      "[epoch: 22, i:  6249]  train_loss: 0.577  |  valid_loss: 0.693\n",
      "[epoch: 22, i:  6374]  train_loss: 0.650  |  valid_loss: 0.526\n",
      "[epoch: 22, i:  6499]  train_loss: 0.574  |  valid_loss: 0.572\n",
      "[epoch: 22, i:  6624]  train_loss: 0.563  |  valid_loss: 0.493\n",
      "[epoch: 22, i:  6749]  train_loss: 0.649  |  valid_loss: 0.464\n",
      "[epoch: 22, i:  6874]  train_loss: 0.581  |  valid_loss: 0.559\n",
      "[epoch: 22, i:  6999]  train_loss: 0.597  |  valid_loss: 0.668\n",
      "[epoch: 22, i:  7124]  train_loss: 0.606  |  valid_loss: 0.682\n",
      "[epoch: 22, i:  7249]  train_loss: 0.639  |  valid_loss: 0.439\n",
      "[epoch: 22, i:  7374]  train_loss: 0.576  |  valid_loss: 0.607\n",
      "[epoch: 22, i:  7499]  train_loss: 0.621  |  valid_loss: 0.582\n",
      "[epoch: 22, i:  7624]  train_loss: 0.583  |  valid_loss: 0.428\n",
      "[epoch: 22, i:  7749]  train_loss: 0.623  |  valid_loss: 0.519\n",
      "[epoch: 22, i:  7874]  train_loss: 0.623  |  valid_loss: 0.471\n",
      "[epoch: 22, i:  7999]  train_loss: 0.613  |  valid_loss: 0.425\n",
      "[epoch: 22, i:  8124]  train_loss: 0.633  |  valid_loss: 0.487\n",
      "[epoch: 22, i:  8249]  train_loss: 0.599  |  valid_loss: 0.570\n",
      "[epoch: 22, i:  8374]  train_loss: 0.595  |  valid_loss: 0.520\n",
      "[epoch: 22, i:  8499]  train_loss: 0.584  |  valid_loss: 0.661\n",
      "[epoch: 22, i:  8624]  train_loss: 0.538  |  valid_loss: 0.519\n",
      "[epoch: 22, i:  8749]  train_loss: 0.623  |  valid_loss: 0.770\n",
      "[epoch: 22, i:  8874]  train_loss: 0.604  |  valid_loss: 0.522\n",
      "[epoch: 22, i:  8999]  train_loss: 0.588  |  valid_loss: 0.468\n",
      "[epoch: 22, i:  9124]  train_loss: 0.673  |  valid_loss: 0.458\n",
      "[epoch: 22, i:  9249]  train_loss: 0.623  |  valid_loss: 0.412\n",
      "[epoch: 22, i:  9374]  train_loss: 0.619  |  valid_loss: 0.498\n",
      "[epoch: 22, i:  9499]  train_loss: 0.643  |  valid_loss: 0.537\n",
      "[epoch: 22, i:  9624]  train_loss: 0.614  |  valid_loss: 0.549\n",
      "[epoch: 22, i:  9749]  train_loss: 0.600  |  valid_loss: 0.594\n",
      "[epoch: 22, i:  9874]  train_loss: 0.621  |  valid_loss: 0.637\n",
      "[epoch: 22, i:  9999]  train_loss: 0.608  |  valid_loss: 0.587\n",
      "[epoch: 22, i: 10124]  train_loss: 0.555  |  valid_loss: 0.456\n",
      "[epoch: 22, i: 10249]  train_loss: 0.613  |  valid_loss: 0.520\n",
      "[epoch: 22, i: 10374]  train_loss: 0.650  |  valid_loss: 0.474\n",
      "[epoch: 22, i: 10499]  train_loss: 0.633  |  valid_loss: 0.512\n",
      "[epoch: 22, i: 10624]  train_loss: 0.595  |  valid_loss: 0.632\n",
      "[epoch: 22, i: 10749]  train_loss: 0.665  |  valid_loss: 0.578\n",
      "[epoch: 22, i: 10874]  train_loss: 0.599  |  valid_loss: 0.581\n",
      "[epoch: 22, i: 10999]  train_loss: 0.598  |  valid_loss: 0.542\n",
      "[epoch: 22, i: 11124]  train_loss: 0.627  |  valid_loss: 0.625\n",
      "[epoch: 22, i: 11249]  train_loss: 0.633  |  valid_loss: 0.578\n",
      "[epoch: 22, i: 11374]  train_loss: 0.607  |  valid_loss: 0.456\n",
      "[epoch: 22, i: 11499]  train_loss: 0.622  |  valid_loss: 0.368\n",
      "[epoch: 22, i: 11624]  train_loss: 0.619  |  valid_loss: 0.643\n",
      "[epoch: 22, i: 11749]  train_loss: 0.639  |  valid_loss: 0.624\n",
      "[epoch: 22, i: 11874]  train_loss: 0.601  |  valid_loss: 0.575\n",
      "[epoch: 22, i: 11999]  train_loss: 0.692  |  valid_loss: 0.448\n",
      "[epoch: 22, i: 12124]  train_loss: 0.571  |  valid_loss: 0.436\n",
      "[epoch: 22, i: 12249]  train_loss: 0.549  |  valid_loss: 0.671\n",
      "[epoch: 22, i: 12374]  train_loss: 0.634  |  valid_loss: 0.584\n",
      "[epoch: 22, i: 12499]  train_loss: 0.628  |  valid_loss: 0.485\n",
      "--> [End of epoch 22] train_accuracy: 79.15%  |  valid_accuracy: 80.53%\n",
      "--> [Start of epoch 23]  lr: 0.000044\n",
      "[epoch: 23, i:   124]  train_loss: 0.601  |  valid_loss: 0.617\n",
      "[epoch: 23, i:   249]  train_loss: 0.630  |  valid_loss: 0.588\n",
      "[epoch: 23, i:   374]  train_loss: 0.580  |  valid_loss: 0.559\n",
      "[epoch: 23, i:   499]  train_loss: 0.652  |  valid_loss: 0.685\n",
      "[epoch: 23, i:   624]  train_loss: 0.668  |  valid_loss: 0.618\n",
      "[epoch: 23, i:   749]  train_loss: 0.594  |  valid_loss: 0.326\n",
      "[epoch: 23, i:   874]  train_loss: 0.630  |  valid_loss: 0.548\n",
      "[epoch: 23, i:   999]  train_loss: 0.591  |  valid_loss: 0.600\n",
      "[epoch: 23, i:  1124]  train_loss: 0.611  |  valid_loss: 0.589\n",
      "[epoch: 23, i:  1249]  train_loss: 0.650  |  valid_loss: 0.501\n",
      "[epoch: 23, i:  1374]  train_loss: 0.645  |  valid_loss: 0.518\n",
      "[epoch: 23, i:  1499]  train_loss: 0.604  |  valid_loss: 0.651\n",
      "[epoch: 23, i:  1624]  train_loss: 0.673  |  valid_loss: 0.486\n",
      "[epoch: 23, i:  1749]  train_loss: 0.612  |  valid_loss: 0.556\n",
      "[epoch: 23, i:  1874]  train_loss: 0.680  |  valid_loss: 0.493\n",
      "[epoch: 23, i:  1999]  train_loss: 0.622  |  valid_loss: 0.633\n",
      "[epoch: 23, i:  2124]  train_loss: 0.609  |  valid_loss: 0.555\n",
      "[epoch: 23, i:  2249]  train_loss: 0.607  |  valid_loss: 0.694\n",
      "[epoch: 23, i:  2374]  train_loss: 0.631  |  valid_loss: 0.598\n",
      "[epoch: 23, i:  2499]  train_loss: 0.587  |  valid_loss: 0.851\n",
      "[epoch: 23, i:  2624]  train_loss: 0.591  |  valid_loss: 0.672\n",
      "[epoch: 23, i:  2749]  train_loss: 0.628  |  valid_loss: 0.534\n",
      "[epoch: 23, i:  2874]  train_loss: 0.624  |  valid_loss: 0.672\n",
      "[epoch: 23, i:  2999]  train_loss: 0.602  |  valid_loss: 0.575\n",
      "[epoch: 23, i:  3124]  train_loss: 0.615  |  valid_loss: 0.632\n",
      "[epoch: 23, i:  3249]  train_loss: 0.657  |  valid_loss: 0.816\n",
      "[epoch: 23, i:  3374]  train_loss: 0.602  |  valid_loss: 0.508\n",
      "[epoch: 23, i:  3499]  train_loss: 0.669  |  valid_loss: 0.580\n",
      "[epoch: 23, i:  3624]  train_loss: 0.647  |  valid_loss: 0.692\n",
      "[epoch: 23, i:  3749]  train_loss: 0.621  |  valid_loss: 0.625\n",
      "[epoch: 23, i:  3874]  train_loss: 0.644  |  valid_loss: 0.533\n",
      "[epoch: 23, i:  3999]  train_loss: 0.632  |  valid_loss: 0.578\n",
      "[epoch: 23, i:  4124]  train_loss: 0.601  |  valid_loss: 0.564\n",
      "[epoch: 23, i:  4249]  train_loss: 0.589  |  valid_loss: 0.605\n",
      "[epoch: 23, i:  4374]  train_loss: 0.617  |  valid_loss: 0.744\n",
      "[epoch: 23, i:  4499]  train_loss: 0.580  |  valid_loss: 0.438\n",
      "[epoch: 23, i:  4624]  train_loss: 0.581  |  valid_loss: 0.804\n",
      "[epoch: 23, i:  4749]  train_loss: 0.553  |  valid_loss: 0.536\n",
      "[epoch: 23, i:  4874]  train_loss: 0.639  |  valid_loss: 0.455\n",
      "[epoch: 23, i:  4999]  train_loss: 0.600  |  valid_loss: 0.493\n",
      "[epoch: 23, i:  5124]  train_loss: 0.652  |  valid_loss: 0.515\n",
      "[epoch: 23, i:  5249]  train_loss: 0.622  |  valid_loss: 0.577\n",
      "[epoch: 23, i:  5374]  train_loss: 0.654  |  valid_loss: 0.361\n",
      "[epoch: 23, i:  5499]  train_loss: 0.607  |  valid_loss: 0.581\n",
      "[epoch: 23, i:  5624]  train_loss: 0.656  |  valid_loss: 0.596\n",
      "[epoch: 23, i:  5749]  train_loss: 0.612  |  valid_loss: 0.495\n",
      "[epoch: 23, i:  5874]  train_loss: 0.580  |  valid_loss: 0.446\n",
      "[epoch: 23, i:  5999]  train_loss: 0.632  |  valid_loss: 0.571\n",
      "[epoch: 23, i:  6124]  train_loss: 0.617  |  valid_loss: 0.457\n",
      "[epoch: 23, i:  6249]  train_loss: 0.608  |  valid_loss: 0.726\n",
      "[epoch: 23, i:  6374]  train_loss: 0.644  |  valid_loss: 0.518\n",
      "[epoch: 23, i:  6499]  train_loss: 0.633  |  valid_loss: 0.617\n",
      "[epoch: 23, i:  6624]  train_loss: 0.634  |  valid_loss: 0.529\n",
      "[epoch: 23, i:  6749]  train_loss: 0.588  |  valid_loss: 0.457\n",
      "[epoch: 23, i:  6874]  train_loss: 0.664  |  valid_loss: 0.581\n",
      "[epoch: 23, i:  6999]  train_loss: 0.623  |  valid_loss: 0.670\n",
      "[epoch: 23, i:  7124]  train_loss: 0.642  |  valid_loss: 0.668\n",
      "[epoch: 23, i:  7249]  train_loss: 0.635  |  valid_loss: 0.462\n",
      "[epoch: 23, i:  7374]  train_loss: 0.640  |  valid_loss: 0.642\n",
      "[epoch: 23, i:  7499]  train_loss: 0.574  |  valid_loss: 0.550\n",
      "[epoch: 23, i:  7624]  train_loss: 0.658  |  valid_loss: 0.452\n",
      "[epoch: 23, i:  7749]  train_loss: 0.585  |  valid_loss: 0.503\n",
      "[epoch: 23, i:  7874]  train_loss: 0.620  |  valid_loss: 0.493\n",
      "[epoch: 23, i:  7999]  train_loss: 0.581  |  valid_loss: 0.409\n",
      "[epoch: 23, i:  8124]  train_loss: 0.582  |  valid_loss: 0.469\n",
      "[epoch: 23, i:  8249]  train_loss: 0.551  |  valid_loss: 0.580\n",
      "[epoch: 23, i:  8374]  train_loss: 0.609  |  valid_loss: 0.497\n",
      "[epoch: 23, i:  8499]  train_loss: 0.653  |  valid_loss: 0.582\n",
      "[epoch: 23, i:  8624]  train_loss: 0.625  |  valid_loss: 0.552\n",
      "[epoch: 23, i:  8749]  train_loss: 0.640  |  valid_loss: 0.752\n",
      "[epoch: 23, i:  8874]  train_loss: 0.661  |  valid_loss: 0.508\n",
      "[epoch: 23, i:  8999]  train_loss: 0.585  |  valid_loss: 0.460\n",
      "[epoch: 23, i:  9124]  train_loss: 0.580  |  valid_loss: 0.479\n",
      "[epoch: 23, i:  9249]  train_loss: 0.557  |  valid_loss: 0.415\n",
      "[epoch: 23, i:  9374]  train_loss: 0.648  |  valid_loss: 0.500\n",
      "[epoch: 23, i:  9499]  train_loss: 0.567  |  valid_loss: 0.512\n",
      "[epoch: 23, i:  9624]  train_loss: 0.658  |  valid_loss: 0.534\n",
      "[epoch: 23, i:  9749]  train_loss: 0.618  |  valid_loss: 0.593\n",
      "[epoch: 23, i:  9874]  train_loss: 0.619  |  valid_loss: 0.598\n",
      "[epoch: 23, i:  9999]  train_loss: 0.673  |  valid_loss: 0.611\n",
      "[epoch: 23, i: 10124]  train_loss: 0.615  |  valid_loss: 0.505\n",
      "[epoch: 23, i: 10249]  train_loss: 0.618  |  valid_loss: 0.515\n",
      "[epoch: 23, i: 10374]  train_loss: 0.643  |  valid_loss: 0.510\n",
      "[epoch: 23, i: 10499]  train_loss: 0.628  |  valid_loss: 0.468\n",
      "[epoch: 23, i: 10624]  train_loss: 0.692  |  valid_loss: 0.639\n",
      "[epoch: 23, i: 10749]  train_loss: 0.645  |  valid_loss: 0.561\n",
      "[epoch: 23, i: 10874]  train_loss: 0.559  |  valid_loss: 0.503\n",
      "[epoch: 23, i: 10999]  train_loss: 0.599  |  valid_loss: 0.539\n",
      "[epoch: 23, i: 11124]  train_loss: 0.618  |  valid_loss: 0.625\n",
      "[epoch: 23, i: 11249]  train_loss: 0.580  |  valid_loss: 0.591\n",
      "[epoch: 23, i: 11374]  train_loss: 0.653  |  valid_loss: 0.447\n",
      "[epoch: 23, i: 11499]  train_loss: 0.588  |  valid_loss: 0.372\n",
      "[epoch: 23, i: 11624]  train_loss: 0.606  |  valid_loss: 0.638\n",
      "[epoch: 23, i: 11749]  train_loss: 0.636  |  valid_loss: 0.616\n",
      "[epoch: 23, i: 11874]  train_loss: 0.693  |  valid_loss: 0.572\n",
      "[epoch: 23, i: 11999]  train_loss: 0.612  |  valid_loss: 0.479\n",
      "[epoch: 23, i: 12124]  train_loss: 0.528  |  valid_loss: 0.423\n",
      "[epoch: 23, i: 12249]  train_loss: 0.579  |  valid_loss: 0.690\n",
      "[epoch: 23, i: 12374]  train_loss: 0.589  |  valid_loss: 0.586\n",
      "[epoch: 23, i: 12499]  train_loss: 0.621  |  valid_loss: 0.479\n",
      "--> [End of epoch 23] train_accuracy: 79.07%  |  valid_accuracy: 80.82%\n",
      "--> [Start of epoch 24]  lr: 0.000040\n",
      "[epoch: 24, i:   124]  train_loss: 0.611  |  valid_loss: 0.634\n",
      "[epoch: 24, i:   249]  train_loss: 0.581  |  valid_loss: 0.617\n",
      "[epoch: 24, i:   374]  train_loss: 0.613  |  valid_loss: 0.558\n",
      "[epoch: 24, i:   499]  train_loss: 0.612  |  valid_loss: 0.658\n",
      "[epoch: 24, i:   624]  train_loss: 0.650  |  valid_loss: 0.587\n",
      "[epoch: 24, i:   749]  train_loss: 0.640  |  valid_loss: 0.325\n",
      "[epoch: 24, i:   874]  train_loss: 0.617  |  valid_loss: 0.587\n",
      "[epoch: 24, i:   999]  train_loss: 0.600  |  valid_loss: 0.600\n",
      "[epoch: 24, i:  1124]  train_loss: 0.591  |  valid_loss: 0.581\n",
      "[epoch: 24, i:  1249]  train_loss: 0.606  |  valid_loss: 0.520\n",
      "[epoch: 24, i:  1374]  train_loss: 0.545  |  valid_loss: 0.523\n",
      "[epoch: 24, i:  1499]  train_loss: 0.629  |  valid_loss: 0.653\n",
      "[epoch: 24, i:  1624]  train_loss: 0.614  |  valid_loss: 0.533\n",
      "[epoch: 24, i:  1749]  train_loss: 0.614  |  valid_loss: 0.548\n",
      "[epoch: 24, i:  1874]  train_loss: 0.544  |  valid_loss: 0.508\n",
      "[epoch: 24, i:  1999]  train_loss: 0.616  |  valid_loss: 0.671\n",
      "[epoch: 24, i:  2124]  train_loss: 0.594  |  valid_loss: 0.569\n",
      "[epoch: 24, i:  2249]  train_loss: 0.696  |  valid_loss: 0.669\n",
      "[epoch: 24, i:  2374]  train_loss: 0.610  |  valid_loss: 0.556\n",
      "[epoch: 24, i:  2499]  train_loss: 0.596  |  valid_loss: 0.812\n",
      "[epoch: 24, i:  2624]  train_loss: 0.646  |  valid_loss: 0.733\n",
      "[epoch: 24, i:  2749]  train_loss: 0.551  |  valid_loss: 0.541\n",
      "[epoch: 24, i:  2874]  train_loss: 0.596  |  valid_loss: 0.698\n",
      "[epoch: 24, i:  2999]  train_loss: 0.544  |  valid_loss: 0.564\n",
      "[epoch: 24, i:  3124]  train_loss: 0.608  |  valid_loss: 0.632\n",
      "[epoch: 24, i:  3249]  train_loss: 0.622  |  valid_loss: 0.807\n",
      "[epoch: 24, i:  3374]  train_loss: 0.616  |  valid_loss: 0.482\n",
      "[epoch: 24, i:  3499]  train_loss: 0.614  |  valid_loss: 0.599\n",
      "[epoch: 24, i:  3624]  train_loss: 0.591  |  valid_loss: 0.657\n",
      "[epoch: 24, i:  3749]  train_loss: 0.630  |  valid_loss: 0.613\n",
      "[epoch: 24, i:  3874]  train_loss: 0.635  |  valid_loss: 0.565\n",
      "[epoch: 24, i:  3999]  train_loss: 0.579  |  valid_loss: 0.596\n",
      "[epoch: 24, i:  4124]  train_loss: 0.643  |  valid_loss: 0.541\n",
      "[epoch: 24, i:  4249]  train_loss: 0.595  |  valid_loss: 0.626\n",
      "[epoch: 24, i:  4374]  train_loss: 0.617  |  valid_loss: 0.764\n",
      "[epoch: 24, i:  4499]  train_loss: 0.577  |  valid_loss: 0.444\n",
      "[epoch: 24, i:  4624]  train_loss: 0.619  |  valid_loss: 0.805\n",
      "[epoch: 24, i:  4749]  train_loss: 0.616  |  valid_loss: 0.553\n",
      "[epoch: 24, i:  4874]  train_loss: 0.612  |  valid_loss: 0.443\n",
      "[epoch: 24, i:  4999]  train_loss: 0.574  |  valid_loss: 0.475\n",
      "[epoch: 24, i:  5124]  train_loss: 0.612  |  valid_loss: 0.513\n",
      "[epoch: 24, i:  5249]  train_loss: 0.580  |  valid_loss: 0.597\n",
      "[epoch: 24, i:  5374]  train_loss: 0.654  |  valid_loss: 0.371\n",
      "[epoch: 24, i:  5499]  train_loss: 0.627  |  valid_loss: 0.551\n",
      "[epoch: 24, i:  5624]  train_loss: 0.670  |  valid_loss: 0.616\n",
      "[epoch: 24, i:  5749]  train_loss: 0.617  |  valid_loss: 0.498\n",
      "[epoch: 24, i:  5874]  train_loss: 0.617  |  valid_loss: 0.452\n",
      "[epoch: 24, i:  5999]  train_loss: 0.562  |  valid_loss: 0.576\n",
      "[epoch: 24, i:  6124]  train_loss: 0.626  |  valid_loss: 0.445\n",
      "[epoch: 24, i:  6249]  train_loss: 0.603  |  valid_loss: 0.710\n",
      "[epoch: 24, i:  6374]  train_loss: 0.595  |  valid_loss: 0.502\n",
      "[epoch: 24, i:  6499]  train_loss: 0.599  |  valid_loss: 0.586\n",
      "[epoch: 24, i:  6624]  train_loss: 0.581  |  valid_loss: 0.476\n",
      "[epoch: 24, i:  6749]  train_loss: 0.618  |  valid_loss: 0.460\n",
      "[epoch: 24, i:  6874]  train_loss: 0.677  |  valid_loss: 0.565\n",
      "[epoch: 24, i:  6999]  train_loss: 0.630  |  valid_loss: 0.675\n",
      "[epoch: 24, i:  7124]  train_loss: 0.604  |  valid_loss: 0.673\n",
      "[epoch: 24, i:  7249]  train_loss: 0.603  |  valid_loss: 0.487\n",
      "[epoch: 24, i:  7374]  train_loss: 0.594  |  valid_loss: 0.615\n",
      "[epoch: 24, i:  7499]  train_loss: 0.602  |  valid_loss: 0.541\n",
      "[epoch: 24, i:  7624]  train_loss: 0.627  |  valid_loss: 0.489\n",
      "[epoch: 24, i:  7749]  train_loss: 0.653  |  valid_loss: 0.500\n",
      "[epoch: 24, i:  7874]  train_loss: 0.608  |  valid_loss: 0.471\n",
      "[epoch: 24, i:  7999]  train_loss: 0.604  |  valid_loss: 0.395\n",
      "[epoch: 24, i:  8124]  train_loss: 0.577  |  valid_loss: 0.489\n",
      "[epoch: 24, i:  8249]  train_loss: 0.558  |  valid_loss: 0.616\n",
      "[epoch: 24, i:  8374]  train_loss: 0.586  |  valid_loss: 0.485\n",
      "[epoch: 24, i:  8499]  train_loss: 0.594  |  valid_loss: 0.651\n",
      "[epoch: 24, i:  8624]  train_loss: 0.575  |  valid_loss: 0.499\n",
      "[epoch: 24, i:  8749]  train_loss: 0.637  |  valid_loss: 0.728\n",
      "[epoch: 24, i:  8874]  train_loss: 0.617  |  valid_loss: 0.543\n",
      "[epoch: 24, i:  8999]  train_loss: 0.628  |  valid_loss: 0.479\n",
      "[epoch: 24, i:  9124]  train_loss: 0.637  |  valid_loss: 0.446\n",
      "[epoch: 24, i:  9249]  train_loss: 0.668  |  valid_loss: 0.413\n",
      "[epoch: 24, i:  9374]  train_loss: 0.597  |  valid_loss: 0.494\n",
      "[epoch: 24, i:  9499]  train_loss: 0.605  |  valid_loss: 0.518\n",
      "[epoch: 24, i:  9624]  train_loss: 0.558  |  valid_loss: 0.542\n",
      "[epoch: 24, i:  9749]  train_loss: 0.565  |  valid_loss: 0.610\n",
      "[epoch: 24, i:  9874]  train_loss: 0.590  |  valid_loss: 0.630\n",
      "[epoch: 24, i:  9999]  train_loss: 0.632  |  valid_loss: 0.596\n",
      "[epoch: 24, i: 10124]  train_loss: 0.571  |  valid_loss: 0.471\n",
      "[epoch: 24, i: 10249]  train_loss: 0.582  |  valid_loss: 0.538\n",
      "[epoch: 24, i: 10374]  train_loss: 0.538  |  valid_loss: 0.485\n",
      "[epoch: 24, i: 10499]  train_loss: 0.546  |  valid_loss: 0.543\n",
      "[epoch: 24, i: 10624]  train_loss: 0.651  |  valid_loss: 0.612\n",
      "[epoch: 24, i: 10749]  train_loss: 0.635  |  valid_loss: 0.553\n",
      "[epoch: 24, i: 10874]  train_loss: 0.616  |  valid_loss: 0.565\n",
      "[epoch: 24, i: 10999]  train_loss: 0.616  |  valid_loss: 0.570\n",
      "[epoch: 24, i: 11124]  train_loss: 0.615  |  valid_loss: 0.612\n",
      "[epoch: 24, i: 11249]  train_loss: 0.652  |  valid_loss: 0.594\n",
      "[epoch: 24, i: 11374]  train_loss: 0.613  |  valid_loss: 0.434\n",
      "[epoch: 24, i: 11499]  train_loss: 0.635  |  valid_loss: 0.388\n",
      "[epoch: 24, i: 11624]  train_loss: 0.605  |  valid_loss: 0.631\n",
      "[epoch: 24, i: 11749]  train_loss: 0.585  |  valid_loss: 0.623\n",
      "[epoch: 24, i: 11874]  train_loss: 0.638  |  valid_loss: 0.596\n",
      "[epoch: 24, i: 11999]  train_loss: 0.647  |  valid_loss: 0.498\n",
      "[epoch: 24, i: 12124]  train_loss: 0.612  |  valid_loss: 0.468\n",
      "[epoch: 24, i: 12249]  train_loss: 0.586  |  valid_loss: 0.684\n",
      "[epoch: 24, i: 12374]  train_loss: 0.616  |  valid_loss: 0.585\n",
      "[epoch: 24, i: 12499]  train_loss: 0.635  |  valid_loss: 0.454\n",
      "--> [End of epoch 24] train_accuracy: 79.12%  |  valid_accuracy: 80.81%\n",
      "--> [Start of epoch 25]  lr: 0.000036\n",
      "[epoch: 25, i:   124]  train_loss: 0.607  |  valid_loss: 0.637\n",
      "[epoch: 25, i:   249]  train_loss: 0.641  |  valid_loss: 0.622\n",
      "[epoch: 25, i:   374]  train_loss: 0.641  |  valid_loss: 0.564\n",
      "[epoch: 25, i:   499]  train_loss: 0.609  |  valid_loss: 0.637\n",
      "[epoch: 25, i:   624]  train_loss: 0.580  |  valid_loss: 0.589\n",
      "[epoch: 25, i:   749]  train_loss: 0.597  |  valid_loss: 0.343\n",
      "[epoch: 25, i:   874]  train_loss: 0.577  |  valid_loss: 0.563\n",
      "[epoch: 25, i:   999]  train_loss: 0.618  |  valid_loss: 0.585\n",
      "[epoch: 25, i:  1124]  train_loss: 0.660  |  valid_loss: 0.570\n",
      "[epoch: 25, i:  1249]  train_loss: 0.622  |  valid_loss: 0.488\n",
      "[epoch: 25, i:  1374]  train_loss: 0.609  |  valid_loss: 0.551\n",
      "[epoch: 25, i:  1499]  train_loss: 0.623  |  valid_loss: 0.680\n",
      "[epoch: 25, i:  1624]  train_loss: 0.567  |  valid_loss: 0.523\n",
      "[epoch: 25, i:  1749]  train_loss: 0.608  |  valid_loss: 0.560\n",
      "[epoch: 25, i:  1874]  train_loss: 0.583  |  valid_loss: 0.524\n",
      "[epoch: 25, i:  1999]  train_loss: 0.598  |  valid_loss: 0.653\n",
      "[epoch: 25, i:  2124]  train_loss: 0.569  |  valid_loss: 0.541\n",
      "[epoch: 25, i:  2249]  train_loss: 0.576  |  valid_loss: 0.656\n",
      "[epoch: 25, i:  2374]  train_loss: 0.651  |  valid_loss: 0.570\n",
      "[epoch: 25, i:  2499]  train_loss: 0.649  |  valid_loss: 0.796\n",
      "[epoch: 25, i:  2624]  train_loss: 0.630  |  valid_loss: 0.710\n",
      "[epoch: 25, i:  2749]  train_loss: 0.585  |  valid_loss: 0.530\n",
      "[epoch: 25, i:  2874]  train_loss: 0.640  |  valid_loss: 0.663\n",
      "[epoch: 25, i:  2999]  train_loss: 0.623  |  valid_loss: 0.546\n",
      "[epoch: 25, i:  3124]  train_loss: 0.613  |  valid_loss: 0.620\n",
      "[epoch: 25, i:  3249]  train_loss: 0.668  |  valid_loss: 0.818\n",
      "[epoch: 25, i:  3374]  train_loss: 0.587  |  valid_loss: 0.464\n",
      "[epoch: 25, i:  3499]  train_loss: 0.605  |  valid_loss: 0.631\n",
      "[epoch: 25, i:  3624]  train_loss: 0.634  |  valid_loss: 0.648\n",
      "[epoch: 25, i:  3749]  train_loss: 0.581  |  valid_loss: 0.583\n",
      "[epoch: 25, i:  3874]  train_loss: 0.634  |  valid_loss: 0.547\n",
      "[epoch: 25, i:  3999]  train_loss: 0.630  |  valid_loss: 0.598\n",
      "[epoch: 25, i:  4124]  train_loss: 0.583  |  valid_loss: 0.530\n",
      "[epoch: 25, i:  4249]  train_loss: 0.574  |  valid_loss: 0.605\n",
      "[epoch: 25, i:  4374]  train_loss: 0.582  |  valid_loss: 0.762\n",
      "[epoch: 25, i:  4499]  train_loss: 0.650  |  valid_loss: 0.437\n",
      "[epoch: 25, i:  4624]  train_loss: 0.594  |  valid_loss: 0.812\n",
      "[epoch: 25, i:  4749]  train_loss: 0.638  |  valid_loss: 0.545\n",
      "[epoch: 25, i:  4874]  train_loss: 0.597  |  valid_loss: 0.465\n",
      "[epoch: 25, i:  4999]  train_loss: 0.649  |  valid_loss: 0.469\n",
      "[epoch: 25, i:  5124]  train_loss: 0.623  |  valid_loss: 0.499\n",
      "[epoch: 25, i:  5249]  train_loss: 0.589  |  valid_loss: 0.547\n",
      "[epoch: 25, i:  5374]  train_loss: 0.641  |  valid_loss: 0.357\n",
      "[epoch: 25, i:  5499]  train_loss: 0.563  |  valid_loss: 0.557\n",
      "[epoch: 25, i:  5624]  train_loss: 0.580  |  valid_loss: 0.591\n",
      "[epoch: 25, i:  5749]  train_loss: 0.599  |  valid_loss: 0.463\n",
      "[epoch: 25, i:  5874]  train_loss: 0.589  |  valid_loss: 0.433\n",
      "[epoch: 25, i:  5999]  train_loss: 0.585  |  valid_loss: 0.591\n",
      "[epoch: 25, i:  6124]  train_loss: 0.565  |  valid_loss: 0.451\n",
      "[epoch: 25, i:  6249]  train_loss: 0.622  |  valid_loss: 0.702\n",
      "[epoch: 25, i:  6374]  train_loss: 0.568  |  valid_loss: 0.496\n",
      "[epoch: 25, i:  6499]  train_loss: 0.587  |  valid_loss: 0.572\n",
      "[epoch: 25, i:  6624]  train_loss: 0.527  |  valid_loss: 0.516\n",
      "[epoch: 25, i:  6749]  train_loss: 0.655  |  valid_loss: 0.445\n",
      "[epoch: 25, i:  6874]  train_loss: 0.582  |  valid_loss: 0.605\n",
      "[epoch: 25, i:  6999]  train_loss: 0.609  |  valid_loss: 0.665\n",
      "[epoch: 25, i:  7124]  train_loss: 0.575  |  valid_loss: 0.671\n",
      "[epoch: 25, i:  7249]  train_loss: 0.582  |  valid_loss: 0.468\n",
      "[epoch: 25, i:  7374]  train_loss: 0.598  |  valid_loss: 0.624\n",
      "[epoch: 25, i:  7499]  train_loss: 0.620  |  valid_loss: 0.536\n",
      "[epoch: 25, i:  7624]  train_loss: 0.613  |  valid_loss: 0.467\n",
      "[epoch: 25, i:  7749]  train_loss: 0.568  |  valid_loss: 0.503\n",
      "[epoch: 25, i:  7874]  train_loss: 0.612  |  valid_loss: 0.456\n",
      "[epoch: 25, i:  7999]  train_loss: 0.617  |  valid_loss: 0.410\n",
      "[epoch: 25, i:  8124]  train_loss: 0.599  |  valid_loss: 0.511\n",
      "[epoch: 25, i:  8249]  train_loss: 0.670  |  valid_loss: 0.558\n",
      "[epoch: 25, i:  8374]  train_loss: 0.568  |  valid_loss: 0.486\n",
      "[epoch: 25, i:  8499]  train_loss: 0.573  |  valid_loss: 0.618\n",
      "[epoch: 25, i:  8624]  train_loss: 0.678  |  valid_loss: 0.518\n",
      "[epoch: 25, i:  8749]  train_loss: 0.609  |  valid_loss: 0.744\n",
      "[epoch: 25, i:  8874]  train_loss: 0.598  |  valid_loss: 0.524\n",
      "[epoch: 25, i:  8999]  train_loss: 0.667  |  valid_loss: 0.468\n",
      "[epoch: 25, i:  9124]  train_loss: 0.591  |  valid_loss: 0.442\n",
      "[epoch: 25, i:  9249]  train_loss: 0.596  |  valid_loss: 0.440\n",
      "[epoch: 25, i:  9374]  train_loss: 0.605  |  valid_loss: 0.499\n",
      "[epoch: 25, i:  9499]  train_loss: 0.648  |  valid_loss: 0.549\n",
      "[epoch: 25, i:  9624]  train_loss: 0.596  |  valid_loss: 0.513\n",
      "[epoch: 25, i:  9749]  train_loss: 0.608  |  valid_loss: 0.626\n",
      "[epoch: 25, i:  9874]  train_loss: 0.617  |  valid_loss: 0.624\n",
      "[epoch: 25, i:  9999]  train_loss: 0.555  |  valid_loss: 0.604\n",
      "[epoch: 25, i: 10124]  train_loss: 0.605  |  valid_loss: 0.420\n",
      "[epoch: 25, i: 10249]  train_loss: 0.611  |  valid_loss: 0.519\n",
      "[epoch: 25, i: 10374]  train_loss: 0.662  |  valid_loss: 0.478\n",
      "[epoch: 25, i: 10499]  train_loss: 0.618  |  valid_loss: 0.504\n",
      "[epoch: 25, i: 10624]  train_loss: 0.636  |  valid_loss: 0.624\n",
      "[epoch: 25, i: 10749]  train_loss: 0.644  |  valid_loss: 0.541\n",
      "[epoch: 25, i: 10874]  train_loss: 0.625  |  valid_loss: 0.582\n",
      "[epoch: 25, i: 10999]  train_loss: 0.614  |  valid_loss: 0.554\n",
      "[epoch: 25, i: 11124]  train_loss: 0.660  |  valid_loss: 0.589\n",
      "[epoch: 25, i: 11249]  train_loss: 0.612  |  valid_loss: 0.600\n",
      "[epoch: 25, i: 11374]  train_loss: 0.606  |  valid_loss: 0.452\n",
      "[epoch: 25, i: 11499]  train_loss: 0.641  |  valid_loss: 0.384\n",
      "[epoch: 25, i: 11624]  train_loss: 0.644  |  valid_loss: 0.637\n",
      "[epoch: 25, i: 11749]  train_loss: 0.640  |  valid_loss: 0.622\n",
      "[epoch: 25, i: 11874]  train_loss: 0.601  |  valid_loss: 0.550\n",
      "[epoch: 25, i: 11999]  train_loss: 0.549  |  valid_loss: 0.511\n",
      "[epoch: 25, i: 12124]  train_loss: 0.616  |  valid_loss: 0.441\n",
      "[epoch: 25, i: 12249]  train_loss: 0.606  |  valid_loss: 0.699\n",
      "[epoch: 25, i: 12374]  train_loss: 0.602  |  valid_loss: 0.586\n",
      "[epoch: 25, i: 12499]  train_loss: 0.540  |  valid_loss: 0.489\n",
      "--> [End of epoch 25] train_accuracy: 79.36%  |  valid_accuracy: 80.96%\n",
      "--> [Start of epoch 26]  lr: 0.000032\n",
      "[epoch: 26, i:   124]  train_loss: 0.638  |  valid_loss: 0.657\n",
      "[epoch: 26, i:   249]  train_loss: 0.556  |  valid_loss: 0.592\n",
      "[epoch: 26, i:   374]  train_loss: 0.592  |  valid_loss: 0.566\n",
      "[epoch: 26, i:   499]  train_loss: 0.637  |  valid_loss: 0.662\n",
      "[epoch: 26, i:   624]  train_loss: 0.637  |  valid_loss: 0.560\n",
      "[epoch: 26, i:   749]  train_loss: 0.578  |  valid_loss: 0.339\n",
      "[epoch: 26, i:   874]  train_loss: 0.653  |  valid_loss: 0.587\n",
      "[epoch: 26, i:   999]  train_loss: 0.605  |  valid_loss: 0.607\n",
      "[epoch: 26, i:  1124]  train_loss: 0.627  |  valid_loss: 0.560\n",
      "[epoch: 26, i:  1249]  train_loss: 0.622  |  valid_loss: 0.501\n",
      "[epoch: 26, i:  1374]  train_loss: 0.612  |  valid_loss: 0.515\n",
      "[epoch: 26, i:  1499]  train_loss: 0.676  |  valid_loss: 0.652\n",
      "[epoch: 26, i:  1624]  train_loss: 0.574  |  valid_loss: 0.552\n",
      "[epoch: 26, i:  1749]  train_loss: 0.630  |  valid_loss: 0.564\n",
      "[epoch: 26, i:  1874]  train_loss: 0.660  |  valid_loss: 0.498\n",
      "[epoch: 26, i:  1999]  train_loss: 0.583  |  valid_loss: 0.630\n",
      "[epoch: 26, i:  2124]  train_loss: 0.545  |  valid_loss: 0.516\n",
      "[epoch: 26, i:  2249]  train_loss: 0.608  |  valid_loss: 0.648\n",
      "[epoch: 26, i:  2374]  train_loss: 0.578  |  valid_loss: 0.581\n",
      "[epoch: 26, i:  2499]  train_loss: 0.606  |  valid_loss: 0.811\n",
      "[epoch: 26, i:  2624]  train_loss: 0.559  |  valid_loss: 0.699\n",
      "[epoch: 26, i:  2749]  train_loss: 0.599  |  valid_loss: 0.532\n",
      "[epoch: 26, i:  2874]  train_loss: 0.647  |  valid_loss: 0.693\n",
      "[epoch: 26, i:  2999]  train_loss: 0.667  |  valid_loss: 0.571\n",
      "[epoch: 26, i:  3124]  train_loss: 0.648  |  valid_loss: 0.634\n",
      "[epoch: 26, i:  3249]  train_loss: 0.575  |  valid_loss: 0.829\n",
      "[epoch: 26, i:  3374]  train_loss: 0.619  |  valid_loss: 0.474\n",
      "[epoch: 26, i:  3499]  train_loss: 0.601  |  valid_loss: 0.645\n",
      "[epoch: 26, i:  3624]  train_loss: 0.577  |  valid_loss: 0.669\n",
      "[epoch: 26, i:  3749]  train_loss: 0.567  |  valid_loss: 0.582\n",
      "[epoch: 26, i:  3874]  train_loss: 0.641  |  valid_loss: 0.536\n",
      "[epoch: 26, i:  3999]  train_loss: 0.568  |  valid_loss: 0.601\n",
      "[epoch: 26, i:  4124]  train_loss: 0.632  |  valid_loss: 0.558\n",
      "[epoch: 26, i:  4249]  train_loss: 0.617  |  valid_loss: 0.622\n",
      "[epoch: 26, i:  4374]  train_loss: 0.579  |  valid_loss: 0.727\n",
      "[epoch: 26, i:  4499]  train_loss: 0.593  |  valid_loss: 0.449\n",
      "[epoch: 26, i:  4624]  train_loss: 0.583  |  valid_loss: 0.803\n",
      "[epoch: 26, i:  4749]  train_loss: 0.602  |  valid_loss: 0.529\n",
      "[epoch: 26, i:  4874]  train_loss: 0.661  |  valid_loss: 0.451\n",
      "[epoch: 26, i:  4999]  train_loss: 0.611  |  valid_loss: 0.485\n",
      "[epoch: 26, i:  5124]  train_loss: 0.696  |  valid_loss: 0.493\n",
      "[epoch: 26, i:  5249]  train_loss: 0.598  |  valid_loss: 0.559\n",
      "[epoch: 26, i:  5374]  train_loss: 0.611  |  valid_loss: 0.381\n",
      "[epoch: 26, i:  5499]  train_loss: 0.651  |  valid_loss: 0.557\n",
      "[epoch: 26, i:  5624]  train_loss: 0.578  |  valid_loss: 0.619\n",
      "[epoch: 26, i:  5749]  train_loss: 0.557  |  valid_loss: 0.485\n",
      "[epoch: 26, i:  5874]  train_loss: 0.626  |  valid_loss: 0.444\n",
      "[epoch: 26, i:  5999]  train_loss: 0.525  |  valid_loss: 0.591\n",
      "[epoch: 26, i:  6124]  train_loss: 0.558  |  valid_loss: 0.440\n",
      "[epoch: 26, i:  6249]  train_loss: 0.606  |  valid_loss: 0.694\n",
      "[epoch: 26, i:  6374]  train_loss: 0.604  |  valid_loss: 0.532\n",
      "[epoch: 26, i:  6499]  train_loss: 0.622  |  valid_loss: 0.558\n",
      "[epoch: 26, i:  6624]  train_loss: 0.582  |  valid_loss: 0.490\n",
      "[epoch: 26, i:  6749]  train_loss: 0.638  |  valid_loss: 0.487\n",
      "[epoch: 26, i:  6874]  train_loss: 0.603  |  valid_loss: 0.586\n",
      "[epoch: 26, i:  6999]  train_loss: 0.589  |  valid_loss: 0.666\n",
      "[epoch: 26, i:  7124]  train_loss: 0.586  |  valid_loss: 0.698\n",
      "[epoch: 26, i:  7249]  train_loss: 0.640  |  valid_loss: 0.467\n",
      "[epoch: 26, i:  7374]  train_loss: 0.636  |  valid_loss: 0.653\n",
      "[epoch: 26, i:  7499]  train_loss: 0.588  |  valid_loss: 0.518\n",
      "[epoch: 26, i:  7624]  train_loss: 0.633  |  valid_loss: 0.467\n",
      "[epoch: 26, i:  7749]  train_loss: 0.551  |  valid_loss: 0.509\n",
      "[epoch: 26, i:  7874]  train_loss: 0.622  |  valid_loss: 0.480\n",
      "[epoch: 26, i:  7999]  train_loss: 0.554  |  valid_loss: 0.415\n",
      "[epoch: 26, i:  8124]  train_loss: 0.689  |  valid_loss: 0.455\n",
      "[epoch: 26, i:  8249]  train_loss: 0.549  |  valid_loss: 0.539\n",
      "[epoch: 26, i:  8374]  train_loss: 0.561  |  valid_loss: 0.504\n",
      "[epoch: 26, i:  8499]  train_loss: 0.615  |  valid_loss: 0.617\n",
      "[epoch: 26, i:  8624]  train_loss: 0.669  |  valid_loss: 0.580\n",
      "[epoch: 26, i:  8749]  train_loss: 0.609  |  valid_loss: 0.730\n",
      "[epoch: 26, i:  8874]  train_loss: 0.633  |  valid_loss: 0.511\n",
      "[epoch: 26, i:  8999]  train_loss: 0.621  |  valid_loss: 0.458\n",
      "[epoch: 26, i:  9124]  train_loss: 0.666  |  valid_loss: 0.447\n",
      "[epoch: 26, i:  9249]  train_loss: 0.561  |  valid_loss: 0.441\n",
      "[epoch: 26, i:  9374]  train_loss: 0.624  |  valid_loss: 0.502\n",
      "[epoch: 26, i:  9499]  train_loss: 0.620  |  valid_loss: 0.495\n",
      "[epoch: 26, i:  9624]  train_loss: 0.621  |  valid_loss: 0.551\n",
      "[epoch: 26, i:  9749]  train_loss: 0.594  |  valid_loss: 0.606\n",
      "[epoch: 26, i:  9874]  train_loss: 0.653  |  valid_loss: 0.607\n",
      "[epoch: 26, i:  9999]  train_loss: 0.645  |  valid_loss: 0.580\n",
      "[epoch: 26, i: 10124]  train_loss: 0.626  |  valid_loss: 0.472\n",
      "[epoch: 26, i: 10249]  train_loss: 0.581  |  valid_loss: 0.499\n",
      "[epoch: 26, i: 10374]  train_loss: 0.609  |  valid_loss: 0.506\n",
      "[epoch: 26, i: 10499]  train_loss: 0.596  |  valid_loss: 0.517\n",
      "[epoch: 26, i: 10624]  train_loss: 0.615  |  valid_loss: 0.642\n",
      "[epoch: 26, i: 10749]  train_loss: 0.637  |  valid_loss: 0.536\n",
      "[epoch: 26, i: 10874]  train_loss: 0.612  |  valid_loss: 0.560\n",
      "[epoch: 26, i: 10999]  train_loss: 0.631  |  valid_loss: 0.553\n",
      "[epoch: 26, i: 11124]  train_loss: 0.584  |  valid_loss: 0.614\n",
      "[epoch: 26, i: 11249]  train_loss: 0.586  |  valid_loss: 0.595\n",
      "[epoch: 26, i: 11374]  train_loss: 0.654  |  valid_loss: 0.458\n",
      "[epoch: 26, i: 11499]  train_loss: 0.578  |  valid_loss: 0.357\n",
      "[epoch: 26, i: 11624]  train_loss: 0.622  |  valid_loss: 0.635\n",
      "[epoch: 26, i: 11749]  train_loss: 0.609  |  valid_loss: 0.606\n",
      "[epoch: 26, i: 11874]  train_loss: 0.603  |  valid_loss: 0.558\n",
      "[epoch: 26, i: 11999]  train_loss: 0.595  |  valid_loss: 0.489\n",
      "[epoch: 26, i: 12124]  train_loss: 0.522  |  valid_loss: 0.445\n",
      "[epoch: 26, i: 12249]  train_loss: 0.617  |  valid_loss: 0.662\n",
      "[epoch: 26, i: 12374]  train_loss: 0.556  |  valid_loss: 0.550\n",
      "[epoch: 26, i: 12499]  train_loss: 0.627  |  valid_loss: 0.480\n",
      "--> [End of epoch 26] train_accuracy: 79.41%  |  valid_accuracy: 80.80%\n",
      "--> [Start of epoch 27]  lr: 0.000029\n",
      "[epoch: 27, i:   124]  train_loss: 0.642  |  valid_loss: 0.653\n",
      "[epoch: 27, i:   249]  train_loss: 0.637  |  valid_loss: 0.625\n",
      "[epoch: 27, i:   374]  train_loss: 0.575  |  valid_loss: 0.592\n",
      "[epoch: 27, i:   499]  train_loss: 0.618  |  valid_loss: 0.638\n",
      "[epoch: 27, i:   624]  train_loss: 0.560  |  valid_loss: 0.575\n",
      "[epoch: 27, i:   749]  train_loss: 0.630  |  valid_loss: 0.342\n",
      "[epoch: 27, i:   874]  train_loss: 0.608  |  valid_loss: 0.579\n",
      "[epoch: 27, i:   999]  train_loss: 0.588  |  valid_loss: 0.563\n",
      "[epoch: 27, i:  1124]  train_loss: 0.651  |  valid_loss: 0.587\n",
      "[epoch: 27, i:  1249]  train_loss: 0.662  |  valid_loss: 0.487\n",
      "[epoch: 27, i:  1374]  train_loss: 0.641  |  valid_loss: 0.527\n",
      "[epoch: 27, i:  1499]  train_loss: 0.578  |  valid_loss: 0.608\n",
      "[epoch: 27, i:  1624]  train_loss: 0.617  |  valid_loss: 0.518\n",
      "[epoch: 27, i:  1749]  train_loss: 0.602  |  valid_loss: 0.560\n",
      "[epoch: 27, i:  1874]  train_loss: 0.554  |  valid_loss: 0.527\n",
      "[epoch: 27, i:  1999]  train_loss: 0.583  |  valid_loss: 0.599\n",
      "[epoch: 27, i:  2124]  train_loss: 0.605  |  valid_loss: 0.596\n",
      "[epoch: 27, i:  2249]  train_loss: 0.579  |  valid_loss: 0.653\n",
      "[epoch: 27, i:  2374]  train_loss: 0.605  |  valid_loss: 0.597\n",
      "[epoch: 27, i:  2499]  train_loss: 0.519  |  valid_loss: 0.836\n",
      "[epoch: 27, i:  2624]  train_loss: 0.643  |  valid_loss: 0.703\n",
      "[epoch: 27, i:  2749]  train_loss: 0.582  |  valid_loss: 0.540\n",
      "[epoch: 27, i:  2874]  train_loss: 0.651  |  valid_loss: 0.658\n",
      "[epoch: 27, i:  2999]  train_loss: 0.626  |  valid_loss: 0.578\n",
      "[epoch: 27, i:  3124]  train_loss: 0.590  |  valid_loss: 0.630\n",
      "[epoch: 27, i:  3249]  train_loss: 0.639  |  valid_loss: 0.814\n",
      "[epoch: 27, i:  3374]  train_loss: 0.607  |  valid_loss: 0.451\n",
      "[epoch: 27, i:  3499]  train_loss: 0.609  |  valid_loss: 0.600\n",
      "[epoch: 27, i:  3624]  train_loss: 0.585  |  valid_loss: 0.700\n",
      "[epoch: 27, i:  3749]  train_loss: 0.596  |  valid_loss: 0.594\n",
      "[epoch: 27, i:  3874]  train_loss: 0.589  |  valid_loss: 0.513\n",
      "[epoch: 27, i:  3999]  train_loss: 0.601  |  valid_loss: 0.577\n",
      "[epoch: 27, i:  4124]  train_loss: 0.609  |  valid_loss: 0.517\n",
      "[epoch: 27, i:  4249]  train_loss: 0.555  |  valid_loss: 0.612\n",
      "[epoch: 27, i:  4374]  train_loss: 0.573  |  valid_loss: 0.734\n",
      "[epoch: 27, i:  4499]  train_loss: 0.579  |  valid_loss: 0.427\n",
      "[epoch: 27, i:  4624]  train_loss: 0.615  |  valid_loss: 0.779\n",
      "[epoch: 27, i:  4749]  train_loss: 0.711  |  valid_loss: 0.479\n",
      "[epoch: 27, i:  4874]  train_loss: 0.635  |  valid_loss: 0.455\n",
      "[epoch: 27, i:  4999]  train_loss: 0.568  |  valid_loss: 0.439\n",
      "[epoch: 27, i:  5124]  train_loss: 0.536  |  valid_loss: 0.520\n",
      "[epoch: 27, i:  5249]  train_loss: 0.596  |  valid_loss: 0.550\n",
      "[epoch: 27, i:  5374]  train_loss: 0.591  |  valid_loss: 0.410\n",
      "[epoch: 27, i:  5499]  train_loss: 0.627  |  valid_loss: 0.566\n",
      "[epoch: 27, i:  5624]  train_loss: 0.618  |  valid_loss: 0.613\n",
      "[epoch: 27, i:  5749]  train_loss: 0.626  |  valid_loss: 0.467\n",
      "[epoch: 27, i:  5874]  train_loss: 0.626  |  valid_loss: 0.435\n",
      "[epoch: 27, i:  5999]  train_loss: 0.616  |  valid_loss: 0.618\n",
      "[epoch: 27, i:  6124]  train_loss: 0.591  |  valid_loss: 0.414\n",
      "[epoch: 27, i:  6249]  train_loss: 0.603  |  valid_loss: 0.704\n",
      "[epoch: 27, i:  6374]  train_loss: 0.565  |  valid_loss: 0.476\n",
      "[epoch: 27, i:  6499]  train_loss: 0.622  |  valid_loss: 0.552\n",
      "[epoch: 27, i:  6624]  train_loss: 0.640  |  valid_loss: 0.456\n",
      "[epoch: 27, i:  6749]  train_loss: 0.618  |  valid_loss: 0.478\n",
      "[epoch: 27, i:  6874]  train_loss: 0.574  |  valid_loss: 0.575\n",
      "[epoch: 27, i:  6999]  train_loss: 0.579  |  valid_loss: 0.653\n",
      "[epoch: 27, i:  7124]  train_loss: 0.640  |  valid_loss: 0.676\n",
      "[epoch: 27, i:  7249]  train_loss: 0.628  |  valid_loss: 0.472\n",
      "[epoch: 27, i:  7374]  train_loss: 0.602  |  valid_loss: 0.616\n",
      "[epoch: 27, i:  7499]  train_loss: 0.653  |  valid_loss: 0.554\n",
      "[epoch: 27, i:  7624]  train_loss: 0.607  |  valid_loss: 0.458\n",
      "[epoch: 27, i:  7749]  train_loss: 0.637  |  valid_loss: 0.472\n",
      "[epoch: 27, i:  7874]  train_loss: 0.582  |  valid_loss: 0.481\n",
      "[epoch: 27, i:  7999]  train_loss: 0.607  |  valid_loss: 0.399\n",
      "[epoch: 27, i:  8124]  train_loss: 0.552  |  valid_loss: 0.514\n",
      "[epoch: 27, i:  8249]  train_loss: 0.594  |  valid_loss: 0.509\n",
      "[epoch: 27, i:  8374]  train_loss: 0.576  |  valid_loss: 0.491\n",
      "[epoch: 27, i:  8499]  train_loss: 0.611  |  valid_loss: 0.681\n",
      "[epoch: 27, i:  8624]  train_loss: 0.637  |  valid_loss: 0.524\n",
      "[epoch: 27, i:  8749]  train_loss: 0.603  |  valid_loss: 0.744\n",
      "[epoch: 27, i:  8874]  train_loss: 0.671  |  valid_loss: 0.504\n",
      "[epoch: 27, i:  8999]  train_loss: 0.590  |  valid_loss: 0.457\n",
      "[epoch: 27, i:  9124]  train_loss: 0.584  |  valid_loss: 0.474\n",
      "[epoch: 27, i:  9249]  train_loss: 0.591  |  valid_loss: 0.438\n",
      "[epoch: 27, i:  9374]  train_loss: 0.651  |  valid_loss: 0.506\n",
      "[epoch: 27, i:  9499]  train_loss: 0.587  |  valid_loss: 0.482\n",
      "[epoch: 27, i:  9624]  train_loss: 0.652  |  valid_loss: 0.575\n",
      "[epoch: 27, i:  9749]  train_loss: 0.601  |  valid_loss: 0.607\n",
      "[epoch: 27, i:  9874]  train_loss: 0.561  |  valid_loss: 0.593\n",
      "[epoch: 27, i:  9999]  train_loss: 0.596  |  valid_loss: 0.602\n",
      "[epoch: 27, i: 10124]  train_loss: 0.605  |  valid_loss: 0.485\n",
      "[epoch: 27, i: 10249]  train_loss: 0.639  |  valid_loss: 0.537\n",
      "[epoch: 27, i: 10374]  train_loss: 0.620  |  valid_loss: 0.472\n",
      "[epoch: 27, i: 10499]  train_loss: 0.614  |  valid_loss: 0.526\n",
      "[epoch: 27, i: 10624]  train_loss: 0.609  |  valid_loss: 0.611\n",
      "[epoch: 27, i: 10749]  train_loss: 0.646  |  valid_loss: 0.543\n",
      "[epoch: 27, i: 10874]  train_loss: 0.580  |  valid_loss: 0.564\n",
      "[epoch: 27, i: 10999]  train_loss: 0.582  |  valid_loss: 0.542\n",
      "[epoch: 27, i: 11124]  train_loss: 0.607  |  valid_loss: 0.612\n",
      "[epoch: 27, i: 11249]  train_loss: 0.605  |  valid_loss: 0.605\n",
      "[epoch: 27, i: 11374]  train_loss: 0.654  |  valid_loss: 0.467\n",
      "[epoch: 27, i: 11499]  train_loss: 0.592  |  valid_loss: 0.350\n",
      "[epoch: 27, i: 11624]  train_loss: 0.633  |  valid_loss: 0.642\n",
      "[epoch: 27, i: 11749]  train_loss: 0.543  |  valid_loss: 0.617\n",
      "[epoch: 27, i: 11874]  train_loss: 0.630  |  valid_loss: 0.620\n",
      "[epoch: 27, i: 11999]  train_loss: 0.618  |  valid_loss: 0.487\n",
      "[epoch: 27, i: 12124]  train_loss: 0.545  |  valid_loss: 0.450\n",
      "[epoch: 27, i: 12249]  train_loss: 0.659  |  valid_loss: 0.655\n",
      "[epoch: 27, i: 12374]  train_loss: 0.617  |  valid_loss: 0.589\n",
      "[epoch: 27, i: 12499]  train_loss: 0.602  |  valid_loss: 0.479\n",
      "--> [End of epoch 27] train_accuracy: 79.22%  |  valid_accuracy: 80.81%\n",
      "--> [Start of epoch 28]  lr: 0.000026\n",
      "[epoch: 28, i:   124]  train_loss: 0.625  |  valid_loss: 0.637\n",
      "[epoch: 28, i:   249]  train_loss: 0.599  |  valid_loss: 0.586\n",
      "[epoch: 28, i:   374]  train_loss: 0.575  |  valid_loss: 0.558\n",
      "[epoch: 28, i:   499]  train_loss: 0.590  |  valid_loss: 0.676\n",
      "[epoch: 28, i:   624]  train_loss: 0.554  |  valid_loss: 0.579\n",
      "[epoch: 28, i:   749]  train_loss: 0.629  |  valid_loss: 0.333\n",
      "[epoch: 28, i:   874]  train_loss: 0.592  |  valid_loss: 0.624\n",
      "[epoch: 28, i:   999]  train_loss: 0.578  |  valid_loss: 0.618\n",
      "[epoch: 28, i:  1124]  train_loss: 0.550  |  valid_loss: 0.573\n",
      "[epoch: 28, i:  1249]  train_loss: 0.595  |  valid_loss: 0.498\n",
      "[epoch: 28, i:  1374]  train_loss: 0.637  |  valid_loss: 0.467\n",
      "[epoch: 28, i:  1499]  train_loss: 0.633  |  valid_loss: 0.621\n",
      "[epoch: 28, i:  1624]  train_loss: 0.561  |  valid_loss: 0.520\n",
      "[epoch: 28, i:  1749]  train_loss: 0.639  |  valid_loss: 0.553\n",
      "[epoch: 28, i:  1874]  train_loss: 0.569  |  valid_loss: 0.498\n",
      "[epoch: 28, i:  1999]  train_loss: 0.531  |  valid_loss: 0.617\n",
      "[epoch: 28, i:  2124]  train_loss: 0.644  |  valid_loss: 0.530\n",
      "[epoch: 28, i:  2249]  train_loss: 0.604  |  valid_loss: 0.646\n",
      "[epoch: 28, i:  2374]  train_loss: 0.627  |  valid_loss: 0.550\n",
      "[epoch: 28, i:  2499]  train_loss: 0.595  |  valid_loss: 0.803\n",
      "[epoch: 28, i:  2624]  train_loss: 0.621  |  valid_loss: 0.693\n",
      "[epoch: 28, i:  2749]  train_loss: 0.591  |  valid_loss: 0.522\n",
      "[epoch: 28, i:  2874]  train_loss: 0.570  |  valid_loss: 0.649\n",
      "[epoch: 28, i:  2999]  train_loss: 0.553  |  valid_loss: 0.568\n",
      "[epoch: 28, i:  3124]  train_loss: 0.581  |  valid_loss: 0.615\n",
      "[epoch: 28, i:  3249]  train_loss: 0.581  |  valid_loss: 0.796\n",
      "[epoch: 28, i:  3374]  train_loss: 0.590  |  valid_loss: 0.455\n",
      "[epoch: 28, i:  3499]  train_loss: 0.625  |  valid_loss: 0.619\n",
      "[epoch: 28, i:  3624]  train_loss: 0.566  |  valid_loss: 0.703\n",
      "[epoch: 28, i:  3749]  train_loss: 0.579  |  valid_loss: 0.596\n",
      "[epoch: 28, i:  3874]  train_loss: 0.592  |  valid_loss: 0.527\n",
      "[epoch: 28, i:  3999]  train_loss: 0.592  |  valid_loss: 0.596\n",
      "[epoch: 28, i:  4124]  train_loss: 0.603  |  valid_loss: 0.563\n",
      "[epoch: 28, i:  4249]  train_loss: 0.578  |  valid_loss: 0.617\n",
      "[epoch: 28, i:  4374]  train_loss: 0.630  |  valid_loss: 0.729\n",
      "[epoch: 28, i:  4499]  train_loss: 0.594  |  valid_loss: 0.416\n",
      "[epoch: 28, i:  4624]  train_loss: 0.554  |  valid_loss: 0.774\n",
      "[epoch: 28, i:  4749]  train_loss: 0.628  |  valid_loss: 0.495\n",
      "[epoch: 28, i:  4874]  train_loss: 0.554  |  valid_loss: 0.461\n",
      "[epoch: 28, i:  4999]  train_loss: 0.596  |  valid_loss: 0.502\n",
      "[epoch: 28, i:  5124]  train_loss: 0.598  |  valid_loss: 0.499\n",
      "[epoch: 28, i:  5249]  train_loss: 0.614  |  valid_loss: 0.571\n",
      "[epoch: 28, i:  5374]  train_loss: 0.609  |  valid_loss: 0.380\n",
      "[epoch: 28, i:  5499]  train_loss: 0.606  |  valid_loss: 0.560\n",
      "[epoch: 28, i:  5624]  train_loss: 0.622  |  valid_loss: 0.616\n",
      "[epoch: 28, i:  5749]  train_loss: 0.609  |  valid_loss: 0.469\n",
      "[epoch: 28, i:  5874]  train_loss: 0.595  |  valid_loss: 0.424\n",
      "[epoch: 28, i:  5999]  train_loss: 0.609  |  valid_loss: 0.566\n",
      "[epoch: 28, i:  6124]  train_loss: 0.639  |  valid_loss: 0.420\n",
      "[epoch: 28, i:  6249]  train_loss: 0.611  |  valid_loss: 0.716\n",
      "[epoch: 28, i:  6374]  train_loss: 0.577  |  valid_loss: 0.491\n",
      "[epoch: 28, i:  6499]  train_loss: 0.614  |  valid_loss: 0.570\n",
      "[epoch: 28, i:  6624]  train_loss: 0.639  |  valid_loss: 0.496\n",
      "[epoch: 28, i:  6749]  train_loss: 0.633  |  valid_loss: 0.451\n",
      "[epoch: 28, i:  6874]  train_loss: 0.594  |  valid_loss: 0.572\n",
      "[epoch: 28, i:  6999]  train_loss: 0.566  |  valid_loss: 0.646\n",
      "[epoch: 28, i:  7124]  train_loss: 0.551  |  valid_loss: 0.685\n",
      "[epoch: 28, i:  7249]  train_loss: 0.573  |  valid_loss: 0.491\n",
      "[epoch: 28, i:  7374]  train_loss: 0.550  |  valid_loss: 0.618\n",
      "[epoch: 28, i:  7499]  train_loss: 0.593  |  valid_loss: 0.592\n",
      "[epoch: 28, i:  7624]  train_loss: 0.620  |  valid_loss: 0.468\n",
      "[epoch: 28, i:  7749]  train_loss: 0.597  |  valid_loss: 0.500\n",
      "[epoch: 28, i:  7874]  train_loss: 0.603  |  valid_loss: 0.491\n",
      "[epoch: 28, i:  7999]  train_loss: 0.652  |  valid_loss: 0.419\n",
      "[epoch: 28, i:  8124]  train_loss: 0.635  |  valid_loss: 0.500\n",
      "[epoch: 28, i:  8249]  train_loss: 0.616  |  valid_loss: 0.524\n",
      "[epoch: 28, i:  8374]  train_loss: 0.600  |  valid_loss: 0.479\n",
      "[epoch: 28, i:  8499]  train_loss: 0.633  |  valid_loss: 0.638\n",
      "[epoch: 28, i:  8624]  train_loss: 0.650  |  valid_loss: 0.532\n",
      "[epoch: 28, i:  8749]  train_loss: 0.572  |  valid_loss: 0.701\n",
      "[epoch: 28, i:  8874]  train_loss: 0.630  |  valid_loss: 0.569\n",
      "[epoch: 28, i:  8999]  train_loss: 0.576  |  valid_loss: 0.472\n",
      "[epoch: 28, i:  9124]  train_loss: 0.581  |  valid_loss: 0.421\n",
      "[epoch: 28, i:  9249]  train_loss: 0.597  |  valid_loss: 0.428\n",
      "[epoch: 28, i:  9374]  train_loss: 0.638  |  valid_loss: 0.492\n",
      "[epoch: 28, i:  9499]  train_loss: 0.598  |  valid_loss: 0.562\n",
      "[epoch: 28, i:  9624]  train_loss: 0.614  |  valid_loss: 0.534\n",
      "[epoch: 28, i:  9749]  train_loss: 0.566  |  valid_loss: 0.589\n",
      "[epoch: 28, i:  9874]  train_loss: 0.653  |  valid_loss: 0.597\n",
      "[epoch: 28, i:  9999]  train_loss: 0.626  |  valid_loss: 0.615\n",
      "[epoch: 28, i: 10124]  train_loss: 0.616  |  valid_loss: 0.493\n",
      "[epoch: 28, i: 10249]  train_loss: 0.652  |  valid_loss: 0.551\n",
      "[epoch: 28, i: 10374]  train_loss: 0.656  |  valid_loss: 0.467\n",
      "[epoch: 28, i: 10499]  train_loss: 0.562  |  valid_loss: 0.539\n",
      "[epoch: 28, i: 10624]  train_loss: 0.577  |  valid_loss: 0.648\n",
      "[epoch: 28, i: 10749]  train_loss: 0.555  |  valid_loss: 0.547\n",
      "[epoch: 28, i: 10874]  train_loss: 0.579  |  valid_loss: 0.555\n",
      "[epoch: 28, i: 10999]  train_loss: 0.606  |  valid_loss: 0.557\n",
      "[epoch: 28, i: 11124]  train_loss: 0.558  |  valid_loss: 0.630\n",
      "[epoch: 28, i: 11249]  train_loss: 0.560  |  valid_loss: 0.627\n",
      "[epoch: 28, i: 11374]  train_loss: 0.573  |  valid_loss: 0.470\n",
      "[epoch: 28, i: 11499]  train_loss: 0.629  |  valid_loss: 0.382\n",
      "[epoch: 28, i: 11624]  train_loss: 0.624  |  valid_loss: 0.653\n",
      "[epoch: 28, i: 11749]  train_loss: 0.608  |  valid_loss: 0.616\n",
      "[epoch: 28, i: 11874]  train_loss: 0.600  |  valid_loss: 0.586\n",
      "[epoch: 28, i: 11999]  train_loss: 0.578  |  valid_loss: 0.452\n",
      "[epoch: 28, i: 12124]  train_loss: 0.664  |  valid_loss: 0.457\n",
      "[epoch: 28, i: 12249]  train_loss: 0.668  |  valid_loss: 0.662\n",
      "[epoch: 28, i: 12374]  train_loss: 0.629  |  valid_loss: 0.558\n",
      "[epoch: 28, i: 12499]  train_loss: 0.606  |  valid_loss: 0.503\n",
      "--> [End of epoch 28] train_accuracy: 79.71%  |  valid_accuracy: 81.14%\n",
      "--> [Start of epoch 29]  lr: 0.000024\n",
      "[epoch: 29, i:   124]  train_loss: 0.673  |  valid_loss: 0.632\n",
      "[epoch: 29, i:   249]  train_loss: 0.600  |  valid_loss: 0.598\n",
      "[epoch: 29, i:   374]  train_loss: 0.622  |  valid_loss: 0.563\n",
      "[epoch: 29, i:   499]  train_loss: 0.633  |  valid_loss: 0.632\n",
      "[epoch: 29, i:   624]  train_loss: 0.622  |  valid_loss: 0.555\n",
      "[epoch: 29, i:   749]  train_loss: 0.575  |  valid_loss: 0.308\n",
      "[epoch: 29, i:   874]  train_loss: 0.566  |  valid_loss: 0.579\n",
      "[epoch: 29, i:   999]  train_loss: 0.548  |  valid_loss: 0.602\n",
      "[epoch: 29, i:  1124]  train_loss: 0.564  |  valid_loss: 0.583\n",
      "[epoch: 29, i:  1249]  train_loss: 0.555  |  valid_loss: 0.517\n",
      "[epoch: 29, i:  1374]  train_loss: 0.617  |  valid_loss: 0.474\n",
      "[epoch: 29, i:  1499]  train_loss: 0.589  |  valid_loss: 0.621\n",
      "[epoch: 29, i:  1624]  train_loss: 0.587  |  valid_loss: 0.530\n",
      "[epoch: 29, i:  1749]  train_loss: 0.610  |  valid_loss: 0.580\n",
      "[epoch: 29, i:  1874]  train_loss: 0.595  |  valid_loss: 0.503\n",
      "[epoch: 29, i:  1999]  train_loss: 0.608  |  valid_loss: 0.608\n",
      "[epoch: 29, i:  2124]  train_loss: 0.624  |  valid_loss: 0.541\n",
      "[epoch: 29, i:  2249]  train_loss: 0.604  |  valid_loss: 0.643\n",
      "[epoch: 29, i:  2374]  train_loss: 0.596  |  valid_loss: 0.589\n",
      "[epoch: 29, i:  2499]  train_loss: 0.646  |  valid_loss: 0.844\n",
      "[epoch: 29, i:  2624]  train_loss: 0.605  |  valid_loss: 0.719\n",
      "[epoch: 29, i:  2749]  train_loss: 0.560  |  valid_loss: 0.514\n",
      "[epoch: 29, i:  2874]  train_loss: 0.591  |  valid_loss: 0.661\n",
      "[epoch: 29, i:  2999]  train_loss: 0.589  |  valid_loss: 0.607\n",
      "[epoch: 29, i:  3124]  train_loss: 0.597  |  valid_loss: 0.648\n",
      "[epoch: 29, i:  3249]  train_loss: 0.568  |  valid_loss: 0.828\n",
      "[epoch: 29, i:  3374]  train_loss: 0.621  |  valid_loss: 0.463\n",
      "[epoch: 29, i:  3499]  train_loss: 0.636  |  valid_loss: 0.592\n",
      "[epoch: 29, i:  3624]  train_loss: 0.574  |  valid_loss: 0.671\n",
      "[epoch: 29, i:  3749]  train_loss: 0.651  |  valid_loss: 0.586\n",
      "[epoch: 29, i:  3874]  train_loss: 0.557  |  valid_loss: 0.541\n",
      "[epoch: 29, i:  3999]  train_loss: 0.618  |  valid_loss: 0.578\n",
      "[epoch: 29, i:  4124]  train_loss: 0.621  |  valid_loss: 0.523\n",
      "[epoch: 29, i:  4249]  train_loss: 0.594  |  valid_loss: 0.619\n",
      "[epoch: 29, i:  4374]  train_loss: 0.608  |  valid_loss: 0.741\n",
      "[epoch: 29, i:  4499]  train_loss: 0.617  |  valid_loss: 0.436\n",
      "[epoch: 29, i:  4624]  train_loss: 0.550  |  valid_loss: 0.769\n",
      "[epoch: 29, i:  4749]  train_loss: 0.606  |  valid_loss: 0.507\n",
      "[epoch: 29, i:  4874]  train_loss: 0.676  |  valid_loss: 0.453\n",
      "[epoch: 29, i:  4999]  train_loss: 0.582  |  valid_loss: 0.461\n",
      "[epoch: 29, i:  5124]  train_loss: 0.599  |  valid_loss: 0.536\n",
      "[epoch: 29, i:  5249]  train_loss: 0.632  |  valid_loss: 0.555\n",
      "[epoch: 29, i:  5374]  train_loss: 0.572  |  valid_loss: 0.375\n",
      "[epoch: 29, i:  5499]  train_loss: 0.644  |  valid_loss: 0.591\n",
      "[epoch: 29, i:  5624]  train_loss: 0.540  |  valid_loss: 0.627\n",
      "[epoch: 29, i:  5749]  train_loss: 0.596  |  valid_loss: 0.499\n",
      "[epoch: 29, i:  5874]  train_loss: 0.572  |  valid_loss: 0.429\n",
      "[epoch: 29, i:  5999]  train_loss: 0.595  |  valid_loss: 0.571\n",
      "[epoch: 29, i:  6124]  train_loss: 0.591  |  valid_loss: 0.440\n",
      "[epoch: 29, i:  6249]  train_loss: 0.601  |  valid_loss: 0.716\n",
      "[epoch: 29, i:  6374]  train_loss: 0.624  |  valid_loss: 0.482\n",
      "[epoch: 29, i:  6499]  train_loss: 0.588  |  valid_loss: 0.552\n",
      "[epoch: 29, i:  6624]  train_loss: 0.564  |  valid_loss: 0.491\n",
      "[epoch: 29, i:  6749]  train_loss: 0.613  |  valid_loss: 0.463\n",
      "[epoch: 29, i:  6874]  train_loss: 0.620  |  valid_loss: 0.568\n",
      "[epoch: 29, i:  6999]  train_loss: 0.634  |  valid_loss: 0.624\n",
      "[epoch: 29, i:  7124]  train_loss: 0.598  |  valid_loss: 0.669\n",
      "[epoch: 29, i:  7249]  train_loss: 0.566  |  valid_loss: 0.477\n",
      "[epoch: 29, i:  7374]  train_loss: 0.593  |  valid_loss: 0.596\n",
      "[epoch: 29, i:  7499]  train_loss: 0.598  |  valid_loss: 0.580\n",
      "[epoch: 29, i:  7624]  train_loss: 0.604  |  valid_loss: 0.436\n",
      "[epoch: 29, i:  7749]  train_loss: 0.599  |  valid_loss: 0.509\n",
      "[epoch: 29, i:  7874]  train_loss: 0.570  |  valid_loss: 0.470\n",
      "[epoch: 29, i:  7999]  train_loss: 0.586  |  valid_loss: 0.406\n",
      "[epoch: 29, i:  8124]  train_loss: 0.596  |  valid_loss: 0.495\n",
      "[epoch: 29, i:  8249]  train_loss: 0.564  |  valid_loss: 0.540\n",
      "[epoch: 29, i:  8374]  train_loss: 0.608  |  valid_loss: 0.500\n",
      "[epoch: 29, i:  8499]  train_loss: 0.569  |  valid_loss: 0.630\n",
      "[epoch: 29, i:  8624]  train_loss: 0.626  |  valid_loss: 0.544\n",
      "[epoch: 29, i:  8749]  train_loss: 0.635  |  valid_loss: 0.700\n",
      "[epoch: 29, i:  8874]  train_loss: 0.549  |  valid_loss: 0.516\n",
      "[epoch: 29, i:  8999]  train_loss: 0.626  |  valid_loss: 0.464\n",
      "[epoch: 29, i:  9124]  train_loss: 0.618  |  valid_loss: 0.445\n",
      "[epoch: 29, i:  9249]  train_loss: 0.535  |  valid_loss: 0.418\n",
      "[epoch: 29, i:  9374]  train_loss: 0.576  |  valid_loss: 0.519\n",
      "[epoch: 29, i:  9499]  train_loss: 0.667  |  valid_loss: 0.512\n",
      "[epoch: 29, i:  9624]  train_loss: 0.572  |  valid_loss: 0.548\n",
      "[epoch: 29, i:  9749]  train_loss: 0.628  |  valid_loss: 0.606\n",
      "[epoch: 29, i:  9874]  train_loss: 0.651  |  valid_loss: 0.581\n",
      "[epoch: 29, i:  9999]  train_loss: 0.585  |  valid_loss: 0.600\n",
      "[epoch: 29, i: 10124]  train_loss: 0.658  |  valid_loss: 0.480\n",
      "[epoch: 29, i: 10249]  train_loss: 0.562  |  valid_loss: 0.532\n",
      "[epoch: 29, i: 10374]  train_loss: 0.602  |  valid_loss: 0.457\n",
      "[epoch: 29, i: 10499]  train_loss: 0.574  |  valid_loss: 0.534\n",
      "[epoch: 29, i: 10624]  train_loss: 0.652  |  valid_loss: 0.611\n",
      "[epoch: 29, i: 10749]  train_loss: 0.633  |  valid_loss: 0.529\n",
      "[epoch: 29, i: 10874]  train_loss: 0.645  |  valid_loss: 0.526\n",
      "[epoch: 29, i: 10999]  train_loss: 0.640  |  valid_loss: 0.538\n",
      "[epoch: 29, i: 11124]  train_loss: 0.577  |  valid_loss: 0.642\n",
      "[epoch: 29, i: 11249]  train_loss: 0.601  |  valid_loss: 0.595\n",
      "[epoch: 29, i: 11374]  train_loss: 0.642  |  valid_loss: 0.467\n",
      "[epoch: 29, i: 11499]  train_loss: 0.565  |  valid_loss: 0.370\n",
      "[epoch: 29, i: 11624]  train_loss: 0.628  |  valid_loss: 0.644\n",
      "[epoch: 29, i: 11749]  train_loss: 0.595  |  valid_loss: 0.610\n",
      "[epoch: 29, i: 11874]  train_loss: 0.602  |  valid_loss: 0.579\n",
      "[epoch: 29, i: 11999]  train_loss: 0.546  |  valid_loss: 0.496\n",
      "[epoch: 29, i: 12124]  train_loss: 0.650  |  valid_loss: 0.447\n",
      "[epoch: 29, i: 12249]  train_loss: 0.549  |  valid_loss: 0.666\n",
      "[epoch: 29, i: 12374]  train_loss: 0.589  |  valid_loss: 0.562\n",
      "[epoch: 29, i: 12499]  train_loss: 0.579  |  valid_loss: 0.456\n",
      "--> [End of epoch 29] train_accuracy: 79.62%  |  valid_accuracy: 81.02%\n",
      "--> [Start of epoch 30]  lr: 0.000021\n",
      "[epoch: 30, i:   124]  train_loss: 0.560  |  valid_loss: 0.637\n",
      "[epoch: 30, i:   249]  train_loss: 0.560  |  valid_loss: 0.593\n",
      "[epoch: 30, i:   374]  train_loss: 0.621  |  valid_loss: 0.551\n",
      "[epoch: 30, i:   499]  train_loss: 0.525  |  valid_loss: 0.644\n",
      "[epoch: 30, i:   624]  train_loss: 0.610  |  valid_loss: 0.562\n",
      "[epoch: 30, i:   749]  train_loss: 0.626  |  valid_loss: 0.342\n",
      "[epoch: 30, i:   874]  train_loss: 0.620  |  valid_loss: 0.588\n",
      "[epoch: 30, i:   999]  train_loss: 0.637  |  valid_loss: 0.591\n",
      "[epoch: 30, i:  1124]  train_loss: 0.587  |  valid_loss: 0.563\n",
      "[epoch: 30, i:  1249]  train_loss: 0.601  |  valid_loss: 0.509\n",
      "[epoch: 30, i:  1374]  train_loss: 0.544  |  valid_loss: 0.508\n",
      "[epoch: 30, i:  1499]  train_loss: 0.610  |  valid_loss: 0.627\n",
      "[epoch: 30, i:  1624]  train_loss: 0.650  |  valid_loss: 0.567\n",
      "[epoch: 30, i:  1749]  train_loss: 0.593  |  valid_loss: 0.573\n",
      "[epoch: 30, i:  1874]  train_loss: 0.603  |  valid_loss: 0.529\n",
      "[epoch: 30, i:  1999]  train_loss: 0.599  |  valid_loss: 0.643\n",
      "[epoch: 30, i:  2124]  train_loss: 0.535  |  valid_loss: 0.557\n",
      "[epoch: 30, i:  2249]  train_loss: 0.603  |  valid_loss: 0.647\n",
      "[epoch: 30, i:  2374]  train_loss: 0.608  |  valid_loss: 0.574\n",
      "[epoch: 30, i:  2499]  train_loss: 0.551  |  valid_loss: 0.842\n",
      "[epoch: 30, i:  2624]  train_loss: 0.616  |  valid_loss: 0.690\n",
      "[epoch: 30, i:  2749]  train_loss: 0.612  |  valid_loss: 0.517\n",
      "[epoch: 30, i:  2874]  train_loss: 0.594  |  valid_loss: 0.647\n",
      "[epoch: 30, i:  2999]  train_loss: 0.571  |  valid_loss: 0.562\n",
      "[epoch: 30, i:  3124]  train_loss: 0.664  |  valid_loss: 0.642\n",
      "[epoch: 30, i:  3249]  train_loss: 0.607  |  valid_loss: 0.828\n",
      "[epoch: 30, i:  3374]  train_loss: 0.590  |  valid_loss: 0.479\n",
      "[epoch: 30, i:  3499]  train_loss: 0.551  |  valid_loss: 0.602\n",
      "[epoch: 30, i:  3624]  train_loss: 0.642  |  valid_loss: 0.655\n",
      "[epoch: 30, i:  3749]  train_loss: 0.567  |  valid_loss: 0.586\n",
      "[epoch: 30, i:  3874]  train_loss: 0.586  |  valid_loss: 0.538\n",
      "[epoch: 30, i:  3999]  train_loss: 0.592  |  valid_loss: 0.588\n",
      "[epoch: 30, i:  4124]  train_loss: 0.542  |  valid_loss: 0.556\n",
      "[epoch: 30, i:  4249]  train_loss: 0.561  |  valid_loss: 0.628\n",
      "[epoch: 30, i:  4374]  train_loss: 0.612  |  valid_loss: 0.747\n",
      "[epoch: 30, i:  4499]  train_loss: 0.610  |  valid_loss: 0.443\n",
      "[epoch: 30, i:  4624]  train_loss: 0.576  |  valid_loss: 0.782\n",
      "[epoch: 30, i:  4749]  train_loss: 0.622  |  valid_loss: 0.529\n",
      "[epoch: 30, i:  4874]  train_loss: 0.609  |  valid_loss: 0.470\n",
      "[epoch: 30, i:  4999]  train_loss: 0.593  |  valid_loss: 0.432\n",
      "[epoch: 30, i:  5124]  train_loss: 0.589  |  valid_loss: 0.500\n",
      "[epoch: 30, i:  5249]  train_loss: 0.553  |  valid_loss: 0.580\n",
      "[epoch: 30, i:  5374]  train_loss: 0.627  |  valid_loss: 0.394\n",
      "[epoch: 30, i:  5499]  train_loss: 0.604  |  valid_loss: 0.587\n",
      "[epoch: 30, i:  5624]  train_loss: 0.612  |  valid_loss: 0.624\n",
      "[epoch: 30, i:  5749]  train_loss: 0.593  |  valid_loss: 0.495\n",
      "[epoch: 30, i:  5874]  train_loss: 0.621  |  valid_loss: 0.472\n",
      "[epoch: 30, i:  5999]  train_loss: 0.637  |  valid_loss: 0.598\n",
      "[epoch: 30, i:  6124]  train_loss: 0.623  |  valid_loss: 0.412\n",
      "[epoch: 30, i:  6249]  train_loss: 0.517  |  valid_loss: 0.713\n",
      "[epoch: 30, i:  6374]  train_loss: 0.610  |  valid_loss: 0.485\n",
      "[epoch: 30, i:  6499]  train_loss: 0.577  |  valid_loss: 0.541\n",
      "[epoch: 30, i:  6624]  train_loss: 0.588  |  valid_loss: 0.479\n",
      "[epoch: 30, i:  6749]  train_loss: 0.563  |  valid_loss: 0.457\n",
      "[epoch: 30, i:  6874]  train_loss: 0.578  |  valid_loss: 0.579\n",
      "[epoch: 30, i:  6999]  train_loss: 0.586  |  valid_loss: 0.673\n",
      "[epoch: 30, i:  7124]  train_loss: 0.594  |  valid_loss: 0.700\n",
      "[epoch: 30, i:  7249]  train_loss: 0.598  |  valid_loss: 0.467\n",
      "[epoch: 30, i:  7374]  train_loss: 0.633  |  valid_loss: 0.601\n",
      "[epoch: 30, i:  7499]  train_loss: 0.626  |  valid_loss: 0.525\n",
      "[epoch: 30, i:  7624]  train_loss: 0.530  |  valid_loss: 0.457\n",
      "[epoch: 30, i:  7749]  train_loss: 0.637  |  valid_loss: 0.506\n",
      "[epoch: 30, i:  7874]  train_loss: 0.536  |  valid_loss: 0.470\n",
      "[epoch: 30, i:  7999]  train_loss: 0.599  |  valid_loss: 0.426\n",
      "[epoch: 30, i:  8124]  train_loss: 0.552  |  valid_loss: 0.494\n",
      "[epoch: 30, i:  8249]  train_loss: 0.588  |  valid_loss: 0.571\n",
      "[epoch: 30, i:  8374]  train_loss: 0.565  |  valid_loss: 0.478\n",
      "[epoch: 30, i:  8499]  train_loss: 0.626  |  valid_loss: 0.646\n",
      "[epoch: 30, i:  8624]  train_loss: 0.553  |  valid_loss: 0.522\n",
      "[epoch: 30, i:  8749]  train_loss: 0.535  |  valid_loss: 0.743\n",
      "[epoch: 30, i:  8874]  train_loss: 0.580  |  valid_loss: 0.520\n",
      "[epoch: 30, i:  8999]  train_loss: 0.597  |  valid_loss: 0.475\n",
      "[epoch: 30, i:  9124]  train_loss: 0.635  |  valid_loss: 0.467\n",
      "[epoch: 30, i:  9249]  train_loss: 0.609  |  valid_loss: 0.415\n",
      "[epoch: 30, i:  9374]  train_loss: 0.581  |  valid_loss: 0.513\n",
      "[epoch: 30, i:  9499]  train_loss: 0.583  |  valid_loss: 0.515\n",
      "[epoch: 30, i:  9624]  train_loss: 0.602  |  valid_loss: 0.538\n",
      "[epoch: 30, i:  9749]  train_loss: 0.588  |  valid_loss: 0.608\n",
      "[epoch: 30, i:  9874]  train_loss: 0.661  |  valid_loss: 0.594\n",
      "[epoch: 30, i:  9999]  train_loss: 0.668  |  valid_loss: 0.627\n",
      "[epoch: 30, i: 10124]  train_loss: 0.600  |  valid_loss: 0.474\n",
      "[epoch: 30, i: 10249]  train_loss: 0.550  |  valid_loss: 0.527\n",
      "[epoch: 30, i: 10374]  train_loss: 0.582  |  valid_loss: 0.484\n",
      "[epoch: 30, i: 10499]  train_loss: 0.679  |  valid_loss: 0.517\n",
      "[epoch: 30, i: 10624]  train_loss: 0.556  |  valid_loss: 0.626\n",
      "[epoch: 30, i: 10749]  train_loss: 0.627  |  valid_loss: 0.550\n",
      "[epoch: 30, i: 10874]  train_loss: 0.637  |  valid_loss: 0.513\n",
      "[epoch: 30, i: 10999]  train_loss: 0.560  |  valid_loss: 0.521\n",
      "[epoch: 30, i: 11124]  train_loss: 0.607  |  valid_loss: 0.619\n",
      "[epoch: 30, i: 11249]  train_loss: 0.609  |  valid_loss: 0.577\n",
      "[epoch: 30, i: 11374]  train_loss: 0.620  |  valid_loss: 0.458\n",
      "[epoch: 30, i: 11499]  train_loss: 0.599  |  valid_loss: 0.374\n",
      "[epoch: 30, i: 11624]  train_loss: 0.563  |  valid_loss: 0.618\n",
      "[epoch: 30, i: 11749]  train_loss: 0.589  |  valid_loss: 0.611\n",
      "[epoch: 30, i: 11874]  train_loss: 0.629  |  valid_loss: 0.582\n",
      "[epoch: 30, i: 11999]  train_loss: 0.588  |  valid_loss: 0.469\n",
      "[epoch: 30, i: 12124]  train_loss: 0.594  |  valid_loss: 0.461\n",
      "[epoch: 30, i: 12249]  train_loss: 0.574  |  valid_loss: 0.679\n",
      "[epoch: 30, i: 12374]  train_loss: 0.654  |  valid_loss: 0.572\n",
      "[epoch: 30, i: 12499]  train_loss: 0.564  |  valid_loss: 0.469\n",
      "--> [End of epoch 30] train_accuracy: 79.77%  |  valid_accuracy: 80.95%\n",
      "--> [Start of epoch 31]  lr: 0.000019\n",
      "[epoch: 31, i:   124]  train_loss: 0.627  |  valid_loss: 0.649\n",
      "[epoch: 31, i:   249]  train_loss: 0.595  |  valid_loss: 0.600\n",
      "[epoch: 31, i:   374]  train_loss: 0.597  |  valid_loss: 0.612\n",
      "[epoch: 31, i:   499]  train_loss: 0.562  |  valid_loss: 0.597\n",
      "[epoch: 31, i:   624]  train_loss: 0.631  |  valid_loss: 0.582\n",
      "[epoch: 31, i:   749]  train_loss: 0.584  |  valid_loss: 0.332\n",
      "[epoch: 31, i:   874]  train_loss: 0.573  |  valid_loss: 0.574\n",
      "[epoch: 31, i:   999]  train_loss: 0.635  |  valid_loss: 0.567\n",
      "[epoch: 31, i:  1124]  train_loss: 0.654  |  valid_loss: 0.571\n",
      "[epoch: 31, i:  1249]  train_loss: 0.562  |  valid_loss: 0.504\n",
      "[epoch: 31, i:  1374]  train_loss: 0.574  |  valid_loss: 0.533\n",
      "[epoch: 31, i:  1499]  train_loss: 0.564  |  valid_loss: 0.620\n",
      "[epoch: 31, i:  1624]  train_loss: 0.604  |  valid_loss: 0.540\n",
      "[epoch: 31, i:  1749]  train_loss: 0.614  |  valid_loss: 0.554\n",
      "[epoch: 31, i:  1874]  train_loss: 0.604  |  valid_loss: 0.522\n",
      "[epoch: 31, i:  1999]  train_loss: 0.590  |  valid_loss: 0.608\n",
      "[epoch: 31, i:  2124]  train_loss: 0.609  |  valid_loss: 0.560\n",
      "[epoch: 31, i:  2249]  train_loss: 0.603  |  valid_loss: 0.665\n",
      "[epoch: 31, i:  2374]  train_loss: 0.594  |  valid_loss: 0.598\n",
      "[epoch: 31, i:  2499]  train_loss: 0.603  |  valid_loss: 0.806\n",
      "[epoch: 31, i:  2624]  train_loss: 0.662  |  valid_loss: 0.724\n",
      "[epoch: 31, i:  2749]  train_loss: 0.567  |  valid_loss: 0.540\n",
      "[epoch: 31, i:  2874]  train_loss: 0.633  |  valid_loss: 0.667\n",
      "[epoch: 31, i:  2999]  train_loss: 0.581  |  valid_loss: 0.552\n",
      "[epoch: 31, i:  3124]  train_loss: 0.600  |  valid_loss: 0.617\n",
      "[epoch: 31, i:  3249]  train_loss: 0.588  |  valid_loss: 0.796\n",
      "[epoch: 31, i:  3374]  train_loss: 0.620  |  valid_loss: 0.477\n",
      "[epoch: 31, i:  3499]  train_loss: 0.643  |  valid_loss: 0.618\n",
      "[epoch: 31, i:  3624]  train_loss: 0.664  |  valid_loss: 0.693\n",
      "[epoch: 31, i:  3749]  train_loss: 0.602  |  valid_loss: 0.592\n",
      "[epoch: 31, i:  3874]  train_loss: 0.630  |  valid_loss: 0.557\n",
      "[epoch: 31, i:  3999]  train_loss: 0.586  |  valid_loss: 0.554\n",
      "[epoch: 31, i:  4124]  train_loss: 0.626  |  valid_loss: 0.521\n",
      "[epoch: 31, i:  4249]  train_loss: 0.572  |  valid_loss: 0.616\n",
      "[epoch: 31, i:  4374]  train_loss: 0.586  |  valid_loss: 0.775\n",
      "[epoch: 31, i:  4499]  train_loss: 0.668  |  valid_loss: 0.437\n",
      "[epoch: 31, i:  4624]  train_loss: 0.592  |  valid_loss: 0.782\n",
      "[epoch: 31, i:  4749]  train_loss: 0.586  |  valid_loss: 0.534\n",
      "[epoch: 31, i:  4874]  train_loss: 0.618  |  valid_loss: 0.451\n",
      "[epoch: 31, i:  4999]  train_loss: 0.599  |  valid_loss: 0.459\n",
      "[epoch: 31, i:  5124]  train_loss: 0.516  |  valid_loss: 0.507\n",
      "[epoch: 31, i:  5249]  train_loss: 0.628  |  valid_loss: 0.565\n",
      "[epoch: 31, i:  5374]  train_loss: 0.603  |  valid_loss: 0.383\n",
      "[epoch: 31, i:  5499]  train_loss: 0.625  |  valid_loss: 0.563\n",
      "[epoch: 31, i:  5624]  train_loss: 0.636  |  valid_loss: 0.584\n",
      "[epoch: 31, i:  5749]  train_loss: 0.578  |  valid_loss: 0.490\n",
      "[epoch: 31, i:  5874]  train_loss: 0.596  |  valid_loss: 0.443\n",
      "[epoch: 31, i:  5999]  train_loss: 0.596  |  valid_loss: 0.610\n",
      "[epoch: 31, i:  6124]  train_loss: 0.583  |  valid_loss: 0.419\n",
      "[epoch: 31, i:  6249]  train_loss: 0.609  |  valid_loss: 0.714\n",
      "[epoch: 31, i:  6374]  train_loss: 0.574  |  valid_loss: 0.502\n",
      "[epoch: 31, i:  6499]  train_loss: 0.580  |  valid_loss: 0.558\n",
      "[epoch: 31, i:  6624]  train_loss: 0.578  |  valid_loss: 0.492\n",
      "[epoch: 31, i:  6749]  train_loss: 0.694  |  valid_loss: 0.467\n",
      "[epoch: 31, i:  6874]  train_loss: 0.628  |  valid_loss: 0.563\n",
      "[epoch: 31, i:  6999]  train_loss: 0.588  |  valid_loss: 0.630\n",
      "[epoch: 31, i:  7124]  train_loss: 0.684  |  valid_loss: 0.674\n",
      "[epoch: 31, i:  7249]  train_loss: 0.534  |  valid_loss: 0.474\n",
      "[epoch: 31, i:  7374]  train_loss: 0.560  |  valid_loss: 0.603\n",
      "[epoch: 31, i:  7499]  train_loss: 0.547  |  valid_loss: 0.527\n",
      "[epoch: 31, i:  7624]  train_loss: 0.609  |  valid_loss: 0.470\n",
      "[epoch: 31, i:  7749]  train_loss: 0.617  |  valid_loss: 0.490\n",
      "[epoch: 31, i:  7874]  train_loss: 0.613  |  valid_loss: 0.473\n",
      "[epoch: 31, i:  7999]  train_loss: 0.636  |  valid_loss: 0.400\n",
      "[epoch: 31, i:  8124]  train_loss: 0.587  |  valid_loss: 0.477\n",
      "[epoch: 31, i:  8249]  train_loss: 0.648  |  valid_loss: 0.563\n",
      "[epoch: 31, i:  8374]  train_loss: 0.609  |  valid_loss: 0.502\n",
      "[epoch: 31, i:  8499]  train_loss: 0.607  |  valid_loss: 0.609\n",
      "[epoch: 31, i:  8624]  train_loss: 0.615  |  valid_loss: 0.527\n",
      "[epoch: 31, i:  8749]  train_loss: 0.615  |  valid_loss: 0.749\n",
      "[epoch: 31, i:  8874]  train_loss: 0.634  |  valid_loss: 0.501\n",
      "[epoch: 31, i:  8999]  train_loss: 0.585  |  valid_loss: 0.459\n",
      "[epoch: 31, i:  9124]  train_loss: 0.626  |  valid_loss: 0.430\n",
      "[epoch: 31, i:  9249]  train_loss: 0.610  |  valid_loss: 0.411\n",
      "[epoch: 31, i:  9374]  train_loss: 0.555  |  valid_loss: 0.511\n",
      "[epoch: 31, i:  9499]  train_loss: 0.571  |  valid_loss: 0.526\n",
      "[epoch: 31, i:  9624]  train_loss: 0.620  |  valid_loss: 0.498\n",
      "[epoch: 31, i:  9749]  train_loss: 0.544  |  valid_loss: 0.607\n",
      "[epoch: 31, i:  9874]  train_loss: 0.587  |  valid_loss: 0.613\n",
      "[epoch: 31, i:  9999]  train_loss: 0.584  |  valid_loss: 0.620\n",
      "[epoch: 31, i: 10124]  train_loss: 0.620  |  valid_loss: 0.456\n",
      "[epoch: 31, i: 10249]  train_loss: 0.551  |  valid_loss: 0.492\n",
      "[epoch: 31, i: 10374]  train_loss: 0.551  |  valid_loss: 0.494\n",
      "[epoch: 31, i: 10499]  train_loss: 0.535  |  valid_loss: 0.520\n",
      "[epoch: 31, i: 10624]  train_loss: 0.667  |  valid_loss: 0.605\n",
      "[epoch: 31, i: 10749]  train_loss: 0.598  |  valid_loss: 0.558\n",
      "[epoch: 31, i: 10874]  train_loss: 0.589  |  valid_loss: 0.524\n",
      "[epoch: 31, i: 10999]  train_loss: 0.578  |  valid_loss: 0.574\n",
      "[epoch: 31, i: 11124]  train_loss: 0.617  |  valid_loss: 0.643\n",
      "[epoch: 31, i: 11249]  train_loss: 0.603  |  valid_loss: 0.577\n",
      "[epoch: 31, i: 11374]  train_loss: 0.589  |  valid_loss: 0.438\n",
      "[epoch: 31, i: 11499]  train_loss: 0.587  |  valid_loss: 0.359\n",
      "[epoch: 31, i: 11624]  train_loss: 0.619  |  valid_loss: 0.622\n",
      "[epoch: 31, i: 11749]  train_loss: 0.598  |  valid_loss: 0.630\n",
      "[epoch: 31, i: 11874]  train_loss: 0.597  |  valid_loss: 0.563\n",
      "[epoch: 31, i: 11999]  train_loss: 0.571  |  valid_loss: 0.514\n",
      "[epoch: 31, i: 12124]  train_loss: 0.572  |  valid_loss: 0.466\n",
      "[epoch: 31, i: 12249]  train_loss: 0.546  |  valid_loss: 0.679\n",
      "[epoch: 31, i: 12374]  train_loss: 0.544  |  valid_loss: 0.556\n",
      "[epoch: 31, i: 12499]  train_loss: 0.630  |  valid_loss: 0.469\n",
      "--> [End of epoch 31] train_accuracy: 79.62%  |  valid_accuracy: 80.87%\n",
      "--> [Start of epoch 32]  lr: 0.000017\n",
      "[epoch: 32, i:   124]  train_loss: 0.612  |  valid_loss: 0.632\n",
      "[epoch: 32, i:   249]  train_loss: 0.579  |  valid_loss: 0.614\n",
      "[epoch: 32, i:   374]  train_loss: 0.641  |  valid_loss: 0.560\n",
      "[epoch: 32, i:   499]  train_loss: 0.614  |  valid_loss: 0.649\n",
      "[epoch: 32, i:   624]  train_loss: 0.577  |  valid_loss: 0.540\n",
      "[epoch: 32, i:   749]  train_loss: 0.597  |  valid_loss: 0.333\n",
      "[epoch: 32, i:   874]  train_loss: 0.617  |  valid_loss: 0.589\n",
      "[epoch: 32, i:   999]  train_loss: 0.607  |  valid_loss: 0.593\n",
      "[epoch: 32, i:  1124]  train_loss: 0.613  |  valid_loss: 0.558\n",
      "[epoch: 32, i:  1249]  train_loss: 0.572  |  valid_loss: 0.497\n",
      "[epoch: 32, i:  1374]  train_loss: 0.632  |  valid_loss: 0.515\n",
      "[epoch: 32, i:  1499]  train_loss: 0.561  |  valid_loss: 0.654\n",
      "[epoch: 32, i:  1624]  train_loss: 0.576  |  valid_loss: 0.526\n",
      "[epoch: 32, i:  1749]  train_loss: 0.629  |  valid_loss: 0.531\n",
      "[epoch: 32, i:  1874]  train_loss: 0.549  |  valid_loss: 0.531\n",
      "[epoch: 32, i:  1999]  train_loss: 0.574  |  valid_loss: 0.632\n",
      "[epoch: 32, i:  2124]  train_loss: 0.603  |  valid_loss: 0.565\n",
      "[epoch: 32, i:  2249]  train_loss: 0.642  |  valid_loss: 0.667\n",
      "[epoch: 32, i:  2374]  train_loss: 0.590  |  valid_loss: 0.584\n",
      "[epoch: 32, i:  2499]  train_loss: 0.580  |  valid_loss: 0.786\n",
      "[epoch: 32, i:  2624]  train_loss: 0.586  |  valid_loss: 0.725\n",
      "[epoch: 32, i:  2749]  train_loss: 0.593  |  valid_loss: 0.532\n",
      "[epoch: 32, i:  2874]  train_loss: 0.592  |  valid_loss: 0.661\n",
      "[epoch: 32, i:  2999]  train_loss: 0.577  |  valid_loss: 0.572\n",
      "[epoch: 32, i:  3124]  train_loss: 0.613  |  valid_loss: 0.637\n",
      "[epoch: 32, i:  3249]  train_loss: 0.615  |  valid_loss: 0.797\n",
      "[epoch: 32, i:  3374]  train_loss: 0.608  |  valid_loss: 0.484\n",
      "[epoch: 32, i:  3499]  train_loss: 0.587  |  valid_loss: 0.614\n",
      "[epoch: 32, i:  3624]  train_loss: 0.615  |  valid_loss: 0.701\n",
      "[epoch: 32, i:  3749]  train_loss: 0.586  |  valid_loss: 0.574\n",
      "[epoch: 32, i:  3874]  train_loss: 0.553  |  valid_loss: 0.528\n",
      "[epoch: 32, i:  3999]  train_loss: 0.598  |  valid_loss: 0.578\n",
      "[epoch: 32, i:  4124]  train_loss: 0.556  |  valid_loss: 0.545\n",
      "[epoch: 32, i:  4249]  train_loss: 0.637  |  valid_loss: 0.614\n",
      "[epoch: 32, i:  4374]  train_loss: 0.605  |  valid_loss: 0.738\n",
      "[epoch: 32, i:  4499]  train_loss: 0.615  |  valid_loss: 0.436\n",
      "[epoch: 32, i:  4624]  train_loss: 0.618  |  valid_loss: 0.742\n",
      "[epoch: 32, i:  4749]  train_loss: 0.582  |  valid_loss: 0.516\n",
      "[epoch: 32, i:  4874]  train_loss: 0.588  |  valid_loss: 0.464\n",
      "[epoch: 32, i:  4999]  train_loss: 0.618  |  valid_loss: 0.472\n",
      "[epoch: 32, i:  5124]  train_loss: 0.594  |  valid_loss: 0.514\n",
      "[epoch: 32, i:  5249]  train_loss: 0.599  |  valid_loss: 0.556\n",
      "[epoch: 32, i:  5374]  train_loss: 0.614  |  valid_loss: 0.398\n",
      "[epoch: 32, i:  5499]  train_loss: 0.651  |  valid_loss: 0.568\n",
      "[epoch: 32, i:  5624]  train_loss: 0.574  |  valid_loss: 0.607\n",
      "[epoch: 32, i:  5749]  train_loss: 0.614  |  valid_loss: 0.470\n",
      "[epoch: 32, i:  5874]  train_loss: 0.644  |  valid_loss: 0.431\n",
      "[epoch: 32, i:  5999]  train_loss: 0.621  |  valid_loss: 0.613\n",
      "[epoch: 32, i:  6124]  train_loss: 0.650  |  valid_loss: 0.426\n",
      "[epoch: 32, i:  6249]  train_loss: 0.604  |  valid_loss: 0.701\n",
      "[epoch: 32, i:  6374]  train_loss: 0.627  |  valid_loss: 0.522\n",
      "[epoch: 32, i:  6499]  train_loss: 0.615  |  valid_loss: 0.516\n",
      "[epoch: 32, i:  6624]  train_loss: 0.651  |  valid_loss: 0.520\n",
      "[epoch: 32, i:  6749]  train_loss: 0.582  |  valid_loss: 0.432\n",
      "[epoch: 32, i:  6874]  train_loss: 0.629  |  valid_loss: 0.551\n",
      "[epoch: 32, i:  6999]  train_loss: 0.574  |  valid_loss: 0.631\n",
      "[epoch: 32, i:  7124]  train_loss: 0.621  |  valid_loss: 0.670\n",
      "[epoch: 32, i:  7249]  train_loss: 0.636  |  valid_loss: 0.489\n",
      "[epoch: 32, i:  7374]  train_loss: 0.659  |  valid_loss: 0.595\n",
      "[epoch: 32, i:  7499]  train_loss: 0.576  |  valid_loss: 0.571\n",
      "[epoch: 32, i:  7624]  train_loss: 0.585  |  valid_loss: 0.452\n",
      "[epoch: 32, i:  7749]  train_loss: 0.566  |  valid_loss: 0.507\n",
      "[epoch: 32, i:  7874]  train_loss: 0.569  |  valid_loss: 0.474\n",
      "[epoch: 32, i:  7999]  train_loss: 0.579  |  valid_loss: 0.405\n",
      "[epoch: 32, i:  8124]  train_loss: 0.603  |  valid_loss: 0.498\n",
      "[epoch: 32, i:  8249]  train_loss: 0.517  |  valid_loss: 0.587\n",
      "[epoch: 32, i:  8374]  train_loss: 0.611  |  valid_loss: 0.505\n",
      "[epoch: 32, i:  8499]  train_loss: 0.592  |  valid_loss: 0.609\n",
      "[epoch: 32, i:  8624]  train_loss: 0.583  |  valid_loss: 0.538\n",
      "[epoch: 32, i:  8749]  train_loss: 0.598  |  valid_loss: 0.733\n",
      "[epoch: 32, i:  8874]  train_loss: 0.580  |  valid_loss: 0.485\n",
      "[epoch: 32, i:  8999]  train_loss: 0.571  |  valid_loss: 0.491\n",
      "[epoch: 32, i:  9124]  train_loss: 0.605  |  valid_loss: 0.436\n",
      "[epoch: 32, i:  9249]  train_loss: 0.599  |  valid_loss: 0.430\n",
      "[epoch: 32, i:  9374]  train_loss: 0.585  |  valid_loss: 0.536\n",
      "[epoch: 32, i:  9499]  train_loss: 0.617  |  valid_loss: 0.527\n",
      "[epoch: 32, i:  9624]  train_loss: 0.590  |  valid_loss: 0.537\n",
      "[epoch: 32, i:  9749]  train_loss: 0.645  |  valid_loss: 0.595\n",
      "[epoch: 32, i:  9874]  train_loss: 0.603  |  valid_loss: 0.627\n",
      "[epoch: 32, i:  9999]  train_loss: 0.629  |  valid_loss: 0.568\n",
      "[epoch: 32, i: 10124]  train_loss: 0.540  |  valid_loss: 0.479\n",
      "[epoch: 32, i: 10249]  train_loss: 0.545  |  valid_loss: 0.533\n",
      "[epoch: 32, i: 10374]  train_loss: 0.616  |  valid_loss: 0.452\n",
      "[epoch: 32, i: 10499]  train_loss: 0.563  |  valid_loss: 0.528\n",
      "[epoch: 32, i: 10624]  train_loss: 0.551  |  valid_loss: 0.631\n",
      "[epoch: 32, i: 10749]  train_loss: 0.598  |  valid_loss: 0.546\n",
      "[epoch: 32, i: 10874]  train_loss: 0.602  |  valid_loss: 0.534\n",
      "[epoch: 32, i: 10999]  train_loss: 0.594  |  valid_loss: 0.546\n",
      "[epoch: 32, i: 11124]  train_loss: 0.569  |  valid_loss: 0.646\n",
      "[epoch: 32, i: 11249]  train_loss: 0.582  |  valid_loss: 0.602\n",
      "[epoch: 32, i: 11374]  train_loss: 0.635  |  valid_loss: 0.458\n",
      "[epoch: 32, i: 11499]  train_loss: 0.597  |  valid_loss: 0.370\n",
      "[epoch: 32, i: 11624]  train_loss: 0.548  |  valid_loss: 0.634\n",
      "[epoch: 32, i: 11749]  train_loss: 0.600  |  valid_loss: 0.632\n",
      "[epoch: 32, i: 11874]  train_loss: 0.634  |  valid_loss: 0.563\n",
      "[epoch: 32, i: 11999]  train_loss: 0.548  |  valid_loss: 0.509\n",
      "[epoch: 32, i: 12124]  train_loss: 0.579  |  valid_loss: 0.463\n",
      "[epoch: 32, i: 12249]  train_loss: 0.563  |  valid_loss: 0.703\n",
      "[epoch: 32, i: 12374]  train_loss: 0.610  |  valid_loss: 0.573\n",
      "[epoch: 32, i: 12499]  train_loss: 0.621  |  valid_loss: 0.489\n",
      "--> [End of epoch 32] train_accuracy: 79.61%  |  valid_accuracy: 80.82%\n",
      "--> [Start of epoch 33]  lr: 0.000015\n",
      "[epoch: 33, i:   124]  train_loss: 0.535  |  valid_loss: 0.651\n",
      "[epoch: 33, i:   249]  train_loss: 0.582  |  valid_loss: 0.585\n",
      "[epoch: 33, i:   374]  train_loss: 0.561  |  valid_loss: 0.574\n",
      "[epoch: 33, i:   499]  train_loss: 0.599  |  valid_loss: 0.625\n",
      "[epoch: 33, i:   624]  train_loss: 0.629  |  valid_loss: 0.543\n",
      "[epoch: 33, i:   749]  train_loss: 0.545  |  valid_loss: 0.328\n",
      "[epoch: 33, i:   874]  train_loss: 0.554  |  valid_loss: 0.583\n",
      "[epoch: 33, i:   999]  train_loss: 0.627  |  valid_loss: 0.615\n",
      "[epoch: 33, i:  1124]  train_loss: 0.581  |  valid_loss: 0.569\n",
      "[epoch: 33, i:  1249]  train_loss: 0.634  |  valid_loss: 0.505\n",
      "[epoch: 33, i:  1374]  train_loss: 0.608  |  valid_loss: 0.496\n",
      "[epoch: 33, i:  1499]  train_loss: 0.614  |  valid_loss: 0.623\n",
      "[epoch: 33, i:  1624]  train_loss: 0.625  |  valid_loss: 0.544\n",
      "[epoch: 33, i:  1749]  train_loss: 0.539  |  valid_loss: 0.539\n",
      "[epoch: 33, i:  1874]  train_loss: 0.649  |  valid_loss: 0.519\n",
      "[epoch: 33, i:  1999]  train_loss: 0.613  |  valid_loss: 0.626\n",
      "[epoch: 33, i:  2124]  train_loss: 0.596  |  valid_loss: 0.560\n",
      "[epoch: 33, i:  2249]  train_loss: 0.636  |  valid_loss: 0.665\n",
      "[epoch: 33, i:  2374]  train_loss: 0.595  |  valid_loss: 0.575\n",
      "[epoch: 33, i:  2499]  train_loss: 0.568  |  valid_loss: 0.867\n",
      "[epoch: 33, i:  2624]  train_loss: 0.542  |  valid_loss: 0.715\n",
      "[epoch: 33, i:  2749]  train_loss: 0.633  |  valid_loss: 0.511\n",
      "[epoch: 33, i:  2874]  train_loss: 0.577  |  valid_loss: 0.645\n",
      "[epoch: 33, i:  2999]  train_loss: 0.622  |  valid_loss: 0.569\n",
      "[epoch: 33, i:  3124]  train_loss: 0.558  |  valid_loss: 0.607\n",
      "[epoch: 33, i:  3249]  train_loss: 0.565  |  valid_loss: 0.815\n",
      "[epoch: 33, i:  3374]  train_loss: 0.602  |  valid_loss: 0.446\n",
      "[epoch: 33, i:  3499]  train_loss: 0.570  |  valid_loss: 0.598\n",
      "[epoch: 33, i:  3624]  train_loss: 0.587  |  valid_loss: 0.700\n",
      "[epoch: 33, i:  3749]  train_loss: 0.628  |  valid_loss: 0.602\n",
      "[epoch: 33, i:  3874]  train_loss: 0.579  |  valid_loss: 0.552\n",
      "[epoch: 33, i:  3999]  train_loss: 0.600  |  valid_loss: 0.584\n",
      "[epoch: 33, i:  4124]  train_loss: 0.620  |  valid_loss: 0.529\n",
      "[epoch: 33, i:  4249]  train_loss: 0.650  |  valid_loss: 0.613\n",
      "[epoch: 33, i:  4374]  train_loss: 0.523  |  valid_loss: 0.772\n",
      "[epoch: 33, i:  4499]  train_loss: 0.594  |  valid_loss: 0.467\n",
      "[epoch: 33, i:  4624]  train_loss: 0.578  |  valid_loss: 0.765\n",
      "[epoch: 33, i:  4749]  train_loss: 0.626  |  valid_loss: 0.527\n",
      "[epoch: 33, i:  4874]  train_loss: 0.626  |  valid_loss: 0.455\n",
      "[epoch: 33, i:  4999]  train_loss: 0.592  |  valid_loss: 0.459\n",
      "[epoch: 33, i:  5124]  train_loss: 0.590  |  valid_loss: 0.492\n",
      "[epoch: 33, i:  5249]  train_loss: 0.568  |  valid_loss: 0.552\n",
      "[epoch: 33, i:  5374]  train_loss: 0.545  |  valid_loss: 0.367\n",
      "[epoch: 33, i:  5499]  train_loss: 0.585  |  valid_loss: 0.560\n",
      "[epoch: 33, i:  5624]  train_loss: 0.574  |  valid_loss: 0.603\n",
      "[epoch: 33, i:  5749]  train_loss: 0.554  |  valid_loss: 0.480\n",
      "[epoch: 33, i:  5874]  train_loss: 0.577  |  valid_loss: 0.441\n",
      "[epoch: 33, i:  5999]  train_loss: 0.634  |  valid_loss: 0.598\n",
      "[epoch: 33, i:  6124]  train_loss: 0.593  |  valid_loss: 0.408\n",
      "[epoch: 33, i:  6249]  train_loss: 0.567  |  valid_loss: 0.725\n",
      "[epoch: 33, i:  6374]  train_loss: 0.580  |  valid_loss: 0.493\n",
      "[epoch: 33, i:  6499]  train_loss: 0.592  |  valid_loss: 0.564\n",
      "[epoch: 33, i:  6624]  train_loss: 0.562  |  valid_loss: 0.521\n",
      "[epoch: 33, i:  6749]  train_loss: 0.610  |  valid_loss: 0.442\n",
      "[epoch: 33, i:  6874]  train_loss: 0.659  |  valid_loss: 0.540\n",
      "[epoch: 33, i:  6999]  train_loss: 0.622  |  valid_loss: 0.660\n",
      "[epoch: 33, i:  7124]  train_loss: 0.525  |  valid_loss: 0.670\n",
      "[epoch: 33, i:  7249]  train_loss: 0.601  |  valid_loss: 0.486\n",
      "[epoch: 33, i:  7374]  train_loss: 0.587  |  valid_loss: 0.602\n",
      "[epoch: 33, i:  7499]  train_loss: 0.666  |  valid_loss: 0.539\n",
      "[epoch: 33, i:  7624]  train_loss: 0.597  |  valid_loss: 0.445\n",
      "[epoch: 33, i:  7749]  train_loss: 0.583  |  valid_loss: 0.526\n",
      "[epoch: 33, i:  7874]  train_loss: 0.622  |  valid_loss: 0.469\n",
      "[epoch: 33, i:  7999]  train_loss: 0.593  |  valid_loss: 0.395\n",
      "[epoch: 33, i:  8124]  train_loss: 0.620  |  valid_loss: 0.506\n",
      "[epoch: 33, i:  8249]  train_loss: 0.558  |  valid_loss: 0.553\n",
      "[epoch: 33, i:  8374]  train_loss: 0.544  |  valid_loss: 0.473\n",
      "[epoch: 33, i:  8499]  train_loss: 0.516  |  valid_loss: 0.632\n",
      "[epoch: 33, i:  8624]  train_loss: 0.605  |  valid_loss: 0.552\n",
      "[epoch: 33, i:  8749]  train_loss: 0.573  |  valid_loss: 0.713\n",
      "[epoch: 33, i:  8874]  train_loss: 0.553  |  valid_loss: 0.534\n",
      "[epoch: 33, i:  8999]  train_loss: 0.587  |  valid_loss: 0.495\n",
      "[epoch: 33, i:  9124]  train_loss: 0.576  |  valid_loss: 0.489\n",
      "[epoch: 33, i:  9249]  train_loss: 0.643  |  valid_loss: 0.423\n",
      "[epoch: 33, i:  9374]  train_loss: 0.624  |  valid_loss: 0.535\n",
      "[epoch: 33, i:  9499]  train_loss: 0.613  |  valid_loss: 0.525\n",
      "[epoch: 33, i:  9624]  train_loss: 0.600  |  valid_loss: 0.536\n",
      "[epoch: 33, i:  9749]  train_loss: 0.578  |  valid_loss: 0.610\n",
      "[epoch: 33, i:  9874]  train_loss: 0.631  |  valid_loss: 0.580\n",
      "[epoch: 33, i:  9999]  train_loss: 0.589  |  valid_loss: 0.613\n",
      "[epoch: 33, i: 10124]  train_loss: 0.572  |  valid_loss: 0.438\n",
      "[epoch: 33, i: 10249]  train_loss: 0.568  |  valid_loss: 0.521\n",
      "[epoch: 33, i: 10374]  train_loss: 0.610  |  valid_loss: 0.476\n",
      "[epoch: 33, i: 10499]  train_loss: 0.632  |  valid_loss: 0.489\n",
      "[epoch: 33, i: 10624]  train_loss: 0.576  |  valid_loss: 0.615\n",
      "[epoch: 33, i: 10749]  train_loss: 0.622  |  valid_loss: 0.568\n",
      "[epoch: 33, i: 10874]  train_loss: 0.613  |  valid_loss: 0.532\n",
      "[epoch: 33, i: 10999]  train_loss: 0.651  |  valid_loss: 0.541\n",
      "[epoch: 33, i: 11124]  train_loss: 0.611  |  valid_loss: 0.637\n",
      "[epoch: 33, i: 11249]  train_loss: 0.591  |  valid_loss: 0.577\n",
      "[epoch: 33, i: 11374]  train_loss: 0.626  |  valid_loss: 0.439\n",
      "[epoch: 33, i: 11499]  train_loss: 0.590  |  valid_loss: 0.366\n",
      "[epoch: 33, i: 11624]  train_loss: 0.565  |  valid_loss: 0.608\n",
      "[epoch: 33, i: 11749]  train_loss: 0.660  |  valid_loss: 0.621\n",
      "[epoch: 33, i: 11874]  train_loss: 0.597  |  valid_loss: 0.586\n",
      "[epoch: 33, i: 11999]  train_loss: 0.615  |  valid_loss: 0.465\n",
      "[epoch: 33, i: 12124]  train_loss: 0.574  |  valid_loss: 0.462\n",
      "[epoch: 33, i: 12249]  train_loss: 0.573  |  valid_loss: 0.691\n",
      "[epoch: 33, i: 12374]  train_loss: 0.562  |  valid_loss: 0.544\n",
      "[epoch: 33, i: 12499]  train_loss: 0.613  |  valid_loss: 0.502\n",
      "--> [End of epoch 33] train_accuracy: 79.76%  |  valid_accuracy: 80.99%\n",
      "--> [Start of epoch 34]  lr: 0.000014\n",
      "[epoch: 34, i:   124]  train_loss: 0.593  |  valid_loss: 0.640\n",
      "[epoch: 34, i:   249]  train_loss: 0.571  |  valid_loss: 0.594\n",
      "[epoch: 34, i:   374]  train_loss: 0.586  |  valid_loss: 0.584\n",
      "[epoch: 34, i:   499]  train_loss: 0.640  |  valid_loss: 0.613\n",
      "[epoch: 34, i:   624]  train_loss: 0.540  |  valid_loss: 0.544\n",
      "[epoch: 34, i:   749]  train_loss: 0.636  |  valid_loss: 0.331\n",
      "[epoch: 34, i:   874]  train_loss: 0.651  |  valid_loss: 0.605\n",
      "[epoch: 34, i:   999]  train_loss: 0.613  |  valid_loss: 0.582\n",
      "[epoch: 34, i:  1124]  train_loss: 0.579  |  valid_loss: 0.570\n",
      "[epoch: 34, i:  1249]  train_loss: 0.573  |  valid_loss: 0.496\n",
      "[epoch: 34, i:  1374]  train_loss: 0.554  |  valid_loss: 0.484\n",
      "[epoch: 34, i:  1499]  train_loss: 0.631  |  valid_loss: 0.635\n",
      "[epoch: 34, i:  1624]  train_loss: 0.602  |  valid_loss: 0.525\n",
      "[epoch: 34, i:  1749]  train_loss: 0.630  |  valid_loss: 0.541\n",
      "[epoch: 34, i:  1874]  train_loss: 0.554  |  valid_loss: 0.519\n",
      "[epoch: 34, i:  1999]  train_loss: 0.617  |  valid_loss: 0.606\n",
      "[epoch: 34, i:  2124]  train_loss: 0.563  |  valid_loss: 0.557\n",
      "[epoch: 34, i:  2249]  train_loss: 0.632  |  valid_loss: 0.652\n",
      "[epoch: 34, i:  2374]  train_loss: 0.583  |  valid_loss: 0.576\n",
      "[epoch: 34, i:  2499]  train_loss: 0.556  |  valid_loss: 0.809\n",
      "[epoch: 34, i:  2624]  train_loss: 0.626  |  valid_loss: 0.708\n",
      "[epoch: 34, i:  2749]  train_loss: 0.552  |  valid_loss: 0.531\n",
      "[epoch: 34, i:  2874]  train_loss: 0.592  |  valid_loss: 0.667\n",
      "[epoch: 34, i:  2999]  train_loss: 0.588  |  valid_loss: 0.567\n",
      "[epoch: 34, i:  3124]  train_loss: 0.575  |  valid_loss: 0.608\n",
      "[epoch: 34, i:  3249]  train_loss: 0.660  |  valid_loss: 0.811\n",
      "[epoch: 34, i:  3374]  train_loss: 0.616  |  valid_loss: 0.488\n",
      "[epoch: 34, i:  3499]  train_loss: 0.590  |  valid_loss: 0.570\n",
      "[epoch: 34, i:  3624]  train_loss: 0.586  |  valid_loss: 0.667\n",
      "[epoch: 34, i:  3749]  train_loss: 0.544  |  valid_loss: 0.607\n",
      "[epoch: 34, i:  3874]  train_loss: 0.605  |  valid_loss: 0.545\n",
      "[epoch: 34, i:  3999]  train_loss: 0.573  |  valid_loss: 0.574\n",
      "[epoch: 34, i:  4124]  train_loss: 0.586  |  valid_loss: 0.515\n",
      "[epoch: 34, i:  4249]  train_loss: 0.584  |  valid_loss: 0.601\n",
      "[epoch: 34, i:  4374]  train_loss: 0.570  |  valid_loss: 0.728\n",
      "[epoch: 34, i:  4499]  train_loss: 0.558  |  valid_loss: 0.426\n",
      "[epoch: 34, i:  4624]  train_loss: 0.554  |  valid_loss: 0.758\n",
      "[epoch: 34, i:  4749]  train_loss: 0.633  |  valid_loss: 0.517\n",
      "[epoch: 34, i:  4874]  train_loss: 0.618  |  valid_loss: 0.433\n",
      "[epoch: 34, i:  4999]  train_loss: 0.605  |  valid_loss: 0.476\n",
      "[epoch: 34, i:  5124]  train_loss: 0.615  |  valid_loss: 0.496\n",
      "[epoch: 34, i:  5249]  train_loss: 0.541  |  valid_loss: 0.588\n",
      "[epoch: 34, i:  5374]  train_loss: 0.592  |  valid_loss: 0.363\n",
      "[epoch: 34, i:  5499]  train_loss: 0.629  |  valid_loss: 0.564\n",
      "[epoch: 34, i:  5624]  train_loss: 0.574  |  valid_loss: 0.613\n",
      "[epoch: 34, i:  5749]  train_loss: 0.616  |  valid_loss: 0.477\n",
      "[epoch: 34, i:  5874]  train_loss: 0.538  |  valid_loss: 0.454\n",
      "[epoch: 34, i:  5999]  train_loss: 0.575  |  valid_loss: 0.609\n",
      "[epoch: 34, i:  6124]  train_loss: 0.643  |  valid_loss: 0.420\n",
      "[epoch: 34, i:  6249]  train_loss: 0.616  |  valid_loss: 0.698\n",
      "[epoch: 34, i:  6374]  train_loss: 0.581  |  valid_loss: 0.496\n",
      "[epoch: 34, i:  6499]  train_loss: 0.599  |  valid_loss: 0.552\n",
      "[epoch: 34, i:  6624]  train_loss: 0.602  |  valid_loss: 0.498\n",
      "[epoch: 34, i:  6749]  train_loss: 0.590  |  valid_loss: 0.447\n",
      "[epoch: 34, i:  6874]  train_loss: 0.564  |  valid_loss: 0.561\n",
      "[epoch: 34, i:  6999]  train_loss: 0.589  |  valid_loss: 0.634\n",
      "[epoch: 34, i:  7124]  train_loss: 0.606  |  valid_loss: 0.689\n",
      "[epoch: 34, i:  7249]  train_loss: 0.606  |  valid_loss: 0.458\n",
      "[epoch: 34, i:  7374]  train_loss: 0.565  |  valid_loss: 0.607\n",
      "[epoch: 34, i:  7499]  train_loss: 0.596  |  valid_loss: 0.529\n",
      "[epoch: 34, i:  7624]  train_loss: 0.568  |  valid_loss: 0.463\n",
      "[epoch: 34, i:  7749]  train_loss: 0.588  |  valid_loss: 0.476\n",
      "[epoch: 34, i:  7874]  train_loss: 0.594  |  valid_loss: 0.471\n",
      "[epoch: 34, i:  7999]  train_loss: 0.597  |  valid_loss: 0.393\n",
      "[epoch: 34, i:  8124]  train_loss: 0.565  |  valid_loss: 0.482\n",
      "[epoch: 34, i:  8249]  train_loss: 0.561  |  valid_loss: 0.601\n",
      "[epoch: 34, i:  8374]  train_loss: 0.607  |  valid_loss: 0.501\n",
      "[epoch: 34, i:  8499]  train_loss: 0.626  |  valid_loss: 0.655\n",
      "[epoch: 34, i:  8624]  train_loss: 0.531  |  valid_loss: 0.523\n",
      "[epoch: 34, i:  8749]  train_loss: 0.616  |  valid_loss: 0.721\n",
      "[epoch: 34, i:  8874]  train_loss: 0.592  |  valid_loss: 0.526\n",
      "[epoch: 34, i:  8999]  train_loss: 0.542  |  valid_loss: 0.463\n",
      "[epoch: 34, i:  9124]  train_loss: 0.583  |  valid_loss: 0.474\n",
      "[epoch: 34, i:  9249]  train_loss: 0.554  |  valid_loss: 0.405\n",
      "[epoch: 34, i:  9374]  train_loss: 0.578  |  valid_loss: 0.500\n",
      "[epoch: 34, i:  9499]  train_loss: 0.577  |  valid_loss: 0.525\n",
      "[epoch: 34, i:  9624]  train_loss: 0.601  |  valid_loss: 0.545\n",
      "[epoch: 34, i:  9749]  train_loss: 0.584  |  valid_loss: 0.580\n",
      "[epoch: 34, i:  9874]  train_loss: 0.630  |  valid_loss: 0.591\n",
      "[epoch: 34, i:  9999]  train_loss: 0.596  |  valid_loss: 0.562\n",
      "[epoch: 34, i: 10124]  train_loss: 0.619  |  valid_loss: 0.463\n",
      "[epoch: 34, i: 10249]  train_loss: 0.591  |  valid_loss: 0.501\n",
      "[epoch: 34, i: 10374]  train_loss: 0.630  |  valid_loss: 0.471\n",
      "[epoch: 34, i: 10499]  train_loss: 0.582  |  valid_loss: 0.502\n",
      "[epoch: 34, i: 10624]  train_loss: 0.593  |  valid_loss: 0.634\n",
      "[epoch: 34, i: 10749]  train_loss: 0.565  |  valid_loss: 0.536\n",
      "[epoch: 34, i: 10874]  train_loss: 0.600  |  valid_loss: 0.550\n",
      "[epoch: 34, i: 10999]  train_loss: 0.586  |  valid_loss: 0.541\n",
      "[epoch: 34, i: 11124]  train_loss: 0.569  |  valid_loss: 0.654\n",
      "[epoch: 34, i: 11249]  train_loss: 0.589  |  valid_loss: 0.596\n",
      "[epoch: 34, i: 11374]  train_loss: 0.579  |  valid_loss: 0.433\n",
      "[epoch: 34, i: 11499]  train_loss: 0.616  |  valid_loss: 0.343\n",
      "[epoch: 34, i: 11624]  train_loss: 0.611  |  valid_loss: 0.611\n",
      "[epoch: 34, i: 11749]  train_loss: 0.582  |  valid_loss: 0.603\n",
      "[epoch: 34, i: 11874]  train_loss: 0.583  |  valid_loss: 0.593\n",
      "[epoch: 34, i: 11999]  train_loss: 0.610  |  valid_loss: 0.487\n",
      "[epoch: 34, i: 12124]  train_loss: 0.535  |  valid_loss: 0.460\n",
      "[epoch: 34, i: 12249]  train_loss: 0.633  |  valid_loss: 0.678\n",
      "[epoch: 34, i: 12374]  train_loss: 0.636  |  valid_loss: 0.569\n",
      "[epoch: 34, i: 12499]  train_loss: 0.608  |  valid_loss: 0.479\n",
      "--> [End of epoch 34] train_accuracy: 79.83%  |  valid_accuracy: 80.90%\n",
      "--> [Start of epoch 35]  lr: 0.000013\n",
      "[epoch: 35, i:   124]  train_loss: 0.558  |  valid_loss: 0.656\n",
      "[epoch: 35, i:   249]  train_loss: 0.634  |  valid_loss: 0.580\n",
      "[epoch: 35, i:   374]  train_loss: 0.552  |  valid_loss: 0.571\n",
      "[epoch: 35, i:   499]  train_loss: 0.557  |  valid_loss: 0.654\n",
      "[epoch: 35, i:   624]  train_loss: 0.537  |  valid_loss: 0.530\n",
      "[epoch: 35, i:   749]  train_loss: 0.534  |  valid_loss: 0.338\n",
      "[epoch: 35, i:   874]  train_loss: 0.517  |  valid_loss: 0.561\n",
      "[epoch: 35, i:   999]  train_loss: 0.608  |  valid_loss: 0.578\n",
      "[epoch: 35, i:  1124]  train_loss: 0.610  |  valid_loss: 0.590\n",
      "[epoch: 35, i:  1249]  train_loss: 0.610  |  valid_loss: 0.511\n",
      "[epoch: 35, i:  1374]  train_loss: 0.568  |  valid_loss: 0.486\n",
      "[epoch: 35, i:  1499]  train_loss: 0.593  |  valid_loss: 0.631\n",
      "[epoch: 35, i:  1624]  train_loss: 0.638  |  valid_loss: 0.533\n",
      "[epoch: 35, i:  1749]  train_loss: 0.520  |  valid_loss: 0.550\n",
      "[epoch: 35, i:  1874]  train_loss: 0.568  |  valid_loss: 0.536\n",
      "[epoch: 35, i:  1999]  train_loss: 0.592  |  valid_loss: 0.606\n",
      "[epoch: 35, i:  2124]  train_loss: 0.558  |  valid_loss: 0.522\n",
      "[epoch: 35, i:  2249]  train_loss: 0.572  |  valid_loss: 0.652\n",
      "[epoch: 35, i:  2374]  train_loss: 0.573  |  valid_loss: 0.579\n",
      "[epoch: 35, i:  2499]  train_loss: 0.608  |  valid_loss: 0.835\n",
      "[epoch: 35, i:  2624]  train_loss: 0.597  |  valid_loss: 0.716\n",
      "[epoch: 35, i:  2749]  train_loss: 0.495  |  valid_loss: 0.516\n",
      "[epoch: 35, i:  2874]  train_loss: 0.600  |  valid_loss: 0.679\n",
      "[epoch: 35, i:  2999]  train_loss: 0.564  |  valid_loss: 0.551\n",
      "[epoch: 35, i:  3124]  train_loss: 0.593  |  valid_loss: 0.593\n",
      "[epoch: 35, i:  3249]  train_loss: 0.539  |  valid_loss: 0.828\n",
      "[epoch: 35, i:  3374]  train_loss: 0.552  |  valid_loss: 0.475\n",
      "[epoch: 35, i:  3499]  train_loss: 0.562  |  valid_loss: 0.582\n",
      "[epoch: 35, i:  3624]  train_loss: 0.625  |  valid_loss: 0.682\n",
      "[epoch: 35, i:  3749]  train_loss: 0.621  |  valid_loss: 0.586\n",
      "[epoch: 35, i:  3874]  train_loss: 0.574  |  valid_loss: 0.509\n",
      "[epoch: 35, i:  3999]  train_loss: 0.587  |  valid_loss: 0.558\n",
      "[epoch: 35, i:  4124]  train_loss: 0.541  |  valid_loss: 0.528\n",
      "[epoch: 35, i:  4249]  train_loss: 0.640  |  valid_loss: 0.624\n",
      "[epoch: 35, i:  4374]  train_loss: 0.599  |  valid_loss: 0.737\n",
      "[epoch: 35, i:  4499]  train_loss: 0.614  |  valid_loss: 0.429\n",
      "[epoch: 35, i:  4624]  train_loss: 0.645  |  valid_loss: 0.797\n",
      "[epoch: 35, i:  4749]  train_loss: 0.502  |  valid_loss: 0.542\n",
      "[epoch: 35, i:  4874]  train_loss: 0.635  |  valid_loss: 0.446\n",
      "[epoch: 35, i:  4999]  train_loss: 0.616  |  valid_loss: 0.451\n",
      "[epoch: 35, i:  5124]  train_loss: 0.554  |  valid_loss: 0.503\n",
      "[epoch: 35, i:  5249]  train_loss: 0.577  |  valid_loss: 0.560\n",
      "[epoch: 35, i:  5374]  train_loss: 0.630  |  valid_loss: 0.385\n",
      "[epoch: 35, i:  5499]  train_loss: 0.539  |  valid_loss: 0.564\n",
      "[epoch: 35, i:  5624]  train_loss: 0.596  |  valid_loss: 0.612\n",
      "[epoch: 35, i:  5749]  train_loss: 0.559  |  valid_loss: 0.480\n",
      "[epoch: 35, i:  5874]  train_loss: 0.545  |  valid_loss: 0.459\n",
      "[epoch: 35, i:  5999]  train_loss: 0.629  |  valid_loss: 0.606\n",
      "[epoch: 35, i:  6124]  train_loss: 0.596  |  valid_loss: 0.440\n",
      "[epoch: 35, i:  6249]  train_loss: 0.624  |  valid_loss: 0.745\n",
      "[epoch: 35, i:  6374]  train_loss: 0.582  |  valid_loss: 0.502\n",
      "[epoch: 35, i:  6499]  train_loss: 0.574  |  valid_loss: 0.558\n",
      "[epoch: 35, i:  6624]  train_loss: 0.581  |  valid_loss: 0.479\n",
      "[epoch: 35, i:  6749]  train_loss: 0.621  |  valid_loss: 0.449\n",
      "[epoch: 35, i:  6874]  train_loss: 0.573  |  valid_loss: 0.558\n",
      "[epoch: 35, i:  6999]  train_loss: 0.580  |  valid_loss: 0.654\n",
      "[epoch: 35, i:  7124]  train_loss: 0.594  |  valid_loss: 0.684\n",
      "[epoch: 35, i:  7249]  train_loss: 0.605  |  valid_loss: 0.468\n",
      "[epoch: 35, i:  7374]  train_loss: 0.605  |  valid_loss: 0.602\n",
      "[epoch: 35, i:  7499]  train_loss: 0.597  |  valid_loss: 0.515\n",
      "[epoch: 35, i:  7624]  train_loss: 0.546  |  valid_loss: 0.452\n",
      "[epoch: 35, i:  7749]  train_loss: 0.649  |  valid_loss: 0.492\n",
      "[epoch: 35, i:  7874]  train_loss: 0.608  |  valid_loss: 0.486\n",
      "[epoch: 35, i:  7999]  train_loss: 0.578  |  valid_loss: 0.393\n",
      "[epoch: 35, i:  8124]  train_loss: 0.572  |  valid_loss: 0.465\n",
      "[epoch: 35, i:  8249]  train_loss: 0.567  |  valid_loss: 0.560\n",
      "[epoch: 35, i:  8374]  train_loss: 0.627  |  valid_loss: 0.476\n",
      "[epoch: 35, i:  8499]  train_loss: 0.562  |  valid_loss: 0.674\n",
      "[epoch: 35, i:  8624]  train_loss: 0.644  |  valid_loss: 0.550\n",
      "[epoch: 35, i:  8749]  train_loss: 0.558  |  valid_loss: 0.734\n",
      "[epoch: 35, i:  8874]  train_loss: 0.620  |  valid_loss: 0.518\n",
      "[epoch: 35, i:  8999]  train_loss: 0.606  |  valid_loss: 0.467\n",
      "[epoch: 35, i:  9124]  train_loss: 0.598  |  valid_loss: 0.457\n",
      "[epoch: 35, i:  9249]  train_loss: 0.562  |  valid_loss: 0.400\n",
      "[epoch: 35, i:  9374]  train_loss: 0.586  |  valid_loss: 0.496\n",
      "[epoch: 35, i:  9499]  train_loss: 0.617  |  valid_loss: 0.530\n",
      "[epoch: 35, i:  9624]  train_loss: 0.678  |  valid_loss: 0.529\n",
      "[epoch: 35, i:  9749]  train_loss: 0.551  |  valid_loss: 0.605\n",
      "[epoch: 35, i:  9874]  train_loss: 0.598  |  valid_loss: 0.574\n",
      "[epoch: 35, i:  9999]  train_loss: 0.646  |  valid_loss: 0.597\n",
      "[epoch: 35, i: 10124]  train_loss: 0.629  |  valid_loss: 0.465\n",
      "[epoch: 35, i: 10249]  train_loss: 0.573  |  valid_loss: 0.523\n",
      "[epoch: 35, i: 10374]  train_loss: 0.607  |  valid_loss: 0.488\n",
      "[epoch: 35, i: 10499]  train_loss: 0.604  |  valid_loss: 0.505\n",
      "[epoch: 35, i: 10624]  train_loss: 0.605  |  valid_loss: 0.588\n",
      "[epoch: 35, i: 10749]  train_loss: 0.634  |  valid_loss: 0.544\n",
      "[epoch: 35, i: 10874]  train_loss: 0.582  |  valid_loss: 0.520\n",
      "[epoch: 35, i: 10999]  train_loss: 0.566  |  valid_loss: 0.551\n",
      "[epoch: 35, i: 11124]  train_loss: 0.578  |  valid_loss: 0.630\n",
      "[epoch: 35, i: 11249]  train_loss: 0.585  |  valid_loss: 0.587\n",
      "[epoch: 35, i: 11374]  train_loss: 0.564  |  valid_loss: 0.445\n",
      "[epoch: 35, i: 11499]  train_loss: 0.636  |  valid_loss: 0.370\n",
      "[epoch: 35, i: 11624]  train_loss: 0.562  |  valid_loss: 0.596\n",
      "[epoch: 35, i: 11749]  train_loss: 0.505  |  valid_loss: 0.618\n",
      "[epoch: 35, i: 11874]  train_loss: 0.601  |  valid_loss: 0.605\n",
      "[epoch: 35, i: 11999]  train_loss: 0.660  |  valid_loss: 0.473\n",
      "[epoch: 35, i: 12124]  train_loss: 0.603  |  valid_loss: 0.443\n",
      "[epoch: 35, i: 12249]  train_loss: 0.612  |  valid_loss: 0.686\n",
      "[epoch: 35, i: 12374]  train_loss: 0.609  |  valid_loss: 0.555\n",
      "[epoch: 35, i: 12499]  train_loss: 0.631  |  valid_loss: 0.499\n",
      "--> [End of epoch 35] train_accuracy: 79.92%  |  valid_accuracy: 81.09%\n",
      "--> [Start of epoch 36]  lr: 0.000011\n",
      "[epoch: 36, i:   124]  train_loss: 0.619  |  valid_loss: 0.602\n",
      "[epoch: 36, i:   249]  train_loss: 0.546  |  valid_loss: 0.590\n",
      "[epoch: 36, i:   374]  train_loss: 0.604  |  valid_loss: 0.580\n",
      "[epoch: 36, i:   499]  train_loss: 0.590  |  valid_loss: 0.637\n",
      "[epoch: 36, i:   624]  train_loss: 0.598  |  valid_loss: 0.532\n",
      "[epoch: 36, i:   749]  train_loss: 0.578  |  valid_loss: 0.325\n",
      "[epoch: 36, i:   874]  train_loss: 0.566  |  valid_loss: 0.572\n",
      "[epoch: 36, i:   999]  train_loss: 0.541  |  valid_loss: 0.575\n",
      "[epoch: 36, i:  1124]  train_loss: 0.601  |  valid_loss: 0.557\n",
      "[epoch: 36, i:  1249]  train_loss: 0.638  |  valid_loss: 0.522\n",
      "[epoch: 36, i:  1374]  train_loss: 0.599  |  valid_loss: 0.486\n",
      "[epoch: 36, i:  1499]  train_loss: 0.600  |  valid_loss: 0.640\n",
      "[epoch: 36, i:  1624]  train_loss: 0.577  |  valid_loss: 0.557\n",
      "[epoch: 36, i:  1749]  train_loss: 0.580  |  valid_loss: 0.579\n",
      "[epoch: 36, i:  1874]  train_loss: 0.609  |  valid_loss: 0.504\n",
      "[epoch: 36, i:  1999]  train_loss: 0.560  |  valid_loss: 0.610\n",
      "[epoch: 36, i:  2124]  train_loss: 0.565  |  valid_loss: 0.558\n",
      "[epoch: 36, i:  2249]  train_loss: 0.573  |  valid_loss: 0.656\n",
      "[epoch: 36, i:  2374]  train_loss: 0.592  |  valid_loss: 0.562\n",
      "[epoch: 36, i:  2499]  train_loss: 0.585  |  valid_loss: 0.823\n",
      "[epoch: 36, i:  2624]  train_loss: 0.600  |  valid_loss: 0.701\n",
      "[epoch: 36, i:  2749]  train_loss: 0.591  |  valid_loss: 0.521\n",
      "[epoch: 36, i:  2874]  train_loss: 0.595  |  valid_loss: 0.653\n",
      "[epoch: 36, i:  2999]  train_loss: 0.629  |  valid_loss: 0.565\n",
      "[epoch: 36, i:  3124]  train_loss: 0.590  |  valid_loss: 0.616\n",
      "[epoch: 36, i:  3249]  train_loss: 0.634  |  valid_loss: 0.800\n",
      "[epoch: 36, i:  3374]  train_loss: 0.601  |  valid_loss: 0.483\n",
      "[epoch: 36, i:  3499]  train_loss: 0.609  |  valid_loss: 0.606\n",
      "[epoch: 36, i:  3624]  train_loss: 0.600  |  valid_loss: 0.677\n",
      "[epoch: 36, i:  3749]  train_loss: 0.587  |  valid_loss: 0.584\n",
      "[epoch: 36, i:  3874]  train_loss: 0.527  |  valid_loss: 0.536\n",
      "[epoch: 36, i:  3999]  train_loss: 0.603  |  valid_loss: 0.536\n",
      "[epoch: 36, i:  4124]  train_loss: 0.631  |  valid_loss: 0.523\n",
      "[epoch: 36, i:  4249]  train_loss: 0.644  |  valid_loss: 0.617\n",
      "[epoch: 36, i:  4374]  train_loss: 0.596  |  valid_loss: 0.745\n",
      "[epoch: 36, i:  4499]  train_loss: 0.592  |  valid_loss: 0.459\n",
      "[epoch: 36, i:  4624]  train_loss: 0.546  |  valid_loss: 0.783\n",
      "[epoch: 36, i:  4749]  train_loss: 0.569  |  valid_loss: 0.525\n",
      "[epoch: 36, i:  4874]  train_loss: 0.590  |  valid_loss: 0.439\n",
      "[epoch: 36, i:  4999]  train_loss: 0.580  |  valid_loss: 0.429\n",
      "[epoch: 36, i:  5124]  train_loss: 0.510  |  valid_loss: 0.527\n",
      "[epoch: 36, i:  5249]  train_loss: 0.534  |  valid_loss: 0.582\n",
      "[epoch: 36, i:  5374]  train_loss: 0.556  |  valid_loss: 0.365\n",
      "[epoch: 36, i:  5499]  train_loss: 0.594  |  valid_loss: 0.581\n",
      "[epoch: 36, i:  5624]  train_loss: 0.651  |  valid_loss: 0.586\n",
      "[epoch: 36, i:  5749]  train_loss: 0.607  |  valid_loss: 0.490\n",
      "[epoch: 36, i:  5874]  train_loss: 0.607  |  valid_loss: 0.445\n",
      "[epoch: 36, i:  5999]  train_loss: 0.609  |  valid_loss: 0.568\n",
      "[epoch: 36, i:  6124]  train_loss: 0.591  |  valid_loss: 0.415\n",
      "[epoch: 36, i:  6249]  train_loss: 0.597  |  valid_loss: 0.702\n",
      "[epoch: 36, i:  6374]  train_loss: 0.548  |  valid_loss: 0.512\n",
      "[epoch: 36, i:  6499]  train_loss: 0.542  |  valid_loss: 0.557\n",
      "[epoch: 36, i:  6624]  train_loss: 0.552  |  valid_loss: 0.499\n",
      "[epoch: 36, i:  6749]  train_loss: 0.616  |  valid_loss: 0.437\n",
      "[epoch: 36, i:  6874]  train_loss: 0.538  |  valid_loss: 0.536\n",
      "[epoch: 36, i:  6999]  train_loss: 0.591  |  valid_loss: 0.659\n",
      "[epoch: 36, i:  7124]  train_loss: 0.560  |  valid_loss: 0.663\n",
      "[epoch: 36, i:  7249]  train_loss: 0.576  |  valid_loss: 0.476\n",
      "[epoch: 36, i:  7374]  train_loss: 0.576  |  valid_loss: 0.623\n",
      "[epoch: 36, i:  7499]  train_loss: 0.595  |  valid_loss: 0.545\n",
      "[epoch: 36, i:  7624]  train_loss: 0.634  |  valid_loss: 0.488\n",
      "[epoch: 36, i:  7749]  train_loss: 0.620  |  valid_loss: 0.491\n",
      "[epoch: 36, i:  7874]  train_loss: 0.597  |  valid_loss: 0.479\n",
      "[epoch: 36, i:  7999]  train_loss: 0.575  |  valid_loss: 0.432\n",
      "[epoch: 36, i:  8124]  train_loss: 0.609  |  valid_loss: 0.485\n",
      "[epoch: 36, i:  8249]  train_loss: 0.631  |  valid_loss: 0.564\n",
      "[epoch: 36, i:  8374]  train_loss: 0.628  |  valid_loss: 0.510\n",
      "[epoch: 36, i:  8499]  train_loss: 0.590  |  valid_loss: 0.635\n",
      "[epoch: 36, i:  8624]  train_loss: 0.566  |  valid_loss: 0.524\n",
      "[epoch: 36, i:  8749]  train_loss: 0.569  |  valid_loss: 0.714\n",
      "[epoch: 36, i:  8874]  train_loss: 0.563  |  valid_loss: 0.520\n",
      "[epoch: 36, i:  8999]  train_loss: 0.616  |  valid_loss: 0.438\n",
      "[epoch: 36, i:  9124]  train_loss: 0.579  |  valid_loss: 0.455\n",
      "[epoch: 36, i:  9249]  train_loss: 0.651  |  valid_loss: 0.407\n",
      "[epoch: 36, i:  9374]  train_loss: 0.600  |  valid_loss: 0.508\n",
      "[epoch: 36, i:  9499]  train_loss: 0.529  |  valid_loss: 0.523\n",
      "[epoch: 36, i:  9624]  train_loss: 0.558  |  valid_loss: 0.536\n",
      "[epoch: 36, i:  9749]  train_loss: 0.587  |  valid_loss: 0.592\n",
      "[epoch: 36, i:  9874]  train_loss: 0.590  |  valid_loss: 0.596\n",
      "[epoch: 36, i:  9999]  train_loss: 0.594  |  valid_loss: 0.569\n",
      "[epoch: 36, i: 10124]  train_loss: 0.570  |  valid_loss: 0.476\n",
      "[epoch: 36, i: 10249]  train_loss: 0.534  |  valid_loss: 0.524\n",
      "[epoch: 36, i: 10374]  train_loss: 0.585  |  valid_loss: 0.481\n",
      "[epoch: 36, i: 10499]  train_loss: 0.571  |  valid_loss: 0.538\n",
      "[epoch: 36, i: 10624]  train_loss: 0.627  |  valid_loss: 0.628\n",
      "[epoch: 36, i: 10749]  train_loss: 0.578  |  valid_loss: 0.543\n",
      "[epoch: 36, i: 10874]  train_loss: 0.587  |  valid_loss: 0.534\n",
      "[epoch: 36, i: 10999]  train_loss: 0.571  |  valid_loss: 0.535\n",
      "[epoch: 36, i: 11124]  train_loss: 0.587  |  valid_loss: 0.614\n",
      "[epoch: 36, i: 11249]  train_loss: 0.564  |  valid_loss: 0.618\n",
      "[epoch: 36, i: 11374]  train_loss: 0.643  |  valid_loss: 0.450\n",
      "[epoch: 36, i: 11499]  train_loss: 0.601  |  valid_loss: 0.371\n",
      "[epoch: 36, i: 11624]  train_loss: 0.570  |  valid_loss: 0.634\n",
      "[epoch: 36, i: 11749]  train_loss: 0.643  |  valid_loss: 0.582\n",
      "[epoch: 36, i: 11874]  train_loss: 0.631  |  valid_loss: 0.615\n",
      "[epoch: 36, i: 11999]  train_loss: 0.601  |  valid_loss: 0.492\n",
      "[epoch: 36, i: 12124]  train_loss: 0.642  |  valid_loss: 0.435\n",
      "[epoch: 36, i: 12249]  train_loss: 0.555  |  valid_loss: 0.700\n",
      "[epoch: 36, i: 12374]  train_loss: 0.565  |  valid_loss: 0.565\n",
      "[epoch: 36, i: 12499]  train_loss: 0.608  |  valid_loss: 0.469\n",
      "--> [End of epoch 36] train_accuracy: 80.01%  |  valid_accuracy: 80.83%\n",
      "--> [Start of epoch 37]  lr: 0.000010\n",
      "[epoch: 37, i:   124]  train_loss: 0.584  |  valid_loss: 0.645\n",
      "[epoch: 37, i:   249]  train_loss: 0.581  |  valid_loss: 0.617\n",
      "[epoch: 37, i:   374]  train_loss: 0.569  |  valid_loss: 0.578\n",
      "[epoch: 37, i:   499]  train_loss: 0.584  |  valid_loss: 0.624\n",
      "[epoch: 37, i:   624]  train_loss: 0.574  |  valid_loss: 0.543\n",
      "[epoch: 37, i:   749]  train_loss: 0.570  |  valid_loss: 0.333\n",
      "[epoch: 37, i:   874]  train_loss: 0.602  |  valid_loss: 0.587\n",
      "[epoch: 37, i:   999]  train_loss: 0.570  |  valid_loss: 0.603\n",
      "[epoch: 37, i:  1124]  train_loss: 0.632  |  valid_loss: 0.556\n",
      "[epoch: 37, i:  1249]  train_loss: 0.550  |  valid_loss: 0.468\n",
      "[epoch: 37, i:  1374]  train_loss: 0.587  |  valid_loss: 0.502\n",
      "[epoch: 37, i:  1499]  train_loss: 0.561  |  valid_loss: 0.623\n",
      "[epoch: 37, i:  1624]  train_loss: 0.617  |  valid_loss: 0.544\n",
      "[epoch: 37, i:  1749]  train_loss: 0.559  |  valid_loss: 0.574\n",
      "[epoch: 37, i:  1874]  train_loss: 0.582  |  valid_loss: 0.514\n",
      "[epoch: 37, i:  1999]  train_loss: 0.603  |  valid_loss: 0.615\n",
      "[epoch: 37, i:  2124]  train_loss: 0.615  |  valid_loss: 0.557\n",
      "[epoch: 37, i:  2249]  train_loss: 0.605  |  valid_loss: 0.653\n",
      "[epoch: 37, i:  2374]  train_loss: 0.581  |  valid_loss: 0.583\n",
      "[epoch: 37, i:  2499]  train_loss: 0.573  |  valid_loss: 0.808\n",
      "[epoch: 37, i:  2624]  train_loss: 0.558  |  valid_loss: 0.736\n",
      "[epoch: 37, i:  2749]  train_loss: 0.605  |  valid_loss: 0.508\n",
      "[epoch: 37, i:  2874]  train_loss: 0.577  |  valid_loss: 0.678\n",
      "[epoch: 37, i:  2999]  train_loss: 0.572  |  valid_loss: 0.553\n",
      "[epoch: 37, i:  3124]  train_loss: 0.533  |  valid_loss: 0.606\n",
      "[epoch: 37, i:  3249]  train_loss: 0.589  |  valid_loss: 0.795\n",
      "[epoch: 37, i:  3374]  train_loss: 0.627  |  valid_loss: 0.472\n",
      "[epoch: 37, i:  3499]  train_loss: 0.550  |  valid_loss: 0.620\n",
      "[epoch: 37, i:  3624]  train_loss: 0.625  |  valid_loss: 0.650\n",
      "[epoch: 37, i:  3749]  train_loss: 0.575  |  valid_loss: 0.587\n",
      "[epoch: 37, i:  3874]  train_loss: 0.619  |  valid_loss: 0.548\n",
      "[epoch: 37, i:  3999]  train_loss: 0.536  |  valid_loss: 0.595\n",
      "[epoch: 37, i:  4124]  train_loss: 0.559  |  valid_loss: 0.524\n",
      "[epoch: 37, i:  4249]  train_loss: 0.561  |  valid_loss: 0.603\n",
      "[epoch: 37, i:  4374]  train_loss: 0.571  |  valid_loss: 0.733\n",
      "[epoch: 37, i:  4499]  train_loss: 0.573  |  valid_loss: 0.461\n",
      "[epoch: 37, i:  4624]  train_loss: 0.621  |  valid_loss: 0.762\n",
      "[epoch: 37, i:  4749]  train_loss: 0.601  |  valid_loss: 0.517\n",
      "[epoch: 37, i:  4874]  train_loss: 0.587  |  valid_loss: 0.457\n",
      "[epoch: 37, i:  4999]  train_loss: 0.601  |  valid_loss: 0.473\n",
      "[epoch: 37, i:  5124]  train_loss: 0.576  |  valid_loss: 0.521\n",
      "[epoch: 37, i:  5249]  train_loss: 0.628  |  valid_loss: 0.595\n",
      "[epoch: 37, i:  5374]  train_loss: 0.586  |  valid_loss: 0.370\n",
      "[epoch: 37, i:  5499]  train_loss: 0.562  |  valid_loss: 0.545\n",
      "[epoch: 37, i:  5624]  train_loss: 0.570  |  valid_loss: 0.582\n",
      "[epoch: 37, i:  5749]  train_loss: 0.631  |  valid_loss: 0.472\n",
      "[epoch: 37, i:  5874]  train_loss: 0.581  |  valid_loss: 0.422\n",
      "[epoch: 37, i:  5999]  train_loss: 0.593  |  valid_loss: 0.659\n",
      "[epoch: 37, i:  6124]  train_loss: 0.631  |  valid_loss: 0.431\n",
      "[epoch: 37, i:  6249]  train_loss: 0.588  |  valid_loss: 0.683\n",
      "[epoch: 37, i:  6374]  train_loss: 0.596  |  valid_loss: 0.501\n",
      "[epoch: 37, i:  6499]  train_loss: 0.576  |  valid_loss: 0.556\n",
      "[epoch: 37, i:  6624]  train_loss: 0.635  |  valid_loss: 0.504\n",
      "[epoch: 37, i:  6749]  train_loss: 0.626  |  valid_loss: 0.443\n",
      "[epoch: 37, i:  6874]  train_loss: 0.610  |  valid_loss: 0.577\n",
      "[epoch: 37, i:  6999]  train_loss: 0.568  |  valid_loss: 0.653\n",
      "[epoch: 37, i:  7124]  train_loss: 0.590  |  valid_loss: 0.682\n",
      "[epoch: 37, i:  7249]  train_loss: 0.636  |  valid_loss: 0.478\n",
      "[epoch: 37, i:  7374]  train_loss: 0.586  |  valid_loss: 0.606\n",
      "[epoch: 37, i:  7499]  train_loss: 0.601  |  valid_loss: 0.543\n",
      "[epoch: 37, i:  7624]  train_loss: 0.620  |  valid_loss: 0.448\n",
      "[epoch: 37, i:  7749]  train_loss: 0.560  |  valid_loss: 0.501\n",
      "[epoch: 37, i:  7874]  train_loss: 0.576  |  valid_loss: 0.478\n",
      "[epoch: 37, i:  7999]  train_loss: 0.543  |  valid_loss: 0.390\n",
      "[epoch: 37, i:  8124]  train_loss: 0.589  |  valid_loss: 0.487\n",
      "[epoch: 37, i:  8249]  train_loss: 0.645  |  valid_loss: 0.523\n",
      "[epoch: 37, i:  8374]  train_loss: 0.580  |  valid_loss: 0.514\n",
      "[epoch: 37, i:  8499]  train_loss: 0.593  |  valid_loss: 0.644\n",
      "[epoch: 37, i:  8624]  train_loss: 0.556  |  valid_loss: 0.511\n",
      "[epoch: 37, i:  8749]  train_loss: 0.609  |  valid_loss: 0.717\n",
      "[epoch: 37, i:  8874]  train_loss: 0.585  |  valid_loss: 0.526\n",
      "[epoch: 37, i:  8999]  train_loss: 0.592  |  valid_loss: 0.474\n",
      "[epoch: 37, i:  9124]  train_loss: 0.567  |  valid_loss: 0.466\n",
      "[epoch: 37, i:  9249]  train_loss: 0.568  |  valid_loss: 0.417\n",
      "[epoch: 37, i:  9374]  train_loss: 0.661  |  valid_loss: 0.512\n",
      "[epoch: 37, i:  9499]  train_loss: 0.572  |  valid_loss: 0.535\n",
      "[epoch: 37, i:  9624]  train_loss: 0.586  |  valid_loss: 0.529\n",
      "[epoch: 37, i:  9749]  train_loss: 0.624  |  valid_loss: 0.620\n",
      "[epoch: 37, i:  9874]  train_loss: 0.624  |  valid_loss: 0.599\n",
      "[epoch: 37, i:  9999]  train_loss: 0.573  |  valid_loss: 0.561\n",
      "[epoch: 37, i: 10124]  train_loss: 0.576  |  valid_loss: 0.480\n",
      "[epoch: 37, i: 10249]  train_loss: 0.593  |  valid_loss: 0.522\n",
      "[epoch: 37, i: 10374]  train_loss: 0.610  |  valid_loss: 0.467\n",
      "[epoch: 37, i: 10499]  train_loss: 0.579  |  valid_loss: 0.521\n",
      "[epoch: 37, i: 10624]  train_loss: 0.614  |  valid_loss: 0.621\n",
      "[epoch: 37, i: 10749]  train_loss: 0.601  |  valid_loss: 0.552\n",
      "[epoch: 37, i: 10874]  train_loss: 0.529  |  valid_loss: 0.541\n",
      "[epoch: 37, i: 10999]  train_loss: 0.566  |  valid_loss: 0.540\n",
      "[epoch: 37, i: 11124]  train_loss: 0.592  |  valid_loss: 0.620\n",
      "[epoch: 37, i: 11249]  train_loss: 0.591  |  valid_loss: 0.604\n",
      "[epoch: 37, i: 11374]  train_loss: 0.613  |  valid_loss: 0.428\n",
      "[epoch: 37, i: 11499]  train_loss: 0.675  |  valid_loss: 0.366\n",
      "[epoch: 37, i: 11624]  train_loss: 0.603  |  valid_loss: 0.605\n",
      "[epoch: 37, i: 11749]  train_loss: 0.587  |  valid_loss: 0.625\n",
      "[epoch: 37, i: 11874]  train_loss: 0.561  |  valid_loss: 0.573\n",
      "[epoch: 37, i: 11999]  train_loss: 0.613  |  valid_loss: 0.500\n",
      "[epoch: 37, i: 12124]  train_loss: 0.572  |  valid_loss: 0.441\n",
      "[epoch: 37, i: 12249]  train_loss: 0.580  |  valid_loss: 0.667\n",
      "[epoch: 37, i: 12374]  train_loss: 0.582  |  valid_loss: 0.570\n",
      "[epoch: 37, i: 12499]  train_loss: 0.583  |  valid_loss: 0.496\n",
      "--> [End of epoch 37] train_accuracy: 79.99%  |  valid_accuracy: 80.93%\n",
      "--> [Start of epoch 38]  lr: 0.000009\n",
      "[epoch: 38, i:   124]  train_loss: 0.612  |  valid_loss: 0.673\n",
      "[epoch: 38, i:   249]  train_loss: 0.631  |  valid_loss: 0.587\n",
      "[epoch: 38, i:   374]  train_loss: 0.590  |  valid_loss: 0.602\n",
      "[epoch: 38, i:   499]  train_loss: 0.603  |  valid_loss: 0.624\n",
      "[epoch: 38, i:   624]  train_loss: 0.588  |  valid_loss: 0.559\n",
      "[epoch: 38, i:   749]  train_loss: 0.611  |  valid_loss: 0.313\n",
      "[epoch: 38, i:   874]  train_loss: 0.582  |  valid_loss: 0.623\n",
      "[epoch: 38, i:   999]  train_loss: 0.569  |  valid_loss: 0.591\n",
      "[epoch: 38, i:  1124]  train_loss: 0.621  |  valid_loss: 0.553\n",
      "[epoch: 38, i:  1249]  train_loss: 0.579  |  valid_loss: 0.497\n",
      "[epoch: 38, i:  1374]  train_loss: 0.602  |  valid_loss: 0.481\n",
      "[epoch: 38, i:  1499]  train_loss: 0.636  |  valid_loss: 0.656\n",
      "[epoch: 38, i:  1624]  train_loss: 0.586  |  valid_loss: 0.513\n",
      "[epoch: 38, i:  1749]  train_loss: 0.613  |  valid_loss: 0.555\n",
      "[epoch: 38, i:  1874]  train_loss: 0.603  |  valid_loss: 0.508\n",
      "[epoch: 38, i:  1999]  train_loss: 0.544  |  valid_loss: 0.616\n",
      "[epoch: 38, i:  2124]  train_loss: 0.617  |  valid_loss: 0.553\n",
      "[epoch: 38, i:  2249]  train_loss: 0.544  |  valid_loss: 0.671\n",
      "[epoch: 38, i:  2374]  train_loss: 0.606  |  valid_loss: 0.629\n",
      "[epoch: 38, i:  2499]  train_loss: 0.623  |  valid_loss: 0.851\n",
      "[epoch: 38, i:  2624]  train_loss: 0.543  |  valid_loss: 0.715\n",
      "[epoch: 38, i:  2749]  train_loss: 0.574  |  valid_loss: 0.512\n",
      "[epoch: 38, i:  2874]  train_loss: 0.595  |  valid_loss: 0.647\n",
      "[epoch: 38, i:  2999]  train_loss: 0.553  |  valid_loss: 0.576\n",
      "[epoch: 38, i:  3124]  train_loss: 0.584  |  valid_loss: 0.607\n",
      "[epoch: 38, i:  3249]  train_loss: 0.492  |  valid_loss: 0.810\n",
      "[epoch: 38, i:  3374]  train_loss: 0.576  |  valid_loss: 0.487\n",
      "[epoch: 38, i:  3499]  train_loss: 0.636  |  valid_loss: 0.623\n",
      "[epoch: 38, i:  3624]  train_loss: 0.507  |  valid_loss: 0.672\n",
      "[epoch: 38, i:  3749]  train_loss: 0.602  |  valid_loss: 0.569\n",
      "[epoch: 38, i:  3874]  train_loss: 0.574  |  valid_loss: 0.506\n",
      "[epoch: 38, i:  3999]  train_loss: 0.591  |  valid_loss: 0.562\n",
      "[epoch: 38, i:  4124]  train_loss: 0.591  |  valid_loss: 0.516\n",
      "[epoch: 38, i:  4249]  train_loss: 0.575  |  valid_loss: 0.597\n",
      "[epoch: 38, i:  4374]  train_loss: 0.602  |  valid_loss: 0.738\n",
      "[epoch: 38, i:  4499]  train_loss: 0.581  |  valid_loss: 0.434\n",
      "[epoch: 38, i:  4624]  train_loss: 0.591  |  valid_loss: 0.781\n",
      "[epoch: 38, i:  4749]  train_loss: 0.644  |  valid_loss: 0.522\n",
      "[epoch: 38, i:  4874]  train_loss: 0.597  |  valid_loss: 0.451\n",
      "[epoch: 38, i:  4999]  train_loss: 0.601  |  valid_loss: 0.454\n",
      "[epoch: 38, i:  5124]  train_loss: 0.594  |  valid_loss: 0.499\n",
      "[epoch: 38, i:  5249]  train_loss: 0.603  |  valid_loss: 0.585\n",
      "[epoch: 38, i:  5374]  train_loss: 0.586  |  valid_loss: 0.381\n",
      "[epoch: 38, i:  5499]  train_loss: 0.581  |  valid_loss: 0.541\n",
      "[epoch: 38, i:  5624]  train_loss: 0.603  |  valid_loss: 0.574\n",
      "[epoch: 38, i:  5749]  train_loss: 0.557  |  valid_loss: 0.488\n",
      "[epoch: 38, i:  5874]  train_loss: 0.539  |  valid_loss: 0.453\n",
      "[epoch: 38, i:  5999]  train_loss: 0.633  |  valid_loss: 0.572\n",
      "[epoch: 38, i:  6124]  train_loss: 0.585  |  valid_loss: 0.439\n",
      "[epoch: 38, i:  6249]  train_loss: 0.590  |  valid_loss: 0.739\n",
      "[epoch: 38, i:  6374]  train_loss: 0.611  |  valid_loss: 0.504\n",
      "[epoch: 38, i:  6499]  train_loss: 0.591  |  valid_loss: 0.551\n",
      "[epoch: 38, i:  6624]  train_loss: 0.651  |  valid_loss: 0.468\n",
      "[epoch: 38, i:  6749]  train_loss: 0.681  |  valid_loss: 0.449\n",
      "[epoch: 38, i:  6874]  train_loss: 0.611  |  valid_loss: 0.554\n",
      "[epoch: 38, i:  6999]  train_loss: 0.559  |  valid_loss: 0.648\n",
      "[epoch: 38, i:  7124]  train_loss: 0.590  |  valid_loss: 0.681\n",
      "[epoch: 38, i:  7249]  train_loss: 0.590  |  valid_loss: 0.480\n",
      "[epoch: 38, i:  7374]  train_loss: 0.556  |  valid_loss: 0.589\n",
      "[epoch: 38, i:  7499]  train_loss: 0.547  |  valid_loss: 0.539\n",
      "[epoch: 38, i:  7624]  train_loss: 0.575  |  valid_loss: 0.471\n",
      "[epoch: 38, i:  7749]  train_loss: 0.570  |  valid_loss: 0.484\n",
      "[epoch: 38, i:  7874]  train_loss: 0.590  |  valid_loss: 0.479\n",
      "[epoch: 38, i:  7999]  train_loss: 0.579  |  valid_loss: 0.372\n",
      "[epoch: 38, i:  8124]  train_loss: 0.584  |  valid_loss: 0.496\n",
      "[epoch: 38, i:  8249]  train_loss: 0.572  |  valid_loss: 0.584\n",
      "[epoch: 38, i:  8374]  train_loss: 0.533  |  valid_loss: 0.504\n",
      "[epoch: 38, i:  8499]  train_loss: 0.609  |  valid_loss: 0.652\n",
      "[epoch: 38, i:  8624]  train_loss: 0.659  |  valid_loss: 0.532\n",
      "[epoch: 38, i:  8749]  train_loss: 0.618  |  valid_loss: 0.714\n",
      "[epoch: 38, i:  8874]  train_loss: 0.612  |  valid_loss: 0.485\n",
      "[epoch: 38, i:  8999]  train_loss: 0.604  |  valid_loss: 0.460\n",
      "[epoch: 38, i:  9124]  train_loss: 0.557  |  valid_loss: 0.464\n",
      "[epoch: 38, i:  9249]  train_loss: 0.567  |  valid_loss: 0.412\n",
      "[epoch: 38, i:  9374]  train_loss: 0.620  |  valid_loss: 0.485\n",
      "[epoch: 38, i:  9499]  train_loss: 0.556  |  valid_loss: 0.499\n",
      "[epoch: 38, i:  9624]  train_loss: 0.543  |  valid_loss: 0.528\n",
      "[epoch: 38, i:  9749]  train_loss: 0.537  |  valid_loss: 0.592\n",
      "[epoch: 38, i:  9874]  train_loss: 0.584  |  valid_loss: 0.586\n",
      "[epoch: 38, i:  9999]  train_loss: 0.587  |  valid_loss: 0.565\n",
      "[epoch: 38, i: 10124]  train_loss: 0.682  |  valid_loss: 0.488\n",
      "[epoch: 38, i: 10249]  train_loss: 0.604  |  valid_loss: 0.514\n",
      "[epoch: 38, i: 10374]  train_loss: 0.571  |  valid_loss: 0.473\n",
      "[epoch: 38, i: 10499]  train_loss: 0.586  |  valid_loss: 0.484\n",
      "[epoch: 38, i: 10624]  train_loss: 0.573  |  valid_loss: 0.629\n",
      "[epoch: 38, i: 10749]  train_loss: 0.585  |  valid_loss: 0.529\n",
      "[epoch: 38, i: 10874]  train_loss: 0.587  |  valid_loss: 0.538\n",
      "[epoch: 38, i: 10999]  train_loss: 0.612  |  valid_loss: 0.542\n",
      "[epoch: 38, i: 11124]  train_loss: 0.644  |  valid_loss: 0.662\n",
      "[epoch: 38, i: 11249]  train_loss: 0.627  |  valid_loss: 0.595\n",
      "[epoch: 38, i: 11374]  train_loss: 0.594  |  valid_loss: 0.444\n",
      "[epoch: 38, i: 11499]  train_loss: 0.552  |  valid_loss: 0.366\n",
      "[epoch: 38, i: 11624]  train_loss: 0.625  |  valid_loss: 0.620\n",
      "[epoch: 38, i: 11749]  train_loss: 0.599  |  valid_loss: 0.620\n",
      "[epoch: 38, i: 11874]  train_loss: 0.562  |  valid_loss: 0.576\n",
      "[epoch: 38, i: 11999]  train_loss: 0.617  |  valid_loss: 0.477\n",
      "[epoch: 38, i: 12124]  train_loss: 0.564  |  valid_loss: 0.447\n",
      "[epoch: 38, i: 12249]  train_loss: 0.556  |  valid_loss: 0.665\n",
      "[epoch: 38, i: 12374]  train_loss: 0.585  |  valid_loss: 0.584\n",
      "[epoch: 38, i: 12499]  train_loss: 0.609  |  valid_loss: 0.488\n",
      "--> [End of epoch 38] train_accuracy: 79.91%  |  valid_accuracy: 81.20%\n",
      "--> [Start of epoch 39]  lr: 0.000008\n",
      "[epoch: 39, i:   124]  train_loss: 0.594  |  valid_loss: 0.656\n",
      "[epoch: 39, i:   249]  train_loss: 0.542  |  valid_loss: 0.576\n",
      "[epoch: 39, i:   374]  train_loss: 0.576  |  valid_loss: 0.610\n",
      "[epoch: 39, i:   499]  train_loss: 0.572  |  valid_loss: 0.642\n",
      "[epoch: 39, i:   624]  train_loss: 0.558  |  valid_loss: 0.539\n",
      "[epoch: 39, i:   749]  train_loss: 0.617  |  valid_loss: 0.314\n",
      "[epoch: 39, i:   874]  train_loss: 0.624  |  valid_loss: 0.596\n",
      "[epoch: 39, i:   999]  train_loss: 0.563  |  valid_loss: 0.585\n",
      "[epoch: 39, i:  1124]  train_loss: 0.623  |  valid_loss: 0.568\n",
      "[epoch: 39, i:  1249]  train_loss: 0.576  |  valid_loss: 0.522\n",
      "[epoch: 39, i:  1374]  train_loss: 0.603  |  valid_loss: 0.507\n",
      "[epoch: 39, i:  1499]  train_loss: 0.541  |  valid_loss: 0.656\n",
      "[epoch: 39, i:  1624]  train_loss: 0.592  |  valid_loss: 0.509\n",
      "[epoch: 39, i:  1749]  train_loss: 0.578  |  valid_loss: 0.541\n",
      "[epoch: 39, i:  1874]  train_loss: 0.629  |  valid_loss: 0.503\n",
      "[epoch: 39, i:  1999]  train_loss: 0.544  |  valid_loss: 0.607\n",
      "[epoch: 39, i:  2124]  train_loss: 0.655  |  valid_loss: 0.554\n",
      "[epoch: 39, i:  2249]  train_loss: 0.600  |  valid_loss: 0.610\n",
      "[epoch: 39, i:  2374]  train_loss: 0.617  |  valid_loss: 0.586\n",
      "[epoch: 39, i:  2499]  train_loss: 0.515  |  valid_loss: 0.821\n",
      "[epoch: 39, i:  2624]  train_loss: 0.610  |  valid_loss: 0.695\n",
      "[epoch: 39, i:  2749]  train_loss: 0.623  |  valid_loss: 0.506\n",
      "[epoch: 39, i:  2874]  train_loss: 0.566  |  valid_loss: 0.663\n",
      "[epoch: 39, i:  2999]  train_loss: 0.588  |  valid_loss: 0.562\n",
      "[epoch: 39, i:  3124]  train_loss: 0.579  |  valid_loss: 0.600\n",
      "[epoch: 39, i:  3249]  train_loss: 0.589  |  valid_loss: 0.792\n",
      "[epoch: 39, i:  3374]  train_loss: 0.639  |  valid_loss: 0.478\n",
      "[epoch: 39, i:  3499]  train_loss: 0.563  |  valid_loss: 0.604\n",
      "[epoch: 39, i:  3624]  train_loss: 0.615  |  valid_loss: 0.678\n",
      "[epoch: 39, i:  3749]  train_loss: 0.624  |  valid_loss: 0.578\n",
      "[epoch: 39, i:  3874]  train_loss: 0.540  |  valid_loss: 0.516\n",
      "[epoch: 39, i:  3999]  train_loss: 0.538  |  valid_loss: 0.590\n",
      "[epoch: 39, i:  4124]  train_loss: 0.609  |  valid_loss: 0.528\n",
      "[epoch: 39, i:  4249]  train_loss: 0.609  |  valid_loss: 0.612\n",
      "[epoch: 39, i:  4374]  train_loss: 0.555  |  valid_loss: 0.730\n",
      "[epoch: 39, i:  4499]  train_loss: 0.609  |  valid_loss: 0.452\n",
      "[epoch: 39, i:  4624]  train_loss: 0.525  |  valid_loss: 0.777\n",
      "[epoch: 39, i:  4749]  train_loss: 0.515  |  valid_loss: 0.497\n",
      "[epoch: 39, i:  4874]  train_loss: 0.620  |  valid_loss: 0.431\n",
      "[epoch: 39, i:  4999]  train_loss: 0.532  |  valid_loss: 0.438\n",
      "[epoch: 39, i:  5124]  train_loss: 0.581  |  valid_loss: 0.494\n",
      "[epoch: 39, i:  5249]  train_loss: 0.586  |  valid_loss: 0.587\n",
      "[epoch: 39, i:  5374]  train_loss: 0.586  |  valid_loss: 0.374\n",
      "[epoch: 39, i:  5499]  train_loss: 0.566  |  valid_loss: 0.539\n",
      "[epoch: 39, i:  5624]  train_loss: 0.591  |  valid_loss: 0.604\n",
      "[epoch: 39, i:  5749]  train_loss: 0.568  |  valid_loss: 0.482\n",
      "[epoch: 39, i:  5874]  train_loss: 0.611  |  valid_loss: 0.455\n",
      "[epoch: 39, i:  5999]  train_loss: 0.589  |  valid_loss: 0.557\n",
      "[epoch: 39, i:  6124]  train_loss: 0.639  |  valid_loss: 0.429\n",
      "[epoch: 39, i:  6249]  train_loss: 0.620  |  valid_loss: 0.717\n",
      "[epoch: 39, i:  6374]  train_loss: 0.584  |  valid_loss: 0.504\n",
      "[epoch: 39, i:  6499]  train_loss: 0.558  |  valid_loss: 0.557\n",
      "[epoch: 39, i:  6624]  train_loss: 0.543  |  valid_loss: 0.477\n",
      "[epoch: 39, i:  6749]  train_loss: 0.626  |  valid_loss: 0.435\n",
      "[epoch: 39, i:  6874]  train_loss: 0.617  |  valid_loss: 0.554\n",
      "[epoch: 39, i:  6999]  train_loss: 0.598  |  valid_loss: 0.659\n",
      "[epoch: 39, i:  7124]  train_loss: 0.575  |  valid_loss: 0.654\n",
      "[epoch: 39, i:  7249]  train_loss: 0.623  |  valid_loss: 0.447\n",
      "[epoch: 39, i:  7374]  train_loss: 0.605  |  valid_loss: 0.607\n",
      "[epoch: 39, i:  7499]  train_loss: 0.561  |  valid_loss: 0.539\n",
      "[epoch: 39, i:  7624]  train_loss: 0.572  |  valid_loss: 0.427\n",
      "[epoch: 39, i:  7749]  train_loss: 0.555  |  valid_loss: 0.498\n",
      "[epoch: 39, i:  7874]  train_loss: 0.571  |  valid_loss: 0.500\n",
      "[epoch: 39, i:  7999]  train_loss: 0.501  |  valid_loss: 0.382\n",
      "[epoch: 39, i:  8124]  train_loss: 0.575  |  valid_loss: 0.514\n",
      "[epoch: 39, i:  8249]  train_loss: 0.615  |  valid_loss: 0.569\n",
      "[epoch: 39, i:  8374]  train_loss: 0.600  |  valid_loss: 0.511\n",
      "[epoch: 39, i:  8499]  train_loss: 0.652  |  valid_loss: 0.634\n",
      "[epoch: 39, i:  8624]  train_loss: 0.664  |  valid_loss: 0.549\n",
      "[epoch: 39, i:  8749]  train_loss: 0.621  |  valid_loss: 0.694\n",
      "[epoch: 39, i:  8874]  train_loss: 0.581  |  valid_loss: 0.496\n",
      "[epoch: 39, i:  8999]  train_loss: 0.549  |  valid_loss: 0.430\n",
      "[epoch: 39, i:  9124]  train_loss: 0.625  |  valid_loss: 0.454\n",
      "[epoch: 39, i:  9249]  train_loss: 0.612  |  valid_loss: 0.406\n",
      "[epoch: 39, i:  9374]  train_loss: 0.607  |  valid_loss: 0.494\n",
      "[epoch: 39, i:  9499]  train_loss: 0.603  |  valid_loss: 0.507\n",
      "[epoch: 39, i:  9624]  train_loss: 0.615  |  valid_loss: 0.522\n",
      "[epoch: 39, i:  9749]  train_loss: 0.620  |  valid_loss: 0.577\n",
      "[epoch: 39, i:  9874]  train_loss: 0.564  |  valid_loss: 0.614\n",
      "[epoch: 39, i:  9999]  train_loss: 0.600  |  valid_loss: 0.588\n",
      "[epoch: 39, i: 10124]  train_loss: 0.582  |  valid_loss: 0.511\n",
      "[epoch: 39, i: 10249]  train_loss: 0.553  |  valid_loss: 0.490\n",
      "[epoch: 39, i: 10374]  train_loss: 0.574  |  valid_loss: 0.455\n",
      "[epoch: 39, i: 10499]  train_loss: 0.570  |  valid_loss: 0.527\n",
      "[epoch: 39, i: 10624]  train_loss: 0.596  |  valid_loss: 0.624\n",
      "[epoch: 39, i: 10749]  train_loss: 0.568  |  valid_loss: 0.557\n",
      "[epoch: 39, i: 10874]  train_loss: 0.549  |  valid_loss: 0.529\n",
      "[epoch: 39, i: 10999]  train_loss: 0.648  |  valid_loss: 0.543\n",
      "[epoch: 39, i: 11124]  train_loss: 0.580  |  valid_loss: 0.614\n",
      "[epoch: 39, i: 11249]  train_loss: 0.626  |  valid_loss: 0.595\n",
      "[epoch: 39, i: 11374]  train_loss: 0.574  |  valid_loss: 0.414\n",
      "[epoch: 39, i: 11499]  train_loss: 0.558  |  valid_loss: 0.359\n",
      "[epoch: 39, i: 11624]  train_loss: 0.629  |  valid_loss: 0.599\n",
      "[epoch: 39, i: 11749]  train_loss: 0.621  |  valid_loss: 0.605\n",
      "[epoch: 39, i: 11874]  train_loss: 0.613  |  valid_loss: 0.596\n",
      "[epoch: 39, i: 11999]  train_loss: 0.605  |  valid_loss: 0.489\n",
      "[epoch: 39, i: 12124]  train_loss: 0.544  |  valid_loss: 0.445\n",
      "[epoch: 39, i: 12249]  train_loss: 0.665  |  valid_loss: 0.639\n",
      "[epoch: 39, i: 12374]  train_loss: 0.656  |  valid_loss: 0.555\n",
      "[epoch: 39, i: 12499]  train_loss: 0.628  |  valid_loss: 0.508\n",
      "--> [End of epoch 39] train_accuracy: 79.91%  |  valid_accuracy: 81.39%\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "epochs = 40  # Total epochs.\n",
    "\n",
    "for epoch in range(epoch_start, epoch_start + epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    running_val_loss = 0.0     # Initialize running train_loss for validation set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    valid_total = 0   \n",
    "    valid_correct = 0\n",
    "    \n",
    "    print('--> [Start of epoch {}]'.format(epoch) +\n",
    "          '  lr: {:.6f}'.format(scheduler.get_last_lr()[0]))\n",
    "    \n",
    "    # print('--> [Start of epoch {}]'.format(epoch))\n",
    "    \n",
    "    validiter = iter(validloader)\n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Set the model to training mode.\n",
    "        dense_max.train()\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = dense_max(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "        \n",
    "        dense_max.eval()\n",
    "        \n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, train_predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "        \n",
    "        # only iterate through validation set according to train_per_valid ratio\n",
    "        if i % train_per_valid == train_per_valid - 1:\n",
    "            # Set the model to evaluation mode.\n",
    "            with torch.no_grad():\n",
    "                valid_inputs, valid_labels = next(validiter)\n",
    "                valid_inputs, valid_labels = valid_inputs.to(device), valid_labels.to(device)\n",
    "                valid_output = dense_max(valid_inputs)\n",
    "                valid_loss = loss_func(valid_output, valid_labels)\n",
    "                running_val_loss += valid_loss.item()\n",
    "                \n",
    "                _, valid_predicted = torch.max(valid_output.data, 1)\n",
    "                valid_total += valid_labels.size(0)\n",
    "                valid_correct += (valid_predicted == valid_labels).sum().item()\n",
    "            \n",
    "        # Record training/validation loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            avg_train_losses.append(avg_train_loss)\n",
    "            avg_valid_loss = train_per_valid * running_val_loss / record_freq\n",
    "            avg_valid_losses.append(avg_valid_loss)\n",
    "            running_train_loss, running_val_loss = 0.0, 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}]'.format(epoch, i) +\n",
    "                      '  train_loss: {:.3f}'.format(avg_train_loss) + \n",
    "                      '  |  valid_loss: {:.3f}'.format(avg_valid_loss))\n",
    "                            \n",
    "\n",
    "    # exponential scheduling\n",
    "    scheduler.step()\n",
    "                   \n",
    "    # calculating train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    valid_accuracy = 100 * valid_correct / valid_total\n",
    "    valid_accuracies.append(valid_accuracy)     \n",
    "    \n",
    "    # Store the networks after each epochs.\n",
    "    # in case we want to do simple average or weighted average\n",
    "    save_path = './models/dense_max_epoch_{:04d}.pth'.format(epoch)\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': dense_max.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': avg_train_losses[epoch],\n",
    "            'train_accuracy': train_accuracies[epoch],\n",
    "            'valid_accuracy': valid_accuracies[epoch],\n",
    "            }, save_path)\n",
    "    \n",
    "    print('--> [End of epoch {}]'.format(epoch) +\n",
    "                      ' train_accuracy: {:.2f}%'.format(train_accuracy) + \n",
    "                      '  |  valid_accuracy: {:.2f}%'.format(valid_accuracy))\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_train_losses)\n",
    "plt.plot(avg_valid_losses)\n",
    "plt.title('DenseNet loss curve + exponential scheduling + l2 regularization')\n",
    "plt.xlabel('mini-batch index / {}'.format(record_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.legend(['training loss', 'validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def moving_average(data, window_size):\n",
    "    \"\"\"Compute the moving average of the data using a specified window size.\"\"\"\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "window_size = 20  # Adjust this based on your preference\n",
    "train_losses_ma = moving_average(avg_train_losses, window_size)\n",
    "valid_losses_ma = moving_average(avg_valid_losses, window_size)\n",
    "\n",
    "# x_axis = np.arange(len(train_losses_ma))/100 \n",
    "x_axis = np.arange(window_size - 1, len(train_losses_ma) + window_size - 1)\n",
    "\n",
    "plt.plot(avg_train_losses)\n",
    "plt.plot(avg_valid_losses)\n",
    "plt.plot(x_axis, train_losses_ma, linewidth=2)\n",
    "plt.plot(x_axis, valid_losses_ma, linewidth=2)\n",
    "plt.title('DenseNet loss trend + exponential scheduling + l2 regularization')\n",
    "plt.xlabel('mini-batch index / {}'.format(record_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.legend(['training loss', 'validation loss', 'training loss (moving avg)', 'validation loss (moving avg)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracies)\n",
    "plt.plot(valid_accuracies)\n",
    "plt.title('DenseMax accuracy curve for exponential scheduling + l2 regularization')\n",
    "plt.xlabel('epoch / {}'.format(record_freq))\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train accuracy', 'validation accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to show an image.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # Unnormalize.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "# Check several images.\n",
    "dataiter = iter(validloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "outputs = dense_max(images.to(device))\n",
    "\n",
    "# max compare along the row, return the index of the max value, which is the predicted class\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 81.21 %\n"
     ]
    }
   ],
   "source": [
    "dense_max.to(device)\n",
    "dense_max.eval()\n",
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = dense_max(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 83 %\n",
      "Accuracy of   car : 91 %\n",
      "Accuracy of  bird : 69 %\n",
      "Accuracy of   cat : 65 %\n",
      "Accuracy of  deer : 79 %\n",
      "Accuracy of   dog : 73 %\n",
      "Accuracy of  frog : 85 %\n",
      "Accuracy of horse : 83 %\n",
      "Accuracy of  ship : 88 %\n",
      "Accuracy of truck : 90 %\n"
     ]
    }
   ],
   "source": [
    "dense_max.to(device)\n",
    "dense_max.eval()\n",
    "\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = dense_max(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 83 %\n",
      "Accuracy of   car : 85 %\n",
      "Accuracy of  bird : 30 %\n",
      "Accuracy of   cat : 22 %\n",
      "Accuracy of  deer : 79 %\n",
      "Accuracy of   dog : 30 %\n",
      "Accuracy of  frog : 88 %\n",
      "Accuracy of horse : 84 %\n",
      "Accuracy of  ship : 89 %\n",
      "Accuracy of truck : 79 %\n"
     ]
    }
   ],
   "source": [
    "dense_max.to(device)\n",
    "dense_max.eval()\n",
    "\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = dense_max(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "Before doing any experiment, I gathered some information from the average pooling based model as described in Q5.\n",
    "\n",
    "I first plot the training loss curve at a frequency of 100 times per epoch to understand the training process. Then I plot the accuracy comparison once per epoch (computing accuracy is expensive) to make more observations.\n",
    "\n",
    "Judging from the training loss curve alone, the model converge nicely and the loss does not fluctuate too much toward the end of the training,\n",
    "\n",
    "Observing the accuracy comparison chart from average pooling based model as described in Q5, we can see the gap between train accuracy and test accuracy start getting bigger in each epoch; more precisely, test accuracy does not increase in proportion to train accuracy. This is a clear sign of overfitting.\n",
    "\n",
    "#### Experiment\n",
    "To address overfitting, some form of regularization is needed, therefore I decided to try out various techniques such as Batch Normalization and Dropout. I've also tried switching from average pooling to max pooling because it's a more common practice than average pooling to extract features from the input.\n",
    "\n",
    "I was then to achieve around 68-69 percent in different variations of the max pooling model with either dropout or l2 regularization.\n",
    "\n",
    "The ones I've found giving the most consistent good result is just either max or average pooling approach with batch normalization after every Conv2D layer and linear layer before activation function.\n",
    "\n",
    "#### Final Implementation (went crazy)\n",
    "However, I then decided to restructure my model completely, I was able to achieve around 70 percent with very simple 2 residual blocks Resnet model + batch normalization + l2 regularization\n",
    "\n",
    "Then I added one extra layer, and implement Densenet's idea, you can see in my code I not only have the standard skip connection, I also have the dense connection, which is the concatenation of all previous layers. This model initially achieved incredible 73.98% validation accuracies, but this process definitely took a lot of time to train just 10 epochs\n",
    "\n",
    "Then I decided to add back max pooling in between residual blocks just right after concatenation with dense skip connection because from my understanding in limited resources, having max pooling can reduce some computation while allowing deeper network to be trained, which proven to be the case.\n",
    "\n",
    "There, my final model is a Densenet with 3 residual blocks + 3 max pooling layers + 3 dense skip connections + all associated batch normalization layers + 2 fully connection layers, using Adam with default betas (0.9, 0.99) and weight decay of 1e-4 (which is the equivalence of l2 regularization in Pytorch implementation). This model achieved 75.73% accuracy from just 10 epochs.\n",
    "\n",
    "#### Potential further improvement\n",
    "The model still have problem with classifying cat, dog and bird, which I believe can be improved by adding more data augmentation on the training set just for those classes. I think it wouldn't be too much of a challenge to get my accuracy to 80% with cyclic learning rate scheduling + data augmentation, and then just use model esembling to get that couple more percents.\n",
    "\n",
    "#### Some Interesting Notes \n",
    "In Resnet's paper, they don't use max pooling in their model, which I believe is not suitable in achieving the best result for the purpose of this experiment because I don't have the resource to train a very deep network. Resnet also doesn't use fully connected layer, instead they only have one global avg pooling layer that compute one mean per feature map and pass to a linear layer right into Softmax for classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs181",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
