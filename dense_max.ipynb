{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "mps\n",
      "50000\n",
      "6250\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "std_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "std_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=std_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(std_trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=std_transforms)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "# the order for cifar10 10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(device)\n",
    "print(len(std_trainset))\n",
    "print(len(trainloader))  \n",
    "# If 'mps or cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Apply data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "70000\n",
      "8750\n"
     ]
    }
   ],
   "source": [
    "from custom_nn.datasets import CustomCIFAR10\n",
    "\n",
    "# Additional focused augmentations\n",
    "focused_augmentations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "])\n",
    "\n",
    "# using custom dataset class to add focused augmentations capability\n",
    "aug_trainset = CustomCIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=std_transforms,\n",
    "    focused_transform=focused_augmentations\n",
    ")\n",
    "\n",
    "# the class we want the augmentation for birds, cats, deer, and dogs\n",
    "desired_classes = [1, 2, 3, 4]\n",
    "\n",
    "# Filter the dataset\n",
    "filtered_indices = [i for i, (_, label) in enumerate(aug_trainset) if label in desired_classes]\n",
    "\n",
    "filtered_dataset = torch.utils.data.Subset(aug_trainset, filtered_indices)\n",
    "\n",
    "# Combine the two datasets\n",
    "combined_trainset = torch.utils.data.ConcatDataset([std_trainset, filtered_dataset])\n",
    "trainloader = torch.utils.data.DataLoader(combined_trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "print(len(combined_trainset))\n",
    "print(len(trainloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_per_valid: 7.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from custom_nn.models import DenseMax\n",
    "\n",
    "epoch_start = 0     # Start from epoch 0 or last checkpoint epoch\n",
    "iter_n = len(trainloader)  # number of iteration per epoch\n",
    "record_freq = 100 # how many times to record the loss and accuracy per epoch\n",
    "print_freq = 100 # Print frequency, need to be multiple of record_freq.\n",
    "iter_n_per_record = iter_n // record_freq  # Record frequency.\n",
    "iter_n_per_print = iter_n // print_freq # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "# a number for computing running validation loss in each iteration.\n",
    "train_per_valid = len(trainloader) / len(validloader)  \n",
    "\n",
    "avg_train_losses, avg_valid_losses = [], []   # Avg. losses.\n",
    "train_accuracies, valid_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "dense_max = DenseMax()     # Create the network instance.\n",
    "# Move the network parameters to the specified device\n",
    "# need to be done before passing to optimizer.\n",
    "dense_max.to(device)  \n",
    "\n",
    "assert dense_max(torch.randn(4, 3, 32, 32).to(device)).shape == torch.Size([4, 10])\n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(dense_max.parameters(), lr=5e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "\n",
    "# add scheduling\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(opt, gamma=0.8)\n",
    "# scheduler = optim.lr_scheduler.StepLR(opt, step_size=5, gamma=0.8)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='max', factor=0.1, patience=4, threshold=1e-4)\n",
    "\n",
    "# directory to save the model\n",
    "directory_path = Path(\"./checkpoints/dense_max_aug_plateau_batch\" + str(batch_size))\n",
    "# Make the directory if it doesn't exist\n",
    "directory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"train_per_valid:\", train_per_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest checkpoint file is: models/dense_max/epoch_0039.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Pattern to match the files and extract epoch numbers\n",
    "pattern = r'epoch_(\\d+).pth'\n",
    "\n",
    "# Use Path.glob to list all files matching the pattern\n",
    "files = list(directory_path.glob('epoch_*.pth'))\n",
    "\n",
    "# Extract epochs and files into a list of tuples\n",
    "epoch_files = []\n",
    "for file_path in files:\n",
    "    match = re.search(pattern, file_path.name)\n",
    "    if match:\n",
    "        epoch_num = int(match.group(1))\n",
    "        epoch_files.append((epoch_num, file_path))\n",
    "\n",
    "# Sort the list by epoch number in descending order\n",
    "epoch_files.sort(key=lambda x: x[0], reverse=False)\n",
    "\n",
    "if epoch_files:\n",
    "    # populating history for loss and accuracy for plotting\n",
    "    for file in epoch_files:\n",
    "        checkpoint = torch.load(file[1])\n",
    "        avg_train_losses += checkpoint['avg_train_losses']\n",
    "        avg_valid_losses += checkpoint['avg_valid_losses']\n",
    "        train_accuracies.append(checkpoint['train_accuracy'])\n",
    "        valid_accuracies.append(checkpoint['valid_accuracy'])\n",
    "    \n",
    "    # load the model from the latest checkpoint file\n",
    "    latest_file_path = epoch_files[-1][1]\n",
    "    print(f\"The latest checkpoint file is: {latest_file_path}\")\n",
    "    checkpoint = torch.load(latest_file_path)\n",
    "    dense_max.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # start training from the next epoch\n",
    "    epoch_start = checkpoint['epoch'] + 1\n",
    "else:\n",
    "    print(\"No checkpoint files found.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> [Start of epoch 0]  lr: 0.000500\n",
      "[epoch: 0, i:    86]  train_loss: 2.080  |  valid_loss: 2.222\n",
      "[epoch: 0, i:   173]  train_loss: 1.845  |  valid_loss: 1.943\n",
      "[epoch: 0, i:   260]  train_loss: 1.770  |  valid_loss: 1.908\n",
      "[epoch: 0, i:   347]  train_loss: 1.724  |  valid_loss: 1.694\n",
      "[epoch: 0, i:   434]  train_loss: 1.635  |  valid_loss: 1.817\n",
      "[epoch: 0, i:   521]  train_loss: 1.591  |  valid_loss: 1.664\n",
      "[epoch: 0, i:   608]  train_loss: 1.565  |  valid_loss: 1.710\n",
      "[epoch: 0, i:   695]  train_loss: 1.588  |  valid_loss: 1.540\n",
      "[epoch: 0, i:   782]  train_loss: 1.556  |  valid_loss: 1.440\n",
      "[epoch: 0, i:   869]  train_loss: 1.532  |  valid_loss: 1.606\n",
      "[epoch: 0, i:   956]  train_loss: 1.499  |  valid_loss: 1.413\n",
      "[epoch: 0, i:  1043]  train_loss: 1.530  |  valid_loss: 1.555\n",
      "[epoch: 0, i:  1130]  train_loss: 1.431  |  valid_loss: 1.480\n",
      "[epoch: 0, i:  1217]  train_loss: 1.434  |  valid_loss: 1.514\n",
      "[epoch: 0, i:  1304]  train_loss: 1.489  |  valid_loss: 1.303\n",
      "[epoch: 0, i:  1391]  train_loss: 1.430  |  valid_loss: 1.355\n",
      "[epoch: 0, i:  1478]  train_loss: 1.455  |  valid_loss: 1.448\n",
      "[epoch: 0, i:  1565]  train_loss: 1.384  |  valid_loss: 1.446\n",
      "[epoch: 0, i:  1652]  train_loss: 1.457  |  valid_loss: 1.426\n",
      "[epoch: 0, i:  1739]  train_loss: 1.362  |  valid_loss: 1.362\n",
      "[epoch: 0, i:  1826]  train_loss: 1.445  |  valid_loss: 1.529\n",
      "[epoch: 0, i:  1913]  train_loss: 1.372  |  valid_loss: 1.314\n",
      "[epoch: 0, i:  2000]  train_loss: 1.423  |  valid_loss: 1.289\n",
      "[epoch: 0, i:  2087]  train_loss: 1.450  |  valid_loss: 1.503\n",
      "[epoch: 0, i:  2174]  train_loss: 1.275  |  valid_loss: 1.276\n",
      "[epoch: 0, i:  2261]  train_loss: 1.355  |  valid_loss: 1.616\n",
      "[epoch: 0, i:  2348]  train_loss: 1.411  |  valid_loss: 1.240\n",
      "[epoch: 0, i:  2435]  train_loss: 1.342  |  valid_loss: 1.426\n",
      "[epoch: 0, i:  2522]  train_loss: 1.308  |  valid_loss: 1.255\n",
      "[epoch: 0, i:  2609]  train_loss: 1.321  |  valid_loss: 1.168\n",
      "[epoch: 0, i:  2696]  train_loss: 1.293  |  valid_loss: 1.386\n",
      "[epoch: 0, i:  2783]  train_loss: 1.233  |  valid_loss: 1.107\n",
      "[epoch: 0, i:  2870]  train_loss: 1.300  |  valid_loss: 1.337\n",
      "[epoch: 0, i:  2957]  train_loss: 1.275  |  valid_loss: 1.185\n",
      "[epoch: 0, i:  3044]  train_loss: 1.326  |  valid_loss: 1.319\n",
      "[epoch: 0, i:  3131]  train_loss: 1.290  |  valid_loss: 1.229\n",
      "[epoch: 0, i:  3218]  train_loss: 1.209  |  valid_loss: 1.166\n",
      "[epoch: 0, i:  3305]  train_loss: 1.328  |  valid_loss: 1.328\n",
      "[epoch: 0, i:  3392]  train_loss: 1.284  |  valid_loss: 1.135\n",
      "[epoch: 0, i:  3479]  train_loss: 1.236  |  valid_loss: 1.263\n",
      "[epoch: 0, i:  3566]  train_loss: 1.308  |  valid_loss: 1.194\n",
      "[epoch: 0, i:  3653]  train_loss: 1.260  |  valid_loss: 1.173\n",
      "[epoch: 0, i:  3740]  train_loss: 1.168  |  valid_loss: 1.021\n",
      "[epoch: 0, i:  3827]  train_loss: 1.232  |  valid_loss: 1.036\n",
      "[epoch: 0, i:  3914]  train_loss: 1.275  |  valid_loss: 1.168\n",
      "[epoch: 0, i:  4001]  train_loss: 1.231  |  valid_loss: 1.230\n",
      "[epoch: 0, i:  4088]  train_loss: 1.193  |  valid_loss: 1.260\n",
      "[epoch: 0, i:  4175]  train_loss: 1.217  |  valid_loss: 1.124\n",
      "[epoch: 0, i:  4262]  train_loss: 1.205  |  valid_loss: 1.075\n",
      "[epoch: 0, i:  4349]  train_loss: 1.176  |  valid_loss: 0.971\n",
      "[epoch: 0, i:  4436]  train_loss: 1.292  |  valid_loss: 1.130\n",
      "[epoch: 0, i:  4523]  train_loss: 1.189  |  valid_loss: 1.299\n",
      "[epoch: 0, i:  4610]  train_loss: 1.235  |  valid_loss: 1.076\n",
      "[epoch: 0, i:  4697]  train_loss: 1.142  |  valid_loss: 1.165\n",
      "[epoch: 0, i:  4784]  train_loss: 1.209  |  valid_loss: 1.149\n",
      "[epoch: 0, i:  4871]  train_loss: 1.194  |  valid_loss: 1.281\n",
      "[epoch: 0, i:  4958]  train_loss: 1.172  |  valid_loss: 1.335\n",
      "[epoch: 0, i:  5045]  train_loss: 1.175  |  valid_loss: 0.854\n",
      "[epoch: 0, i:  5132]  train_loss: 1.141  |  valid_loss: 1.256\n",
      "[epoch: 0, i:  5219]  train_loss: 1.150  |  valid_loss: 1.213\n",
      "[epoch: 0, i:  5306]  train_loss: 1.158  |  valid_loss: 1.160\n",
      "[epoch: 0, i:  5393]  train_loss: 1.174  |  valid_loss: 1.070\n",
      "[epoch: 0, i:  5480]  train_loss: 1.144  |  valid_loss: 1.324\n",
      "[epoch: 0, i:  5567]  train_loss: 1.211  |  valid_loss: 0.869\n",
      "[epoch: 0, i:  5654]  train_loss: 1.131  |  valid_loss: 1.165\n",
      "[epoch: 0, i:  5741]  train_loss: 1.203  |  valid_loss: 1.044\n",
      "[epoch: 0, i:  5828]  train_loss: 1.202  |  valid_loss: 1.142\n",
      "[epoch: 0, i:  5915]  train_loss: 1.167  |  valid_loss: 1.273\n",
      "[epoch: 0, i:  6002]  train_loss: 1.193  |  valid_loss: 0.996\n",
      "[epoch: 0, i:  6089]  train_loss: 1.152  |  valid_loss: 1.328\n",
      "[epoch: 0, i:  6176]  train_loss: 1.161  |  valid_loss: 1.268\n",
      "[epoch: 0, i:  6263]  train_loss: 1.243  |  valid_loss: 0.981\n",
      "[epoch: 0, i:  6350]  train_loss: 1.081  |  valid_loss: 1.083\n",
      "[epoch: 0, i:  6437]  train_loss: 1.152  |  valid_loss: 0.926\n",
      "[epoch: 0, i:  6524]  train_loss: 1.143  |  valid_loss: 0.993\n",
      "[epoch: 0, i:  6611]  train_loss: 1.102  |  valid_loss: 0.879\n",
      "[epoch: 0, i:  6698]  train_loss: 1.184  |  valid_loss: 1.228\n",
      "[epoch: 0, i:  6785]  train_loss: 1.116  |  valid_loss: 1.025\n",
      "[epoch: 0, i:  6872]  train_loss: 1.138  |  valid_loss: 1.012\n",
      "[epoch: 0, i:  6959]  train_loss: 1.086  |  valid_loss: 1.197\n",
      "[epoch: 0, i:  7046]  train_loss: 1.124  |  valid_loss: 1.012\n",
      "[epoch: 0, i:  7133]  train_loss: 1.078  |  valid_loss: 1.016\n",
      "[epoch: 0, i:  7220]  train_loss: 1.123  |  valid_loss: 0.986\n",
      "[epoch: 0, i:  7307]  train_loss: 1.135  |  valid_loss: 1.224\n",
      "[epoch: 0, i:  7394]  train_loss: 1.095  |  valid_loss: 0.876\n",
      "[epoch: 0, i:  7481]  train_loss: 1.132  |  valid_loss: 1.096\n",
      "[epoch: 0, i:  7568]  train_loss: 1.098  |  valid_loss: 1.081\n",
      "[epoch: 0, i:  7655]  train_loss: 1.130  |  valid_loss: 1.184\n",
      "[epoch: 0, i:  7742]  train_loss: 1.109  |  valid_loss: 1.005\n",
      "[epoch: 0, i:  7829]  train_loss: 1.110  |  valid_loss: 1.090\n",
      "[epoch: 0, i:  7916]  train_loss: 0.982  |  valid_loss: 1.264\n",
      "[epoch: 0, i:  8003]  train_loss: 1.053  |  valid_loss: 1.013\n",
      "[epoch: 0, i:  8090]  train_loss: 1.050  |  valid_loss: 0.838\n",
      "[epoch: 0, i:  8177]  train_loss: 1.009  |  valid_loss: 1.054\n",
      "[epoch: 0, i:  8264]  train_loss: 1.110  |  valid_loss: 1.120\n",
      "[epoch: 0, i:  8351]  train_loss: 1.060  |  valid_loss: 1.264\n",
      "[epoch: 0, i:  8438]  train_loss: 1.030  |  valid_loss: 0.855\n",
      "[epoch: 0, i:  8525]  train_loss: 1.005  |  valid_loss: 1.098\n",
      "[epoch: 0, i:  8612]  train_loss: 1.103  |  valid_loss: 1.056\n",
      "[epoch: 0, i:  8699]  train_loss: 1.053  |  valid_loss: 1.092\n",
      "--> [End of epoch 0] train_accuracy: 54.62%  |  valid_accuracy: 55.59%\n",
      "--> [Start of epoch 1]  lr: 0.000500\n",
      "[epoch: 1, i:    86]  train_loss: 0.988  |  valid_loss: 0.813\n",
      "[epoch: 1, i:   173]  train_loss: 1.030  |  valid_loss: 1.046\n",
      "[epoch: 1, i:   260]  train_loss: 1.056  |  valid_loss: 1.137\n",
      "[epoch: 1, i:   347]  train_loss: 1.007  |  valid_loss: 0.869\n",
      "[epoch: 1, i:   434]  train_loss: 1.000  |  valid_loss: 1.097\n",
      "[epoch: 1, i:   521]  train_loss: 1.028  |  valid_loss: 0.851\n",
      "[epoch: 1, i:   608]  train_loss: 1.053  |  valid_loss: 1.033\n",
      "[epoch: 1, i:   695]  train_loss: 1.062  |  valid_loss: 0.865\n",
      "[epoch: 1, i:   782]  train_loss: 1.087  |  valid_loss: 1.034\n",
      "[epoch: 1, i:   869]  train_loss: 0.979  |  valid_loss: 0.969\n",
      "[epoch: 1, i:   956]  train_loss: 1.038  |  valid_loss: 0.830\n",
      "[epoch: 1, i:  1043]  train_loss: 1.077  |  valid_loss: 0.958\n",
      "[epoch: 1, i:  1130]  train_loss: 1.095  |  valid_loss: 0.928\n",
      "[epoch: 1, i:  1217]  train_loss: 1.048  |  valid_loss: 0.987\n",
      "[epoch: 1, i:  1304]  train_loss: 0.998  |  valid_loss: 0.749\n",
      "[epoch: 1, i:  1391]  train_loss: 0.951  |  valid_loss: 0.986\n",
      "[epoch: 1, i:  1478]  train_loss: 1.013  |  valid_loss: 0.951\n",
      "[epoch: 1, i:  1565]  train_loss: 1.005  |  valid_loss: 0.965\n",
      "[epoch: 1, i:  1652]  train_loss: 1.046  |  valid_loss: 0.907\n",
      "[epoch: 1, i:  1739]  train_loss: 1.049  |  valid_loss: 1.084\n",
      "[epoch: 1, i:  1826]  train_loss: 0.997  |  valid_loss: 0.978\n",
      "[epoch: 1, i:  1913]  train_loss: 0.975  |  valid_loss: 0.936\n",
      "[epoch: 1, i:  2000]  train_loss: 0.975  |  valid_loss: 0.897\n",
      "[epoch: 1, i:  2087]  train_loss: 1.022  |  valid_loss: 1.018\n",
      "[epoch: 1, i:  2174]  train_loss: 0.973  |  valid_loss: 0.798\n",
      "[epoch: 1, i:  2261]  train_loss: 0.966  |  valid_loss: 1.271\n",
      "[epoch: 1, i:  2348]  train_loss: 0.973  |  valid_loss: 0.889\n",
      "[epoch: 1, i:  2435]  train_loss: 1.039  |  valid_loss: 1.141\n",
      "[epoch: 1, i:  2522]  train_loss: 1.013  |  valid_loss: 0.880\n",
      "[epoch: 1, i:  2609]  train_loss: 0.995  |  valid_loss: 0.732\n",
      "[epoch: 1, i:  2696]  train_loss: 1.012  |  valid_loss: 0.980\n",
      "[epoch: 1, i:  2783]  train_loss: 0.976  |  valid_loss: 0.850\n",
      "[epoch: 1, i:  2870]  train_loss: 0.999  |  valid_loss: 0.945\n",
      "[epoch: 1, i:  2957]  train_loss: 1.008  |  valid_loss: 0.971\n",
      "[epoch: 1, i:  3044]  train_loss: 0.931  |  valid_loss: 1.088\n",
      "[epoch: 1, i:  3131]  train_loss: 1.128  |  valid_loss: 0.990\n",
      "[epoch: 1, i:  3218]  train_loss: 1.023  |  valid_loss: 0.957\n",
      "[epoch: 1, i:  3305]  train_loss: 1.032  |  valid_loss: 1.033\n",
      "[epoch: 1, i:  3392]  train_loss: 1.080  |  valid_loss: 0.906\n",
      "[epoch: 1, i:  3479]  train_loss: 1.014  |  valid_loss: 0.905\n",
      "[epoch: 1, i:  3566]  train_loss: 0.984  |  valid_loss: 0.818\n",
      "[epoch: 1, i:  3653]  train_loss: 0.963  |  valid_loss: 0.922\n",
      "[epoch: 1, i:  3740]  train_loss: 1.001  |  valid_loss: 0.640\n",
      "[epoch: 1, i:  3827]  train_loss: 0.972  |  valid_loss: 0.928\n",
      "[epoch: 1, i:  3914]  train_loss: 0.922  |  valid_loss: 0.878\n",
      "[epoch: 1, i:  4001]  train_loss: 1.034  |  valid_loss: 0.915\n",
      "[epoch: 1, i:  4088]  train_loss: 0.981  |  valid_loss: 0.982\n",
      "[epoch: 1, i:  4175]  train_loss: 1.065  |  valid_loss: 0.926\n",
      "[epoch: 1, i:  4262]  train_loss: 0.939  |  valid_loss: 0.729\n",
      "[epoch: 1, i:  4349]  train_loss: 0.988  |  valid_loss: 0.863\n",
      "[epoch: 1, i:  4436]  train_loss: 1.001  |  valid_loss: 0.872\n",
      "[epoch: 1, i:  4523]  train_loss: 1.091  |  valid_loss: 0.965\n",
      "[epoch: 1, i:  4610]  train_loss: 0.949  |  valid_loss: 0.790\n",
      "[epoch: 1, i:  4697]  train_loss: 0.984  |  valid_loss: 0.871\n",
      "[epoch: 1, i:  4784]  train_loss: 0.953  |  valid_loss: 0.923\n",
      "[epoch: 1, i:  4871]  train_loss: 0.954  |  valid_loss: 1.025\n",
      "[epoch: 1, i:  4958]  train_loss: 0.940  |  valid_loss: 1.092\n",
      "[epoch: 1, i:  5045]  train_loss: 0.899  |  valid_loss: 0.687\n",
      "[epoch: 1, i:  5132]  train_loss: 0.946  |  valid_loss: 0.980\n",
      "[epoch: 1, i:  5219]  train_loss: 0.992  |  valid_loss: 1.049\n",
      "[epoch: 1, i:  5306]  train_loss: 1.037  |  valid_loss: 1.042\n",
      "[epoch: 1, i:  5393]  train_loss: 0.955  |  valid_loss: 0.828\n",
      "[epoch: 1, i:  5480]  train_loss: 0.972  |  valid_loss: 0.888\n",
      "[epoch: 1, i:  5567]  train_loss: 0.919  |  valid_loss: 0.693\n",
      "[epoch: 1, i:  5654]  train_loss: 0.982  |  valid_loss: 1.008\n",
      "[epoch: 1, i:  5741]  train_loss: 0.997  |  valid_loss: 0.875\n",
      "[epoch: 1, i:  5828]  train_loss: 0.996  |  valid_loss: 0.945\n",
      "[epoch: 1, i:  5915]  train_loss: 0.948  |  valid_loss: 1.061\n",
      "[epoch: 1, i:  6002]  train_loss: 0.971  |  valid_loss: 0.780\n",
      "[epoch: 1, i:  6089]  train_loss: 0.881  |  valid_loss: 1.095\n",
      "[epoch: 1, i:  6176]  train_loss: 0.972  |  valid_loss: 1.006\n",
      "[epoch: 1, i:  6263]  train_loss: 1.050  |  valid_loss: 0.792\n",
      "[epoch: 1, i:  6350]  train_loss: 0.912  |  valid_loss: 0.862\n",
      "[epoch: 1, i:  6437]  train_loss: 1.028  |  valid_loss: 0.652\n",
      "[epoch: 1, i:  6524]  train_loss: 0.978  |  valid_loss: 0.988\n",
      "[epoch: 1, i:  6611]  train_loss: 0.898  |  valid_loss: 0.710\n",
      "[epoch: 1, i:  6698]  train_loss: 0.902  |  valid_loss: 0.970\n",
      "[epoch: 1, i:  6785]  train_loss: 0.995  |  valid_loss: 0.704\n",
      "[epoch: 1, i:  6872]  train_loss: 0.908  |  valid_loss: 0.914\n",
      "[epoch: 1, i:  6959]  train_loss: 0.989  |  valid_loss: 1.020\n",
      "[epoch: 1, i:  7046]  train_loss: 0.897  |  valid_loss: 0.894\n",
      "[epoch: 1, i:  7133]  train_loss: 0.944  |  valid_loss: 0.796\n",
      "[epoch: 1, i:  7220]  train_loss: 0.948  |  valid_loss: 0.844\n",
      "[epoch: 1, i:  7307]  train_loss: 0.906  |  valid_loss: 0.952\n",
      "[epoch: 1, i:  7394]  train_loss: 0.952  |  valid_loss: 0.769\n",
      "[epoch: 1, i:  7481]  train_loss: 0.936  |  valid_loss: 0.913\n",
      "[epoch: 1, i:  7568]  train_loss: 0.965  |  valid_loss: 0.888\n",
      "[epoch: 1, i:  7655]  train_loss: 0.957  |  valid_loss: 0.940\n",
      "[epoch: 1, i:  7742]  train_loss: 0.889  |  valid_loss: 0.938\n",
      "[epoch: 1, i:  7829]  train_loss: 0.984  |  valid_loss: 0.760\n",
      "[epoch: 1, i:  7916]  train_loss: 0.995  |  valid_loss: 0.944\n",
      "[epoch: 1, i:  8003]  train_loss: 0.868  |  valid_loss: 0.760\n",
      "[epoch: 1, i:  8090]  train_loss: 0.916  |  valid_loss: 0.602\n",
      "[epoch: 1, i:  8177]  train_loss: 0.912  |  valid_loss: 0.913\n",
      "[epoch: 1, i:  8264]  train_loss: 0.888  |  valid_loss: 0.953\n",
      "[epoch: 1, i:  8351]  train_loss: 0.982  |  valid_loss: 1.043\n",
      "[epoch: 1, i:  8438]  train_loss: 0.882  |  valid_loss: 0.736\n",
      "[epoch: 1, i:  8525]  train_loss: 0.949  |  valid_loss: 0.909\n",
      "[epoch: 1, i:  8612]  train_loss: 0.932  |  valid_loss: 0.976\n",
      "[epoch: 1, i:  8699]  train_loss: 0.974  |  valid_loss: 0.986\n",
      "--> [End of epoch 1] train_accuracy: 65.23%  |  valid_accuracy: 68.46%\n",
      "--> [Start of epoch 2]  lr: 0.000500\n",
      "[epoch: 2, i:    86]  train_loss: 0.923  |  valid_loss: 0.674\n",
      "[epoch: 2, i:   173]  train_loss: 0.957  |  valid_loss: 0.881\n",
      "[epoch: 2, i:   260]  train_loss: 0.793  |  valid_loss: 0.956\n",
      "[epoch: 2, i:   347]  train_loss: 0.928  |  valid_loss: 0.836\n",
      "[epoch: 2, i:   434]  train_loss: 0.875  |  valid_loss: 0.871\n",
      "[epoch: 2, i:   521]  train_loss: 0.860  |  valid_loss: 0.711\n",
      "[epoch: 2, i:   608]  train_loss: 0.872  |  valid_loss: 0.895\n",
      "[epoch: 2, i:   695]  train_loss: 0.784  |  valid_loss: 0.818\n",
      "[epoch: 2, i:   782]  train_loss: 0.855  |  valid_loss: 0.857\n",
      "[epoch: 2, i:   869]  train_loss: 0.868  |  valid_loss: 0.827\n",
      "[epoch: 2, i:   956]  train_loss: 0.916  |  valid_loss: 0.739\n",
      "[epoch: 2, i:  1043]  train_loss: 0.901  |  valid_loss: 0.901\n",
      "[epoch: 2, i:  1130]  train_loss: 0.908  |  valid_loss: 0.849\n",
      "[epoch: 2, i:  1217]  train_loss: 0.947  |  valid_loss: 0.924\n",
      "[epoch: 2, i:  1304]  train_loss: 0.953  |  valid_loss: 0.705\n",
      "[epoch: 2, i:  1391]  train_loss: 0.928  |  valid_loss: 0.913\n",
      "[epoch: 2, i:  1478]  train_loss: 0.913  |  valid_loss: 0.851\n",
      "[epoch: 2, i:  1565]  train_loss: 0.956  |  valid_loss: 0.801\n",
      "[epoch: 2, i:  1652]  train_loss: 0.812  |  valid_loss: 0.849\n",
      "[epoch: 2, i:  1739]  train_loss: 0.868  |  valid_loss: 1.006\n",
      "[epoch: 2, i:  1826]  train_loss: 0.855  |  valid_loss: 0.988\n",
      "[epoch: 2, i:  1913]  train_loss: 0.891  |  valid_loss: 0.867\n",
      "[epoch: 2, i:  2000]  train_loss: 0.906  |  valid_loss: 0.829\n",
      "[epoch: 2, i:  2087]  train_loss: 0.847  |  valid_loss: 0.953\n",
      "[epoch: 2, i:  2174]  train_loss: 0.869  |  valid_loss: 0.722\n",
      "[epoch: 2, i:  2261]  train_loss: 0.870  |  valid_loss: 1.041\n",
      "[epoch: 2, i:  2348]  train_loss: 0.934  |  valid_loss: 0.809\n",
      "[epoch: 2, i:  2435]  train_loss: 0.900  |  valid_loss: 1.007\n",
      "[epoch: 2, i:  2522]  train_loss: 0.914  |  valid_loss: 0.793\n",
      "[epoch: 2, i:  2609]  train_loss: 0.868  |  valid_loss: 0.704\n",
      "[epoch: 2, i:  2696]  train_loss: 0.899  |  valid_loss: 0.823\n",
      "[epoch: 2, i:  2783]  train_loss: 0.918  |  valid_loss: 0.693\n",
      "[epoch: 2, i:  2870]  train_loss: 0.810  |  valid_loss: 0.891\n",
      "[epoch: 2, i:  2957]  train_loss: 0.925  |  valid_loss: 0.968\n",
      "[epoch: 2, i:  3044]  train_loss: 0.815  |  valid_loss: 0.917\n",
      "[epoch: 2, i:  3131]  train_loss: 0.909  |  valid_loss: 0.886\n",
      "[epoch: 2, i:  3218]  train_loss: 0.961  |  valid_loss: 0.890\n",
      "[epoch: 2, i:  3305]  train_loss: 0.906  |  valid_loss: 1.056\n",
      "[epoch: 2, i:  3392]  train_loss: 0.917  |  valid_loss: 0.738\n",
      "[epoch: 2, i:  3479]  train_loss: 0.918  |  valid_loss: 0.716\n",
      "[epoch: 2, i:  3566]  train_loss: 0.890  |  valid_loss: 0.789\n",
      "[epoch: 2, i:  3653]  train_loss: 0.903  |  valid_loss: 0.815\n",
      "[epoch: 2, i:  3740]  train_loss: 0.837  |  valid_loss: 0.589\n",
      "[epoch: 2, i:  3827]  train_loss: 0.807  |  valid_loss: 0.939\n",
      "[epoch: 2, i:  3914]  train_loss: 0.953  |  valid_loss: 0.761\n",
      "[epoch: 2, i:  4001]  train_loss: 0.944  |  valid_loss: 0.801\n",
      "[epoch: 2, i:  4088]  train_loss: 0.863  |  valid_loss: 0.904\n",
      "[epoch: 2, i:  4175]  train_loss: 0.899  |  valid_loss: 0.832\n",
      "[epoch: 2, i:  4262]  train_loss: 0.859  |  valid_loss: 0.752\n",
      "[epoch: 2, i:  4349]  train_loss: 0.792  |  valid_loss: 0.762\n",
      "[epoch: 2, i:  4436]  train_loss: 0.841  |  valid_loss: 0.683\n",
      "[epoch: 2, i:  4523]  train_loss: 0.871  |  valid_loss: 0.887\n",
      "[epoch: 2, i:  4610]  train_loss: 0.870  |  valid_loss: 0.737\n",
      "[epoch: 2, i:  4697]  train_loss: 0.929  |  valid_loss: 0.768\n",
      "[epoch: 2, i:  4784]  train_loss: 0.908  |  valid_loss: 0.857\n",
      "[epoch: 2, i:  4871]  train_loss: 0.760  |  valid_loss: 0.958\n",
      "[epoch: 2, i:  4958]  train_loss: 0.830  |  valid_loss: 0.937\n",
      "[epoch: 2, i:  5045]  train_loss: 0.935  |  valid_loss: 0.554\n",
      "[epoch: 2, i:  5132]  train_loss: 0.883  |  valid_loss: 0.840\n",
      "[epoch: 2, i:  5219]  train_loss: 0.835  |  valid_loss: 0.987\n",
      "[epoch: 2, i:  5306]  train_loss: 0.896  |  valid_loss: 0.856\n",
      "[epoch: 2, i:  5393]  train_loss: 0.991  |  valid_loss: 0.745\n",
      "[epoch: 2, i:  5480]  train_loss: 0.912  |  valid_loss: 0.818\n",
      "[epoch: 2, i:  5567]  train_loss: 0.890  |  valid_loss: 0.651\n",
      "[epoch: 2, i:  5654]  train_loss: 0.941  |  valid_loss: 0.855\n",
      "[epoch: 2, i:  5741]  train_loss: 0.809  |  valid_loss: 0.760\n",
      "[epoch: 2, i:  5828]  train_loss: 0.911  |  valid_loss: 0.810\n",
      "[epoch: 2, i:  5915]  train_loss: 0.854  |  valid_loss: 0.969\n",
      "[epoch: 2, i:  6002]  train_loss: 0.881  |  valid_loss: 0.730\n",
      "[epoch: 2, i:  6089]  train_loss: 0.837  |  valid_loss: 1.008\n",
      "[epoch: 2, i:  6176]  train_loss: 0.868  |  valid_loss: 1.004\n",
      "[epoch: 2, i:  6263]  train_loss: 0.824  |  valid_loss: 0.751\n",
      "[epoch: 2, i:  6350]  train_loss: 0.834  |  valid_loss: 0.795\n",
      "[epoch: 2, i:  6437]  train_loss: 0.915  |  valid_loss: 0.656\n",
      "[epoch: 2, i:  6524]  train_loss: 0.941  |  valid_loss: 0.923\n",
      "[epoch: 2, i:  6611]  train_loss: 0.877  |  valid_loss: 0.558\n",
      "[epoch: 2, i:  6698]  train_loss: 0.856  |  valid_loss: 0.865\n",
      "[epoch: 2, i:  6785]  train_loss: 0.865  |  valid_loss: 0.648\n",
      "[epoch: 2, i:  6872]  train_loss: 0.849  |  valid_loss: 0.972\n",
      "[epoch: 2, i:  6959]  train_loss: 0.877  |  valid_loss: 0.928\n",
      "[epoch: 2, i:  7046]  train_loss: 0.806  |  valid_loss: 0.846\n",
      "[epoch: 2, i:  7133]  train_loss: 0.830  |  valid_loss: 0.712\n",
      "[epoch: 2, i:  7220]  train_loss: 0.894  |  valid_loss: 0.774\n",
      "[epoch: 2, i:  7307]  train_loss: 0.823  |  valid_loss: 0.965\n",
      "[epoch: 2, i:  7394]  train_loss: 0.829  |  valid_loss: 0.803\n",
      "[epoch: 2, i:  7481]  train_loss: 0.890  |  valid_loss: 0.829\n",
      "[epoch: 2, i:  7568]  train_loss: 0.795  |  valid_loss: 0.867\n",
      "[epoch: 2, i:  7655]  train_loss: 0.866  |  valid_loss: 0.816\n",
      "[epoch: 2, i:  7742]  train_loss: 0.832  |  valid_loss: 0.883\n",
      "[epoch: 2, i:  7829]  train_loss: 0.848  |  valid_loss: 0.689\n",
      "[epoch: 2, i:  7916]  train_loss: 0.890  |  valid_loss: 0.838\n",
      "[epoch: 2, i:  8003]  train_loss: 0.926  |  valid_loss: 0.740\n",
      "[epoch: 2, i:  8090]  train_loss: 0.901  |  valid_loss: 0.591\n",
      "[epoch: 2, i:  8177]  train_loss: 0.831  |  valid_loss: 0.816\n",
      "[epoch: 2, i:  8264]  train_loss: 0.869  |  valid_loss: 0.896\n",
      "[epoch: 2, i:  8351]  train_loss: 0.803  |  valid_loss: 0.935\n",
      "[epoch: 2, i:  8438]  train_loss: 0.862  |  valid_loss: 0.739\n",
      "[epoch: 2, i:  8525]  train_loss: 0.807  |  valid_loss: 0.809\n",
      "[epoch: 2, i:  8612]  train_loss: 0.826  |  valid_loss: 0.989\n",
      "[epoch: 2, i:  8699]  train_loss: 0.852  |  valid_loss: 0.831\n",
      "--> [End of epoch 2] train_accuracy: 69.27%  |  valid_accuracy: 71.20%\n",
      "--> [Start of epoch 3]  lr: 0.000500\n",
      "[epoch: 3, i:    86]  train_loss: 0.844  |  valid_loss: 0.678\n",
      "[epoch: 3, i:   173]  train_loss: 0.813  |  valid_loss: 0.669\n",
      "[epoch: 3, i:   260]  train_loss: 0.824  |  valid_loss: 0.974\n",
      "[epoch: 3, i:   347]  train_loss: 0.839  |  valid_loss: 0.672\n",
      "[epoch: 3, i:   434]  train_loss: 0.773  |  valid_loss: 0.848\n",
      "[epoch: 3, i:   521]  train_loss: 0.832  |  valid_loss: 0.570\n",
      "[epoch: 3, i:   608]  train_loss: 0.841  |  valid_loss: 0.840\n",
      "[epoch: 3, i:   695]  train_loss: 0.769  |  valid_loss: 0.773\n",
      "[epoch: 3, i:   782]  train_loss: 0.878  |  valid_loss: 0.756\n",
      "[epoch: 3, i:   869]  train_loss: 0.864  |  valid_loss: 0.753\n",
      "[epoch: 3, i:   956]  train_loss: 0.929  |  valid_loss: 0.602\n",
      "[epoch: 3, i:  1043]  train_loss: 0.854  |  valid_loss: 0.777\n",
      "[epoch: 3, i:  1130]  train_loss: 0.854  |  valid_loss: 0.740\n",
      "[epoch: 3, i:  1217]  train_loss: 0.767  |  valid_loss: 0.715\n",
      "[epoch: 3, i:  1304]  train_loss: 0.744  |  valid_loss: 0.601\n",
      "[epoch: 3, i:  1391]  train_loss: 0.813  |  valid_loss: 0.915\n",
      "[epoch: 3, i:  1478]  train_loss: 0.764  |  valid_loss: 0.723\n",
      "[epoch: 3, i:  1565]  train_loss: 0.825  |  valid_loss: 0.777\n",
      "[epoch: 3, i:  1652]  train_loss: 0.825  |  valid_loss: 0.798\n",
      "[epoch: 3, i:  1739]  train_loss: 0.768  |  valid_loss: 0.989\n",
      "[epoch: 3, i:  1826]  train_loss: 0.873  |  valid_loss: 0.920\n",
      "[epoch: 3, i:  1913]  train_loss: 0.849  |  valid_loss: 0.866\n",
      "[epoch: 3, i:  2000]  train_loss: 0.841  |  valid_loss: 0.704\n",
      "[epoch: 3, i:  2087]  train_loss: 0.831  |  valid_loss: 0.893\n",
      "[epoch: 3, i:  2174]  train_loss: 0.861  |  valid_loss: 0.644\n",
      "[epoch: 3, i:  2261]  train_loss: 0.834  |  valid_loss: 1.034\n",
      "[epoch: 3, i:  2348]  train_loss: 0.762  |  valid_loss: 0.755\n",
      "[epoch: 3, i:  2435]  train_loss: 0.871  |  valid_loss: 0.755\n",
      "[epoch: 3, i:  2522]  train_loss: 0.835  |  valid_loss: 0.697\n",
      "[epoch: 3, i:  2609]  train_loss: 0.878  |  valid_loss: 0.726\n",
      "[epoch: 3, i:  2696]  train_loss: 0.848  |  valid_loss: 0.884\n",
      "[epoch: 3, i:  2783]  train_loss: 0.908  |  valid_loss: 0.569\n",
      "[epoch: 3, i:  2870]  train_loss: 0.844  |  valid_loss: 0.833\n",
      "[epoch: 3, i:  2957]  train_loss: 0.807  |  valid_loss: 0.973\n",
      "[epoch: 3, i:  3044]  train_loss: 0.889  |  valid_loss: 0.875\n",
      "[epoch: 3, i:  3131]  train_loss: 0.793  |  valid_loss: 0.821\n",
      "[epoch: 3, i:  3218]  train_loss: 0.841  |  valid_loss: 0.778\n",
      "[epoch: 3, i:  3305]  train_loss: 0.822  |  valid_loss: 0.904\n",
      "[epoch: 3, i:  3392]  train_loss: 0.839  |  valid_loss: 0.721\n",
      "[epoch: 3, i:  3479]  train_loss: 0.875  |  valid_loss: 0.755\n",
      "[epoch: 3, i:  3566]  train_loss: 0.791  |  valid_loss: 0.689\n",
      "[epoch: 3, i:  3653]  train_loss: 0.823  |  valid_loss: 0.836\n",
      "[epoch: 3, i:  3740]  train_loss: 0.796  |  valid_loss: 0.536\n",
      "[epoch: 3, i:  3827]  train_loss: 0.802  |  valid_loss: 0.811\n",
      "[epoch: 3, i:  3914]  train_loss: 0.867  |  valid_loss: 0.732\n",
      "[epoch: 3, i:  4001]  train_loss: 0.796  |  valid_loss: 0.731\n",
      "[epoch: 3, i:  4088]  train_loss: 0.801  |  valid_loss: 0.804\n",
      "[epoch: 3, i:  4175]  train_loss: 0.849  |  valid_loss: 0.809\n",
      "[epoch: 3, i:  4262]  train_loss: 0.734  |  valid_loss: 0.665\n",
      "[epoch: 3, i:  4349]  train_loss: 0.804  |  valid_loss: 0.732\n",
      "[epoch: 3, i:  4436]  train_loss: 0.779  |  valid_loss: 0.725\n",
      "[epoch: 3, i:  4523]  train_loss: 0.801  |  valid_loss: 0.923\n",
      "[epoch: 3, i:  4610]  train_loss: 0.823  |  valid_loss: 0.613\n",
      "[epoch: 3, i:  4697]  train_loss: 0.934  |  valid_loss: 0.822\n",
      "[epoch: 3, i:  4784]  train_loss: 0.883  |  valid_loss: 0.739\n",
      "[epoch: 3, i:  4871]  train_loss: 0.862  |  valid_loss: 0.877\n",
      "[epoch: 3, i:  4958]  train_loss: 0.850  |  valid_loss: 0.930\n",
      "[epoch: 3, i:  5045]  train_loss: 0.816  |  valid_loss: 0.563\n",
      "[epoch: 3, i:  5132]  train_loss: 0.796  |  valid_loss: 0.783\n",
      "[epoch: 3, i:  5219]  train_loss: 0.826  |  valid_loss: 0.840\n",
      "[epoch: 3, i:  5306]  train_loss: 0.797  |  valid_loss: 0.754\n",
      "[epoch: 3, i:  5393]  train_loss: 0.808  |  valid_loss: 0.711\n",
      "[epoch: 3, i:  5480]  train_loss: 0.849  |  valid_loss: 0.752\n",
      "[epoch: 3, i:  5567]  train_loss: 0.840  |  valid_loss: 0.574\n",
      "[epoch: 3, i:  5654]  train_loss: 0.814  |  valid_loss: 0.860\n",
      "[epoch: 3, i:  5741]  train_loss: 0.750  |  valid_loss: 0.775\n",
      "[epoch: 3, i:  5828]  train_loss: 0.782  |  valid_loss: 0.808\n",
      "[epoch: 3, i:  5915]  train_loss: 0.828  |  valid_loss: 0.894\n",
      "[epoch: 3, i:  6002]  train_loss: 0.849  |  valid_loss: 0.735\n",
      "[epoch: 3, i:  6089]  train_loss: 0.881  |  valid_loss: 0.925\n",
      "[epoch: 3, i:  6176]  train_loss: 0.801  |  valid_loss: 0.849\n",
      "[epoch: 3, i:  6263]  train_loss: 0.880  |  valid_loss: 0.703\n",
      "[epoch: 3, i:  6350]  train_loss: 0.837  |  valid_loss: 0.784\n",
      "[epoch: 3, i:  6437]  train_loss: 0.841  |  valid_loss: 0.598\n",
      "[epoch: 3, i:  6524]  train_loss: 0.741  |  valid_loss: 0.935\n",
      "[epoch: 3, i:  6611]  train_loss: 0.812  |  valid_loss: 0.576\n",
      "[epoch: 3, i:  6698]  train_loss: 0.794  |  valid_loss: 0.809\n",
      "[epoch: 3, i:  6785]  train_loss: 0.770  |  valid_loss: 0.636\n",
      "[epoch: 3, i:  6872]  train_loss: 0.836  |  valid_loss: 0.856\n",
      "[epoch: 3, i:  6959]  train_loss: 0.774  |  valid_loss: 0.912\n",
      "[epoch: 3, i:  7046]  train_loss: 0.834  |  valid_loss: 0.727\n",
      "[epoch: 3, i:  7133]  train_loss: 0.778  |  valid_loss: 0.725\n",
      "[epoch: 3, i:  7220]  train_loss: 0.808  |  valid_loss: 0.724\n",
      "[epoch: 3, i:  7307]  train_loss: 0.903  |  valid_loss: 0.862\n",
      "[epoch: 3, i:  7394]  train_loss: 0.790  |  valid_loss: 0.688\n",
      "[epoch: 3, i:  7481]  train_loss: 0.787  |  valid_loss: 0.723\n",
      "[epoch: 3, i:  7568]  train_loss: 0.815  |  valid_loss: 0.862\n",
      "[epoch: 3, i:  7655]  train_loss: 0.773  |  valid_loss: 0.757\n",
      "[epoch: 3, i:  7742]  train_loss: 0.873  |  valid_loss: 0.805\n",
      "[epoch: 3, i:  7829]  train_loss: 0.883  |  valid_loss: 0.642\n",
      "[epoch: 3, i:  7916]  train_loss: 0.833  |  valid_loss: 0.896\n",
      "[epoch: 3, i:  8003]  train_loss: 0.874  |  valid_loss: 0.658\n",
      "[epoch: 3, i:  8090]  train_loss: 0.800  |  valid_loss: 0.534\n",
      "[epoch: 3, i:  8177]  train_loss: 0.826  |  valid_loss: 0.852\n",
      "[epoch: 3, i:  8264]  train_loss: 0.860  |  valid_loss: 0.834\n",
      "[epoch: 3, i:  8351]  train_loss: 0.802  |  valid_loss: 0.879\n",
      "[epoch: 3, i:  8438]  train_loss: 0.678  |  valid_loss: 0.637\n",
      "[epoch: 3, i:  8525]  train_loss: 0.858  |  valid_loss: 0.751\n",
      "[epoch: 3, i:  8612]  train_loss: 0.828  |  valid_loss: 0.892\n",
      "[epoch: 3, i:  8699]  train_loss: 0.872  |  valid_loss: 0.786\n",
      "--> [End of epoch 3] train_accuracy: 71.08%  |  valid_accuracy: 73.34%\n",
      "--> [Start of epoch 4]  lr: 0.000500\n",
      "[epoch: 4, i:    86]  train_loss: 0.767  |  valid_loss: 0.675\n",
      "[epoch: 4, i:   173]  train_loss: 0.761  |  valid_loss: 0.643\n",
      "[epoch: 4, i:   260]  train_loss: 0.766  |  valid_loss: 0.891\n",
      "[epoch: 4, i:   347]  train_loss: 0.701  |  valid_loss: 0.669\n",
      "[epoch: 4, i:   434]  train_loss: 0.780  |  valid_loss: 0.804\n",
      "[epoch: 4, i:   521]  train_loss: 0.856  |  valid_loss: 0.567\n",
      "[epoch: 4, i:   608]  train_loss: 0.763  |  valid_loss: 0.728\n",
      "[epoch: 4, i:   695]  train_loss: 0.715  |  valid_loss: 0.693\n",
      "[epoch: 4, i:   782]  train_loss: 0.777  |  valid_loss: 0.765\n",
      "[epoch: 4, i:   869]  train_loss: 0.799  |  valid_loss: 0.774\n",
      "[epoch: 4, i:   956]  train_loss: 0.830  |  valid_loss: 0.625\n",
      "[epoch: 4, i:  1043]  train_loss: 0.786  |  valid_loss: 0.762\n",
      "[epoch: 4, i:  1130]  train_loss: 0.758  |  valid_loss: 0.725\n",
      "[epoch: 4, i:  1217]  train_loss: 0.896  |  valid_loss: 0.732\n",
      "[epoch: 4, i:  1304]  train_loss: 0.689  |  valid_loss: 0.614\n",
      "[epoch: 4, i:  1391]  train_loss: 0.750  |  valid_loss: 0.818\n",
      "[epoch: 4, i:  1478]  train_loss: 0.802  |  valid_loss: 0.807\n",
      "[epoch: 4, i:  1565]  train_loss: 0.784  |  valid_loss: 0.774\n",
      "[epoch: 4, i:  1652]  train_loss: 0.749  |  valid_loss: 0.724\n",
      "[epoch: 4, i:  1739]  train_loss: 0.804  |  valid_loss: 0.936\n",
      "[epoch: 4, i:  1826]  train_loss: 0.796  |  valid_loss: 0.933\n",
      "[epoch: 4, i:  1913]  train_loss: 0.847  |  valid_loss: 0.797\n",
      "[epoch: 4, i:  2000]  train_loss: 0.731  |  valid_loss: 0.688\n",
      "[epoch: 4, i:  2087]  train_loss: 0.816  |  valid_loss: 0.829\n",
      "[epoch: 4, i:  2174]  train_loss: 0.759  |  valid_loss: 0.694\n",
      "[epoch: 4, i:  2261]  train_loss: 0.721  |  valid_loss: 1.006\n",
      "[epoch: 4, i:  2348]  train_loss: 0.710  |  valid_loss: 0.783\n",
      "[epoch: 4, i:  2435]  train_loss: 0.785  |  valid_loss: 0.788\n",
      "[epoch: 4, i:  2522]  train_loss: 0.766  |  valid_loss: 0.661\n",
      "[epoch: 4, i:  2609]  train_loss: 0.795  |  valid_loss: 0.649\n",
      "[epoch: 4, i:  2696]  train_loss: 0.702  |  valid_loss: 0.786\n",
      "[epoch: 4, i:  2783]  train_loss: 0.811  |  valid_loss: 0.578\n",
      "[epoch: 4, i:  2870]  train_loss: 0.858  |  valid_loss: 0.823\n",
      "[epoch: 4, i:  2957]  train_loss: 0.815  |  valid_loss: 0.844\n",
      "[epoch: 4, i:  3044]  train_loss: 0.829  |  valid_loss: 0.926\n",
      "[epoch: 4, i:  3131]  train_loss: 0.814  |  valid_loss: 0.823\n",
      "[epoch: 4, i:  3218]  train_loss: 0.824  |  valid_loss: 0.761\n",
      "[epoch: 4, i:  3305]  train_loss: 0.796  |  valid_loss: 0.937\n",
      "[epoch: 4, i:  3392]  train_loss: 0.797  |  valid_loss: 0.624\n",
      "[epoch: 4, i:  3479]  train_loss: 0.752  |  valid_loss: 0.650\n",
      "[epoch: 4, i:  3566]  train_loss: 0.810  |  valid_loss: 0.687\n",
      "[epoch: 4, i:  3653]  train_loss: 0.804  |  valid_loss: 0.742\n",
      "[epoch: 4, i:  3740]  train_loss: 0.754  |  valid_loss: 0.492\n",
      "[epoch: 4, i:  3827]  train_loss: 0.752  |  valid_loss: 0.776\n",
      "[epoch: 4, i:  3914]  train_loss: 0.829  |  valid_loss: 0.643\n",
      "[epoch: 4, i:  4001]  train_loss: 0.779  |  valid_loss: 0.680\n",
      "[epoch: 4, i:  4088]  train_loss: 0.809  |  valid_loss: 0.752\n",
      "[epoch: 4, i:  4175]  train_loss: 0.760  |  valid_loss: 0.817\n",
      "[epoch: 4, i:  4262]  train_loss: 0.783  |  valid_loss: 0.639\n",
      "[epoch: 4, i:  4349]  train_loss: 0.789  |  valid_loss: 0.757\n",
      "[epoch: 4, i:  4436]  train_loss: 0.798  |  valid_loss: 0.744\n",
      "[epoch: 4, i:  4523]  train_loss: 0.735  |  valid_loss: 0.756\n",
      "[epoch: 4, i:  4610]  train_loss: 0.729  |  valid_loss: 0.584\n",
      "[epoch: 4, i:  4697]  train_loss: 0.803  |  valid_loss: 0.711\n",
      "[epoch: 4, i:  4784]  train_loss: 0.784  |  valid_loss: 0.695\n",
      "[epoch: 4, i:  4871]  train_loss: 0.784  |  valid_loss: 0.845\n",
      "[epoch: 4, i:  4958]  train_loss: 0.809  |  valid_loss: 0.862\n",
      "[epoch: 4, i:  5045]  train_loss: 0.797  |  valid_loss: 0.539\n",
      "[epoch: 4, i:  5132]  train_loss: 0.842  |  valid_loss: 0.732\n",
      "[epoch: 4, i:  5219]  train_loss: 0.815  |  valid_loss: 0.889\n",
      "[epoch: 4, i:  5306]  train_loss: 0.802  |  valid_loss: 0.760\n",
      "[epoch: 4, i:  5393]  train_loss: 0.858  |  valid_loss: 0.716\n",
      "[epoch: 4, i:  5480]  train_loss: 0.795  |  valid_loss: 0.731\n",
      "[epoch: 4, i:  5567]  train_loss: 0.796  |  valid_loss: 0.535\n",
      "[epoch: 4, i:  5654]  train_loss: 0.782  |  valid_loss: 0.774\n",
      "[epoch: 4, i:  5741]  train_loss: 0.755  |  valid_loss: 0.765\n",
      "[epoch: 4, i:  5828]  train_loss: 0.771  |  valid_loss: 0.767\n",
      "[epoch: 4, i:  5915]  train_loss: 0.878  |  valid_loss: 0.861\n",
      "[epoch: 4, i:  6002]  train_loss: 0.852  |  valid_loss: 0.651\n",
      "[epoch: 4, i:  6089]  train_loss: 0.763  |  valid_loss: 0.829\n",
      "[epoch: 4, i:  6176]  train_loss: 0.746  |  valid_loss: 0.897\n",
      "[epoch: 4, i:  6263]  train_loss: 0.796  |  valid_loss: 0.614\n",
      "[epoch: 4, i:  6350]  train_loss: 0.820  |  valid_loss: 0.780\n",
      "[epoch: 4, i:  6437]  train_loss: 0.737  |  valid_loss: 0.549\n",
      "[epoch: 4, i:  6524]  train_loss: 0.808  |  valid_loss: 0.922\n",
      "[epoch: 4, i:  6611]  train_loss: 0.774  |  valid_loss: 0.581\n",
      "[epoch: 4, i:  6698]  train_loss: 0.745  |  valid_loss: 0.856\n",
      "[epoch: 4, i:  6785]  train_loss: 0.782  |  valid_loss: 0.567\n",
      "[epoch: 4, i:  6872]  train_loss: 0.810  |  valid_loss: 0.799\n",
      "[epoch: 4, i:  6959]  train_loss: 0.781  |  valid_loss: 0.905\n",
      "[epoch: 4, i:  7046]  train_loss: 0.697  |  valid_loss: 0.760\n",
      "[epoch: 4, i:  7133]  train_loss: 0.729  |  valid_loss: 0.614\n",
      "[epoch: 4, i:  7220]  train_loss: 0.811  |  valid_loss: 0.664\n",
      "[epoch: 4, i:  7307]  train_loss: 0.752  |  valid_loss: 0.812\n",
      "[epoch: 4, i:  7394]  train_loss: 0.745  |  valid_loss: 0.679\n",
      "[epoch: 4, i:  7481]  train_loss: 0.753  |  valid_loss: 0.781\n",
      "[epoch: 4, i:  7568]  train_loss: 0.771  |  valid_loss: 0.815\n",
      "[epoch: 4, i:  7655]  train_loss: 0.786  |  valid_loss: 0.772\n",
      "[epoch: 4, i:  7742]  train_loss: 0.760  |  valid_loss: 0.866\n",
      "[epoch: 4, i:  7829]  train_loss: 0.842  |  valid_loss: 0.683\n",
      "[epoch: 4, i:  7916]  train_loss: 0.799  |  valid_loss: 0.788\n",
      "[epoch: 4, i:  8003]  train_loss: 0.847  |  valid_loss: 0.650\n",
      "[epoch: 4, i:  8090]  train_loss: 0.769  |  valid_loss: 0.534\n",
      "[epoch: 4, i:  8177]  train_loss: 0.710  |  valid_loss: 0.794\n",
      "[epoch: 4, i:  8264]  train_loss: 0.763  |  valid_loss: 0.840\n",
      "[epoch: 4, i:  8351]  train_loss: 0.787  |  valid_loss: 0.937\n",
      "[epoch: 4, i:  8438]  train_loss: 0.768  |  valid_loss: 0.585\n",
      "[epoch: 4, i:  8525]  train_loss: 0.735  |  valid_loss: 0.724\n",
      "[epoch: 4, i:  8612]  train_loss: 0.790  |  valid_loss: 0.918\n",
      "[epoch: 4, i:  8699]  train_loss: 0.742  |  valid_loss: 0.735\n",
      "--> [End of epoch 4] train_accuracy: 72.58%  |  valid_accuracy: 74.40%\n",
      "--> [Start of epoch 5]  lr: 0.000500\n",
      "[epoch: 5, i:    86]  train_loss: 0.723  |  valid_loss: 0.635\n",
      "[epoch: 5, i:   173]  train_loss: 0.711  |  valid_loss: 0.642\n",
      "[epoch: 5, i:   260]  train_loss: 0.764  |  valid_loss: 0.817\n",
      "[epoch: 5, i:   347]  train_loss: 0.721  |  valid_loss: 0.595\n",
      "[epoch: 5, i:   434]  train_loss: 0.702  |  valid_loss: 0.801\n",
      "[epoch: 5, i:   521]  train_loss: 0.713  |  valid_loss: 0.458\n",
      "[epoch: 5, i:   608]  train_loss: 0.687  |  valid_loss: 0.719\n",
      "[epoch: 5, i:   695]  train_loss: 0.717  |  valid_loss: 0.725\n",
      "[epoch: 5, i:   782]  train_loss: 0.719  |  valid_loss: 0.811\n",
      "[epoch: 5, i:   869]  train_loss: 0.781  |  valid_loss: 0.777\n",
      "[epoch: 5, i:   956]  train_loss: 0.777  |  valid_loss: 0.608\n",
      "[epoch: 5, i:  1043]  train_loss: 0.735  |  valid_loss: 0.637\n",
      "[epoch: 5, i:  1130]  train_loss: 0.766  |  valid_loss: 0.639\n",
      "[epoch: 5, i:  1217]  train_loss: 0.751  |  valid_loss: 0.644\n",
      "[epoch: 5, i:  1304]  train_loss: 0.775  |  valid_loss: 0.569\n",
      "[epoch: 5, i:  1391]  train_loss: 0.786  |  valid_loss: 0.755\n",
      "[epoch: 5, i:  1478]  train_loss: 0.753  |  valid_loss: 0.759\n",
      "[epoch: 5, i:  1565]  train_loss: 0.704  |  valid_loss: 0.790\n",
      "[epoch: 5, i:  1652]  train_loss: 0.765  |  valid_loss: 0.692\n",
      "[epoch: 5, i:  1739]  train_loss: 0.732  |  valid_loss: 0.914\n",
      "[epoch: 5, i:  1826]  train_loss: 0.714  |  valid_loss: 0.899\n",
      "[epoch: 5, i:  1913]  train_loss: 0.658  |  valid_loss: 0.682\n",
      "[epoch: 5, i:  2000]  train_loss: 0.724  |  valid_loss: 0.672\n",
      "[epoch: 5, i:  2087]  train_loss: 0.773  |  valid_loss: 0.788\n",
      "[epoch: 5, i:  2174]  train_loss: 0.711  |  valid_loss: 0.633\n",
      "[epoch: 5, i:  2261]  train_loss: 0.716  |  valid_loss: 0.990\n",
      "[epoch: 5, i:  2348]  train_loss: 0.755  |  valid_loss: 0.698\n",
      "[epoch: 5, i:  2435]  train_loss: 0.794  |  valid_loss: 0.857\n",
      "[epoch: 5, i:  2522]  train_loss: 0.804  |  valid_loss: 0.691\n",
      "[epoch: 5, i:  2609]  train_loss: 0.760  |  valid_loss: 0.622\n",
      "[epoch: 5, i:  2696]  train_loss: 0.779  |  valid_loss: 0.786\n",
      "[epoch: 5, i:  2783]  train_loss: 0.831  |  valid_loss: 0.543\n",
      "[epoch: 5, i:  2870]  train_loss: 0.782  |  valid_loss: 0.824\n",
      "[epoch: 5, i:  2957]  train_loss: 0.766  |  valid_loss: 0.838\n",
      "[epoch: 5, i:  3044]  train_loss: 0.732  |  valid_loss: 0.862\n",
      "[epoch: 5, i:  3131]  train_loss: 0.785  |  valid_loss: 0.804\n",
      "[epoch: 5, i:  3218]  train_loss: 0.830  |  valid_loss: 0.791\n",
      "[epoch: 5, i:  3305]  train_loss: 0.759  |  valid_loss: 0.905\n",
      "[epoch: 5, i:  3392]  train_loss: 0.769  |  valid_loss: 0.749\n",
      "[epoch: 5, i:  3479]  train_loss: 0.779  |  valid_loss: 0.622\n",
      "[epoch: 5, i:  3566]  train_loss: 0.809  |  valid_loss: 0.615\n",
      "[epoch: 5, i:  3653]  train_loss: 0.736  |  valid_loss: 0.725\n",
      "[epoch: 5, i:  3740]  train_loss: 0.791  |  valid_loss: 0.491\n",
      "[epoch: 5, i:  3827]  train_loss: 0.769  |  valid_loss: 0.752\n",
      "[epoch: 5, i:  3914]  train_loss: 0.790  |  valid_loss: 0.649\n",
      "[epoch: 5, i:  4001]  train_loss: 0.757  |  valid_loss: 0.740\n",
      "[epoch: 5, i:  4088]  train_loss: 0.752  |  valid_loss: 0.693\n",
      "[epoch: 5, i:  4175]  train_loss: 0.734  |  valid_loss: 0.692\n",
      "[epoch: 5, i:  4262]  train_loss: 0.777  |  valid_loss: 0.660\n",
      "[epoch: 5, i:  4349]  train_loss: 0.754  |  valid_loss: 0.761\n",
      "[epoch: 5, i:  4436]  train_loss: 0.811  |  valid_loss: 0.702\n",
      "[epoch: 5, i:  4523]  train_loss: 0.795  |  valid_loss: 0.755\n",
      "[epoch: 5, i:  4610]  train_loss: 0.824  |  valid_loss: 0.628\n",
      "[epoch: 5, i:  4697]  train_loss: 0.771  |  valid_loss: 0.703\n",
      "[epoch: 5, i:  4784]  train_loss: 0.850  |  valid_loss: 0.729\n",
      "[epoch: 5, i:  4871]  train_loss: 0.822  |  valid_loss: 0.869\n",
      "[epoch: 5, i:  4958]  train_loss: 0.696  |  valid_loss: 0.823\n",
      "[epoch: 5, i:  5045]  train_loss: 0.763  |  valid_loss: 0.532\n",
      "[epoch: 5, i:  5132]  train_loss: 0.756  |  valid_loss: 0.742\n",
      "[epoch: 5, i:  5219]  train_loss: 0.766  |  valid_loss: 0.918\n",
      "[epoch: 5, i:  5306]  train_loss: 0.798  |  valid_loss: 0.827\n",
      "[epoch: 5, i:  5393]  train_loss: 0.776  |  valid_loss: 0.721\n",
      "[epoch: 5, i:  5480]  train_loss: 0.781  |  valid_loss: 0.764\n",
      "[epoch: 5, i:  5567]  train_loss: 0.697  |  valid_loss: 0.512\n",
      "[epoch: 5, i:  5654]  train_loss: 0.749  |  valid_loss: 0.694\n",
      "[epoch: 5, i:  5741]  train_loss: 0.696  |  valid_loss: 0.743\n",
      "[epoch: 5, i:  5828]  train_loss: 0.712  |  valid_loss: 0.838\n",
      "[epoch: 5, i:  5915]  train_loss: 0.781  |  valid_loss: 0.831\n",
      "[epoch: 5, i:  6002]  train_loss: 0.723  |  valid_loss: 0.653\n",
      "[epoch: 5, i:  6089]  train_loss: 0.778  |  valid_loss: 0.881\n",
      "[epoch: 5, i:  6176]  train_loss: 0.752  |  valid_loss: 0.871\n",
      "[epoch: 5, i:  6263]  train_loss: 0.792  |  valid_loss: 0.664\n",
      "[epoch: 5, i:  6350]  train_loss: 0.757  |  valid_loss: 0.768\n",
      "[epoch: 5, i:  6437]  train_loss: 0.696  |  valid_loss: 0.538\n",
      "[epoch: 5, i:  6524]  train_loss: 0.729  |  valid_loss: 0.965\n",
      "[epoch: 5, i:  6611]  train_loss: 0.791  |  valid_loss: 0.490\n",
      "[epoch: 5, i:  6698]  train_loss: 0.844  |  valid_loss: 0.775\n",
      "[epoch: 5, i:  6785]  train_loss: 0.737  |  valid_loss: 0.577\n",
      "[epoch: 5, i:  6872]  train_loss: 0.806  |  valid_loss: 0.963\n",
      "[epoch: 5, i:  6959]  train_loss: 0.795  |  valid_loss: 0.849\n",
      "[epoch: 5, i:  7046]  train_loss: 0.753  |  valid_loss: 0.719\n",
      "[epoch: 5, i:  7133]  train_loss: 0.806  |  valid_loss: 0.605\n",
      "[epoch: 5, i:  7220]  train_loss: 0.776  |  valid_loss: 0.772\n",
      "[epoch: 5, i:  7307]  train_loss: 0.786  |  valid_loss: 0.815\n",
      "[epoch: 5, i:  7394]  train_loss: 0.724  |  valid_loss: 0.672\n",
      "[epoch: 5, i:  7481]  train_loss: 0.724  |  valid_loss: 0.729\n",
      "[epoch: 5, i:  7568]  train_loss: 0.786  |  valid_loss: 0.813\n",
      "[epoch: 5, i:  7655]  train_loss: 0.716  |  valid_loss: 0.722\n",
      "[epoch: 5, i:  7742]  train_loss: 0.768  |  valid_loss: 0.784\n",
      "[epoch: 5, i:  7829]  train_loss: 0.727  |  valid_loss: 0.529\n",
      "[epoch: 5, i:  7916]  train_loss: 0.666  |  valid_loss: 0.834\n",
      "[epoch: 5, i:  8003]  train_loss: 0.762  |  valid_loss: 0.690\n",
      "[epoch: 5, i:  8090]  train_loss: 0.772  |  valid_loss: 0.515\n",
      "[epoch: 5, i:  8177]  train_loss: 0.751  |  valid_loss: 0.719\n",
      "[epoch: 5, i:  8264]  train_loss: 0.692  |  valid_loss: 0.846\n",
      "[epoch: 5, i:  8351]  train_loss: 0.788  |  valid_loss: 0.817\n",
      "[epoch: 5, i:  8438]  train_loss: 0.676  |  valid_loss: 0.575\n",
      "[epoch: 5, i:  8525]  train_loss: 0.775  |  valid_loss: 0.668\n",
      "[epoch: 5, i:  8612]  train_loss: 0.706  |  valid_loss: 0.954\n",
      "[epoch: 5, i:  8699]  train_loss: 0.837  |  valid_loss: 0.800\n",
      "--> [End of epoch 5] train_accuracy: 73.75%  |  valid_accuracy: 75.00%\n",
      "--> [Start of epoch 6]  lr: 0.000500\n",
      "[epoch: 6, i:    86]  train_loss: 0.768  |  valid_loss: 0.676\n",
      "[epoch: 6, i:   173]  train_loss: 0.712  |  valid_loss: 0.639\n",
      "[epoch: 6, i:   260]  train_loss: 0.712  |  valid_loss: 0.834\n",
      "[epoch: 6, i:   347]  train_loss: 0.770  |  valid_loss: 0.654\n",
      "[epoch: 6, i:   434]  train_loss: 0.798  |  valid_loss: 0.752\n",
      "[epoch: 6, i:   521]  train_loss: 0.660  |  valid_loss: 0.470\n",
      "[epoch: 6, i:   608]  train_loss: 0.724  |  valid_loss: 0.753\n",
      "[epoch: 6, i:   695]  train_loss: 0.759  |  valid_loss: 0.747\n",
      "[epoch: 6, i:   782]  train_loss: 0.688  |  valid_loss: 0.789\n",
      "[epoch: 6, i:   869]  train_loss: 0.664  |  valid_loss: 0.800\n",
      "[epoch: 6, i:   956]  train_loss: 0.735  |  valid_loss: 0.643\n",
      "[epoch: 6, i:  1043]  train_loss: 0.755  |  valid_loss: 0.683\n",
      "[epoch: 6, i:  1130]  train_loss: 0.692  |  valid_loss: 0.653\n",
      "[epoch: 6, i:  1217]  train_loss: 0.785  |  valid_loss: 0.668\n",
      "[epoch: 6, i:  1304]  train_loss: 0.680  |  valid_loss: 0.514\n",
      "[epoch: 6, i:  1391]  train_loss: 0.730  |  valid_loss: 0.737\n",
      "[epoch: 6, i:  1478]  train_loss: 0.731  |  valid_loss: 0.653\n",
      "[epoch: 6, i:  1565]  train_loss: 0.755  |  valid_loss: 0.723\n",
      "[epoch: 6, i:  1652]  train_loss: 0.716  |  valid_loss: 0.734\n",
      "[epoch: 6, i:  1739]  train_loss: 0.708  |  valid_loss: 0.874\n",
      "[epoch: 6, i:  1826]  train_loss: 0.729  |  valid_loss: 0.875\n",
      "[epoch: 6, i:  1913]  train_loss: 0.730  |  valid_loss: 0.720\n",
      "[epoch: 6, i:  2000]  train_loss: 0.736  |  valid_loss: 0.704\n",
      "[epoch: 6, i:  2087]  train_loss: 0.694  |  valid_loss: 0.806\n",
      "[epoch: 6, i:  2174]  train_loss: 0.759  |  valid_loss: 0.638\n",
      "[epoch: 6, i:  2261]  train_loss: 0.802  |  valid_loss: 0.970\n",
      "[epoch: 6, i:  2348]  train_loss: 0.726  |  valid_loss: 0.614\n",
      "[epoch: 6, i:  2435]  train_loss: 0.721  |  valid_loss: 0.815\n",
      "[epoch: 6, i:  2522]  train_loss: 0.707  |  valid_loss: 0.594\n",
      "[epoch: 6, i:  2609]  train_loss: 0.735  |  valid_loss: 0.703\n",
      "[epoch: 6, i:  2696]  train_loss: 0.804  |  valid_loss: 0.824\n",
      "[epoch: 6, i:  2783]  train_loss: 0.734  |  valid_loss: 0.580\n",
      "[epoch: 6, i:  2870]  train_loss: 0.742  |  valid_loss: 0.795\n",
      "[epoch: 6, i:  2957]  train_loss: 0.764  |  valid_loss: 0.778\n",
      "[epoch: 6, i:  3044]  train_loss: 0.722  |  valid_loss: 0.792\n",
      "[epoch: 6, i:  3131]  train_loss: 0.735  |  valid_loss: 0.809\n",
      "[epoch: 6, i:  3218]  train_loss: 0.726  |  valid_loss: 0.740\n",
      "[epoch: 6, i:  3305]  train_loss: 0.734  |  valid_loss: 0.857\n",
      "[epoch: 6, i:  3392]  train_loss: 0.715  |  valid_loss: 0.667\n",
      "[epoch: 6, i:  3479]  train_loss: 0.757  |  valid_loss: 0.604\n",
      "[epoch: 6, i:  3566]  train_loss: 0.670  |  valid_loss: 0.611\n",
      "[epoch: 6, i:  3653]  train_loss: 0.713  |  valid_loss: 0.770\n",
      "[epoch: 6, i:  3740]  train_loss: 0.748  |  valid_loss: 0.497\n",
      "[epoch: 6, i:  3827]  train_loss: 0.747  |  valid_loss: 0.810\n",
      "[epoch: 6, i:  3914]  train_loss: 0.769  |  valid_loss: 0.602\n",
      "[epoch: 6, i:  4001]  train_loss: 0.692  |  valid_loss: 0.703\n",
      "[epoch: 6, i:  4088]  train_loss: 0.705  |  valid_loss: 0.748\n",
      "[epoch: 6, i:  4175]  train_loss: 0.738  |  valid_loss: 0.698\n",
      "[epoch: 6, i:  4262]  train_loss: 0.704  |  valid_loss: 0.645\n",
      "[epoch: 6, i:  4349]  train_loss: 0.761  |  valid_loss: 0.730\n",
      "[epoch: 6, i:  4436]  train_loss: 0.766  |  valid_loss: 0.630\n",
      "[epoch: 6, i:  4523]  train_loss: 0.656  |  valid_loss: 0.799\n",
      "[epoch: 6, i:  4610]  train_loss: 0.699  |  valid_loss: 0.601\n",
      "[epoch: 6, i:  4697]  train_loss: 0.685  |  valid_loss: 0.725\n",
      "[epoch: 6, i:  4784]  train_loss: 0.718  |  valid_loss: 0.741\n",
      "[epoch: 6, i:  4871]  train_loss: 0.763  |  valid_loss: 0.813\n",
      "[epoch: 6, i:  4958]  train_loss: 0.724  |  valid_loss: 0.886\n",
      "[epoch: 6, i:  5045]  train_loss: 0.714  |  valid_loss: 0.525\n",
      "[epoch: 6, i:  5132]  train_loss: 0.697  |  valid_loss: 0.641\n",
      "[epoch: 6, i:  5219]  train_loss: 0.718  |  valid_loss: 0.937\n",
      "[epoch: 6, i:  5306]  train_loss: 0.750  |  valid_loss: 0.790\n",
      "[epoch: 6, i:  5393]  train_loss: 0.705  |  valid_loss: 0.637\n",
      "[epoch: 6, i:  5480]  train_loss: 0.706  |  valid_loss: 0.774\n",
      "[epoch: 6, i:  5567]  train_loss: 0.760  |  valid_loss: 0.402\n",
      "[epoch: 6, i:  5654]  train_loss: 0.765  |  valid_loss: 0.747\n",
      "[epoch: 6, i:  5741]  train_loss: 0.701  |  valid_loss: 0.851\n",
      "[epoch: 6, i:  5828]  train_loss: 0.802  |  valid_loss: 0.652\n",
      "[epoch: 6, i:  5915]  train_loss: 0.697  |  valid_loss: 0.809\n",
      "[epoch: 6, i:  6002]  train_loss: 0.738  |  valid_loss: 0.646\n",
      "[epoch: 6, i:  6089]  train_loss: 0.762  |  valid_loss: 0.957\n",
      "[epoch: 6, i:  6176]  train_loss: 0.783  |  valid_loss: 0.863\n",
      "[epoch: 6, i:  6263]  train_loss: 0.731  |  valid_loss: 0.651\n",
      "[epoch: 6, i:  6350]  train_loss: 0.694  |  valid_loss: 0.714\n",
      "[epoch: 6, i:  6437]  train_loss: 0.766  |  valid_loss: 0.557\n",
      "[epoch: 6, i:  6524]  train_loss: 0.730  |  valid_loss: 0.918\n",
      "[epoch: 6, i:  6611]  train_loss: 0.688  |  valid_loss: 0.561\n",
      "[epoch: 6, i:  6698]  train_loss: 0.714  |  valid_loss: 0.755\n",
      "[epoch: 6, i:  6785]  train_loss: 0.747  |  valid_loss: 0.559\n",
      "[epoch: 6, i:  6872]  train_loss: 0.765  |  valid_loss: 0.833\n",
      "[epoch: 6, i:  6959]  train_loss: 0.732  |  valid_loss: 0.765\n",
      "[epoch: 6, i:  7046]  train_loss: 0.677  |  valid_loss: 0.647\n",
      "[epoch: 6, i:  7133]  train_loss: 0.758  |  valid_loss: 0.649\n",
      "[epoch: 6, i:  7220]  train_loss: 0.751  |  valid_loss: 0.683\n",
      "[epoch: 6, i:  7307]  train_loss: 0.752  |  valid_loss: 0.860\n",
      "[epoch: 6, i:  7394]  train_loss: 0.679  |  valid_loss: 0.681\n",
      "[epoch: 6, i:  7481]  train_loss: 0.725  |  valid_loss: 0.711\n",
      "[epoch: 6, i:  7568]  train_loss: 0.756  |  valid_loss: 0.817\n",
      "[epoch: 6, i:  7655]  train_loss: 0.830  |  valid_loss: 0.716\n",
      "[epoch: 6, i:  7742]  train_loss: 0.690  |  valid_loss: 0.703\n",
      "[epoch: 6, i:  7829]  train_loss: 0.759  |  valid_loss: 0.531\n",
      "[epoch: 6, i:  7916]  train_loss: 0.763  |  valid_loss: 0.792\n",
      "[epoch: 6, i:  8003]  train_loss: 0.872  |  valid_loss: 0.617\n",
      "[epoch: 6, i:  8090]  train_loss: 0.755  |  valid_loss: 0.541\n",
      "[epoch: 6, i:  8177]  train_loss: 0.762  |  valid_loss: 0.699\n",
      "[epoch: 6, i:  8264]  train_loss: 0.688  |  valid_loss: 0.766\n",
      "[epoch: 6, i:  8351]  train_loss: 0.773  |  valid_loss: 0.751\n",
      "[epoch: 6, i:  8438]  train_loss: 0.700  |  valid_loss: 0.568\n",
      "[epoch: 6, i:  8525]  train_loss: 0.786  |  valid_loss: 0.699\n",
      "[epoch: 6, i:  8612]  train_loss: 0.726  |  valid_loss: 0.930\n",
      "[epoch: 6, i:  8699]  train_loss: 0.789  |  valid_loss: 0.739\n",
      "--> [End of epoch 6] train_accuracy: 74.45%  |  valid_accuracy: 75.44%\n",
      "--> [Start of epoch 7]  lr: 0.000500\n",
      "[epoch: 7, i:    86]  train_loss: 0.636  |  valid_loss: 0.579\n",
      "[epoch: 7, i:   173]  train_loss: 0.696  |  valid_loss: 0.584\n",
      "[epoch: 7, i:   260]  train_loss: 0.790  |  valid_loss: 0.680\n",
      "[epoch: 7, i:   347]  train_loss: 0.712  |  valid_loss: 0.570\n",
      "[epoch: 7, i:   434]  train_loss: 0.720  |  valid_loss: 0.765\n",
      "[epoch: 7, i:   521]  train_loss: 0.682  |  valid_loss: 0.499\n",
      "[epoch: 7, i:   608]  train_loss: 0.736  |  valid_loss: 0.729\n",
      "[epoch: 7, i:   695]  train_loss: 0.661  |  valid_loss: 0.745\n",
      "[epoch: 7, i:   782]  train_loss: 0.654  |  valid_loss: 0.738\n",
      "[epoch: 7, i:   869]  train_loss: 0.697  |  valid_loss: 0.738\n",
      "[epoch: 7, i:   956]  train_loss: 0.666  |  valid_loss: 0.572\n",
      "[epoch: 7, i:  1043]  train_loss: 0.680  |  valid_loss: 0.666\n",
      "[epoch: 7, i:  1130]  train_loss: 0.685  |  valid_loss: 0.658\n",
      "[epoch: 7, i:  1217]  train_loss: 0.744  |  valid_loss: 0.634\n",
      "[epoch: 7, i:  1304]  train_loss: 0.698  |  valid_loss: 0.509\n",
      "[epoch: 7, i:  1391]  train_loss: 0.685  |  valid_loss: 0.767\n",
      "[epoch: 7, i:  1478]  train_loss: 0.735  |  valid_loss: 0.720\n",
      "[epoch: 7, i:  1565]  train_loss: 0.716  |  valid_loss: 0.778\n",
      "[epoch: 7, i:  1652]  train_loss: 0.676  |  valid_loss: 0.630\n",
      "[epoch: 7, i:  1739]  train_loss: 0.696  |  valid_loss: 0.915\n",
      "[epoch: 7, i:  1826]  train_loss: 0.779  |  valid_loss: 0.898\n",
      "[epoch: 7, i:  1913]  train_loss: 0.736  |  valid_loss: 0.747\n",
      "[epoch: 7, i:  2000]  train_loss: 0.762  |  valid_loss: 0.613\n",
      "[epoch: 7, i:  2087]  train_loss: 0.669  |  valid_loss: 0.815\n",
      "[epoch: 7, i:  2174]  train_loss: 0.752  |  valid_loss: 0.533\n",
      "[epoch: 7, i:  2261]  train_loss: 0.722  |  valid_loss: 0.988\n",
      "[epoch: 7, i:  2348]  train_loss: 0.687  |  valid_loss: 0.658\n",
      "[epoch: 7, i:  2435]  train_loss: 0.746  |  valid_loss: 0.763\n",
      "[epoch: 7, i:  2522]  train_loss: 0.702  |  valid_loss: 0.599\n",
      "[epoch: 7, i:  2609]  train_loss: 0.780  |  valid_loss: 0.626\n",
      "[epoch: 7, i:  2696]  train_loss: 0.699  |  valid_loss: 0.731\n",
      "[epoch: 7, i:  2783]  train_loss: 0.724  |  valid_loss: 0.529\n",
      "[epoch: 7, i:  2870]  train_loss: 0.740  |  valid_loss: 0.797\n",
      "[epoch: 7, i:  2957]  train_loss: 0.716  |  valid_loss: 0.718\n",
      "[epoch: 7, i:  3044]  train_loss: 0.696  |  valid_loss: 0.810\n",
      "[epoch: 7, i:  3131]  train_loss: 0.751  |  valid_loss: 0.702\n",
      "[epoch: 7, i:  3218]  train_loss: 0.690  |  valid_loss: 0.713\n",
      "[epoch: 7, i:  3305]  train_loss: 0.696  |  valid_loss: 0.841\n",
      "[epoch: 7, i:  3392]  train_loss: 0.725  |  valid_loss: 0.657\n",
      "[epoch: 7, i:  3479]  train_loss: 0.751  |  valid_loss: 0.579\n",
      "[epoch: 7, i:  3566]  train_loss: 0.697  |  valid_loss: 0.662\n",
      "[epoch: 7, i:  3653]  train_loss: 0.706  |  valid_loss: 0.777\n",
      "[epoch: 7, i:  3740]  train_loss: 0.725  |  valid_loss: 0.428\n",
      "[epoch: 7, i:  3827]  train_loss: 0.782  |  valid_loss: 0.836\n",
      "[epoch: 7, i:  3914]  train_loss: 0.674  |  valid_loss: 0.569\n",
      "[epoch: 7, i:  4001]  train_loss: 0.664  |  valid_loss: 0.674\n",
      "[epoch: 7, i:  4088]  train_loss: 0.709  |  valid_loss: 0.684\n",
      "[epoch: 7, i:  4175]  train_loss: 0.717  |  valid_loss: 0.679\n",
      "[epoch: 7, i:  4262]  train_loss: 0.752  |  valid_loss: 0.637\n",
      "[epoch: 7, i:  4349]  train_loss: 0.744  |  valid_loss: 0.755\n",
      "[epoch: 7, i:  4436]  train_loss: 0.678  |  valid_loss: 0.566\n",
      "[epoch: 7, i:  4523]  train_loss: 0.762  |  valid_loss: 0.783\n",
      "[epoch: 7, i:  4610]  train_loss: 0.697  |  valid_loss: 0.550\n",
      "[epoch: 7, i:  4697]  train_loss: 0.693  |  valid_loss: 0.769\n",
      "[epoch: 7, i:  4784]  train_loss: 0.731  |  valid_loss: 0.651\n",
      "[epoch: 7, i:  4871]  train_loss: 0.707  |  valid_loss: 0.790\n",
      "[epoch: 7, i:  4958]  train_loss: 0.712  |  valid_loss: 0.899\n",
      "[epoch: 7, i:  5045]  train_loss: 0.756  |  valid_loss: 0.485\n",
      "[epoch: 7, i:  5132]  train_loss: 0.776  |  valid_loss: 0.693\n",
      "[epoch: 7, i:  5219]  train_loss: 0.742  |  valid_loss: 0.848\n",
      "[epoch: 7, i:  5306]  train_loss: 0.713  |  valid_loss: 0.799\n",
      "[epoch: 7, i:  5393]  train_loss: 0.724  |  valid_loss: 0.630\n",
      "[epoch: 7, i:  5480]  train_loss: 0.717  |  valid_loss: 0.796\n",
      "[epoch: 7, i:  5567]  train_loss: 0.670  |  valid_loss: 0.440\n",
      "[epoch: 7, i:  5654]  train_loss: 0.759  |  valid_loss: 0.683\n",
      "[epoch: 7, i:  5741]  train_loss: 0.731  |  valid_loss: 0.764\n",
      "[epoch: 7, i:  5828]  train_loss: 0.690  |  valid_loss: 0.671\n",
      "[epoch: 7, i:  5915]  train_loss: 0.747  |  valid_loss: 0.726\n",
      "[epoch: 7, i:  6002]  train_loss: 0.740  |  valid_loss: 0.666\n",
      "[epoch: 7, i:  6089]  train_loss: 0.751  |  valid_loss: 0.777\n",
      "[epoch: 7, i:  6176]  train_loss: 0.780  |  valid_loss: 0.893\n",
      "[epoch: 7, i:  6263]  train_loss: 0.671  |  valid_loss: 0.597\n",
      "[epoch: 7, i:  6350]  train_loss: 0.683  |  valid_loss: 0.711\n",
      "[epoch: 7, i:  6437]  train_loss: 0.701  |  valid_loss: 0.484\n",
      "[epoch: 7, i:  6524]  train_loss: 0.813  |  valid_loss: 0.829\n",
      "[epoch: 7, i:  6611]  train_loss: 0.648  |  valid_loss: 0.540\n",
      "[epoch: 7, i:  6698]  train_loss: 0.683  |  valid_loss: 0.799\n",
      "[epoch: 7, i:  6785]  train_loss: 0.656  |  valid_loss: 0.538\n",
      "[epoch: 7, i:  6872]  train_loss: 0.716  |  valid_loss: 0.859\n",
      "[epoch: 7, i:  6959]  train_loss: 0.676  |  valid_loss: 0.754\n",
      "[epoch: 7, i:  7046]  train_loss: 0.743  |  valid_loss: 0.638\n",
      "[epoch: 7, i:  7133]  train_loss: 0.695  |  valid_loss: 0.581\n",
      "[epoch: 7, i:  7220]  train_loss: 0.690  |  valid_loss: 0.749\n",
      "[epoch: 7, i:  7307]  train_loss: 0.671  |  valid_loss: 0.722\n",
      "[epoch: 7, i:  7394]  train_loss: 0.725  |  valid_loss: 0.631\n",
      "[epoch: 7, i:  7481]  train_loss: 0.704  |  valid_loss: 0.717\n",
      "[epoch: 7, i:  7568]  train_loss: 0.682  |  valid_loss: 0.792\n",
      "[epoch: 7, i:  7655]  train_loss: 0.674  |  valid_loss: 0.648\n",
      "[epoch: 7, i:  7742]  train_loss: 0.682  |  valid_loss: 0.678\n",
      "[epoch: 7, i:  7829]  train_loss: 0.682  |  valid_loss: 0.605\n",
      "[epoch: 7, i:  7916]  train_loss: 0.710  |  valid_loss: 0.732\n",
      "[epoch: 7, i:  8003]  train_loss: 0.700  |  valid_loss: 0.674\n",
      "[epoch: 7, i:  8090]  train_loss: 0.701  |  valid_loss: 0.490\n",
      "[epoch: 7, i:  8177]  train_loss: 0.731  |  valid_loss: 0.686\n",
      "[epoch: 7, i:  8264]  train_loss: 0.716  |  valid_loss: 0.753\n",
      "[epoch: 7, i:  8351]  train_loss: 0.781  |  valid_loss: 0.822\n",
      "[epoch: 7, i:  8438]  train_loss: 0.688  |  valid_loss: 0.635\n",
      "[epoch: 7, i:  8525]  train_loss: 0.702  |  valid_loss: 0.665\n",
      "[epoch: 7, i:  8612]  train_loss: 0.764  |  valid_loss: 0.909\n",
      "[epoch: 7, i:  8699]  train_loss: 0.758  |  valid_loss: 0.733\n",
      "--> [End of epoch 7] train_accuracy: 75.14%  |  valid_accuracy: 76.23%\n",
      "--> [Start of epoch 8]  lr: 0.000500\n",
      "[epoch: 8, i:    86]  train_loss: 0.658  |  valid_loss: 0.586\n",
      "[epoch: 8, i:   173]  train_loss: 0.660  |  valid_loss: 0.618\n",
      "[epoch: 8, i:   260]  train_loss: 0.707  |  valid_loss: 0.681\n",
      "[epoch: 8, i:   347]  train_loss: 0.639  |  valid_loss: 0.618\n",
      "[epoch: 8, i:   434]  train_loss: 0.698  |  valid_loss: 0.709\n",
      "[epoch: 8, i:   521]  train_loss: 0.795  |  valid_loss: 0.523\n",
      "[epoch: 8, i:   608]  train_loss: 0.660  |  valid_loss: 0.710\n",
      "[epoch: 8, i:   695]  train_loss: 0.739  |  valid_loss: 0.673\n",
      "[epoch: 8, i:   782]  train_loss: 0.717  |  valid_loss: 0.756\n",
      "[epoch: 8, i:   869]  train_loss: 0.677  |  valid_loss: 0.697\n",
      "[epoch: 8, i:   956]  train_loss: 0.738  |  valid_loss: 0.565\n",
      "[epoch: 8, i:  1043]  train_loss: 0.725  |  valid_loss: 0.691\n",
      "[epoch: 8, i:  1130]  train_loss: 0.733  |  valid_loss: 0.585\n",
      "[epoch: 8, i:  1217]  train_loss: 0.695  |  valid_loss: 0.660\n",
      "[epoch: 8, i:  1304]  train_loss: 0.631  |  valid_loss: 0.511\n",
      "[epoch: 8, i:  1391]  train_loss: 0.738  |  valid_loss: 0.764\n",
      "[epoch: 8, i:  1478]  train_loss: 0.742  |  valid_loss: 0.685\n",
      "[epoch: 8, i:  1565]  train_loss: 0.673  |  valid_loss: 0.710\n",
      "[epoch: 8, i:  1652]  train_loss: 0.637  |  valid_loss: 0.654\n",
      "[epoch: 8, i:  1739]  train_loss: 0.667  |  valid_loss: 0.866\n",
      "[epoch: 8, i:  1826]  train_loss: 0.716  |  valid_loss: 0.921\n",
      "[epoch: 8, i:  1913]  train_loss: 0.709  |  valid_loss: 0.643\n",
      "[epoch: 8, i:  2000]  train_loss: 0.674  |  valid_loss: 0.671\n",
      "[epoch: 8, i:  2087]  train_loss: 0.654  |  valid_loss: 0.844\n",
      "[epoch: 8, i:  2174]  train_loss: 0.796  |  valid_loss: 0.589\n",
      "[epoch: 8, i:  2261]  train_loss: 0.707  |  valid_loss: 1.000\n",
      "[epoch: 8, i:  2348]  train_loss: 0.706  |  valid_loss: 0.602\n",
      "[epoch: 8, i:  2435]  train_loss: 0.660  |  valid_loss: 0.800\n",
      "[epoch: 8, i:  2522]  train_loss: 0.689  |  valid_loss: 0.596\n",
      "[epoch: 8, i:  2609]  train_loss: 0.729  |  valid_loss: 0.643\n",
      "[epoch: 8, i:  2696]  train_loss: 0.714  |  valid_loss: 0.727\n",
      "[epoch: 8, i:  2783]  train_loss: 0.709  |  valid_loss: 0.523\n",
      "[epoch: 8, i:  2870]  train_loss: 0.703  |  valid_loss: 0.720\n",
      "[epoch: 8, i:  2957]  train_loss: 0.771  |  valid_loss: 0.730\n",
      "[epoch: 8, i:  3044]  train_loss: 0.785  |  valid_loss: 0.809\n",
      "[epoch: 8, i:  3131]  train_loss: 0.669  |  valid_loss: 0.689\n",
      "[epoch: 8, i:  3218]  train_loss: 0.720  |  valid_loss: 0.759\n",
      "[epoch: 8, i:  3305]  train_loss: 0.684  |  valid_loss: 0.734\n",
      "[epoch: 8, i:  3392]  train_loss: 0.713  |  valid_loss: 0.662\n",
      "[epoch: 8, i:  3479]  train_loss: 0.683  |  valid_loss: 0.492\n",
      "[epoch: 8, i:  3566]  train_loss: 0.734  |  valid_loss: 0.619\n",
      "[epoch: 8, i:  3653]  train_loss: 0.787  |  valid_loss: 0.812\n",
      "[epoch: 8, i:  3740]  train_loss: 0.655  |  valid_loss: 0.441\n",
      "[epoch: 8, i:  3827]  train_loss: 0.653  |  valid_loss: 0.763\n",
      "[epoch: 8, i:  3914]  train_loss: 0.671  |  valid_loss: 0.554\n",
      "[epoch: 8, i:  4001]  train_loss: 0.714  |  valid_loss: 0.646\n",
      "[epoch: 8, i:  4088]  train_loss: 0.727  |  valid_loss: 0.718\n",
      "[epoch: 8, i:  4175]  train_loss: 0.736  |  valid_loss: 0.643\n",
      "[epoch: 8, i:  4262]  train_loss: 0.712  |  valid_loss: 0.564\n",
      "[epoch: 8, i:  4349]  train_loss: 0.697  |  valid_loss: 0.679\n",
      "[epoch: 8, i:  4436]  train_loss: 0.655  |  valid_loss: 0.568\n",
      "[epoch: 8, i:  4523]  train_loss: 0.686  |  valid_loss: 0.791\n",
      "[epoch: 8, i:  4610]  train_loss: 0.726  |  valid_loss: 0.586\n",
      "[epoch: 8, i:  4697]  train_loss: 0.645  |  valid_loss: 0.651\n",
      "[epoch: 8, i:  4784]  train_loss: 0.706  |  valid_loss: 0.685\n",
      "[epoch: 8, i:  4871]  train_loss: 0.744  |  valid_loss: 0.783\n",
      "[epoch: 8, i:  4958]  train_loss: 0.720  |  valid_loss: 0.908\n",
      "[epoch: 8, i:  5045]  train_loss: 0.732  |  valid_loss: 0.571\n",
      "[epoch: 8, i:  5132]  train_loss: 0.718  |  valid_loss: 0.699\n",
      "[epoch: 8, i:  5219]  train_loss: 0.706  |  valid_loss: 0.798\n",
      "[epoch: 8, i:  5306]  train_loss: 0.686  |  valid_loss: 0.788\n",
      "[epoch: 8, i:  5393]  train_loss: 0.686  |  valid_loss: 0.705\n",
      "[epoch: 8, i:  5480]  train_loss: 0.744  |  valid_loss: 0.782\n",
      "[epoch: 8, i:  5567]  train_loss: 0.687  |  valid_loss: 0.433\n",
      "[epoch: 8, i:  5654]  train_loss: 0.727  |  valid_loss: 0.682\n",
      "[epoch: 8, i:  5741]  train_loss: 0.666  |  valid_loss: 0.790\n",
      "[epoch: 8, i:  5828]  train_loss: 0.695  |  valid_loss: 0.776\n",
      "[epoch: 8, i:  5915]  train_loss: 0.687  |  valid_loss: 0.849\n",
      "[epoch: 8, i:  6002]  train_loss: 0.638  |  valid_loss: 0.655\n",
      "[epoch: 8, i:  6089]  train_loss: 0.647  |  valid_loss: 0.821\n",
      "[epoch: 8, i:  6176]  train_loss: 0.688  |  valid_loss: 0.797\n",
      "[epoch: 8, i:  6263]  train_loss: 0.686  |  valid_loss: 0.666\n",
      "[epoch: 8, i:  6350]  train_loss: 0.725  |  valid_loss: 0.691\n",
      "[epoch: 8, i:  6437]  train_loss: 0.727  |  valid_loss: 0.516\n",
      "[epoch: 8, i:  6524]  train_loss: 0.783  |  valid_loss: 0.739\n",
      "[epoch: 8, i:  6611]  train_loss: 0.678  |  valid_loss: 0.544\n",
      "[epoch: 8, i:  6698]  train_loss: 0.758  |  valid_loss: 0.856\n",
      "[epoch: 8, i:  6785]  train_loss: 0.660  |  valid_loss: 0.611\n",
      "[epoch: 8, i:  6872]  train_loss: 0.626  |  valid_loss: 0.819\n",
      "[epoch: 8, i:  6959]  train_loss: 0.655  |  valid_loss: 0.783\n",
      "[epoch: 8, i:  7046]  train_loss: 0.705  |  valid_loss: 0.634\n",
      "[epoch: 8, i:  7133]  train_loss: 0.665  |  valid_loss: 0.577\n",
      "[epoch: 8, i:  7220]  train_loss: 0.736  |  valid_loss: 0.680\n",
      "[epoch: 8, i:  7307]  train_loss: 0.754  |  valid_loss: 0.731\n",
      "[epoch: 8, i:  7394]  train_loss: 0.725  |  valid_loss: 0.731\n",
      "[epoch: 8, i:  7481]  train_loss: 0.633  |  valid_loss: 0.647\n",
      "[epoch: 8, i:  7568]  train_loss: 0.577  |  valid_loss: 0.741\n",
      "[epoch: 8, i:  7655]  train_loss: 0.750  |  valid_loss: 0.762\n",
      "[epoch: 8, i:  7742]  train_loss: 0.758  |  valid_loss: 0.705\n",
      "[epoch: 8, i:  7829]  train_loss: 0.725  |  valid_loss: 0.527\n",
      "[epoch: 8, i:  7916]  train_loss: 0.627  |  valid_loss: 0.779\n",
      "[epoch: 8, i:  8003]  train_loss: 0.663  |  valid_loss: 0.673\n",
      "[epoch: 8, i:  8090]  train_loss: 0.689  |  valid_loss: 0.548\n",
      "[epoch: 8, i:  8177]  train_loss: 0.694  |  valid_loss: 0.709\n",
      "[epoch: 8, i:  8264]  train_loss: 0.695  |  valid_loss: 0.766\n",
      "[epoch: 8, i:  8351]  train_loss: 0.684  |  valid_loss: 0.772\n",
      "[epoch: 8, i:  8438]  train_loss: 0.735  |  valid_loss: 0.575\n",
      "[epoch: 8, i:  8525]  train_loss: 0.626  |  valid_loss: 0.764\n",
      "[epoch: 8, i:  8612]  train_loss: 0.708  |  valid_loss: 0.875\n",
      "[epoch: 8, i:  8699]  train_loss: 0.681  |  valid_loss: 0.708\n",
      "--> [End of epoch 8] train_accuracy: 75.80%  |  valid_accuracy: 76.32%\n",
      "--> [Start of epoch 9]  lr: 0.000500\n",
      "[epoch: 9, i:    86]  train_loss: 0.663  |  valid_loss: 0.605\n",
      "[epoch: 9, i:   173]  train_loss: 0.640  |  valid_loss: 0.540\n",
      "[epoch: 9, i:   260]  train_loss: 0.588  |  valid_loss: 0.667\n",
      "[epoch: 9, i:   347]  train_loss: 0.673  |  valid_loss: 0.540\n",
      "[epoch: 9, i:   434]  train_loss: 0.638  |  valid_loss: 0.672\n",
      "[epoch: 9, i:   521]  train_loss: 0.656  |  valid_loss: 0.517\n",
      "[epoch: 9, i:   608]  train_loss: 0.680  |  valid_loss: 0.645\n",
      "[epoch: 9, i:   695]  train_loss: 0.653  |  valid_loss: 0.711\n",
      "[epoch: 9, i:   782]  train_loss: 0.692  |  valid_loss: 0.723\n",
      "[epoch: 9, i:   869]  train_loss: 0.667  |  valid_loss: 0.737\n",
      "[epoch: 9, i:   956]  train_loss: 0.716  |  valid_loss: 0.591\n",
      "[epoch: 9, i:  1043]  train_loss: 0.736  |  valid_loss: 0.620\n",
      "[epoch: 9, i:  1130]  train_loss: 0.681  |  valid_loss: 0.629\n",
      "[epoch: 9, i:  1217]  train_loss: 0.673  |  valid_loss: 0.589\n",
      "[epoch: 9, i:  1304]  train_loss: 0.731  |  valid_loss: 0.494\n",
      "[epoch: 9, i:  1391]  train_loss: 0.674  |  valid_loss: 0.697\n",
      "[epoch: 9, i:  1478]  train_loss: 0.649  |  valid_loss: 0.624\n",
      "[epoch: 9, i:  1565]  train_loss: 0.627  |  valid_loss: 0.720\n",
      "[epoch: 9, i:  1652]  train_loss: 0.636  |  valid_loss: 0.631\n",
      "[epoch: 9, i:  1739]  train_loss: 0.615  |  valid_loss: 0.892\n",
      "[epoch: 9, i:  1826]  train_loss: 0.653  |  valid_loss: 0.744\n",
      "[epoch: 9, i:  1913]  train_loss: 0.699  |  valid_loss: 0.715\n",
      "[epoch: 9, i:  2000]  train_loss: 0.650  |  valid_loss: 0.696\n",
      "[epoch: 9, i:  2087]  train_loss: 0.682  |  valid_loss: 0.780\n",
      "[epoch: 9, i:  2174]  train_loss: 0.640  |  valid_loss: 0.596\n",
      "[epoch: 9, i:  2261]  train_loss: 0.738  |  valid_loss: 0.988\n",
      "[epoch: 9, i:  2348]  train_loss: 0.717  |  valid_loss: 0.703\n",
      "[epoch: 9, i:  2435]  train_loss: 0.745  |  valid_loss: 0.698\n",
      "[epoch: 9, i:  2522]  train_loss: 0.683  |  valid_loss: 0.573\n",
      "[epoch: 9, i:  2609]  train_loss: 0.698  |  valid_loss: 0.601\n",
      "[epoch: 9, i:  2696]  train_loss: 0.716  |  valid_loss: 0.767\n",
      "[epoch: 9, i:  2783]  train_loss: 0.658  |  valid_loss: 0.521\n",
      "[epoch: 9, i:  2870]  train_loss: 0.752  |  valid_loss: 0.743\n",
      "[epoch: 9, i:  2957]  train_loss: 0.661  |  valid_loss: 0.681\n",
      "[epoch: 9, i:  3044]  train_loss: 0.657  |  valid_loss: 0.797\n",
      "[epoch: 9, i:  3131]  train_loss: 0.673  |  valid_loss: 0.726\n",
      "[epoch: 9, i:  3218]  train_loss: 0.728  |  valid_loss: 0.777\n",
      "[epoch: 9, i:  3305]  train_loss: 0.650  |  valid_loss: 0.745\n",
      "[epoch: 9, i:  3392]  train_loss: 0.721  |  valid_loss: 0.688\n",
      "[epoch: 9, i:  3479]  train_loss: 0.669  |  valid_loss: 0.500\n",
      "[epoch: 9, i:  3566]  train_loss: 0.797  |  valid_loss: 0.648\n",
      "[epoch: 9, i:  3653]  train_loss: 0.708  |  valid_loss: 0.769\n",
      "[epoch: 9, i:  3740]  train_loss: 0.726  |  valid_loss: 0.418\n",
      "[epoch: 9, i:  3827]  train_loss: 0.671  |  valid_loss: 0.731\n",
      "[epoch: 9, i:  3914]  train_loss: 0.666  |  valid_loss: 0.463\n",
      "[epoch: 9, i:  4001]  train_loss: 0.627  |  valid_loss: 0.703\n",
      "[epoch: 9, i:  4088]  train_loss: 0.602  |  valid_loss: 0.707\n",
      "[epoch: 9, i:  4175]  train_loss: 0.744  |  valid_loss: 0.628\n",
      "[epoch: 9, i:  4262]  train_loss: 0.655  |  valid_loss: 0.583\n",
      "[epoch: 9, i:  4349]  train_loss: 0.676  |  valid_loss: 0.689\n",
      "[epoch: 9, i:  4436]  train_loss: 0.652  |  valid_loss: 0.538\n",
      "[epoch: 9, i:  4523]  train_loss: 0.659  |  valid_loss: 0.745\n",
      "[epoch: 9, i:  4610]  train_loss: 0.671  |  valid_loss: 0.588\n",
      "[epoch: 9, i:  4697]  train_loss: 0.719  |  valid_loss: 0.663\n",
      "[epoch: 9, i:  4784]  train_loss: 0.710  |  valid_loss: 0.701\n",
      "[epoch: 9, i:  4871]  train_loss: 0.659  |  valid_loss: 0.740\n",
      "[epoch: 9, i:  4958]  train_loss: 0.690  |  valid_loss: 0.779\n",
      "[epoch: 9, i:  5045]  train_loss: 0.724  |  valid_loss: 0.526\n",
      "[epoch: 9, i:  5132]  train_loss: 0.666  |  valid_loss: 0.657\n",
      "[epoch: 9, i:  5219]  train_loss: 0.708  |  valid_loss: 0.781\n",
      "[epoch: 9, i:  5306]  train_loss: 0.639  |  valid_loss: 0.814\n",
      "[epoch: 9, i:  5393]  train_loss: 0.730  |  valid_loss: 0.601\n",
      "[epoch: 9, i:  5480]  train_loss: 0.670  |  valid_loss: 0.676\n",
      "[epoch: 9, i:  5567]  train_loss: 0.715  |  valid_loss: 0.455\n",
      "[epoch: 9, i:  5654]  train_loss: 0.668  |  valid_loss: 0.708\n",
      "[epoch: 9, i:  5741]  train_loss: 0.617  |  valid_loss: 0.681\n",
      "[epoch: 9, i:  5828]  train_loss: 0.595  |  valid_loss: 0.654\n",
      "[epoch: 9, i:  5915]  train_loss: 0.692  |  valid_loss: 0.856\n",
      "[epoch: 9, i:  6002]  train_loss: 0.635  |  valid_loss: 0.581\n",
      "[epoch: 9, i:  6089]  train_loss: 0.653  |  valid_loss: 0.825\n",
      "[epoch: 9, i:  6176]  train_loss: 0.743  |  valid_loss: 0.825\n",
      "[epoch: 9, i:  6263]  train_loss: 0.624  |  valid_loss: 0.589\n",
      "[epoch: 9, i:  6350]  train_loss: 0.740  |  valid_loss: 0.650\n",
      "[epoch: 9, i:  6437]  train_loss: 0.728  |  valid_loss: 0.505\n",
      "[epoch: 9, i:  6524]  train_loss: 0.687  |  valid_loss: 0.924\n",
      "[epoch: 9, i:  6611]  train_loss: 0.699  |  valid_loss: 0.587\n",
      "[epoch: 9, i:  6698]  train_loss: 0.672  |  valid_loss: 0.756\n",
      "[epoch: 9, i:  6785]  train_loss: 0.749  |  valid_loss: 0.600\n",
      "[epoch: 9, i:  6872]  train_loss: 0.649  |  valid_loss: 0.804\n",
      "[epoch: 9, i:  6959]  train_loss: 0.630  |  valid_loss: 0.744\n",
      "[epoch: 9, i:  7046]  train_loss: 0.701  |  valid_loss: 0.625\n",
      "[epoch: 9, i:  7133]  train_loss: 0.695  |  valid_loss: 0.543\n",
      "[epoch: 9, i:  7220]  train_loss: 0.618  |  valid_loss: 0.723\n",
      "[epoch: 9, i:  7307]  train_loss: 0.687  |  valid_loss: 0.794\n",
      "[epoch: 9, i:  7394]  train_loss: 0.674  |  valid_loss: 0.639\n",
      "[epoch: 9, i:  7481]  train_loss: 0.631  |  valid_loss: 0.720\n",
      "[epoch: 9, i:  7568]  train_loss: 0.715  |  valid_loss: 0.831\n",
      "[epoch: 9, i:  7655]  train_loss: 0.804  |  valid_loss: 0.762\n",
      "[epoch: 9, i:  7742]  train_loss: 0.576  |  valid_loss: 0.678\n",
      "[epoch: 9, i:  7829]  train_loss: 0.605  |  valid_loss: 0.544\n",
      "[epoch: 9, i:  7916]  train_loss: 0.704  |  valid_loss: 0.833\n",
      "[epoch: 9, i:  8003]  train_loss: 0.694  |  valid_loss: 0.656\n",
      "[epoch: 9, i:  8090]  train_loss: 0.743  |  valid_loss: 0.485\n",
      "[epoch: 9, i:  8177]  train_loss: 0.698  |  valid_loss: 0.601\n",
      "[epoch: 9, i:  8264]  train_loss: 0.688  |  valid_loss: 0.737\n",
      "[epoch: 9, i:  8351]  train_loss: 0.682  |  valid_loss: 0.814\n",
      "[epoch: 9, i:  8438]  train_loss: 0.669  |  valid_loss: 0.506\n",
      "[epoch: 9, i:  8525]  train_loss: 0.696  |  valid_loss: 0.673\n",
      "[epoch: 9, i:  8612]  train_loss: 0.648  |  valid_loss: 0.855\n",
      "[epoch: 9, i:  8699]  train_loss: 0.711  |  valid_loss: 0.681\n",
      "--> [End of epoch 9] train_accuracy: 76.42%  |  valid_accuracy: 76.22%\n",
      "--> [Start of epoch 10]  lr: 0.000500\n",
      "[epoch: 10, i:    86]  train_loss: 0.604  |  valid_loss: 0.552\n",
      "[epoch: 10, i:   173]  train_loss: 0.628  |  valid_loss: 0.525\n",
      "[epoch: 10, i:   260]  train_loss: 0.644  |  valid_loss: 0.745\n",
      "[epoch: 10, i:   347]  train_loss: 0.703  |  valid_loss: 0.558\n",
      "[epoch: 10, i:   434]  train_loss: 0.664  |  valid_loss: 0.749\n",
      "[epoch: 10, i:   521]  train_loss: 0.685  |  valid_loss: 0.466\n",
      "[epoch: 10, i:   608]  train_loss: 0.664  |  valid_loss: 0.783\n",
      "[epoch: 10, i:   695]  train_loss: 0.693  |  valid_loss: 0.693\n",
      "[epoch: 10, i:   782]  train_loss: 0.581  |  valid_loss: 0.758\n",
      "[epoch: 10, i:   869]  train_loss: 0.678  |  valid_loss: 0.709\n",
      "[epoch: 10, i:   956]  train_loss: 0.608  |  valid_loss: 0.529\n",
      "[epoch: 10, i:  1043]  train_loss: 0.636  |  valid_loss: 0.637\n",
      "[epoch: 10, i:  1130]  train_loss: 0.619  |  valid_loss: 0.587\n",
      "[epoch: 10, i:  1217]  train_loss: 0.710  |  valid_loss: 0.626\n",
      "[epoch: 10, i:  1304]  train_loss: 0.609  |  valid_loss: 0.500\n",
      "[epoch: 10, i:  1391]  train_loss: 0.638  |  valid_loss: 0.711\n",
      "[epoch: 10, i:  1478]  train_loss: 0.628  |  valid_loss: 0.679\n",
      "[epoch: 10, i:  1565]  train_loss: 0.637  |  valid_loss: 0.709\n",
      "[epoch: 10, i:  1652]  train_loss: 0.698  |  valid_loss: 0.632\n",
      "[epoch: 10, i:  1739]  train_loss: 0.742  |  valid_loss: 0.801\n",
      "[epoch: 10, i:  1826]  train_loss: 0.735  |  valid_loss: 0.777\n",
      "[epoch: 10, i:  1913]  train_loss: 0.617  |  valid_loss: 0.656\n",
      "[epoch: 10, i:  2000]  train_loss: 0.676  |  valid_loss: 0.645\n",
      "[epoch: 10, i:  2087]  train_loss: 0.694  |  valid_loss: 0.741\n",
      "[epoch: 10, i:  2174]  train_loss: 0.622  |  valid_loss: 0.552\n",
      "[epoch: 10, i:  2261]  train_loss: 0.688  |  valid_loss: 0.966\n",
      "[epoch: 10, i:  2348]  train_loss: 0.719  |  valid_loss: 0.651\n",
      "[epoch: 10, i:  2435]  train_loss: 0.668  |  valid_loss: 0.804\n",
      "[epoch: 10, i:  2522]  train_loss: 0.612  |  valid_loss: 0.666\n",
      "[epoch: 10, i:  2609]  train_loss: 0.649  |  valid_loss: 0.616\n",
      "[epoch: 10, i:  2696]  train_loss: 0.666  |  valid_loss: 0.709\n",
      "[epoch: 10, i:  2783]  train_loss: 0.680  |  valid_loss: 0.552\n",
      "[epoch: 10, i:  2870]  train_loss: 0.651  |  valid_loss: 0.769\n",
      "[epoch: 10, i:  2957]  train_loss: 0.649  |  valid_loss: 0.691\n",
      "[epoch: 10, i:  3044]  train_loss: 0.605  |  valid_loss: 0.725\n",
      "[epoch: 10, i:  3131]  train_loss: 0.640  |  valid_loss: 0.666\n",
      "[epoch: 10, i:  3218]  train_loss: 0.696  |  valid_loss: 0.746\n",
      "[epoch: 10, i:  3305]  train_loss: 0.735  |  valid_loss: 0.684\n",
      "[epoch: 10, i:  3392]  train_loss: 0.759  |  valid_loss: 0.690\n",
      "[epoch: 10, i:  3479]  train_loss: 0.676  |  valid_loss: 0.533\n",
      "[epoch: 10, i:  3566]  train_loss: 0.714  |  valid_loss: 0.615\n",
      "[epoch: 10, i:  3653]  train_loss: 0.717  |  valid_loss: 0.767\n",
      "[epoch: 10, i:  3740]  train_loss: 0.681  |  valid_loss: 0.422\n",
      "[epoch: 10, i:  3827]  train_loss: 0.699  |  valid_loss: 0.790\n",
      "[epoch: 10, i:  3914]  train_loss: 0.651  |  valid_loss: 0.549\n",
      "[epoch: 10, i:  4001]  train_loss: 0.694  |  valid_loss: 0.628\n",
      "[epoch: 10, i:  4088]  train_loss: 0.668  |  valid_loss: 0.650\n",
      "[epoch: 10, i:  4175]  train_loss: 0.658  |  valid_loss: 0.642\n",
      "[epoch: 10, i:  4262]  train_loss: 0.723  |  valid_loss: 0.529\n",
      "[epoch: 10, i:  4349]  train_loss: 0.633  |  valid_loss: 0.671\n",
      "[epoch: 10, i:  4436]  train_loss: 0.646  |  valid_loss: 0.635\n",
      "[epoch: 10, i:  4523]  train_loss: 0.637  |  valid_loss: 0.766\n",
      "[epoch: 10, i:  4610]  train_loss: 0.638  |  valid_loss: 0.538\n",
      "[epoch: 10, i:  4697]  train_loss: 0.680  |  valid_loss: 0.640\n",
      "[epoch: 10, i:  4784]  train_loss: 0.708  |  valid_loss: 0.700\n",
      "[epoch: 10, i:  4871]  train_loss: 0.664  |  valid_loss: 0.804\n",
      "[epoch: 10, i:  4958]  train_loss: 0.746  |  valid_loss: 0.833\n",
      "[epoch: 10, i:  5045]  train_loss: 0.638  |  valid_loss: 0.519\n",
      "[epoch: 10, i:  5132]  train_loss: 0.697  |  valid_loss: 0.596\n",
      "[epoch: 10, i:  5219]  train_loss: 0.642  |  valid_loss: 0.883\n",
      "[epoch: 10, i:  5306]  train_loss: 0.689  |  valid_loss: 0.740\n",
      "[epoch: 10, i:  5393]  train_loss: 0.605  |  valid_loss: 0.590\n",
      "[epoch: 10, i:  5480]  train_loss: 0.681  |  valid_loss: 0.749\n",
      "[epoch: 10, i:  5567]  train_loss: 0.659  |  valid_loss: 0.374\n",
      "[epoch: 10, i:  5654]  train_loss: 0.664  |  valid_loss: 0.652\n",
      "[epoch: 10, i:  5741]  train_loss: 0.734  |  valid_loss: 0.785\n",
      "[epoch: 10, i:  5828]  train_loss: 0.636  |  valid_loss: 0.632\n",
      "[epoch: 10, i:  5915]  train_loss: 0.718  |  valid_loss: 0.785\n",
      "[epoch: 10, i:  6002]  train_loss: 0.703  |  valid_loss: 0.656\n",
      "[epoch: 10, i:  6089]  train_loss: 0.711  |  valid_loss: 0.829\n",
      "[epoch: 10, i:  6176]  train_loss: 0.609  |  valid_loss: 0.755\n",
      "[epoch: 10, i:  6263]  train_loss: 0.622  |  valid_loss: 0.545\n",
      "[epoch: 10, i:  6350]  train_loss: 0.649  |  valid_loss: 0.606\n",
      "[epoch: 10, i:  6437]  train_loss: 0.685  |  valid_loss: 0.547\n",
      "[epoch: 10, i:  6524]  train_loss: 0.711  |  valid_loss: 0.855\n",
      "[epoch: 10, i:  6611]  train_loss: 0.700  |  valid_loss: 0.513\n",
      "[epoch: 10, i:  6698]  train_loss: 0.679  |  valid_loss: 0.829\n",
      "[epoch: 10, i:  6785]  train_loss: 0.639  |  valid_loss: 0.548\n",
      "[epoch: 10, i:  6872]  train_loss: 0.682  |  valid_loss: 0.807\n",
      "[epoch: 10, i:  6959]  train_loss: 0.695  |  valid_loss: 0.746\n",
      "[epoch: 10, i:  7046]  train_loss: 0.691  |  valid_loss: 0.649\n",
      "[epoch: 10, i:  7133]  train_loss: 0.609  |  valid_loss: 0.641\n",
      "[epoch: 10, i:  7220]  train_loss: 0.674  |  valid_loss: 0.706\n",
      "[epoch: 10, i:  7307]  train_loss: 0.674  |  valid_loss: 0.755\n",
      "[epoch: 10, i:  7394]  train_loss: 0.652  |  valid_loss: 0.584\n",
      "[epoch: 10, i:  7481]  train_loss: 0.703  |  valid_loss: 0.711\n",
      "[epoch: 10, i:  7568]  train_loss: 0.660  |  valid_loss: 0.774\n",
      "[epoch: 10, i:  7655]  train_loss: 0.671  |  valid_loss: 0.673\n",
      "[epoch: 10, i:  7742]  train_loss: 0.675  |  valid_loss: 0.652\n",
      "[epoch: 10, i:  7829]  train_loss: 0.644  |  valid_loss: 0.458\n",
      "[epoch: 10, i:  7916]  train_loss: 0.673  |  valid_loss: 0.723\n",
      "[epoch: 10, i:  8003]  train_loss: 0.683  |  valid_loss: 0.625\n",
      "[epoch: 10, i:  8090]  train_loss: 0.587  |  valid_loss: 0.557\n",
      "[epoch: 10, i:  8177]  train_loss: 0.658  |  valid_loss: 0.649\n",
      "[epoch: 10, i:  8264]  train_loss: 0.706  |  valid_loss: 0.717\n",
      "[epoch: 10, i:  8351]  train_loss: 0.659  |  valid_loss: 0.742\n",
      "[epoch: 10, i:  8438]  train_loss: 0.622  |  valid_loss: 0.525\n",
      "[epoch: 10, i:  8525]  train_loss: 0.699  |  valid_loss: 0.630\n",
      "[epoch: 10, i:  8612]  train_loss: 0.708  |  valid_loss: 0.953\n",
      "[epoch: 10, i:  8699]  train_loss: 0.678  |  valid_loss: 0.670\n",
      "--> [End of epoch 10] train_accuracy: 76.70%  |  valid_accuracy: 77.12%\n",
      "--> [Start of epoch 11]  lr: 0.000500\n",
      "[epoch: 11, i:    86]  train_loss: 0.601  |  valid_loss: 0.666\n",
      "[epoch: 11, i:   173]  train_loss: 0.724  |  valid_loss: 0.564\n",
      "[epoch: 11, i:   260]  train_loss: 0.628  |  valid_loss: 0.750\n",
      "[epoch: 11, i:   347]  train_loss: 0.632  |  valid_loss: 0.606\n",
      "[epoch: 11, i:   434]  train_loss: 0.621  |  valid_loss: 0.750\n",
      "[epoch: 11, i:   521]  train_loss: 0.652  |  valid_loss: 0.471\n",
      "[epoch: 11, i:   608]  train_loss: 0.585  |  valid_loss: 0.703\n",
      "[epoch: 11, i:   695]  train_loss: 0.635  |  valid_loss: 0.763\n",
      "[epoch: 11, i:   782]  train_loss: 0.689  |  valid_loss: 0.732\n",
      "[epoch: 11, i:   869]  train_loss: 0.704  |  valid_loss: 0.699\n",
      "[epoch: 11, i:   956]  train_loss: 0.593  |  valid_loss: 0.478\n",
      "[epoch: 11, i:  1043]  train_loss: 0.707  |  valid_loss: 0.617\n",
      "[epoch: 11, i:  1130]  train_loss: 0.649  |  valid_loss: 0.599\n",
      "[epoch: 11, i:  1217]  train_loss: 0.658  |  valid_loss: 0.677\n",
      "[epoch: 11, i:  1304]  train_loss: 0.690  |  valid_loss: 0.457\n",
      "[epoch: 11, i:  1391]  train_loss: 0.689  |  valid_loss: 0.742\n",
      "[epoch: 11, i:  1478]  train_loss: 0.612  |  valid_loss: 0.750\n",
      "[epoch: 11, i:  1565]  train_loss: 0.694  |  valid_loss: 0.757\n",
      "[epoch: 11, i:  1652]  train_loss: 0.684  |  valid_loss: 0.682\n",
      "[epoch: 11, i:  1739]  train_loss: 0.655  |  valid_loss: 0.890\n",
      "[epoch: 11, i:  1826]  train_loss: 0.683  |  valid_loss: 0.859\n",
      "[epoch: 11, i:  1913]  train_loss: 0.634  |  valid_loss: 0.679\n",
      "[epoch: 11, i:  2000]  train_loss: 0.630  |  valid_loss: 0.603\n",
      "[epoch: 11, i:  2087]  train_loss: 0.633  |  valid_loss: 0.746\n",
      "[epoch: 11, i:  2174]  train_loss: 0.692  |  valid_loss: 0.577\n",
      "[epoch: 11, i:  2261]  train_loss: 0.721  |  valid_loss: 0.928\n",
      "[epoch: 11, i:  2348]  train_loss: 0.630  |  valid_loss: 0.634\n",
      "[epoch: 11, i:  2435]  train_loss: 0.606  |  valid_loss: 0.745\n",
      "[epoch: 11, i:  2522]  train_loss: 0.707  |  valid_loss: 0.568\n",
      "[epoch: 11, i:  2609]  train_loss: 0.700  |  valid_loss: 0.600\n",
      "[epoch: 11, i:  2696]  train_loss: 0.649  |  valid_loss: 0.732\n",
      "[epoch: 11, i:  2783]  train_loss: 0.648  |  valid_loss: 0.519\n",
      "[epoch: 11, i:  2870]  train_loss: 0.616  |  valid_loss: 0.752\n",
      "[epoch: 11, i:  2957]  train_loss: 0.627  |  valid_loss: 0.743\n",
      "[epoch: 11, i:  3044]  train_loss: 0.691  |  valid_loss: 0.827\n",
      "[epoch: 11, i:  3131]  train_loss: 0.721  |  valid_loss: 0.701\n",
      "[epoch: 11, i:  3218]  train_loss: 0.695  |  valid_loss: 0.780\n",
      "[epoch: 11, i:  3305]  train_loss: 0.647  |  valid_loss: 0.666\n",
      "[epoch: 11, i:  3392]  train_loss: 0.624  |  valid_loss: 0.679\n",
      "[epoch: 11, i:  3479]  train_loss: 0.675  |  valid_loss: 0.526\n",
      "[epoch: 11, i:  3566]  train_loss: 0.715  |  valid_loss: 0.619\n",
      "[epoch: 11, i:  3653]  train_loss: 0.690  |  valid_loss: 0.759\n",
      "[epoch: 11, i:  3740]  train_loss: 0.650  |  valid_loss: 0.470\n",
      "[epoch: 11, i:  3827]  train_loss: 0.654  |  valid_loss: 0.837\n",
      "[epoch: 11, i:  3914]  train_loss: 0.661  |  valid_loss: 0.563\n",
      "[epoch: 11, i:  4001]  train_loss: 0.643  |  valid_loss: 0.636\n",
      "[epoch: 11, i:  4088]  train_loss: 0.624  |  valid_loss: 0.639\n",
      "[epoch: 11, i:  4175]  train_loss: 0.703  |  valid_loss: 0.576\n",
      "[epoch: 11, i:  4262]  train_loss: 0.614  |  valid_loss: 0.615\n",
      "[epoch: 11, i:  4349]  train_loss: 0.619  |  valid_loss: 0.637\n",
      "[epoch: 11, i:  4436]  train_loss: 0.692  |  valid_loss: 0.541\n",
      "[epoch: 11, i:  4523]  train_loss: 0.620  |  valid_loss: 0.648\n",
      "[epoch: 11, i:  4610]  train_loss: 0.668  |  valid_loss: 0.605\n",
      "[epoch: 11, i:  4697]  train_loss: 0.662  |  valid_loss: 0.547\n",
      "[epoch: 11, i:  4784]  train_loss: 0.708  |  valid_loss: 0.669\n",
      "[epoch: 11, i:  4871]  train_loss: 0.631  |  valid_loss: 0.787\n",
      "[epoch: 11, i:  4958]  train_loss: 0.607  |  valid_loss: 0.812\n",
      "[epoch: 11, i:  5045]  train_loss: 0.590  |  valid_loss: 0.524\n",
      "[epoch: 11, i:  5132]  train_loss: 0.621  |  valid_loss: 0.596\n",
      "[epoch: 11, i:  5219]  train_loss: 0.635  |  valid_loss: 0.845\n",
      "[epoch: 11, i:  5306]  train_loss: 0.605  |  valid_loss: 0.745\n",
      "[epoch: 11, i:  5393]  train_loss: 0.721  |  valid_loss: 0.669\n",
      "[epoch: 11, i:  5480]  train_loss: 0.663  |  valid_loss: 0.704\n",
      "[epoch: 11, i:  5567]  train_loss: 0.617  |  valid_loss: 0.402\n",
      "[epoch: 11, i:  5654]  train_loss: 0.719  |  valid_loss: 0.749\n",
      "[epoch: 11, i:  5741]  train_loss: 0.613  |  valid_loss: 0.685\n",
      "[epoch: 11, i:  5828]  train_loss: 0.680  |  valid_loss: 0.565\n",
      "[epoch: 11, i:  5915]  train_loss: 0.625  |  valid_loss: 0.835\n",
      "[epoch: 11, i:  6002]  train_loss: 0.651  |  valid_loss: 0.592\n",
      "[epoch: 11, i:  6089]  train_loss: 0.673  |  valid_loss: 0.801\n",
      "[epoch: 11, i:  6176]  train_loss: 0.610  |  valid_loss: 0.782\n",
      "[epoch: 11, i:  6263]  train_loss: 0.644  |  valid_loss: 0.659\n",
      "[epoch: 11, i:  6350]  train_loss: 0.651  |  valid_loss: 0.632\n",
      "[epoch: 11, i:  6437]  train_loss: 0.639  |  valid_loss: 0.560\n",
      "[epoch: 11, i:  6524]  train_loss: 0.608  |  valid_loss: 0.737\n",
      "[epoch: 11, i:  6611]  train_loss: 0.774  |  valid_loss: 0.500\n",
      "[epoch: 11, i:  6698]  train_loss: 0.650  |  valid_loss: 0.692\n",
      "[epoch: 11, i:  6785]  train_loss: 0.601  |  valid_loss: 0.580\n",
      "[epoch: 11, i:  6872]  train_loss: 0.660  |  valid_loss: 0.747\n",
      "[epoch: 11, i:  6959]  train_loss: 0.740  |  valid_loss: 0.755\n",
      "[epoch: 11, i:  7046]  train_loss: 0.691  |  valid_loss: 0.640\n",
      "[epoch: 11, i:  7133]  train_loss: 0.730  |  valid_loss: 0.590\n",
      "[epoch: 11, i:  7220]  train_loss: 0.651  |  valid_loss: 0.723\n",
      "[epoch: 11, i:  7307]  train_loss: 0.724  |  valid_loss: 0.852\n",
      "[epoch: 11, i:  7394]  train_loss: 0.696  |  valid_loss: 0.646\n",
      "[epoch: 11, i:  7481]  train_loss: 0.707  |  valid_loss: 0.693\n",
      "[epoch: 11, i:  7568]  train_loss: 0.652  |  valid_loss: 0.855\n",
      "[epoch: 11, i:  7655]  train_loss: 0.710  |  valid_loss: 0.696\n",
      "[epoch: 11, i:  7742]  train_loss: 0.621  |  valid_loss: 0.613\n",
      "[epoch: 11, i:  7829]  train_loss: 0.638  |  valid_loss: 0.521\n",
      "[epoch: 11, i:  7916]  train_loss: 0.689  |  valid_loss: 0.747\n",
      "[epoch: 11, i:  8003]  train_loss: 0.649  |  valid_loss: 0.573\n",
      "[epoch: 11, i:  8090]  train_loss: 0.643  |  valid_loss: 0.512\n",
      "[epoch: 11, i:  8177]  train_loss: 0.760  |  valid_loss: 0.625\n",
      "[epoch: 11, i:  8264]  train_loss: 0.644  |  valid_loss: 0.669\n",
      "[epoch: 11, i:  8351]  train_loss: 0.671  |  valid_loss: 0.668\n",
      "[epoch: 11, i:  8438]  train_loss: 0.621  |  valid_loss: 0.476\n",
      "[epoch: 11, i:  8525]  train_loss: 0.680  |  valid_loss: 0.644\n",
      "[epoch: 11, i:  8612]  train_loss: 0.642  |  valid_loss: 0.867\n",
      "[epoch: 11, i:  8699]  train_loss: 0.676  |  valid_loss: 0.675\n",
      "--> [End of epoch 11] train_accuracy: 77.07%  |  valid_accuracy: 77.41%\n",
      "--> [Start of epoch 12]  lr: 0.000500\n",
      "[epoch: 12, i:    86]  train_loss: 0.680  |  valid_loss: 0.626\n",
      "[epoch: 12, i:   173]  train_loss: 0.593  |  valid_loss: 0.588\n",
      "[epoch: 12, i:   260]  train_loss: 0.547  |  valid_loss: 0.642\n",
      "[epoch: 12, i:   347]  train_loss: 0.650  |  valid_loss: 0.543\n",
      "[epoch: 12, i:   434]  train_loss: 0.656  |  valid_loss: 0.736\n",
      "[epoch: 12, i:   521]  train_loss: 0.676  |  valid_loss: 0.461\n",
      "[epoch: 12, i:   608]  train_loss: 0.607  |  valid_loss: 0.669\n",
      "[epoch: 12, i:   695]  train_loss: 0.634  |  valid_loss: 0.779\n",
      "[epoch: 12, i:   782]  train_loss: 0.586  |  valid_loss: 0.806\n",
      "[epoch: 12, i:   869]  train_loss: 0.670  |  valid_loss: 0.647\n",
      "[epoch: 12, i:   956]  train_loss: 0.586  |  valid_loss: 0.490\n",
      "[epoch: 12, i:  1043]  train_loss: 0.680  |  valid_loss: 0.598\n",
      "[epoch: 12, i:  1130]  train_loss: 0.557  |  valid_loss: 0.556\n",
      "[epoch: 12, i:  1217]  train_loss: 0.558  |  valid_loss: 0.636\n",
      "[epoch: 12, i:  1304]  train_loss: 0.602  |  valid_loss: 0.450\n",
      "[epoch: 12, i:  1391]  train_loss: 0.682  |  valid_loss: 0.694\n",
      "[epoch: 12, i:  1478]  train_loss: 0.701  |  valid_loss: 0.638\n",
      "[epoch: 12, i:  1565]  train_loss: 0.679  |  valid_loss: 0.761\n",
      "[epoch: 12, i:  1652]  train_loss: 0.633  |  valid_loss: 0.651\n",
      "[epoch: 12, i:  1739]  train_loss: 0.718  |  valid_loss: 0.878\n",
      "[epoch: 12, i:  1826]  train_loss: 0.709  |  valid_loss: 0.797\n",
      "[epoch: 12, i:  1913]  train_loss: 0.640  |  valid_loss: 0.658\n",
      "[epoch: 12, i:  2000]  train_loss: 0.669  |  valid_loss: 0.568\n",
      "[epoch: 12, i:  2087]  train_loss: 0.642  |  valid_loss: 0.725\n",
      "[epoch: 12, i:  2174]  train_loss: 0.662  |  valid_loss: 0.584\n",
      "[epoch: 12, i:  2261]  train_loss: 0.654  |  valid_loss: 0.986\n",
      "[epoch: 12, i:  2348]  train_loss: 0.646  |  valid_loss: 0.572\n",
      "[epoch: 12, i:  2435]  train_loss: 0.596  |  valid_loss: 0.693\n",
      "[epoch: 12, i:  2522]  train_loss: 0.645  |  valid_loss: 0.518\n",
      "[epoch: 12, i:  2609]  train_loss: 0.646  |  valid_loss: 0.569\n",
      "[epoch: 12, i:  2696]  train_loss: 0.665  |  valid_loss: 0.762\n",
      "[epoch: 12, i:  2783]  train_loss: 0.576  |  valid_loss: 0.463\n",
      "[epoch: 12, i:  2870]  train_loss: 0.667  |  valid_loss: 0.735\n",
      "[epoch: 12, i:  2957]  train_loss: 0.714  |  valid_loss: 0.786\n",
      "[epoch: 12, i:  3044]  train_loss: 0.639  |  valid_loss: 0.781\n",
      "[epoch: 12, i:  3131]  train_loss: 0.663  |  valid_loss: 0.748\n",
      "[epoch: 12, i:  3218]  train_loss: 0.674  |  valid_loss: 0.718\n",
      "[epoch: 12, i:  3305]  train_loss: 0.643  |  valid_loss: 0.682\n",
      "[epoch: 12, i:  3392]  train_loss: 0.610  |  valid_loss: 0.687\n",
      "[epoch: 12, i:  3479]  train_loss: 0.664  |  valid_loss: 0.462\n",
      "[epoch: 12, i:  3566]  train_loss: 0.613  |  valid_loss: 0.659\n",
      "[epoch: 12, i:  3653]  train_loss: 0.649  |  valid_loss: 0.743\n",
      "[epoch: 12, i:  3740]  train_loss: 0.625  |  valid_loss: 0.431\n",
      "[epoch: 12, i:  3827]  train_loss: 0.652  |  valid_loss: 0.788\n",
      "[epoch: 12, i:  3914]  train_loss: 0.610  |  valid_loss: 0.506\n",
      "[epoch: 12, i:  4001]  train_loss: 0.628  |  valid_loss: 0.667\n",
      "[epoch: 12, i:  4088]  train_loss: 0.661  |  valid_loss: 0.619\n",
      "[epoch: 12, i:  4175]  train_loss: 0.705  |  valid_loss: 0.622\n",
      "[epoch: 12, i:  4262]  train_loss: 0.657  |  valid_loss: 0.553\n",
      "[epoch: 12, i:  4349]  train_loss: 0.624  |  valid_loss: 0.648\n",
      "[epoch: 12, i:  4436]  train_loss: 0.656  |  valid_loss: 0.608\n",
      "[epoch: 12, i:  4523]  train_loss: 0.734  |  valid_loss: 0.800\n",
      "[epoch: 12, i:  4610]  train_loss: 0.685  |  valid_loss: 0.535\n",
      "[epoch: 12, i:  4697]  train_loss: 0.625  |  valid_loss: 0.578\n",
      "[epoch: 12, i:  4784]  train_loss: 0.661  |  valid_loss: 0.686\n",
      "[epoch: 12, i:  4871]  train_loss: 0.594  |  valid_loss: 0.756\n",
      "[epoch: 12, i:  4958]  train_loss: 0.661  |  valid_loss: 0.784\n",
      "[epoch: 12, i:  5045]  train_loss: 0.665  |  valid_loss: 0.506\n",
      "[epoch: 12, i:  5132]  train_loss: 0.692  |  valid_loss: 0.644\n",
      "[epoch: 12, i:  5219]  train_loss: 0.676  |  valid_loss: 0.852\n",
      "[epoch: 12, i:  5306]  train_loss: 0.648  |  valid_loss: 0.729\n",
      "[epoch: 12, i:  5393]  train_loss: 0.644  |  valid_loss: 0.586\n",
      "[epoch: 12, i:  5480]  train_loss: 0.605  |  valid_loss: 0.714\n",
      "[epoch: 12, i:  5567]  train_loss: 0.625  |  valid_loss: 0.409\n",
      "[epoch: 12, i:  5654]  train_loss: 0.669  |  valid_loss: 0.678\n",
      "[epoch: 12, i:  5741]  train_loss: 0.630  |  valid_loss: 0.730\n",
      "[epoch: 12, i:  5828]  train_loss: 0.618  |  valid_loss: 0.645\n",
      "[epoch: 12, i:  5915]  train_loss: 0.656  |  valid_loss: 0.759\n",
      "[epoch: 12, i:  6002]  train_loss: 0.618  |  valid_loss: 0.639\n",
      "[epoch: 12, i:  6089]  train_loss: 0.679  |  valid_loss: 0.832\n",
      "[epoch: 12, i:  6176]  train_loss: 0.686  |  valid_loss: 0.806\n",
      "[epoch: 12, i:  6263]  train_loss: 0.652  |  valid_loss: 0.569\n",
      "[epoch: 12, i:  6350]  train_loss: 0.663  |  valid_loss: 0.644\n",
      "[epoch: 12, i:  6437]  train_loss: 0.640  |  valid_loss: 0.492\n",
      "[epoch: 12, i:  6524]  train_loss: 0.677  |  valid_loss: 0.718\n",
      "[epoch: 12, i:  6611]  train_loss: 0.642  |  valid_loss: 0.472\n",
      "[epoch: 12, i:  6698]  train_loss: 0.682  |  valid_loss: 0.798\n",
      "[epoch: 12, i:  6785]  train_loss: 0.708  |  valid_loss: 0.546\n",
      "[epoch: 12, i:  6872]  train_loss: 0.617  |  valid_loss: 0.774\n",
      "[epoch: 12, i:  6959]  train_loss: 0.690  |  valid_loss: 0.754\n",
      "[epoch: 12, i:  7046]  train_loss: 0.634  |  valid_loss: 0.627\n",
      "[epoch: 12, i:  7133]  train_loss: 0.646  |  valid_loss: 0.568\n",
      "[epoch: 12, i:  7220]  train_loss: 0.701  |  valid_loss: 0.800\n",
      "[epoch: 12, i:  7307]  train_loss: 0.600  |  valid_loss: 0.741\n",
      "[epoch: 12, i:  7394]  train_loss: 0.673  |  valid_loss: 0.597\n",
      "[epoch: 12, i:  7481]  train_loss: 0.646  |  valid_loss: 0.707\n",
      "[epoch: 12, i:  7568]  train_loss: 0.634  |  valid_loss: 0.829\n",
      "[epoch: 12, i:  7655]  train_loss: 0.651  |  valid_loss: 0.644\n",
      "[epoch: 12, i:  7742]  train_loss: 0.609  |  valid_loss: 0.679\n",
      "[epoch: 12, i:  7829]  train_loss: 0.646  |  valid_loss: 0.468\n",
      "[epoch: 12, i:  7916]  train_loss: 0.612  |  valid_loss: 0.776\n",
      "[epoch: 12, i:  8003]  train_loss: 0.572  |  valid_loss: 0.646\n",
      "[epoch: 12, i:  8090]  train_loss: 0.640  |  valid_loss: 0.526\n",
      "[epoch: 12, i:  8177]  train_loss: 0.717  |  valid_loss: 0.585\n",
      "[epoch: 12, i:  8264]  train_loss: 0.673  |  valid_loss: 0.737\n",
      "[epoch: 12, i:  8351]  train_loss: 0.633  |  valid_loss: 0.704\n",
      "[epoch: 12, i:  8438]  train_loss: 0.599  |  valid_loss: 0.488\n",
      "[epoch: 12, i:  8525]  train_loss: 0.659  |  valid_loss: 0.753\n",
      "[epoch: 12, i:  8612]  train_loss: 0.671  |  valid_loss: 0.889\n",
      "[epoch: 12, i:  8699]  train_loss: 0.691  |  valid_loss: 0.571\n",
      "--> [End of epoch 12] train_accuracy: 77.60%  |  valid_accuracy: 77.64%\n",
      "--> [Start of epoch 13]  lr: 0.000500\n",
      "[epoch: 13, i:    86]  train_loss: 0.604  |  valid_loss: 0.664\n",
      "[epoch: 13, i:   173]  train_loss: 0.660  |  valid_loss: 0.588\n",
      "[epoch: 13, i:   260]  train_loss: 0.596  |  valid_loss: 0.726\n",
      "[epoch: 13, i:   347]  train_loss: 0.648  |  valid_loss: 0.583\n",
      "[epoch: 13, i:   434]  train_loss: 0.643  |  valid_loss: 0.763\n",
      "[epoch: 13, i:   521]  train_loss: 0.612  |  valid_loss: 0.485\n",
      "[epoch: 13, i:   608]  train_loss: 0.592  |  valid_loss: 0.616\n",
      "[epoch: 13, i:   695]  train_loss: 0.602  |  valid_loss: 0.686\n",
      "[epoch: 13, i:   782]  train_loss: 0.668  |  valid_loss: 0.731\n",
      "[epoch: 13, i:   869]  train_loss: 0.632  |  valid_loss: 0.699\n",
      "[epoch: 13, i:   956]  train_loss: 0.620  |  valid_loss: 0.515\n",
      "[epoch: 13, i:  1043]  train_loss: 0.607  |  valid_loss: 0.529\n",
      "[epoch: 13, i:  1130]  train_loss: 0.650  |  valid_loss: 0.565\n",
      "[epoch: 13, i:  1217]  train_loss: 0.648  |  valid_loss: 0.620\n",
      "[epoch: 13, i:  1304]  train_loss: 0.666  |  valid_loss: 0.467\n",
      "[epoch: 13, i:  1391]  train_loss: 0.602  |  valid_loss: 0.729\n",
      "[epoch: 13, i:  1478]  train_loss: 0.603  |  valid_loss: 0.588\n",
      "[epoch: 13, i:  1565]  train_loss: 0.661  |  valid_loss: 0.792\n",
      "[epoch: 13, i:  1652]  train_loss: 0.591  |  valid_loss: 0.628\n",
      "[epoch: 13, i:  1739]  train_loss: 0.593  |  valid_loss: 0.747\n",
      "[epoch: 13, i:  1826]  train_loss: 0.672  |  valid_loss: 0.838\n",
      "[epoch: 13, i:  1913]  train_loss: 0.597  |  valid_loss: 0.657\n",
      "[epoch: 13, i:  2000]  train_loss: 0.712  |  valid_loss: 0.601\n",
      "[epoch: 13, i:  2087]  train_loss: 0.643  |  valid_loss: 0.763\n",
      "[epoch: 13, i:  2174]  train_loss: 0.647  |  valid_loss: 0.508\n",
      "[epoch: 13, i:  2261]  train_loss: 0.707  |  valid_loss: 0.960\n",
      "[epoch: 13, i:  2348]  train_loss: 0.581  |  valid_loss: 0.636\n",
      "[epoch: 13, i:  2435]  train_loss: 0.577  |  valid_loss: 0.766\n",
      "[epoch: 13, i:  2522]  train_loss: 0.608  |  valid_loss: 0.554\n",
      "[epoch: 13, i:  2609]  train_loss: 0.591  |  valid_loss: 0.560\n",
      "[epoch: 13, i:  2696]  train_loss: 0.650  |  valid_loss: 0.786\n",
      "[epoch: 13, i:  2783]  train_loss: 0.685  |  valid_loss: 0.511\n",
      "[epoch: 13, i:  2870]  train_loss: 0.672  |  valid_loss: 0.724\n",
      "[epoch: 13, i:  2957]  train_loss: 0.625  |  valid_loss: 0.726\n",
      "[epoch: 13, i:  3044]  train_loss: 0.694  |  valid_loss: 0.735\n",
      "[epoch: 13, i:  3131]  train_loss: 0.649  |  valid_loss: 0.699\n",
      "[epoch: 13, i:  3218]  train_loss: 0.632  |  valid_loss: 0.733\n",
      "[epoch: 13, i:  3305]  train_loss: 0.606  |  valid_loss: 0.681\n",
      "[epoch: 13, i:  3392]  train_loss: 0.615  |  valid_loss: 0.626\n",
      "[epoch: 13, i:  3479]  train_loss: 0.586  |  valid_loss: 0.503\n",
      "[epoch: 13, i:  3566]  train_loss: 0.689  |  valid_loss: 0.593\n",
      "[epoch: 13, i:  3653]  train_loss: 0.627  |  valid_loss: 0.720\n",
      "[epoch: 13, i:  3740]  train_loss: 0.705  |  valid_loss: 0.439\n",
      "[epoch: 13, i:  3827]  train_loss: 0.639  |  valid_loss: 0.739\n",
      "[epoch: 13, i:  3914]  train_loss: 0.643  |  valid_loss: 0.542\n",
      "[epoch: 13, i:  4001]  train_loss: 0.630  |  valid_loss: 0.627\n",
      "[epoch: 13, i:  4088]  train_loss: 0.723  |  valid_loss: 0.644\n",
      "[epoch: 13, i:  4175]  train_loss: 0.589  |  valid_loss: 0.568\n",
      "[epoch: 13, i:  4262]  train_loss: 0.635  |  valid_loss: 0.543\n",
      "[epoch: 13, i:  4349]  train_loss: 0.674  |  valid_loss: 0.595\n",
      "[epoch: 13, i:  4436]  train_loss: 0.641  |  valid_loss: 0.487\n",
      "[epoch: 13, i:  4523]  train_loss: 0.585  |  valid_loss: 0.785\n",
      "[epoch: 13, i:  4610]  train_loss: 0.667  |  valid_loss: 0.572\n",
      "[epoch: 13, i:  4697]  train_loss: 0.663  |  valid_loss: 0.595\n",
      "[epoch: 13, i:  4784]  train_loss: 0.606  |  valid_loss: 0.650\n",
      "[epoch: 13, i:  4871]  train_loss: 0.617  |  valid_loss: 0.783\n",
      "[epoch: 13, i:  4958]  train_loss: 0.652  |  valid_loss: 0.827\n",
      "[epoch: 13, i:  5045]  train_loss: 0.698  |  valid_loss: 0.523\n",
      "[epoch: 13, i:  5132]  train_loss: 0.601  |  valid_loss: 0.681\n",
      "[epoch: 13, i:  5219]  train_loss: 0.602  |  valid_loss: 0.814\n",
      "[epoch: 13, i:  5306]  train_loss: 0.716  |  valid_loss: 0.734\n",
      "[epoch: 13, i:  5393]  train_loss: 0.655  |  valid_loss: 0.620\n",
      "[epoch: 13, i:  5480]  train_loss: 0.640  |  valid_loss: 0.868\n",
      "[epoch: 13, i:  5567]  train_loss: 0.644  |  valid_loss: 0.477\n",
      "[epoch: 13, i:  5654]  train_loss: 0.685  |  valid_loss: 0.581\n",
      "[epoch: 13, i:  5741]  train_loss: 0.599  |  valid_loss: 0.671\n",
      "[epoch: 13, i:  5828]  train_loss: 0.649  |  valid_loss: 0.625\n",
      "[epoch: 13, i:  5915]  train_loss: 0.718  |  valid_loss: 0.697\n",
      "[epoch: 13, i:  6002]  train_loss: 0.705  |  valid_loss: 0.639\n",
      "[epoch: 13, i:  6089]  train_loss: 0.730  |  valid_loss: 0.834\n",
      "[epoch: 13, i:  6176]  train_loss: 0.638  |  valid_loss: 0.709\n",
      "[epoch: 13, i:  6263]  train_loss: 0.627  |  valid_loss: 0.603\n",
      "[epoch: 13, i:  6350]  train_loss: 0.690  |  valid_loss: 0.642\n",
      "[epoch: 13, i:  6437]  train_loss: 0.574  |  valid_loss: 0.414\n",
      "[epoch: 13, i:  6524]  train_loss: 0.690  |  valid_loss: 0.751\n",
      "[epoch: 13, i:  6611]  train_loss: 0.649  |  valid_loss: 0.488\n",
      "[epoch: 13, i:  6698]  train_loss: 0.617  |  valid_loss: 0.739\n",
      "[epoch: 13, i:  6785]  train_loss: 0.656  |  valid_loss: 0.595\n",
      "[epoch: 13, i:  6872]  train_loss: 0.566  |  valid_loss: 0.717\n",
      "[epoch: 13, i:  6959]  train_loss: 0.639  |  valid_loss: 0.817\n",
      "[epoch: 13, i:  7046]  train_loss: 0.612  |  valid_loss: 0.671\n",
      "[epoch: 13, i:  7133]  train_loss: 0.672  |  valid_loss: 0.612\n",
      "[epoch: 13, i:  7220]  train_loss: 0.643  |  valid_loss: 0.689\n",
      "[epoch: 13, i:  7307]  train_loss: 0.606  |  valid_loss: 0.752\n",
      "[epoch: 13, i:  7394]  train_loss: 0.606  |  valid_loss: 0.594\n",
      "[epoch: 13, i:  7481]  train_loss: 0.602  |  valid_loss: 0.625\n",
      "[epoch: 13, i:  7568]  train_loss: 0.595  |  valid_loss: 0.845\n",
      "[epoch: 13, i:  7655]  train_loss: 0.688  |  valid_loss: 0.696\n",
      "[epoch: 13, i:  7742]  train_loss: 0.615  |  valid_loss: 0.758\n",
      "[epoch: 13, i:  7829]  train_loss: 0.592  |  valid_loss: 0.474\n",
      "[epoch: 13, i:  7916]  train_loss: 0.653  |  valid_loss: 0.726\n",
      "[epoch: 13, i:  8003]  train_loss: 0.734  |  valid_loss: 0.578\n",
      "[epoch: 13, i:  8090]  train_loss: 0.565  |  valid_loss: 0.523\n",
      "[epoch: 13, i:  8177]  train_loss: 0.639  |  valid_loss: 0.570\n",
      "[epoch: 13, i:  8264]  train_loss: 0.681  |  valid_loss: 0.740\n",
      "[epoch: 13, i:  8351]  train_loss: 0.621  |  valid_loss: 0.832\n",
      "[epoch: 13, i:  8438]  train_loss: 0.659  |  valid_loss: 0.611\n",
      "[epoch: 13, i:  8525]  train_loss: 0.701  |  valid_loss: 0.671\n",
      "[epoch: 13, i:  8612]  train_loss: 0.661  |  valid_loss: 0.900\n",
      "[epoch: 13, i:  8699]  train_loss: 0.713  |  valid_loss: 0.550\n",
      "--> [End of epoch 13] train_accuracy: 77.71%  |  valid_accuracy: 77.84%\n",
      "--> [Start of epoch 14]  lr: 0.000500\n",
      "[epoch: 14, i:    86]  train_loss: 0.626  |  valid_loss: 0.590\n",
      "[epoch: 14, i:   173]  train_loss: 0.603  |  valid_loss: 0.569\n",
      "[epoch: 14, i:   260]  train_loss: 0.613  |  valid_loss: 0.739\n",
      "[epoch: 14, i:   347]  train_loss: 0.580  |  valid_loss: 0.673\n",
      "[epoch: 14, i:   434]  train_loss: 0.551  |  valid_loss: 0.667\n",
      "[epoch: 14, i:   521]  train_loss: 0.669  |  valid_loss: 0.467\n",
      "[epoch: 14, i:   608]  train_loss: 0.631  |  valid_loss: 0.755\n",
      "[epoch: 14, i:   695]  train_loss: 0.647  |  valid_loss: 0.666\n",
      "[epoch: 14, i:   782]  train_loss: 0.601  |  valid_loss: 0.762\n",
      "[epoch: 14, i:   869]  train_loss: 0.636  |  valid_loss: 0.707\n",
      "[epoch: 14, i:   956]  train_loss: 0.594  |  valid_loss: 0.575\n",
      "[epoch: 14, i:  1043]  train_loss: 0.581  |  valid_loss: 0.632\n",
      "[epoch: 14, i:  1130]  train_loss: 0.660  |  valid_loss: 0.607\n",
      "[epoch: 14, i:  1217]  train_loss: 0.607  |  valid_loss: 0.709\n",
      "[epoch: 14, i:  1304]  train_loss: 0.540  |  valid_loss: 0.472\n",
      "[epoch: 14, i:  1391]  train_loss: 0.568  |  valid_loss: 0.723\n",
      "[epoch: 14, i:  1478]  train_loss: 0.590  |  valid_loss: 0.602\n",
      "[epoch: 14, i:  1565]  train_loss: 0.706  |  valid_loss: 0.712\n",
      "[epoch: 14, i:  1652]  train_loss: 0.550  |  valid_loss: 0.561\n",
      "[epoch: 14, i:  1739]  train_loss: 0.635  |  valid_loss: 0.817\n",
      "[epoch: 14, i:  1826]  train_loss: 0.625  |  valid_loss: 0.798\n",
      "[epoch: 14, i:  1913]  train_loss: 0.676  |  valid_loss: 0.659\n",
      "[epoch: 14, i:  2000]  train_loss: 0.636  |  valid_loss: 0.625\n",
      "[epoch: 14, i:  2087]  train_loss: 0.606  |  valid_loss: 0.773\n",
      "[epoch: 14, i:  2174]  train_loss: 0.590  |  valid_loss: 0.588\n",
      "[epoch: 14, i:  2261]  train_loss: 0.609  |  valid_loss: 0.972\n",
      "[epoch: 14, i:  2348]  train_loss: 0.591  |  valid_loss: 0.640\n",
      "[epoch: 14, i:  2435]  train_loss: 0.645  |  valid_loss: 0.667\n",
      "[epoch: 14, i:  2522]  train_loss: 0.666  |  valid_loss: 0.587\n",
      "[epoch: 14, i:  2609]  train_loss: 0.632  |  valid_loss: 0.578\n",
      "[epoch: 14, i:  2696]  train_loss: 0.562  |  valid_loss: 0.682\n",
      "[epoch: 14, i:  2783]  train_loss: 0.707  |  valid_loss: 0.583\n",
      "[epoch: 14, i:  2870]  train_loss: 0.645  |  valid_loss: 0.642\n",
      "[epoch: 14, i:  2957]  train_loss: 0.631  |  valid_loss: 0.781\n",
      "[epoch: 14, i:  3044]  train_loss: 0.590  |  valid_loss: 0.752\n",
      "[epoch: 14, i:  3131]  train_loss: 0.639  |  valid_loss: 0.722\n",
      "[epoch: 14, i:  3218]  train_loss: 0.608  |  valid_loss: 0.758\n",
      "[epoch: 14, i:  3305]  train_loss: 0.643  |  valid_loss: 0.603\n",
      "[epoch: 14, i:  3392]  train_loss: 0.580  |  valid_loss: 0.693\n",
      "[epoch: 14, i:  3479]  train_loss: 0.647  |  valid_loss: 0.519\n",
      "[epoch: 14, i:  3566]  train_loss: 0.625  |  valid_loss: 0.596\n",
      "[epoch: 14, i:  3653]  train_loss: 0.551  |  valid_loss: 0.697\n",
      "[epoch: 14, i:  3740]  train_loss: 0.626  |  valid_loss: 0.424\n",
      "[epoch: 14, i:  3827]  train_loss: 0.632  |  valid_loss: 0.820\n",
      "[epoch: 14, i:  3914]  train_loss: 0.579  |  valid_loss: 0.553\n",
      "[epoch: 14, i:  4001]  train_loss: 0.559  |  valid_loss: 0.690\n",
      "[epoch: 14, i:  4088]  train_loss: 0.588  |  valid_loss: 0.674\n",
      "[epoch: 14, i:  4175]  train_loss: 0.616  |  valid_loss: 0.630\n",
      "[epoch: 14, i:  4262]  train_loss: 0.684  |  valid_loss: 0.533\n",
      "[epoch: 14, i:  4349]  train_loss: 0.630  |  valid_loss: 0.576\n",
      "[epoch: 14, i:  4436]  train_loss: 0.615  |  valid_loss: 0.555\n",
      "[epoch: 14, i:  4523]  train_loss: 0.652  |  valid_loss: 0.690\n",
      "[epoch: 14, i:  4610]  train_loss: 0.659  |  valid_loss: 0.533\n",
      "[epoch: 14, i:  4697]  train_loss: 0.623  |  valid_loss: 0.554\n",
      "[epoch: 14, i:  4784]  train_loss: 0.704  |  valid_loss: 0.679\n",
      "[epoch: 14, i:  4871]  train_loss: 0.598  |  valid_loss: 0.745\n",
      "[epoch: 14, i:  4958]  train_loss: 0.666  |  valid_loss: 0.839\n",
      "[epoch: 14, i:  5045]  train_loss: 0.686  |  valid_loss: 0.432\n",
      "[epoch: 14, i:  5132]  train_loss: 0.642  |  valid_loss: 0.611\n",
      "[epoch: 14, i:  5219]  train_loss: 0.584  |  valid_loss: 0.875\n",
      "[epoch: 14, i:  5306]  train_loss: 0.699  |  valid_loss: 0.730\n",
      "[epoch: 14, i:  5393]  train_loss: 0.605  |  valid_loss: 0.593\n",
      "[epoch: 14, i:  5480]  train_loss: 0.633  |  valid_loss: 0.824\n",
      "[epoch: 14, i:  5567]  train_loss: 0.634  |  valid_loss: 0.319\n",
      "[epoch: 14, i:  5654]  train_loss: 0.593  |  valid_loss: 0.590\n",
      "[epoch: 14, i:  5741]  train_loss: 0.705  |  valid_loss: 0.663\n",
      "[epoch: 14, i:  5828]  train_loss: 0.632  |  valid_loss: 0.561\n",
      "[epoch: 14, i:  5915]  train_loss: 0.663  |  valid_loss: 0.744\n",
      "[epoch: 14, i:  6002]  train_loss: 0.587  |  valid_loss: 0.621\n",
      "[epoch: 14, i:  6089]  train_loss: 0.592  |  valid_loss: 0.827\n",
      "[epoch: 14, i:  6176]  train_loss: 0.612  |  valid_loss: 0.707\n",
      "[epoch: 14, i:  6263]  train_loss: 0.640  |  valid_loss: 0.513\n",
      "[epoch: 14, i:  6350]  train_loss: 0.625  |  valid_loss: 0.583\n",
      "[epoch: 14, i:  6437]  train_loss: 0.668  |  valid_loss: 0.472\n",
      "[epoch: 14, i:  6524]  train_loss: 0.633  |  valid_loss: 0.862\n",
      "[epoch: 14, i:  6611]  train_loss: 0.649  |  valid_loss: 0.444\n",
      "[epoch: 14, i:  6698]  train_loss: 0.631  |  valid_loss: 0.633\n",
      "[epoch: 14, i:  6785]  train_loss: 0.573  |  valid_loss: 0.551\n",
      "[epoch: 14, i:  6872]  train_loss: 0.643  |  valid_loss: 0.817\n",
      "[epoch: 14, i:  6959]  train_loss: 0.649  |  valid_loss: 0.863\n",
      "[epoch: 14, i:  7046]  train_loss: 0.660  |  valid_loss: 0.629\n",
      "[epoch: 14, i:  7133]  train_loss: 0.672  |  valid_loss: 0.578\n",
      "[epoch: 14, i:  7220]  train_loss: 0.624  |  valid_loss: 0.749\n",
      "[epoch: 14, i:  7307]  train_loss: 0.672  |  valid_loss: 0.804\n",
      "[epoch: 14, i:  7394]  train_loss: 0.602  |  valid_loss: 0.634\n",
      "[epoch: 14, i:  7481]  train_loss: 0.667  |  valid_loss: 0.651\n",
      "[epoch: 14, i:  7568]  train_loss: 0.644  |  valid_loss: 0.813\n",
      "[epoch: 14, i:  7655]  train_loss: 0.630  |  valid_loss: 0.697\n",
      "[epoch: 14, i:  7742]  train_loss: 0.672  |  valid_loss: 0.620\n",
      "[epoch: 14, i:  7829]  train_loss: 0.678  |  valid_loss: 0.468\n",
      "[epoch: 14, i:  7916]  train_loss: 0.549  |  valid_loss: 0.779\n",
      "[epoch: 14, i:  8003]  train_loss: 0.590  |  valid_loss: 0.610\n",
      "[epoch: 14, i:  8090]  train_loss: 0.658  |  valid_loss: 0.483\n",
      "[epoch: 14, i:  8177]  train_loss: 0.692  |  valid_loss: 0.605\n",
      "[epoch: 14, i:  8264]  train_loss: 0.589  |  valid_loss: 0.734\n",
      "[epoch: 14, i:  8351]  train_loss: 0.677  |  valid_loss: 0.719\n",
      "[epoch: 14, i:  8438]  train_loss: 0.650  |  valid_loss: 0.516\n",
      "[epoch: 14, i:  8525]  train_loss: 0.609  |  valid_loss: 0.702\n",
      "[epoch: 14, i:  8612]  train_loss: 0.620  |  valid_loss: 0.893\n",
      "[epoch: 14, i:  8699]  train_loss: 0.683  |  valid_loss: 0.637\n",
      "--> [End of epoch 14] train_accuracy: 78.05%  |  valid_accuracy: 77.99%\n",
      "--> [Start of epoch 15]  lr: 0.000500\n",
      "[epoch: 15, i:    86]  train_loss: 0.652  |  valid_loss: 0.601\n",
      "[epoch: 15, i:   173]  train_loss: 0.606  |  valid_loss: 0.610\n",
      "[epoch: 15, i:   260]  train_loss: 0.680  |  valid_loss: 0.686\n",
      "[epoch: 15, i:   347]  train_loss: 0.543  |  valid_loss: 0.599\n",
      "[epoch: 15, i:   434]  train_loss: 0.574  |  valid_loss: 0.637\n",
      "[epoch: 15, i:   521]  train_loss: 0.556  |  valid_loss: 0.468\n",
      "[epoch: 15, i:   608]  train_loss: 0.649  |  valid_loss: 0.686\n",
      "[epoch: 15, i:   695]  train_loss: 0.612  |  valid_loss: 0.652\n",
      "[epoch: 15, i:   782]  train_loss: 0.554  |  valid_loss: 0.642\n",
      "[epoch: 15, i:   869]  train_loss: 0.557  |  valid_loss: 0.628\n",
      "[epoch: 15, i:   956]  train_loss: 0.585  |  valid_loss: 0.520\n",
      "[epoch: 15, i:  1043]  train_loss: 0.669  |  valid_loss: 0.632\n",
      "[epoch: 15, i:  1130]  train_loss: 0.648  |  valid_loss: 0.561\n",
      "[epoch: 15, i:  1217]  train_loss: 0.582  |  valid_loss: 0.647\n",
      "[epoch: 15, i:  1304]  train_loss: 0.592  |  valid_loss: 0.508\n",
      "[epoch: 15, i:  1391]  train_loss: 0.645  |  valid_loss: 0.648\n",
      "[epoch: 15, i:  1478]  train_loss: 0.563  |  valid_loss: 0.638\n",
      "[epoch: 15, i:  1565]  train_loss: 0.511  |  valid_loss: 0.809\n",
      "[epoch: 15, i:  1652]  train_loss: 0.581  |  valid_loss: 0.623\n",
      "[epoch: 15, i:  1739]  train_loss: 0.692  |  valid_loss: 0.882\n",
      "[epoch: 15, i:  1826]  train_loss: 0.615  |  valid_loss: 0.806\n",
      "[epoch: 15, i:  1913]  train_loss: 0.573  |  valid_loss: 0.695\n",
      "[epoch: 15, i:  2000]  train_loss: 0.699  |  valid_loss: 0.629\n",
      "[epoch: 15, i:  2087]  train_loss: 0.608  |  valid_loss: 0.763\n",
      "[epoch: 15, i:  2174]  train_loss: 0.674  |  valid_loss: 0.552\n",
      "[epoch: 15, i:  2261]  train_loss: 0.612  |  valid_loss: 1.044\n",
      "[epoch: 15, i:  2348]  train_loss: 0.603  |  valid_loss: 0.564\n",
      "[epoch: 15, i:  2435]  train_loss: 0.639  |  valid_loss: 0.712\n",
      "[epoch: 15, i:  2522]  train_loss: 0.634  |  valid_loss: 0.592\n",
      "[epoch: 15, i:  2609]  train_loss: 0.618  |  valid_loss: 0.588\n",
      "[epoch: 15, i:  2696]  train_loss: 0.634  |  valid_loss: 0.710\n",
      "[epoch: 15, i:  2783]  train_loss: 0.567  |  valid_loss: 0.538\n",
      "[epoch: 15, i:  2870]  train_loss: 0.615  |  valid_loss: 0.743\n",
      "[epoch: 15, i:  2957]  train_loss: 0.639  |  valid_loss: 0.743\n",
      "[epoch: 15, i:  3044]  train_loss: 0.562  |  valid_loss: 0.712\n",
      "[epoch: 15, i:  3131]  train_loss: 0.557  |  valid_loss: 0.700\n",
      "[epoch: 15, i:  3218]  train_loss: 0.562  |  valid_loss: 0.765\n",
      "[epoch: 15, i:  3305]  train_loss: 0.636  |  valid_loss: 0.621\n",
      "[epoch: 15, i:  3392]  train_loss: 0.706  |  valid_loss: 0.708\n",
      "[epoch: 15, i:  3479]  train_loss: 0.607  |  valid_loss: 0.467\n",
      "[epoch: 15, i:  3566]  train_loss: 0.636  |  valid_loss: 0.651\n",
      "[epoch: 15, i:  3653]  train_loss: 0.642  |  valid_loss: 0.699\n",
      "[epoch: 15, i:  3740]  train_loss: 0.613  |  valid_loss: 0.460\n",
      "[epoch: 15, i:  3827]  train_loss: 0.626  |  valid_loss: 0.733\n",
      "[epoch: 15, i:  3914]  train_loss: 0.707  |  valid_loss: 0.472\n",
      "[epoch: 15, i:  4001]  train_loss: 0.598  |  valid_loss: 0.656\n",
      "[epoch: 15, i:  4088]  train_loss: 0.688  |  valid_loss: 0.589\n",
      "[epoch: 15, i:  4175]  train_loss: 0.650  |  valid_loss: 0.586\n",
      "[epoch: 15, i:  4262]  train_loss: 0.652  |  valid_loss: 0.548\n",
      "[epoch: 15, i:  4349]  train_loss: 0.613  |  valid_loss: 0.627\n",
      "[epoch: 15, i:  4436]  train_loss: 0.612  |  valid_loss: 0.578\n",
      "[epoch: 15, i:  4523]  train_loss: 0.630  |  valid_loss: 0.684\n",
      "[epoch: 15, i:  4610]  train_loss: 0.632  |  valid_loss: 0.542\n",
      "[epoch: 15, i:  4697]  train_loss: 0.670  |  valid_loss: 0.574\n",
      "[epoch: 15, i:  4784]  train_loss: 0.671  |  valid_loss: 0.686\n",
      "[epoch: 15, i:  4871]  train_loss: 0.643  |  valid_loss: 0.728\n",
      "[epoch: 15, i:  4958]  train_loss: 0.613  |  valid_loss: 0.816\n",
      "[epoch: 15, i:  5045]  train_loss: 0.658  |  valid_loss: 0.558\n",
      "[epoch: 15, i:  5132]  train_loss: 0.582  |  valid_loss: 0.658\n",
      "[epoch: 15, i:  5219]  train_loss: 0.681  |  valid_loss: 0.803\n",
      "[epoch: 15, i:  5306]  train_loss: 0.626  |  valid_loss: 0.827\n",
      "[epoch: 15, i:  5393]  train_loss: 0.615  |  valid_loss: 0.611\n",
      "[epoch: 15, i:  5480]  train_loss: 0.584  |  valid_loss: 0.752\n",
      "[epoch: 15, i:  5567]  train_loss: 0.580  |  valid_loss: 0.393\n",
      "[epoch: 15, i:  5654]  train_loss: 0.610  |  valid_loss: 0.650\n",
      "[epoch: 15, i:  5741]  train_loss: 0.678  |  valid_loss: 0.648\n",
      "[epoch: 15, i:  5828]  train_loss: 0.630  |  valid_loss: 0.537\n",
      "[epoch: 15, i:  5915]  train_loss: 0.488  |  valid_loss: 0.691\n",
      "[epoch: 15, i:  6002]  train_loss: 0.565  |  valid_loss: 0.632\n",
      "[epoch: 15, i:  6089]  train_loss: 0.593  |  valid_loss: 0.761\n",
      "[epoch: 15, i:  6176]  train_loss: 0.634  |  valid_loss: 0.706\n",
      "[epoch: 15, i:  6263]  train_loss: 0.647  |  valid_loss: 0.527\n",
      "[epoch: 15, i:  6350]  train_loss: 0.611  |  valid_loss: 0.584\n",
      "[epoch: 15, i:  6437]  train_loss: 0.576  |  valid_loss: 0.467\n",
      "[epoch: 15, i:  6524]  train_loss: 0.690  |  valid_loss: 0.825\n",
      "[epoch: 15, i:  6611]  train_loss: 0.616  |  valid_loss: 0.484\n",
      "[epoch: 15, i:  6698]  train_loss: 0.615  |  valid_loss: 0.751\n",
      "[epoch: 15, i:  6785]  train_loss: 0.588  |  valid_loss: 0.494\n",
      "[epoch: 15, i:  6872]  train_loss: 0.597  |  valid_loss: 0.839\n",
      "[epoch: 15, i:  6959]  train_loss: 0.606  |  valid_loss: 0.854\n",
      "[epoch: 15, i:  7046]  train_loss: 0.675  |  valid_loss: 0.675\n",
      "[epoch: 15, i:  7133]  train_loss: 0.676  |  valid_loss: 0.603\n",
      "[epoch: 15, i:  7220]  train_loss: 0.667  |  valid_loss: 0.687\n",
      "[epoch: 15, i:  7307]  train_loss: 0.630  |  valid_loss: 0.756\n",
      "[epoch: 15, i:  7394]  train_loss: 0.592  |  valid_loss: 0.623\n",
      "[epoch: 15, i:  7481]  train_loss: 0.636  |  valid_loss: 0.729\n",
      "[epoch: 15, i:  7568]  train_loss: 0.604  |  valid_loss: 0.812\n",
      "[epoch: 15, i:  7655]  train_loss: 0.618  |  valid_loss: 0.638\n",
      "[epoch: 15, i:  7742]  train_loss: 0.657  |  valid_loss: 0.737\n",
      "[epoch: 15, i:  7829]  train_loss: 0.645  |  valid_loss: 0.502\n",
      "[epoch: 15, i:  7916]  train_loss: 0.643  |  valid_loss: 0.675\n",
      "[epoch: 15, i:  8003]  train_loss: 0.612  |  valid_loss: 0.589\n",
      "[epoch: 15, i:  8090]  train_loss: 0.625  |  valid_loss: 0.478\n",
      "[epoch: 15, i:  8177]  train_loss: 0.670  |  valid_loss: 0.582\n",
      "[epoch: 15, i:  8264]  train_loss: 0.655  |  valid_loss: 0.733\n",
      "[epoch: 15, i:  8351]  train_loss: 0.550  |  valid_loss: 0.765\n",
      "[epoch: 15, i:  8438]  train_loss: 0.662  |  valid_loss: 0.537\n",
      "[epoch: 15, i:  8525]  train_loss: 0.627  |  valid_loss: 0.722\n",
      "[epoch: 15, i:  8612]  train_loss: 0.613  |  valid_loss: 0.960\n",
      "[epoch: 15, i:  8699]  train_loss: 0.617  |  valid_loss: 0.662\n",
      "--> [End of epoch 15] train_accuracy: 78.45%  |  valid_accuracy: 77.93%\n",
      "--> [Start of epoch 16]  lr: 0.000500\n",
      "[epoch: 16, i:    86]  train_loss: 0.608  |  valid_loss: 0.576\n",
      "[epoch: 16, i:   173]  train_loss: 0.613  |  valid_loss: 0.594\n",
      "[epoch: 16, i:   260]  train_loss: 0.535  |  valid_loss: 0.731\n",
      "[epoch: 16, i:   347]  train_loss: 0.592  |  valid_loss: 0.562\n",
      "[epoch: 16, i:   434]  train_loss: 0.615  |  valid_loss: 0.689\n",
      "[epoch: 16, i:   521]  train_loss: 0.547  |  valid_loss: 0.387\n",
      "[epoch: 16, i:   608]  train_loss: 0.645  |  valid_loss: 0.720\n",
      "[epoch: 16, i:   695]  train_loss: 0.626  |  valid_loss: 0.648\n",
      "[epoch: 16, i:   782]  train_loss: 0.622  |  valid_loss: 0.700\n",
      "[epoch: 16, i:   869]  train_loss: 0.583  |  valid_loss: 0.621\n",
      "[epoch: 16, i:   956]  train_loss: 0.609  |  valid_loss: 0.483\n",
      "[epoch: 16, i:  1043]  train_loss: 0.659  |  valid_loss: 0.659\n",
      "[epoch: 16, i:  1130]  train_loss: 0.634  |  valid_loss: 0.598\n",
      "[epoch: 16, i:  1217]  train_loss: 0.644  |  valid_loss: 0.639\n",
      "[epoch: 16, i:  1304]  train_loss: 0.573  |  valid_loss: 0.403\n",
      "[epoch: 16, i:  1391]  train_loss: 0.623  |  valid_loss: 0.672\n",
      "[epoch: 16, i:  1478]  train_loss: 0.676  |  valid_loss: 0.656\n",
      "[epoch: 16, i:  1565]  train_loss: 0.592  |  valid_loss: 0.719\n",
      "[epoch: 16, i:  1652]  train_loss: 0.554  |  valid_loss: 0.607\n",
      "[epoch: 16, i:  1739]  train_loss: 0.590  |  valid_loss: 0.853\n",
      "[epoch: 16, i:  1826]  train_loss: 0.562  |  valid_loss: 0.729\n",
      "[epoch: 16, i:  1913]  train_loss: 0.624  |  valid_loss: 0.574\n",
      "[epoch: 16, i:  2000]  train_loss: 0.607  |  valid_loss: 0.655\n",
      "[epoch: 16, i:  2087]  train_loss: 0.562  |  valid_loss: 0.844\n",
      "[epoch: 16, i:  2174]  train_loss: 0.518  |  valid_loss: 0.548\n",
      "[epoch: 16, i:  2261]  train_loss: 0.678  |  valid_loss: 0.920\n",
      "[epoch: 16, i:  2348]  train_loss: 0.586  |  valid_loss: 0.561\n",
      "[epoch: 16, i:  2435]  train_loss: 0.613  |  valid_loss: 0.706\n",
      "[epoch: 16, i:  2522]  train_loss: 0.556  |  valid_loss: 0.595\n",
      "[epoch: 16, i:  2609]  train_loss: 0.660  |  valid_loss: 0.591\n",
      "[epoch: 16, i:  2696]  train_loss: 0.583  |  valid_loss: 0.690\n",
      "[epoch: 16, i:  2783]  train_loss: 0.677  |  valid_loss: 0.502\n",
      "[epoch: 16, i:  2870]  train_loss: 0.604  |  valid_loss: 0.673\n",
      "[epoch: 16, i:  2957]  train_loss: 0.544  |  valid_loss: 0.792\n",
      "[epoch: 16, i:  3044]  train_loss: 0.581  |  valid_loss: 0.749\n",
      "[epoch: 16, i:  3131]  train_loss: 0.589  |  valid_loss: 0.610\n",
      "[epoch: 16, i:  3218]  train_loss: 0.645  |  valid_loss: 0.721\n",
      "[epoch: 16, i:  3305]  train_loss: 0.671  |  valid_loss: 0.720\n",
      "[epoch: 16, i:  3392]  train_loss: 0.571  |  valid_loss: 0.626\n",
      "[epoch: 16, i:  3479]  train_loss: 0.526  |  valid_loss: 0.483\n",
      "[epoch: 16, i:  3566]  train_loss: 0.593  |  valid_loss: 0.620\n",
      "[epoch: 16, i:  3653]  train_loss: 0.625  |  valid_loss: 0.700\n",
      "[epoch: 16, i:  3740]  train_loss: 0.589  |  valid_loss: 0.444\n",
      "[epoch: 16, i:  3827]  train_loss: 0.653  |  valid_loss: 0.776\n",
      "[epoch: 16, i:  3914]  train_loss: 0.619  |  valid_loss: 0.476\n",
      "[epoch: 16, i:  4001]  train_loss: 0.621  |  valid_loss: 0.640\n",
      "[epoch: 16, i:  4088]  train_loss: 0.609  |  valid_loss: 0.678\n",
      "[epoch: 16, i:  4175]  train_loss: 0.669  |  valid_loss: 0.617\n",
      "[epoch: 16, i:  4262]  train_loss: 0.630  |  valid_loss: 0.528\n",
      "[epoch: 16, i:  4349]  train_loss: 0.604  |  valid_loss: 0.584\n",
      "[epoch: 16, i:  4436]  train_loss: 0.596  |  valid_loss: 0.575\n",
      "[epoch: 16, i:  4523]  train_loss: 0.627  |  valid_loss: 0.790\n",
      "[epoch: 16, i:  4610]  train_loss: 0.620  |  valid_loss: 0.498\n",
      "[epoch: 16, i:  4697]  train_loss: 0.569  |  valid_loss: 0.597\n",
      "[epoch: 16, i:  4784]  train_loss: 0.543  |  valid_loss: 0.720\n",
      "[epoch: 16, i:  4871]  train_loss: 0.644  |  valid_loss: 0.764\n",
      "[epoch: 16, i:  4958]  train_loss: 0.626  |  valid_loss: 0.794\n",
      "[epoch: 16, i:  5045]  train_loss: 0.638  |  valid_loss: 0.526\n",
      "[epoch: 16, i:  5132]  train_loss: 0.582  |  valid_loss: 0.615\n",
      "[epoch: 16, i:  5219]  train_loss: 0.608  |  valid_loss: 0.748\n",
      "[epoch: 16, i:  5306]  train_loss: 0.609  |  valid_loss: 0.841\n",
      "[epoch: 16, i:  5393]  train_loss: 0.612  |  valid_loss: 0.566\n",
      "[epoch: 16, i:  5480]  train_loss: 0.688  |  valid_loss: 0.778\n",
      "[epoch: 16, i:  5567]  train_loss: 0.633  |  valid_loss: 0.418\n",
      "[epoch: 16, i:  5654]  train_loss: 0.610  |  valid_loss: 0.628\n",
      "[epoch: 16, i:  5741]  train_loss: 0.670  |  valid_loss: 0.724\n",
      "[epoch: 16, i:  5828]  train_loss: 0.606  |  valid_loss: 0.604\n",
      "[epoch: 16, i:  5915]  train_loss: 0.600  |  valid_loss: 0.749\n",
      "[epoch: 16, i:  6002]  train_loss: 0.541  |  valid_loss: 0.619\n",
      "[epoch: 16, i:  6089]  train_loss: 0.565  |  valid_loss: 0.802\n",
      "[epoch: 16, i:  6176]  train_loss: 0.611  |  valid_loss: 0.770\n",
      "[epoch: 16, i:  6263]  train_loss: 0.578  |  valid_loss: 0.618\n",
      "[epoch: 16, i:  6350]  train_loss: 0.679  |  valid_loss: 0.618\n",
      "[epoch: 16, i:  6437]  train_loss: 0.654  |  valid_loss: 0.427\n",
      "[epoch: 16, i:  6524]  train_loss: 0.637  |  valid_loss: 0.786\n",
      "[epoch: 16, i:  6611]  train_loss: 0.623  |  valid_loss: 0.449\n",
      "[epoch: 16, i:  6698]  train_loss: 0.621  |  valid_loss: 0.775\n",
      "[epoch: 16, i:  6785]  train_loss: 0.617  |  valid_loss: 0.555\n",
      "[epoch: 16, i:  6872]  train_loss: 0.568  |  valid_loss: 0.797\n",
      "[epoch: 16, i:  6959]  train_loss: 0.730  |  valid_loss: 0.829\n",
      "[epoch: 16, i:  7046]  train_loss: 0.655  |  valid_loss: 0.591\n",
      "[epoch: 16, i:  7133]  train_loss: 0.703  |  valid_loss: 0.539\n",
      "[epoch: 16, i:  7220]  train_loss: 0.600  |  valid_loss: 0.742\n",
      "[epoch: 16, i:  7307]  train_loss: 0.588  |  valid_loss: 0.710\n",
      "[epoch: 16, i:  7394]  train_loss: 0.699  |  valid_loss: 0.587\n",
      "[epoch: 16, i:  7481]  train_loss: 0.581  |  valid_loss: 0.714\n",
      "[epoch: 16, i:  7568]  train_loss: 0.693  |  valid_loss: 0.730\n",
      "[epoch: 16, i:  7655]  train_loss: 0.648  |  valid_loss: 0.609\n",
      "[epoch: 16, i:  7742]  train_loss: 0.624  |  valid_loss: 0.667\n",
      "[epoch: 16, i:  7829]  train_loss: 0.643  |  valid_loss: 0.491\n",
      "[epoch: 16, i:  7916]  train_loss: 0.636  |  valid_loss: 0.751\n",
      "[epoch: 16, i:  8003]  train_loss: 0.625  |  valid_loss: 0.593\n",
      "[epoch: 16, i:  8090]  train_loss: 0.635  |  valid_loss: 0.522\n",
      "[epoch: 16, i:  8177]  train_loss: 0.606  |  valid_loss: 0.604\n",
      "[epoch: 16, i:  8264]  train_loss: 0.611  |  valid_loss: 0.754\n",
      "[epoch: 16, i:  8351]  train_loss: 0.622  |  valid_loss: 0.718\n",
      "[epoch: 16, i:  8438]  train_loss: 0.669  |  valid_loss: 0.516\n",
      "[epoch: 16, i:  8525]  train_loss: 0.703  |  valid_loss: 0.703\n",
      "[epoch: 16, i:  8612]  train_loss: 0.597  |  valid_loss: 0.903\n",
      "[epoch: 16, i:  8699]  train_loss: 0.668  |  valid_loss: 0.601\n",
      "--> [End of epoch 16] train_accuracy: 78.51%  |  valid_accuracy: 78.10%\n",
      "--> [Start of epoch 17]  lr: 0.000500\n",
      "[epoch: 17, i:    86]  train_loss: 0.535  |  valid_loss: 0.589\n",
      "[epoch: 17, i:   173]  train_loss: 0.622  |  valid_loss: 0.636\n",
      "[epoch: 17, i:   260]  train_loss: 0.580  |  valid_loss: 0.701\n",
      "[epoch: 17, i:   347]  train_loss: 0.638  |  valid_loss: 0.547\n",
      "[epoch: 17, i:   434]  train_loss: 0.536  |  valid_loss: 0.670\n",
      "[epoch: 17, i:   521]  train_loss: 0.603  |  valid_loss: 0.423\n",
      "[epoch: 17, i:   608]  train_loss: 0.595  |  valid_loss: 0.675\n",
      "[epoch: 17, i:   695]  train_loss: 0.616  |  valid_loss: 0.633\n",
      "[epoch: 17, i:   782]  train_loss: 0.637  |  valid_loss: 0.686\n",
      "[epoch: 17, i:   869]  train_loss: 0.564  |  valid_loss: 0.680\n",
      "[epoch: 17, i:   956]  train_loss: 0.586  |  valid_loss: 0.514\n",
      "[epoch: 17, i:  1043]  train_loss: 0.569  |  valid_loss: 0.615\n",
      "[epoch: 17, i:  1130]  train_loss: 0.627  |  valid_loss: 0.517\n",
      "[epoch: 17, i:  1217]  train_loss: 0.652  |  valid_loss: 0.603\n",
      "[epoch: 17, i:  1304]  train_loss: 0.703  |  valid_loss: 0.460\n",
      "[epoch: 17, i:  1391]  train_loss: 0.641  |  valid_loss: 0.742\n",
      "[epoch: 17, i:  1478]  train_loss: 0.639  |  valid_loss: 0.574\n",
      "[epoch: 17, i:  1565]  train_loss: 0.557  |  valid_loss: 0.694\n",
      "[epoch: 17, i:  1652]  train_loss: 0.601  |  valid_loss: 0.621\n",
      "[epoch: 17, i:  1739]  train_loss: 0.611  |  valid_loss: 0.862\n",
      "[epoch: 17, i:  1826]  train_loss: 0.581  |  valid_loss: 0.794\n",
      "[epoch: 17, i:  1913]  train_loss: 0.575  |  valid_loss: 0.696\n",
      "[epoch: 17, i:  2000]  train_loss: 0.601  |  valid_loss: 0.729\n",
      "[epoch: 17, i:  2087]  train_loss: 0.593  |  valid_loss: 0.818\n",
      "[epoch: 17, i:  2174]  train_loss: 0.617  |  valid_loss: 0.516\n",
      "[epoch: 17, i:  2261]  train_loss: 0.571  |  valid_loss: 0.895\n",
      "[epoch: 17, i:  2348]  train_loss: 0.584  |  valid_loss: 0.591\n",
      "[epoch: 17, i:  2435]  train_loss: 0.596  |  valid_loss: 0.670\n",
      "[epoch: 17, i:  2522]  train_loss: 0.548  |  valid_loss: 0.611\n",
      "[epoch: 17, i:  2609]  train_loss: 0.693  |  valid_loss: 0.603\n",
      "[epoch: 17, i:  2696]  train_loss: 0.649  |  valid_loss: 0.717\n",
      "[epoch: 17, i:  2783]  train_loss: 0.642  |  valid_loss: 0.495\n",
      "[epoch: 17, i:  2870]  train_loss: 0.620  |  valid_loss: 0.693\n",
      "[epoch: 17, i:  2957]  train_loss: 0.612  |  valid_loss: 0.699\n",
      "[epoch: 17, i:  3044]  train_loss: 0.570  |  valid_loss: 0.726\n",
      "[epoch: 17, i:  3131]  train_loss: 0.603  |  valid_loss: 0.637\n",
      "[epoch: 17, i:  3218]  train_loss: 0.598  |  valid_loss: 0.688\n",
      "[epoch: 17, i:  3305]  train_loss: 0.584  |  valid_loss: 0.584\n",
      "[epoch: 17, i:  3392]  train_loss: 0.616  |  valid_loss: 0.645\n",
      "[epoch: 17, i:  3479]  train_loss: 0.628  |  valid_loss: 0.507\n",
      "[epoch: 17, i:  3566]  train_loss: 0.636  |  valid_loss: 0.596\n",
      "[epoch: 17, i:  3653]  train_loss: 0.562  |  valid_loss: 0.754\n",
      "[epoch: 17, i:  3740]  train_loss: 0.517  |  valid_loss: 0.396\n",
      "[epoch: 17, i:  3827]  train_loss: 0.561  |  valid_loss: 0.799\n",
      "[epoch: 17, i:  3914]  train_loss: 0.528  |  valid_loss: 0.536\n",
      "[epoch: 17, i:  4001]  train_loss: 0.627  |  valid_loss: 0.600\n",
      "[epoch: 17, i:  4088]  train_loss: 0.587  |  valid_loss: 0.597\n",
      "[epoch: 17, i:  4175]  train_loss: 0.580  |  valid_loss: 0.575\n",
      "[epoch: 17, i:  4262]  train_loss: 0.665  |  valid_loss: 0.521\n",
      "[epoch: 17, i:  4349]  train_loss: 0.603  |  valid_loss: 0.641\n",
      "[epoch: 17, i:  4436]  train_loss: 0.575  |  valid_loss: 0.520\n",
      "[epoch: 17, i:  4523]  train_loss: 0.596  |  valid_loss: 0.760\n",
      "[epoch: 17, i:  4610]  train_loss: 0.645  |  valid_loss: 0.537\n",
      "[epoch: 17, i:  4697]  train_loss: 0.587  |  valid_loss: 0.605\n",
      "[epoch: 17, i:  4784]  train_loss: 0.565  |  valid_loss: 0.671\n",
      "[epoch: 17, i:  4871]  train_loss: 0.598  |  valid_loss: 0.723\n",
      "[epoch: 17, i:  4958]  train_loss: 0.673  |  valid_loss: 0.918\n",
      "[epoch: 17, i:  5045]  train_loss: 0.590  |  valid_loss: 0.469\n",
      "[epoch: 17, i:  5132]  train_loss: 0.607  |  valid_loss: 0.719\n",
      "[epoch: 17, i:  5219]  train_loss: 0.586  |  valid_loss: 0.845\n",
      "[epoch: 17, i:  5306]  train_loss: 0.669  |  valid_loss: 0.741\n",
      "[epoch: 17, i:  5393]  train_loss: 0.649  |  valid_loss: 0.575\n",
      "[epoch: 17, i:  5480]  train_loss: 0.560  |  valid_loss: 0.803\n",
      "[epoch: 17, i:  5567]  train_loss: 0.668  |  valid_loss: 0.346\n",
      "[epoch: 17, i:  5654]  train_loss: 0.577  |  valid_loss: 0.559\n",
      "[epoch: 17, i:  5741]  train_loss: 0.600  |  valid_loss: 0.632\n",
      "[epoch: 17, i:  5828]  train_loss: 0.582  |  valid_loss: 0.575\n",
      "[epoch: 17, i:  5915]  train_loss: 0.654  |  valid_loss: 0.695\n",
      "[epoch: 17, i:  6002]  train_loss: 0.603  |  valid_loss: 0.599\n",
      "[epoch: 17, i:  6089]  train_loss: 0.593  |  valid_loss: 0.809\n",
      "[epoch: 17, i:  6176]  train_loss: 0.677  |  valid_loss: 0.672\n",
      "[epoch: 17, i:  6263]  train_loss: 0.631  |  valid_loss: 0.656\n",
      "[epoch: 17, i:  6350]  train_loss: 0.688  |  valid_loss: 0.594\n",
      "[epoch: 17, i:  6437]  train_loss: 0.646  |  valid_loss: 0.415\n",
      "[epoch: 17, i:  6524]  train_loss: 0.658  |  valid_loss: 0.807\n",
      "[epoch: 17, i:  6611]  train_loss: 0.638  |  valid_loss: 0.426\n",
      "[epoch: 17, i:  6698]  train_loss: 0.567  |  valid_loss: 0.662\n",
      "[epoch: 17, i:  6785]  train_loss: 0.691  |  valid_loss: 0.458\n",
      "[epoch: 17, i:  6872]  train_loss: 0.624  |  valid_loss: 0.789\n",
      "[epoch: 17, i:  6959]  train_loss: 0.513  |  valid_loss: 0.664\n",
      "[epoch: 17, i:  7046]  train_loss: 0.569  |  valid_loss: 0.672\n",
      "[epoch: 17, i:  7133]  train_loss: 0.613  |  valid_loss: 0.514\n",
      "[epoch: 17, i:  7220]  train_loss: 0.603  |  valid_loss: 0.667\n",
      "[epoch: 17, i:  7307]  train_loss: 0.613  |  valid_loss: 0.718\n",
      "[epoch: 17, i:  7394]  train_loss: 0.636  |  valid_loss: 0.562\n",
      "[epoch: 17, i:  7481]  train_loss: 0.585  |  valid_loss: 0.654\n",
      "[epoch: 17, i:  7568]  train_loss: 0.595  |  valid_loss: 0.740\n",
      "[epoch: 17, i:  7655]  train_loss: 0.673  |  valid_loss: 0.626\n",
      "[epoch: 17, i:  7742]  train_loss: 0.627  |  valid_loss: 0.669\n",
      "[epoch: 17, i:  7829]  train_loss: 0.554  |  valid_loss: 0.455\n",
      "[epoch: 17, i:  7916]  train_loss: 0.647  |  valid_loss: 0.708\n",
      "[epoch: 17, i:  8003]  train_loss: 0.683  |  valid_loss: 0.645\n",
      "[epoch: 17, i:  8090]  train_loss: 0.645  |  valid_loss: 0.481\n",
      "[epoch: 17, i:  8177]  train_loss: 0.622  |  valid_loss: 0.598\n",
      "[epoch: 17, i:  8264]  train_loss: 0.541  |  valid_loss: 0.701\n",
      "[epoch: 17, i:  8351]  train_loss: 0.645  |  valid_loss: 0.730\n",
      "[epoch: 17, i:  8438]  train_loss: 0.645  |  valid_loss: 0.508\n",
      "[epoch: 17, i:  8525]  train_loss: 0.647  |  valid_loss: 0.759\n",
      "[epoch: 17, i:  8612]  train_loss: 0.625  |  valid_loss: 0.776\n",
      "[epoch: 17, i:  8699]  train_loss: 0.653  |  valid_loss: 0.610\n",
      "--> [End of epoch 17] train_accuracy: 78.66%  |  valid_accuracy: 78.37%\n",
      "--> [Start of epoch 18]  lr: 0.000500\n",
      "[epoch: 18, i:    86]  train_loss: 0.591  |  valid_loss: 0.610\n",
      "[epoch: 18, i:   173]  train_loss: 0.529  |  valid_loss: 0.599\n",
      "[epoch: 18, i:   260]  train_loss: 0.625  |  valid_loss: 0.596\n",
      "[epoch: 18, i:   347]  train_loss: 0.524  |  valid_loss: 0.647\n",
      "[epoch: 18, i:   434]  train_loss: 0.513  |  valid_loss: 0.653\n",
      "[epoch: 18, i:   521]  train_loss: 0.628  |  valid_loss: 0.470\n",
      "[epoch: 18, i:   608]  train_loss: 0.614  |  valid_loss: 0.745\n",
      "[epoch: 18, i:   695]  train_loss: 0.556  |  valid_loss: 0.682\n",
      "[epoch: 18, i:   782]  train_loss: 0.541  |  valid_loss: 0.701\n",
      "[epoch: 18, i:   869]  train_loss: 0.613  |  valid_loss: 0.703\n",
      "[epoch: 18, i:   956]  train_loss: 0.613  |  valid_loss: 0.553\n",
      "[epoch: 18, i:  1043]  train_loss: 0.573  |  valid_loss: 0.671\n",
      "[epoch: 18, i:  1130]  train_loss: 0.598  |  valid_loss: 0.558\n",
      "[epoch: 18, i:  1217]  train_loss: 0.538  |  valid_loss: 0.740\n",
      "[epoch: 18, i:  1304]  train_loss: 0.564  |  valid_loss: 0.479\n",
      "[epoch: 18, i:  1391]  train_loss: 0.595  |  valid_loss: 0.710\n",
      "[epoch: 18, i:  1478]  train_loss: 0.608  |  valid_loss: 0.610\n",
      "[epoch: 18, i:  1565]  train_loss: 0.629  |  valid_loss: 0.675\n",
      "[epoch: 18, i:  1652]  train_loss: 0.618  |  valid_loss: 0.588\n",
      "[epoch: 18, i:  1739]  train_loss: 0.674  |  valid_loss: 0.865\n",
      "[epoch: 18, i:  1826]  train_loss: 0.555  |  valid_loss: 0.752\n",
      "[epoch: 18, i:  1913]  train_loss: 0.600  |  valid_loss: 0.737\n",
      "[epoch: 18, i:  2000]  train_loss: 0.616  |  valid_loss: 0.721\n",
      "[epoch: 18, i:  2087]  train_loss: 0.659  |  valid_loss: 0.800\n",
      "[epoch: 18, i:  2174]  train_loss: 0.599  |  valid_loss: 0.567\n",
      "[epoch: 18, i:  2261]  train_loss: 0.612  |  valid_loss: 0.907\n",
      "[epoch: 18, i:  2348]  train_loss: 0.585  |  valid_loss: 0.583\n",
      "[epoch: 18, i:  2435]  train_loss: 0.631  |  valid_loss: 0.754\n",
      "[epoch: 18, i:  2522]  train_loss: 0.570  |  valid_loss: 0.554\n",
      "[epoch: 18, i:  2609]  train_loss: 0.715  |  valid_loss: 0.631\n",
      "[epoch: 18, i:  2696]  train_loss: 0.617  |  valid_loss: 0.733\n",
      "[epoch: 18, i:  2783]  train_loss: 0.568  |  valid_loss: 0.498\n",
      "[epoch: 18, i:  2870]  train_loss: 0.588  |  valid_loss: 0.638\n",
      "[epoch: 18, i:  2957]  train_loss: 0.618  |  valid_loss: 0.789\n",
      "[epoch: 18, i:  3044]  train_loss: 0.628  |  valid_loss: 0.735\n",
      "[epoch: 18, i:  3131]  train_loss: 0.651  |  valid_loss: 0.649\n",
      "[epoch: 18, i:  3218]  train_loss: 0.612  |  valid_loss: 0.760\n",
      "[epoch: 18, i:  3305]  train_loss: 0.599  |  valid_loss: 0.647\n",
      "[epoch: 18, i:  3392]  train_loss: 0.590  |  valid_loss: 0.636\n",
      "[epoch: 18, i:  3479]  train_loss: 0.585  |  valid_loss: 0.450\n",
      "[epoch: 18, i:  3566]  train_loss: 0.628  |  valid_loss: 0.663\n",
      "[epoch: 18, i:  3653]  train_loss: 0.589  |  valid_loss: 0.659\n",
      "[epoch: 18, i:  3740]  train_loss: 0.621  |  valid_loss: 0.456\n",
      "[epoch: 18, i:  3827]  train_loss: 0.642  |  valid_loss: 0.804\n",
      "[epoch: 18, i:  3914]  train_loss: 0.578  |  valid_loss: 0.504\n",
      "[epoch: 18, i:  4001]  train_loss: 0.631  |  valid_loss: 0.617\n",
      "[epoch: 18, i:  4088]  train_loss: 0.685  |  valid_loss: 0.584\n",
      "[epoch: 18, i:  4175]  train_loss: 0.649  |  valid_loss: 0.548\n",
      "[epoch: 18, i:  4262]  train_loss: 0.625  |  valid_loss: 0.520\n",
      "[epoch: 18, i:  4349]  train_loss: 0.568  |  valid_loss: 0.661\n",
      "[epoch: 18, i:  4436]  train_loss: 0.597  |  valid_loss: 0.573\n",
      "[epoch: 18, i:  4523]  train_loss: 0.593  |  valid_loss: 0.732\n",
      "[epoch: 18, i:  4610]  train_loss: 0.606  |  valid_loss: 0.597\n",
      "[epoch: 18, i:  4697]  train_loss: 0.605  |  valid_loss: 0.652\n",
      "[epoch: 18, i:  4784]  train_loss: 0.664  |  valid_loss: 0.614\n",
      "[epoch: 18, i:  4871]  train_loss: 0.612  |  valid_loss: 0.807\n",
      "[epoch: 18, i:  4958]  train_loss: 0.670  |  valid_loss: 0.817\n",
      "[epoch: 18, i:  5045]  train_loss: 0.612  |  valid_loss: 0.464\n",
      "[epoch: 18, i:  5132]  train_loss: 0.577  |  valid_loss: 0.609\n",
      "[epoch: 18, i:  5219]  train_loss: 0.613  |  valid_loss: 0.770\n",
      "[epoch: 18, i:  5306]  train_loss: 0.626  |  valid_loss: 0.696\n",
      "[epoch: 18, i:  5393]  train_loss: 0.559  |  valid_loss: 0.650\n",
      "[epoch: 18, i:  5480]  train_loss: 0.591  |  valid_loss: 0.790\n",
      "[epoch: 18, i:  5567]  train_loss: 0.592  |  valid_loss: 0.374\n",
      "[epoch: 18, i:  5654]  train_loss: 0.548  |  valid_loss: 0.647\n",
      "[epoch: 18, i:  5741]  train_loss: 0.576  |  valid_loss: 0.694\n",
      "[epoch: 18, i:  5828]  train_loss: 0.586  |  valid_loss: 0.524\n",
      "[epoch: 18, i:  5915]  train_loss: 0.648  |  valid_loss: 0.738\n",
      "[epoch: 18, i:  6002]  train_loss: 0.596  |  valid_loss: 0.636\n",
      "[epoch: 18, i:  6089]  train_loss: 0.670  |  valid_loss: 0.749\n",
      "[epoch: 18, i:  6176]  train_loss: 0.597  |  valid_loss: 0.735\n",
      "[epoch: 18, i:  6263]  train_loss: 0.542  |  valid_loss: 0.527\n",
      "[epoch: 18, i:  6350]  train_loss: 0.620  |  valid_loss: 0.557\n",
      "[epoch: 18, i:  6437]  train_loss: 0.607  |  valid_loss: 0.489\n",
      "[epoch: 18, i:  6524]  train_loss: 0.624  |  valid_loss: 0.762\n",
      "[epoch: 18, i:  6611]  train_loss: 0.650  |  valid_loss: 0.454\n",
      "[epoch: 18, i:  6698]  train_loss: 0.589  |  valid_loss: 0.679\n",
      "[epoch: 18, i:  6785]  train_loss: 0.589  |  valid_loss: 0.504\n",
      "[epoch: 18, i:  6872]  train_loss: 0.583  |  valid_loss: 0.735\n",
      "[epoch: 18, i:  6959]  train_loss: 0.566  |  valid_loss: 0.706\n",
      "[epoch: 18, i:  7046]  train_loss: 0.561  |  valid_loss: 0.671\n",
      "[epoch: 18, i:  7133]  train_loss: 0.586  |  valid_loss: 0.515\n",
      "[epoch: 18, i:  7220]  train_loss: 0.594  |  valid_loss: 0.717\n",
      "[epoch: 18, i:  7307]  train_loss: 0.557  |  valid_loss: 0.735\n",
      "[epoch: 18, i:  7394]  train_loss: 0.573  |  valid_loss: 0.607\n",
      "[epoch: 18, i:  7481]  train_loss: 0.592  |  valid_loss: 0.656\n",
      "[epoch: 18, i:  7568]  train_loss: 0.621  |  valid_loss: 0.773\n",
      "[epoch: 18, i:  7655]  train_loss: 0.553  |  valid_loss: 0.699\n",
      "[epoch: 18, i:  7742]  train_loss: 0.601  |  valid_loss: 0.727\n",
      "[epoch: 18, i:  7829]  train_loss: 0.564  |  valid_loss: 0.429\n",
      "[epoch: 18, i:  7916]  train_loss: 0.553  |  valid_loss: 0.715\n",
      "[epoch: 18, i:  8003]  train_loss: 0.611  |  valid_loss: 0.614\n",
      "[epoch: 18, i:  8090]  train_loss: 0.635  |  valid_loss: 0.473\n",
      "[epoch: 18, i:  8177]  train_loss: 0.658  |  valid_loss: 0.615\n",
      "[epoch: 18, i:  8264]  train_loss: 0.615  |  valid_loss: 0.673\n",
      "[epoch: 18, i:  8351]  train_loss: 0.622  |  valid_loss: 0.737\n",
      "[epoch: 18, i:  8438]  train_loss: 0.534  |  valid_loss: 0.449\n",
      "[epoch: 18, i:  8525]  train_loss: 0.651  |  valid_loss: 0.700\n",
      "[epoch: 18, i:  8612]  train_loss: 0.584  |  valid_loss: 0.805\n",
      "[epoch: 18, i:  8699]  train_loss: 0.606  |  valid_loss: 0.628\n",
      "--> [End of epoch 18] train_accuracy: 79.14%  |  valid_accuracy: 78.32%\n",
      "--> [Start of epoch 19]  lr: 0.000500\n",
      "[epoch: 19, i:    86]  train_loss: 0.568  |  valid_loss: 0.620\n",
      "[epoch: 19, i:   173]  train_loss: 0.594  |  valid_loss: 0.607\n",
      "[epoch: 19, i:   260]  train_loss: 0.627  |  valid_loss: 0.693\n",
      "[epoch: 19, i:   347]  train_loss: 0.572  |  valid_loss: 0.520\n",
      "[epoch: 19, i:   434]  train_loss: 0.624  |  valid_loss: 0.649\n",
      "[epoch: 19, i:   521]  train_loss: 0.545  |  valid_loss: 0.441\n",
      "[epoch: 19, i:   608]  train_loss: 0.605  |  valid_loss: 0.743\n",
      "[epoch: 19, i:   695]  train_loss: 0.575  |  valid_loss: 0.661\n",
      "[epoch: 19, i:   782]  train_loss: 0.601  |  valid_loss: 0.697\n",
      "[epoch: 19, i:   869]  train_loss: 0.542  |  valid_loss: 0.678\n",
      "[epoch: 19, i:   956]  train_loss: 0.581  |  valid_loss: 0.638\n",
      "[epoch: 19, i:  1043]  train_loss: 0.575  |  valid_loss: 0.604\n",
      "[epoch: 19, i:  1130]  train_loss: 0.593  |  valid_loss: 0.572\n",
      "[epoch: 19, i:  1217]  train_loss: 0.588  |  valid_loss: 0.662\n",
      "[epoch: 19, i:  1304]  train_loss: 0.605  |  valid_loss: 0.498\n",
      "[epoch: 19, i:  1391]  train_loss: 0.601  |  valid_loss: 0.659\n",
      "[epoch: 19, i:  1478]  train_loss: 0.570  |  valid_loss: 0.595\n",
      "[epoch: 19, i:  1565]  train_loss: 0.590  |  valid_loss: 0.774\n",
      "[epoch: 19, i:  1652]  train_loss: 0.594  |  valid_loss: 0.627\n",
      "[epoch: 19, i:  1739]  train_loss: 0.558  |  valid_loss: 0.802\n",
      "[epoch: 19, i:  1826]  train_loss: 0.613  |  valid_loss: 0.756\n",
      "[epoch: 19, i:  1913]  train_loss: 0.506  |  valid_loss: 0.661\n",
      "[epoch: 19, i:  2000]  train_loss: 0.602  |  valid_loss: 0.633\n",
      "[epoch: 19, i:  2087]  train_loss: 0.582  |  valid_loss: 0.816\n",
      "[epoch: 19, i:  2174]  train_loss: 0.626  |  valid_loss: 0.607\n",
      "[epoch: 19, i:  2261]  train_loss: 0.484  |  valid_loss: 0.982\n",
      "[epoch: 19, i:  2348]  train_loss: 0.588  |  valid_loss: 0.611\n",
      "[epoch: 19, i:  2435]  train_loss: 0.586  |  valid_loss: 0.641\n",
      "[epoch: 19, i:  2522]  train_loss: 0.667  |  valid_loss: 0.587\n",
      "[epoch: 19, i:  2609]  train_loss: 0.646  |  valid_loss: 0.625\n",
      "[epoch: 19, i:  2696]  train_loss: 0.650  |  valid_loss: 0.731\n",
      "[epoch: 19, i:  2783]  train_loss: 0.595  |  valid_loss: 0.509\n",
      "[epoch: 19, i:  2870]  train_loss: 0.536  |  valid_loss: 0.754\n",
      "[epoch: 19, i:  2957]  train_loss: 0.592  |  valid_loss: 0.779\n",
      "[epoch: 19, i:  3044]  train_loss: 0.604  |  valid_loss: 0.676\n",
      "[epoch: 19, i:  3131]  train_loss: 0.623  |  valid_loss: 0.652\n",
      "[epoch: 19, i:  3218]  train_loss: 0.609  |  valid_loss: 0.757\n",
      "[epoch: 19, i:  3305]  train_loss: 0.565  |  valid_loss: 0.706\n",
      "[epoch: 19, i:  3392]  train_loss: 0.602  |  valid_loss: 0.610\n",
      "[epoch: 19, i:  3479]  train_loss: 0.625  |  valid_loss: 0.588\n",
      "[epoch: 19, i:  3566]  train_loss: 0.592  |  valid_loss: 0.590\n",
      "[epoch: 19, i:  3653]  train_loss: 0.585  |  valid_loss: 0.701\n",
      "[epoch: 19, i:  3740]  train_loss: 0.622  |  valid_loss: 0.376\n",
      "[epoch: 19, i:  3827]  train_loss: 0.562  |  valid_loss: 0.866\n",
      "[epoch: 19, i:  3914]  train_loss: 0.584  |  valid_loss: 0.512\n",
      "[epoch: 19, i:  4001]  train_loss: 0.627  |  valid_loss: 0.551\n",
      "[epoch: 19, i:  4088]  train_loss: 0.597  |  valid_loss: 0.620\n",
      "[epoch: 19, i:  4175]  train_loss: 0.599  |  valid_loss: 0.641\n",
      "[epoch: 19, i:  4262]  train_loss: 0.559  |  valid_loss: 0.483\n",
      "[epoch: 19, i:  4349]  train_loss: 0.608  |  valid_loss: 0.610\n",
      "[epoch: 19, i:  4436]  train_loss: 0.565  |  valid_loss: 0.579\n",
      "[epoch: 19, i:  4523]  train_loss: 0.610  |  valid_loss: 0.727\n",
      "[epoch: 19, i:  4610]  train_loss: 0.562  |  valid_loss: 0.550\n",
      "[epoch: 19, i:  4697]  train_loss: 0.656  |  valid_loss: 0.653\n",
      "[epoch: 19, i:  4784]  train_loss: 0.550  |  valid_loss: 0.681\n",
      "[epoch: 19, i:  4871]  train_loss: 0.637  |  valid_loss: 0.729\n",
      "[epoch: 19, i:  4958]  train_loss: 0.605  |  valid_loss: 0.765\n",
      "[epoch: 19, i:  5045]  train_loss: 0.597  |  valid_loss: 0.438\n",
      "[epoch: 19, i:  5132]  train_loss: 0.529  |  valid_loss: 0.742\n",
      "[epoch: 19, i:  5219]  train_loss: 0.711  |  valid_loss: 0.804\n",
      "[epoch: 19, i:  5306]  train_loss: 0.614  |  valid_loss: 0.680\n",
      "[epoch: 19, i:  5393]  train_loss: 0.575  |  valid_loss: 0.525\n",
      "[epoch: 19, i:  5480]  train_loss: 0.583  |  valid_loss: 0.755\n",
      "[epoch: 19, i:  5567]  train_loss: 0.591  |  valid_loss: 0.390\n",
      "[epoch: 19, i:  5654]  train_loss: 0.622  |  valid_loss: 0.604\n",
      "[epoch: 19, i:  5741]  train_loss: 0.569  |  valid_loss: 0.657\n",
      "[epoch: 19, i:  5828]  train_loss: 0.647  |  valid_loss: 0.546\n",
      "[epoch: 19, i:  5915]  train_loss: 0.591  |  valid_loss: 0.713\n",
      "[epoch: 19, i:  6002]  train_loss: 0.642  |  valid_loss: 0.571\n",
      "[epoch: 19, i:  6089]  train_loss: 0.560  |  valid_loss: 0.862\n",
      "[epoch: 19, i:  6176]  train_loss: 0.676  |  valid_loss: 0.697\n",
      "[epoch: 19, i:  6263]  train_loss: 0.578  |  valid_loss: 0.588\n",
      "[epoch: 19, i:  6350]  train_loss: 0.543  |  valid_loss: 0.564\n",
      "[epoch: 19, i:  6437]  train_loss: 0.602  |  valid_loss: 0.465\n",
      "[epoch: 19, i:  6524]  train_loss: 0.610  |  valid_loss: 0.815\n",
      "[epoch: 19, i:  6611]  train_loss: 0.644  |  valid_loss: 0.465\n",
      "[epoch: 19, i:  6698]  train_loss: 0.642  |  valid_loss: 0.711\n",
      "[epoch: 19, i:  6785]  train_loss: 0.596  |  valid_loss: 0.497\n",
      "[epoch: 19, i:  6872]  train_loss: 0.592  |  valid_loss: 0.690\n",
      "[epoch: 19, i:  6959]  train_loss: 0.604  |  valid_loss: 0.746\n",
      "[epoch: 19, i:  7046]  train_loss: 0.632  |  valid_loss: 0.632\n",
      "[epoch: 19, i:  7133]  train_loss: 0.635  |  valid_loss: 0.494\n",
      "[epoch: 19, i:  7220]  train_loss: 0.559  |  valid_loss: 0.686\n",
      "[epoch: 19, i:  7307]  train_loss: 0.610  |  valid_loss: 0.762\n",
      "[epoch: 19, i:  7394]  train_loss: 0.516  |  valid_loss: 0.652\n",
      "[epoch: 19, i:  7481]  train_loss: 0.580  |  valid_loss: 0.592\n",
      "[epoch: 19, i:  7568]  train_loss: 0.554  |  valid_loss: 0.810\n",
      "[epoch: 19, i:  7655]  train_loss: 0.595  |  valid_loss: 0.660\n",
      "[epoch: 19, i:  7742]  train_loss: 0.608  |  valid_loss: 0.707\n",
      "[epoch: 19, i:  7829]  train_loss: 0.579  |  valid_loss: 0.531\n",
      "[epoch: 19, i:  7916]  train_loss: 0.594  |  valid_loss: 0.668\n",
      "[epoch: 19, i:  8003]  train_loss: 0.619  |  valid_loss: 0.508\n",
      "[epoch: 19, i:  8090]  train_loss: 0.600  |  valid_loss: 0.493\n",
      "[epoch: 19, i:  8177]  train_loss: 0.558  |  valid_loss: 0.604\n",
      "[epoch: 19, i:  8264]  train_loss: 0.602  |  valid_loss: 0.707\n",
      "[epoch: 19, i:  8351]  train_loss: 0.661  |  valid_loss: 0.696\n",
      "[epoch: 19, i:  8438]  train_loss: 0.573  |  valid_loss: 0.481\n",
      "[epoch: 19, i:  8525]  train_loss: 0.633  |  valid_loss: 0.704\n",
      "[epoch: 19, i:  8612]  train_loss: 0.608  |  valid_loss: 0.970\n",
      "[epoch: 19, i:  8699]  train_loss: 0.524  |  valid_loss: 0.665\n",
      "--> [End of epoch 19] train_accuracy: 79.24%  |  valid_accuracy: 77.97%\n",
      "--> [Start of epoch 20]  lr: 0.000500\n",
      "[epoch: 20, i:    86]  train_loss: 0.527  |  valid_loss: 0.534\n",
      "[epoch: 20, i:   173]  train_loss: 0.602  |  valid_loss: 0.599\n",
      "[epoch: 20, i:   260]  train_loss: 0.587  |  valid_loss: 0.709\n",
      "[epoch: 20, i:   347]  train_loss: 0.608  |  valid_loss: 0.535\n",
      "[epoch: 20, i:   434]  train_loss: 0.598  |  valid_loss: 0.681\n",
      "[epoch: 20, i:   521]  train_loss: 0.607  |  valid_loss: 0.448\n",
      "[epoch: 20, i:   608]  train_loss: 0.584  |  valid_loss: 0.597\n",
      "[epoch: 20, i:   695]  train_loss: 0.467  |  valid_loss: 0.629\n",
      "[epoch: 20, i:   782]  train_loss: 0.600  |  valid_loss: 0.682\n",
      "[epoch: 20, i:   869]  train_loss: 0.568  |  valid_loss: 0.699\n",
      "[epoch: 20, i:   956]  train_loss: 0.576  |  valid_loss: 0.583\n",
      "[epoch: 20, i:  1043]  train_loss: 0.602  |  valid_loss: 0.564\n",
      "[epoch: 20, i:  1130]  train_loss: 0.535  |  valid_loss: 0.615\n",
      "[epoch: 20, i:  1217]  train_loss: 0.501  |  valid_loss: 0.637\n",
      "[epoch: 20, i:  1304]  train_loss: 0.612  |  valid_loss: 0.423\n",
      "[epoch: 20, i:  1391]  train_loss: 0.651  |  valid_loss: 0.716\n",
      "[epoch: 20, i:  1478]  train_loss: 0.640  |  valid_loss: 0.655\n",
      "[epoch: 20, i:  1565]  train_loss: 0.657  |  valid_loss: 0.765\n",
      "[epoch: 20, i:  1652]  train_loss: 0.632  |  valid_loss: 0.675\n",
      "[epoch: 20, i:  1739]  train_loss: 0.564  |  valid_loss: 0.819\n",
      "[epoch: 20, i:  1826]  train_loss: 0.600  |  valid_loss: 0.749\n",
      "[epoch: 20, i:  1913]  train_loss: 0.538  |  valid_loss: 0.642\n",
      "[epoch: 20, i:  2000]  train_loss: 0.584  |  valid_loss: 0.663\n",
      "[epoch: 20, i:  2087]  train_loss: 0.614  |  valid_loss: 0.851\n",
      "[epoch: 20, i:  2174]  train_loss: 0.611  |  valid_loss: 0.548\n",
      "[epoch: 20, i:  2261]  train_loss: 0.633  |  valid_loss: 0.921\n",
      "[epoch: 20, i:  2348]  train_loss: 0.567  |  valid_loss: 0.523\n",
      "[epoch: 20, i:  2435]  train_loss: 0.592  |  valid_loss: 0.657\n",
      "[epoch: 20, i:  2522]  train_loss: 0.526  |  valid_loss: 0.562\n",
      "[epoch: 20, i:  2609]  train_loss: 0.601  |  valid_loss: 0.540\n",
      "[epoch: 20, i:  2696]  train_loss: 0.634  |  valid_loss: 0.667\n",
      "[epoch: 20, i:  2783]  train_loss: 0.603  |  valid_loss: 0.522\n",
      "[epoch: 20, i:  2870]  train_loss: 0.580  |  valid_loss: 0.695\n",
      "[epoch: 20, i:  2957]  train_loss: 0.563  |  valid_loss: 0.700\n",
      "[epoch: 20, i:  3044]  train_loss: 0.563  |  valid_loss: 0.679\n",
      "[epoch: 20, i:  3131]  train_loss: 0.563  |  valid_loss: 0.679\n",
      "[epoch: 20, i:  3218]  train_loss: 0.582  |  valid_loss: 0.717\n",
      "[epoch: 20, i:  3305]  train_loss: 0.592  |  valid_loss: 0.702\n",
      "[epoch: 20, i:  3392]  train_loss: 0.573  |  valid_loss: 0.623\n",
      "[epoch: 20, i:  3479]  train_loss: 0.579  |  valid_loss: 0.466\n",
      "[epoch: 20, i:  3566]  train_loss: 0.598  |  valid_loss: 0.583\n",
      "[epoch: 20, i:  3653]  train_loss: 0.532  |  valid_loss: 0.764\n",
      "[epoch: 20, i:  3740]  train_loss: 0.653  |  valid_loss: 0.445\n",
      "[epoch: 20, i:  3827]  train_loss: 0.600  |  valid_loss: 0.756\n",
      "[epoch: 20, i:  3914]  train_loss: 0.677  |  valid_loss: 0.496\n",
      "[epoch: 20, i:  4001]  train_loss: 0.542  |  valid_loss: 0.614\n",
      "[epoch: 20, i:  4088]  train_loss: 0.588  |  valid_loss: 0.640\n",
      "[epoch: 20, i:  4175]  train_loss: 0.609  |  valid_loss: 0.619\n",
      "[epoch: 20, i:  4262]  train_loss: 0.549  |  valid_loss: 0.528\n",
      "[epoch: 20, i:  4349]  train_loss: 0.575  |  valid_loss: 0.577\n",
      "[epoch: 20, i:  4436]  train_loss: 0.616  |  valid_loss: 0.531\n",
      "[epoch: 20, i:  4523]  train_loss: 0.564  |  valid_loss: 0.751\n",
      "[epoch: 20, i:  4610]  train_loss: 0.654  |  valid_loss: 0.521\n",
      "[epoch: 20, i:  4697]  train_loss: 0.622  |  valid_loss: 0.657\n",
      "[epoch: 20, i:  4784]  train_loss: 0.540  |  valid_loss: 0.631\n",
      "[epoch: 20, i:  4871]  train_loss: 0.586  |  valid_loss: 0.739\n",
      "[epoch: 20, i:  4958]  train_loss: 0.620  |  valid_loss: 0.797\n",
      "[epoch: 20, i:  5045]  train_loss: 0.562  |  valid_loss: 0.464\n",
      "[epoch: 20, i:  5132]  train_loss: 0.628  |  valid_loss: 0.675\n",
      "[epoch: 20, i:  5219]  train_loss: 0.616  |  valid_loss: 0.813\n",
      "[epoch: 20, i:  5306]  train_loss: 0.573  |  valid_loss: 0.773\n",
      "[epoch: 20, i:  5393]  train_loss: 0.583  |  valid_loss: 0.583\n",
      "[epoch: 20, i:  5480]  train_loss: 0.616  |  valid_loss: 0.805\n",
      "[epoch: 20, i:  5567]  train_loss: 0.597  |  valid_loss: 0.367\n",
      "[epoch: 20, i:  5654]  train_loss: 0.579  |  valid_loss: 0.597\n",
      "[epoch: 20, i:  5741]  train_loss: 0.576  |  valid_loss: 0.671\n",
      "[epoch: 20, i:  5828]  train_loss: 0.668  |  valid_loss: 0.668\n",
      "[epoch: 20, i:  5915]  train_loss: 0.596  |  valid_loss: 0.749\n",
      "[epoch: 20, i:  6002]  train_loss: 0.602  |  valid_loss: 0.590\n",
      "[epoch: 20, i:  6089]  train_loss: 0.617  |  valid_loss: 0.698\n",
      "[epoch: 20, i:  6176]  train_loss: 0.563  |  valid_loss: 0.713\n",
      "[epoch: 20, i:  6263]  train_loss: 0.560  |  valid_loss: 0.516\n",
      "[epoch: 20, i:  6350]  train_loss: 0.590  |  valid_loss: 0.561\n",
      "[epoch: 20, i:  6437]  train_loss: 0.556  |  valid_loss: 0.426\n",
      "[epoch: 20, i:  6524]  train_loss: 0.582  |  valid_loss: 0.765\n",
      "[epoch: 20, i:  6611]  train_loss: 0.631  |  valid_loss: 0.469\n",
      "[epoch: 20, i:  6698]  train_loss: 0.571  |  valid_loss: 0.748\n",
      "[epoch: 20, i:  6785]  train_loss: 0.608  |  valid_loss: 0.535\n",
      "[epoch: 20, i:  6872]  train_loss: 0.605  |  valid_loss: 0.812\n",
      "[epoch: 20, i:  6959]  train_loss: 0.612  |  valid_loss: 0.742\n",
      "[epoch: 20, i:  7046]  train_loss: 0.630  |  valid_loss: 0.647\n",
      "[epoch: 20, i:  7133]  train_loss: 0.583  |  valid_loss: 0.543\n",
      "[epoch: 20, i:  7220]  train_loss: 0.604  |  valid_loss: 0.709\n",
      "[epoch: 20, i:  7307]  train_loss: 0.599  |  valid_loss: 0.816\n",
      "[epoch: 20, i:  7394]  train_loss: 0.583  |  valid_loss: 0.580\n",
      "[epoch: 20, i:  7481]  train_loss: 0.661  |  valid_loss: 0.604\n",
      "[epoch: 20, i:  7568]  train_loss: 0.571  |  valid_loss: 0.805\n",
      "[epoch: 20, i:  7655]  train_loss: 0.574  |  valid_loss: 0.632\n",
      "[epoch: 20, i:  7742]  train_loss: 0.607  |  valid_loss: 0.637\n",
      "[epoch: 20, i:  7829]  train_loss: 0.583  |  valid_loss: 0.526\n",
      "[epoch: 20, i:  7916]  train_loss: 0.655  |  valid_loss: 0.676\n",
      "[epoch: 20, i:  8003]  train_loss: 0.599  |  valid_loss: 0.557\n",
      "[epoch: 20, i:  8090]  train_loss: 0.598  |  valid_loss: 0.472\n",
      "[epoch: 20, i:  8177]  train_loss: 0.599  |  valid_loss: 0.625\n",
      "[epoch: 20, i:  8264]  train_loss: 0.593  |  valid_loss: 0.703\n",
      "[epoch: 20, i:  8351]  train_loss: 0.680  |  valid_loss: 0.754\n",
      "[epoch: 20, i:  8438]  train_loss: 0.577  |  valid_loss: 0.471\n",
      "[epoch: 20, i:  8525]  train_loss: 0.593  |  valid_loss: 0.730\n",
      "[epoch: 20, i:  8612]  train_loss: 0.573  |  valid_loss: 0.865\n",
      "[epoch: 20, i:  8699]  train_loss: 0.598  |  valid_loss: 0.612\n",
      "--> [End of epoch 20] train_accuracy: 79.21%  |  valid_accuracy: 78.08%\n",
      "--> [Start of epoch 21]  lr: 0.000500\n",
      "[epoch: 21, i:    86]  train_loss: 0.624  |  valid_loss: 0.557\n",
      "[epoch: 21, i:   173]  train_loss: 0.588  |  valid_loss: 0.517\n",
      "[epoch: 21, i:   260]  train_loss: 0.567  |  valid_loss: 0.693\n",
      "[epoch: 21, i:   347]  train_loss: 0.555  |  valid_loss: 0.545\n",
      "[epoch: 21, i:   434]  train_loss: 0.570  |  valid_loss: 0.654\n",
      "[epoch: 21, i:   521]  train_loss: 0.590  |  valid_loss: 0.458\n",
      "[epoch: 21, i:   608]  train_loss: 0.569  |  valid_loss: 0.727\n",
      "[epoch: 21, i:   695]  train_loss: 0.564  |  valid_loss: 0.702\n",
      "[epoch: 21, i:   782]  train_loss: 0.570  |  valid_loss: 0.753\n",
      "[epoch: 21, i:   869]  train_loss: 0.607  |  valid_loss: 0.669\n",
      "[epoch: 21, i:   956]  train_loss: 0.548  |  valid_loss: 0.563\n",
      "[epoch: 21, i:  1043]  train_loss: 0.615  |  valid_loss: 0.664\n",
      "[epoch: 21, i:  1130]  train_loss: 0.550  |  valid_loss: 0.585\n",
      "[epoch: 21, i:  1217]  train_loss: 0.668  |  valid_loss: 0.712\n",
      "[epoch: 21, i:  1304]  train_loss: 0.656  |  valid_loss: 0.430\n",
      "[epoch: 21, i:  1391]  train_loss: 0.627  |  valid_loss: 0.653\n",
      "[epoch: 21, i:  1478]  train_loss: 0.598  |  valid_loss: 0.575\n",
      "[epoch: 21, i:  1565]  train_loss: 0.619  |  valid_loss: 0.799\n",
      "[epoch: 21, i:  1652]  train_loss: 0.612  |  valid_loss: 0.528\n",
      "[epoch: 21, i:  1739]  train_loss: 0.616  |  valid_loss: 0.802\n",
      "[epoch: 21, i:  1826]  train_loss: 0.588  |  valid_loss: 0.796\n",
      "[epoch: 21, i:  1913]  train_loss: 0.621  |  valid_loss: 0.674\n",
      "[epoch: 21, i:  2000]  train_loss: 0.574  |  valid_loss: 0.638\n",
      "[epoch: 21, i:  2087]  train_loss: 0.574  |  valid_loss: 0.766\n",
      "[epoch: 21, i:  2174]  train_loss: 0.593  |  valid_loss: 0.622\n",
      "[epoch: 21, i:  2261]  train_loss: 0.588  |  valid_loss: 0.974\n",
      "[epoch: 21, i:  2348]  train_loss: 0.576  |  valid_loss: 0.573\n",
      "[epoch: 21, i:  2435]  train_loss: 0.576  |  valid_loss: 0.780\n",
      "[epoch: 21, i:  2522]  train_loss: 0.607  |  valid_loss: 0.565\n",
      "[epoch: 21, i:  2609]  train_loss: 0.542  |  valid_loss: 0.582\n",
      "[epoch: 21, i:  2696]  train_loss: 0.518  |  valid_loss: 0.732\n",
      "[epoch: 21, i:  2783]  train_loss: 0.516  |  valid_loss: 0.551\n",
      "[epoch: 21, i:  2870]  train_loss: 0.542  |  valid_loss: 0.685\n",
      "[epoch: 21, i:  2957]  train_loss: 0.628  |  valid_loss: 0.750\n",
      "[epoch: 21, i:  3044]  train_loss: 0.618  |  valid_loss: 0.655\n",
      "[epoch: 21, i:  3131]  train_loss: 0.630  |  valid_loss: 0.633\n",
      "[epoch: 21, i:  3218]  train_loss: 0.610  |  valid_loss: 0.697\n",
      "[epoch: 21, i:  3305]  train_loss: 0.557  |  valid_loss: 0.608\n",
      "[epoch: 21, i:  3392]  train_loss: 0.613  |  valid_loss: 0.599\n",
      "[epoch: 21, i:  3479]  train_loss: 0.576  |  valid_loss: 0.479\n",
      "[epoch: 21, i:  3566]  train_loss: 0.571  |  valid_loss: 0.649\n",
      "[epoch: 21, i:  3653]  train_loss: 0.505  |  valid_loss: 0.715\n",
      "[epoch: 21, i:  3740]  train_loss: 0.588  |  valid_loss: 0.468\n",
      "[epoch: 21, i:  3827]  train_loss: 0.539  |  valid_loss: 0.732\n",
      "[epoch: 21, i:  3914]  train_loss: 0.645  |  valid_loss: 0.486\n",
      "[epoch: 21, i:  4001]  train_loss: 0.594  |  valid_loss: 0.670\n",
      "[epoch: 21, i:  4088]  train_loss: 0.628  |  valid_loss: 0.573\n",
      "[epoch: 21, i:  4175]  train_loss: 0.606  |  valid_loss: 0.579\n",
      "[epoch: 21, i:  4262]  train_loss: 0.525  |  valid_loss: 0.593\n",
      "[epoch: 21, i:  4349]  train_loss: 0.574  |  valid_loss: 0.597\n",
      "[epoch: 21, i:  4436]  train_loss: 0.559  |  valid_loss: 0.584\n",
      "[epoch: 21, i:  4523]  train_loss: 0.652  |  valid_loss: 0.728\n",
      "[epoch: 21, i:  4610]  train_loss: 0.609  |  valid_loss: 0.502\n",
      "[epoch: 21, i:  4697]  train_loss: 0.559  |  valid_loss: 0.524\n",
      "[epoch: 21, i:  4784]  train_loss: 0.568  |  valid_loss: 0.634\n",
      "[epoch: 21, i:  4871]  train_loss: 0.622  |  valid_loss: 0.694\n",
      "[epoch: 21, i:  4958]  train_loss: 0.654  |  valid_loss: 0.750\n",
      "[epoch: 21, i:  5045]  train_loss: 0.546  |  valid_loss: 0.388\n",
      "[epoch: 21, i:  5132]  train_loss: 0.661  |  valid_loss: 0.639\n",
      "[epoch: 21, i:  5219]  train_loss: 0.584  |  valid_loss: 0.824\n",
      "[epoch: 21, i:  5306]  train_loss: 0.608  |  valid_loss: 0.683\n",
      "[epoch: 21, i:  5393]  train_loss: 0.555  |  valid_loss: 0.579\n",
      "[epoch: 21, i:  5480]  train_loss: 0.609  |  valid_loss: 0.772\n",
      "[epoch: 21, i:  5567]  train_loss: 0.603  |  valid_loss: 0.374\n",
      "[epoch: 21, i:  5654]  train_loss: 0.654  |  valid_loss: 0.644\n",
      "[epoch: 21, i:  5741]  train_loss: 0.589  |  valid_loss: 0.650\n",
      "[epoch: 21, i:  5828]  train_loss: 0.593  |  valid_loss: 0.564\n",
      "[epoch: 21, i:  5915]  train_loss: 0.545  |  valid_loss: 0.712\n",
      "[epoch: 21, i:  6002]  train_loss: 0.633  |  valid_loss: 0.546\n",
      "[epoch: 21, i:  6089]  train_loss: 0.625  |  valid_loss: 0.747\n",
      "[epoch: 21, i:  6176]  train_loss: 0.581  |  valid_loss: 0.705\n",
      "[epoch: 21, i:  6263]  train_loss: 0.575  |  valid_loss: 0.593\n",
      "[epoch: 21, i:  6350]  train_loss: 0.642  |  valid_loss: 0.609\n",
      "[epoch: 21, i:  6437]  train_loss: 0.590  |  valid_loss: 0.494\n",
      "[epoch: 21, i:  6524]  train_loss: 0.570  |  valid_loss: 0.705\n",
      "[epoch: 21, i:  6611]  train_loss: 0.606  |  valid_loss: 0.443\n",
      "[epoch: 21, i:  6698]  train_loss: 0.593  |  valid_loss: 0.712\n",
      "[epoch: 21, i:  6785]  train_loss: 0.594  |  valid_loss: 0.560\n",
      "[epoch: 21, i:  6872]  train_loss: 0.574  |  valid_loss: 0.714\n",
      "[epoch: 21, i:  6959]  train_loss: 0.628  |  valid_loss: 0.736\n",
      "[epoch: 21, i:  7046]  train_loss: 0.693  |  valid_loss: 0.613\n",
      "[epoch: 21, i:  7133]  train_loss: 0.576  |  valid_loss: 0.581\n",
      "[epoch: 21, i:  7220]  train_loss: 0.586  |  valid_loss: 0.684\n",
      "[epoch: 21, i:  7307]  train_loss: 0.579  |  valid_loss: 0.811\n",
      "[epoch: 21, i:  7394]  train_loss: 0.660  |  valid_loss: 0.659\n",
      "[epoch: 21, i:  7481]  train_loss: 0.548  |  valid_loss: 0.625\n",
      "[epoch: 21, i:  7568]  train_loss: 0.665  |  valid_loss: 0.805\n",
      "[epoch: 21, i:  7655]  train_loss: 0.633  |  valid_loss: 0.653\n",
      "[epoch: 21, i:  7742]  train_loss: 0.611  |  valid_loss: 0.639\n",
      "[epoch: 21, i:  7829]  train_loss: 0.617  |  valid_loss: 0.557\n",
      "[epoch: 21, i:  7916]  train_loss: 0.578  |  valid_loss: 0.688\n",
      "[epoch: 21, i:  8003]  train_loss: 0.634  |  valid_loss: 0.534\n",
      "[epoch: 21, i:  8090]  train_loss: 0.622  |  valid_loss: 0.494\n",
      "[epoch: 21, i:  8177]  train_loss: 0.621  |  valid_loss: 0.552\n",
      "[epoch: 21, i:  8264]  train_loss: 0.638  |  valid_loss: 0.725\n",
      "[epoch: 21, i:  8351]  train_loss: 0.643  |  valid_loss: 0.860\n",
      "[epoch: 21, i:  8438]  train_loss: 0.621  |  valid_loss: 0.490\n",
      "[epoch: 21, i:  8525]  train_loss: 0.607  |  valid_loss: 0.711\n",
      "[epoch: 21, i:  8612]  train_loss: 0.555  |  valid_loss: 0.882\n",
      "[epoch: 21, i:  8699]  train_loss: 0.553  |  valid_loss: 0.574\n",
      "--> [End of epoch 21] train_accuracy: 79.52%  |  valid_accuracy: 78.46%\n",
      "--> [Start of epoch 22]  lr: 0.000500\n",
      "[epoch: 22, i:    86]  train_loss: 0.594  |  valid_loss: 0.517\n",
      "[epoch: 22, i:   173]  train_loss: 0.582  |  valid_loss: 0.591\n",
      "[epoch: 22, i:   260]  train_loss: 0.574  |  valid_loss: 0.770\n",
      "[epoch: 22, i:   347]  train_loss: 0.554  |  valid_loss: 0.558\n",
      "[epoch: 22, i:   434]  train_loss: 0.517  |  valid_loss: 0.716\n",
      "[epoch: 22, i:   521]  train_loss: 0.556  |  valid_loss: 0.423\n",
      "[epoch: 22, i:   608]  train_loss: 0.570  |  valid_loss: 0.677\n",
      "[epoch: 22, i:   695]  train_loss: 0.554  |  valid_loss: 0.687\n",
      "[epoch: 22, i:   782]  train_loss: 0.565  |  valid_loss: 0.770\n",
      "[epoch: 22, i:   869]  train_loss: 0.573  |  valid_loss: 0.603\n",
      "[epoch: 22, i:   956]  train_loss: 0.498  |  valid_loss: 0.500\n",
      "[epoch: 22, i:  1043]  train_loss: 0.566  |  valid_loss: 0.638\n",
      "[epoch: 22, i:  1130]  train_loss: 0.618  |  valid_loss: 0.610\n",
      "[epoch: 22, i:  1217]  train_loss: 0.519  |  valid_loss: 0.698\n",
      "[epoch: 22, i:  1304]  train_loss: 0.546  |  valid_loss: 0.460\n",
      "[epoch: 22, i:  1391]  train_loss: 0.551  |  valid_loss: 0.737\n",
      "[epoch: 22, i:  1478]  train_loss: 0.547  |  valid_loss: 0.601\n",
      "[epoch: 22, i:  1565]  train_loss: 0.613  |  valid_loss: 0.692\n",
      "[epoch: 22, i:  1652]  train_loss: 0.599  |  valid_loss: 0.570\n",
      "[epoch: 22, i:  1739]  train_loss: 0.633  |  valid_loss: 0.764\n",
      "[epoch: 22, i:  1826]  train_loss: 0.556  |  valid_loss: 0.844\n",
      "[epoch: 22, i:  1913]  train_loss: 0.586  |  valid_loss: 0.678\n",
      "[epoch: 22, i:  2000]  train_loss: 0.572  |  valid_loss: 0.705\n",
      "[epoch: 22, i:  2087]  train_loss: 0.612  |  valid_loss: 0.766\n",
      "[epoch: 22, i:  2174]  train_loss: 0.532  |  valid_loss: 0.566\n",
      "[epoch: 22, i:  2261]  train_loss: 0.518  |  valid_loss: 0.826\n",
      "[epoch: 22, i:  2348]  train_loss: 0.587  |  valid_loss: 0.629\n",
      "[epoch: 22, i:  2435]  train_loss: 0.497  |  valid_loss: 0.683\n",
      "[epoch: 22, i:  2522]  train_loss: 0.563  |  valid_loss: 0.497\n",
      "[epoch: 22, i:  2609]  train_loss: 0.581  |  valid_loss: 0.601\n",
      "[epoch: 22, i:  2696]  train_loss: 0.561  |  valid_loss: 0.731\n",
      "[epoch: 22, i:  2783]  train_loss: 0.484  |  valid_loss: 0.476\n",
      "[epoch: 22, i:  2870]  train_loss: 0.616  |  valid_loss: 0.640\n",
      "[epoch: 22, i:  2957]  train_loss: 0.600  |  valid_loss: 0.694\n",
      "[epoch: 22, i:  3044]  train_loss: 0.583  |  valid_loss: 0.750\n",
      "[epoch: 22, i:  3131]  train_loss: 0.551  |  valid_loss: 0.616\n",
      "[epoch: 22, i:  3218]  train_loss: 0.600  |  valid_loss: 0.836\n",
      "[epoch: 22, i:  3305]  train_loss: 0.601  |  valid_loss: 0.670\n",
      "[epoch: 22, i:  3392]  train_loss: 0.526  |  valid_loss: 0.655\n",
      "[epoch: 22, i:  3479]  train_loss: 0.579  |  valid_loss: 0.435\n",
      "[epoch: 22, i:  3566]  train_loss: 0.542  |  valid_loss: 0.568\n",
      "[epoch: 22, i:  3653]  train_loss: 0.574  |  valid_loss: 0.745\n",
      "[epoch: 22, i:  3740]  train_loss: 0.655  |  valid_loss: 0.391\n",
      "[epoch: 22, i:  3827]  train_loss: 0.617  |  valid_loss: 0.734\n",
      "[epoch: 22, i:  3914]  train_loss: 0.570  |  valid_loss: 0.549\n",
      "[epoch: 22, i:  4001]  train_loss: 0.575  |  valid_loss: 0.635\n",
      "[epoch: 22, i:  4088]  train_loss: 0.534  |  valid_loss: 0.624\n",
      "[epoch: 22, i:  4175]  train_loss: 0.538  |  valid_loss: 0.632\n",
      "[epoch: 22, i:  4262]  train_loss: 0.596  |  valid_loss: 0.534\n",
      "[epoch: 22, i:  4349]  train_loss: 0.607  |  valid_loss: 0.633\n",
      "[epoch: 22, i:  4436]  train_loss: 0.578  |  valid_loss: 0.579\n",
      "[epoch: 22, i:  4523]  train_loss: 0.531  |  valid_loss: 0.799\n",
      "[epoch: 22, i:  4610]  train_loss: 0.635  |  valid_loss: 0.546\n",
      "[epoch: 22, i:  4697]  train_loss: 0.597  |  valid_loss: 0.574\n",
      "[epoch: 22, i:  4784]  train_loss: 0.661  |  valid_loss: 0.642\n",
      "[epoch: 22, i:  4871]  train_loss: 0.610  |  valid_loss: 0.663\n",
      "[epoch: 22, i:  4958]  train_loss: 0.580  |  valid_loss: 0.752\n",
      "[epoch: 22, i:  5045]  train_loss: 0.601  |  valid_loss: 0.443\n",
      "[epoch: 22, i:  5132]  train_loss: 0.589  |  valid_loss: 0.617\n",
      "[epoch: 22, i:  5219]  train_loss: 0.640  |  valid_loss: 0.818\n",
      "[epoch: 22, i:  5306]  train_loss: 0.537  |  valid_loss: 0.690\n",
      "[epoch: 22, i:  5393]  train_loss: 0.601  |  valid_loss: 0.595\n",
      "[epoch: 22, i:  5480]  train_loss: 0.634  |  valid_loss: 0.807\n",
      "[epoch: 22, i:  5567]  train_loss: 0.608  |  valid_loss: 0.415\n",
      "[epoch: 22, i:  5654]  train_loss: 0.702  |  valid_loss: 0.732\n",
      "[epoch: 22, i:  5741]  train_loss: 0.584  |  valid_loss: 0.665\n",
      "[epoch: 22, i:  5828]  train_loss: 0.623  |  valid_loss: 0.560\n",
      "[epoch: 22, i:  5915]  train_loss: 0.655  |  valid_loss: 0.788\n",
      "[epoch: 22, i:  6002]  train_loss: 0.573  |  valid_loss: 0.616\n",
      "[epoch: 22, i:  6089]  train_loss: 0.597  |  valid_loss: 0.787\n",
      "[epoch: 22, i:  6176]  train_loss: 0.606  |  valid_loss: 0.731\n",
      "[epoch: 22, i:  6263]  train_loss: 0.588  |  valid_loss: 0.577\n",
      "[epoch: 22, i:  6350]  train_loss: 0.594  |  valid_loss: 0.593\n",
      "[epoch: 22, i:  6437]  train_loss: 0.607  |  valid_loss: 0.336\n",
      "[epoch: 22, i:  6524]  train_loss: 0.553  |  valid_loss: 0.797\n",
      "[epoch: 22, i:  6611]  train_loss: 0.576  |  valid_loss: 0.438\n",
      "[epoch: 22, i:  6698]  train_loss: 0.570  |  valid_loss: 0.745\n",
      "[epoch: 22, i:  6785]  train_loss: 0.558  |  valid_loss: 0.554\n",
      "[epoch: 22, i:  6872]  train_loss: 0.552  |  valid_loss: 0.713\n",
      "[epoch: 22, i:  6959]  train_loss: 0.620  |  valid_loss: 0.650\n",
      "[epoch: 22, i:  7046]  train_loss: 0.582  |  valid_loss: 0.640\n",
      "[epoch: 22, i:  7133]  train_loss: 0.592  |  valid_loss: 0.554\n",
      "[epoch: 22, i:  7220]  train_loss: 0.641  |  valid_loss: 0.679\n",
      "[epoch: 22, i:  7307]  train_loss: 0.650  |  valid_loss: 0.673\n",
      "[epoch: 22, i:  7394]  train_loss: 0.582  |  valid_loss: 0.552\n",
      "[epoch: 22, i:  7481]  train_loss: 0.567  |  valid_loss: 0.649\n",
      "[epoch: 22, i:  7568]  train_loss: 0.625  |  valid_loss: 0.801\n",
      "[epoch: 22, i:  7655]  train_loss: 0.528  |  valid_loss: 0.633\n",
      "[epoch: 22, i:  7742]  train_loss: 0.572  |  valid_loss: 0.599\n",
      "[epoch: 22, i:  7829]  train_loss: 0.591  |  valid_loss: 0.518\n",
      "[epoch: 22, i:  7916]  train_loss: 0.589  |  valid_loss: 0.699\n",
      "[epoch: 22, i:  8003]  train_loss: 0.649  |  valid_loss: 0.513\n",
      "[epoch: 22, i:  8090]  train_loss: 0.550  |  valid_loss: 0.522\n",
      "[epoch: 22, i:  8177]  train_loss: 0.568  |  valid_loss: 0.603\n",
      "[epoch: 22, i:  8264]  train_loss: 0.542  |  valid_loss: 0.725\n",
      "[epoch: 22, i:  8351]  train_loss: 0.562  |  valid_loss: 0.714\n",
      "[epoch: 22, i:  8438]  train_loss: 0.578  |  valid_loss: 0.427\n",
      "[epoch: 22, i:  8525]  train_loss: 0.622  |  valid_loss: 0.626\n",
      "[epoch: 22, i:  8612]  train_loss: 0.594  |  valid_loss: 0.805\n",
      "[epoch: 22, i:  8699]  train_loss: 0.572  |  valid_loss: 0.660\n",
      "--> [End of epoch 22] train_accuracy: 79.63%  |  valid_accuracy: 78.55%\n",
      "--> [Start of epoch 23]  lr: 0.000500\n",
      "[epoch: 23, i:    86]  train_loss: 0.567  |  valid_loss: 0.573\n",
      "[epoch: 23, i:   173]  train_loss: 0.587  |  valid_loss: 0.606\n",
      "[epoch: 23, i:   260]  train_loss: 0.521  |  valid_loss: 0.676\n",
      "[epoch: 23, i:   347]  train_loss: 0.600  |  valid_loss: 0.670\n",
      "[epoch: 23, i:   434]  train_loss: 0.574  |  valid_loss: 0.664\n",
      "[epoch: 23, i:   521]  train_loss: 0.551  |  valid_loss: 0.472\n",
      "[epoch: 23, i:   608]  train_loss: 0.593  |  valid_loss: 0.684\n",
      "[epoch: 23, i:   695]  train_loss: 0.598  |  valid_loss: 0.702\n",
      "[epoch: 23, i:   782]  train_loss: 0.523  |  valid_loss: 0.705\n",
      "[epoch: 23, i:   869]  train_loss: 0.561  |  valid_loss: 0.654\n",
      "[epoch: 23, i:   956]  train_loss: 0.500  |  valid_loss: 0.510\n",
      "[epoch: 23, i:  1043]  train_loss: 0.547  |  valid_loss: 0.550\n",
      "[epoch: 23, i:  1130]  train_loss: 0.566  |  valid_loss: 0.549\n",
      "[epoch: 23, i:  1217]  train_loss: 0.551  |  valid_loss: 0.709\n",
      "[epoch: 23, i:  1304]  train_loss: 0.581  |  valid_loss: 0.409\n",
      "[epoch: 23, i:  1391]  train_loss: 0.559  |  valid_loss: 0.661\n",
      "[epoch: 23, i:  1478]  train_loss: 0.581  |  valid_loss: 0.671\n",
      "[epoch: 23, i:  1565]  train_loss: 0.588  |  valid_loss: 0.696\n",
      "[epoch: 23, i:  1652]  train_loss: 0.571  |  valid_loss: 0.652\n",
      "[epoch: 23, i:  1739]  train_loss: 0.543  |  valid_loss: 0.842\n",
      "[epoch: 23, i:  1826]  train_loss: 0.635  |  valid_loss: 0.726\n",
      "[epoch: 23, i:  1913]  train_loss: 0.555  |  valid_loss: 0.666\n",
      "[epoch: 23, i:  2000]  train_loss: 0.552  |  valid_loss: 0.668\n",
      "[epoch: 23, i:  2087]  train_loss: 0.569  |  valid_loss: 0.798\n",
      "[epoch: 23, i:  2174]  train_loss: 0.533  |  valid_loss: 0.515\n",
      "[epoch: 23, i:  2261]  train_loss: 0.556  |  valid_loss: 0.906\n",
      "[epoch: 23, i:  2348]  train_loss: 0.554  |  valid_loss: 0.502\n",
      "[epoch: 23, i:  2435]  train_loss: 0.597  |  valid_loss: 0.693\n",
      "[epoch: 23, i:  2522]  train_loss: 0.574  |  valid_loss: 0.520\n",
      "[epoch: 23, i:  2609]  train_loss: 0.592  |  valid_loss: 0.537\n",
      "[epoch: 23, i:  2696]  train_loss: 0.541  |  valid_loss: 0.673\n",
      "[epoch: 23, i:  2783]  train_loss: 0.534  |  valid_loss: 0.457\n",
      "[epoch: 23, i:  2870]  train_loss: 0.550  |  valid_loss: 0.685\n",
      "[epoch: 23, i:  2957]  train_loss: 0.570  |  valid_loss: 0.731\n",
      "[epoch: 23, i:  3044]  train_loss: 0.513  |  valid_loss: 0.769\n",
      "[epoch: 23, i:  3131]  train_loss: 0.594  |  valid_loss: 0.556\n",
      "[epoch: 23, i:  3218]  train_loss: 0.563  |  valid_loss: 0.754\n",
      "[epoch: 23, i:  3305]  train_loss: 0.557  |  valid_loss: 0.610\n",
      "[epoch: 23, i:  3392]  train_loss: 0.663  |  valid_loss: 0.562\n",
      "[epoch: 23, i:  3479]  train_loss: 0.617  |  valid_loss: 0.489\n",
      "[epoch: 23, i:  3566]  train_loss: 0.510  |  valid_loss: 0.635\n",
      "[epoch: 23, i:  3653]  train_loss: 0.536  |  valid_loss: 0.617\n",
      "[epoch: 23, i:  3740]  train_loss: 0.523  |  valid_loss: 0.409\n",
      "[epoch: 23, i:  3827]  train_loss: 0.577  |  valid_loss: 0.788\n",
      "[epoch: 23, i:  3914]  train_loss: 0.622  |  valid_loss: 0.482\n",
      "[epoch: 23, i:  4001]  train_loss: 0.577  |  valid_loss: 0.642\n",
      "[epoch: 23, i:  4088]  train_loss: 0.634  |  valid_loss: 0.620\n",
      "[epoch: 23, i:  4175]  train_loss: 0.568  |  valid_loss: 0.513\n",
      "[epoch: 23, i:  4262]  train_loss: 0.581  |  valid_loss: 0.544\n",
      "[epoch: 23, i:  4349]  train_loss: 0.572  |  valid_loss: 0.618\n",
      "[epoch: 23, i:  4436]  train_loss: 0.557  |  valid_loss: 0.596\n",
      "[epoch: 23, i:  4523]  train_loss: 0.626  |  valid_loss: 0.647\n",
      "[epoch: 23, i:  4610]  train_loss: 0.601  |  valid_loss: 0.609\n",
      "[epoch: 23, i:  4697]  train_loss: 0.592  |  valid_loss: 0.589\n",
      "[epoch: 23, i:  4784]  train_loss: 0.573  |  valid_loss: 0.687\n",
      "[epoch: 23, i:  4871]  train_loss: 0.622  |  valid_loss: 0.738\n",
      "[epoch: 23, i:  4958]  train_loss: 0.587  |  valid_loss: 0.839\n",
      "[epoch: 23, i:  5045]  train_loss: 0.598  |  valid_loss: 0.482\n",
      "[epoch: 23, i:  5132]  train_loss: 0.610  |  valid_loss: 0.682\n",
      "[epoch: 23, i:  5219]  train_loss: 0.548  |  valid_loss: 0.727\n",
      "[epoch: 23, i:  5306]  train_loss: 0.576  |  valid_loss: 0.719\n",
      "[epoch: 23, i:  5393]  train_loss: 0.626  |  valid_loss: 0.594\n",
      "[epoch: 23, i:  5480]  train_loss: 0.539  |  valid_loss: 0.831\n",
      "[epoch: 23, i:  5567]  train_loss: 0.670  |  valid_loss: 0.417\n",
      "[epoch: 23, i:  5654]  train_loss: 0.631  |  valid_loss: 0.606\n",
      "[epoch: 23, i:  5741]  train_loss: 0.581  |  valid_loss: 0.674\n",
      "[epoch: 23, i:  5828]  train_loss: 0.575  |  valid_loss: 0.593\n",
      "[epoch: 23, i:  5915]  train_loss: 0.599  |  valid_loss: 0.730\n",
      "[epoch: 23, i:  6002]  train_loss: 0.589  |  valid_loss: 0.584\n",
      "[epoch: 23, i:  6089]  train_loss: 0.568  |  valid_loss: 0.788\n",
      "[epoch: 23, i:  6176]  train_loss: 0.625  |  valid_loss: 0.624\n",
      "[epoch: 23, i:  6263]  train_loss: 0.568  |  valid_loss: 0.532\n",
      "[epoch: 23, i:  6350]  train_loss: 0.568  |  valid_loss: 0.559\n",
      "[epoch: 23, i:  6437]  train_loss: 0.587  |  valid_loss: 0.404\n",
      "[epoch: 23, i:  6524]  train_loss: 0.632  |  valid_loss: 0.783\n",
      "[epoch: 23, i:  6611]  train_loss: 0.636  |  valid_loss: 0.457\n",
      "[epoch: 23, i:  6698]  train_loss: 0.628  |  valid_loss: 0.672\n",
      "[epoch: 23, i:  6785]  train_loss: 0.641  |  valid_loss: 0.583\n",
      "[epoch: 23, i:  6872]  train_loss: 0.547  |  valid_loss: 0.771\n",
      "[epoch: 23, i:  6959]  train_loss: 0.669  |  valid_loss: 0.679\n",
      "[epoch: 23, i:  7046]  train_loss: 0.500  |  valid_loss: 0.618\n",
      "[epoch: 23, i:  7133]  train_loss: 0.547  |  valid_loss: 0.470\n",
      "[epoch: 23, i:  7220]  train_loss: 0.554  |  valid_loss: 0.796\n",
      "[epoch: 23, i:  7307]  train_loss: 0.549  |  valid_loss: 0.808\n",
      "[epoch: 23, i:  7394]  train_loss: 0.688  |  valid_loss: 0.537\n",
      "[epoch: 23, i:  7481]  train_loss: 0.646  |  valid_loss: 0.576\n",
      "[epoch: 23, i:  7568]  train_loss: 0.604  |  valid_loss: 0.716\n",
      "[epoch: 23, i:  7655]  train_loss: 0.530  |  valid_loss: 0.647\n",
      "[epoch: 23, i:  7742]  train_loss: 0.611  |  valid_loss: 0.576\n",
      "[epoch: 23, i:  7829]  train_loss: 0.584  |  valid_loss: 0.404\n",
      "[epoch: 23, i:  7916]  train_loss: 0.669  |  valid_loss: 0.690\n",
      "[epoch: 23, i:  8003]  train_loss: 0.539  |  valid_loss: 0.485\n",
      "[epoch: 23, i:  8090]  train_loss: 0.565  |  valid_loss: 0.498\n",
      "[epoch: 23, i:  8177]  train_loss: 0.556  |  valid_loss: 0.529\n",
      "[epoch: 23, i:  8264]  train_loss: 0.616  |  valid_loss: 0.637\n",
      "[epoch: 23, i:  8351]  train_loss: 0.575  |  valid_loss: 0.701\n",
      "[epoch: 23, i:  8438]  train_loss: 0.670  |  valid_loss: 0.478\n",
      "[epoch: 23, i:  8525]  train_loss: 0.542  |  valid_loss: 0.657\n",
      "[epoch: 23, i:  8612]  train_loss: 0.588  |  valid_loss: 0.928\n",
      "[epoch: 23, i:  8699]  train_loss: 0.600  |  valid_loss: 0.607\n",
      "--> [End of epoch 23] train_accuracy: 79.80%  |  valid_accuracy: 78.60%\n",
      "--> [Start of epoch 24]  lr: 0.000500\n",
      "[epoch: 24, i:    86]  train_loss: 0.582  |  valid_loss: 0.545\n",
      "[epoch: 24, i:   173]  train_loss: 0.610  |  valid_loss: 0.545\n",
      "[epoch: 24, i:   260]  train_loss: 0.583  |  valid_loss: 0.647\n",
      "[epoch: 24, i:   347]  train_loss: 0.551  |  valid_loss: 0.550\n",
      "[epoch: 24, i:   434]  train_loss: 0.644  |  valid_loss: 0.734\n",
      "[epoch: 24, i:   521]  train_loss: 0.580  |  valid_loss: 0.412\n",
      "[epoch: 24, i:   608]  train_loss: 0.538  |  valid_loss: 0.643\n",
      "[epoch: 24, i:   695]  train_loss: 0.604  |  valid_loss: 0.572\n",
      "[epoch: 24, i:   782]  train_loss: 0.568  |  valid_loss: 0.668\n",
      "[epoch: 24, i:   869]  train_loss: 0.645  |  valid_loss: 0.729\n",
      "[epoch: 24, i:   956]  train_loss: 0.592  |  valid_loss: 0.532\n",
      "[epoch: 24, i:  1043]  train_loss: 0.509  |  valid_loss: 0.603\n",
      "[epoch: 24, i:  1130]  train_loss: 0.539  |  valid_loss: 0.561\n",
      "[epoch: 24, i:  1217]  train_loss: 0.460  |  valid_loss: 0.654\n",
      "[epoch: 24, i:  1304]  train_loss: 0.592  |  valid_loss: 0.414\n",
      "[epoch: 24, i:  1391]  train_loss: 0.580  |  valid_loss: 0.681\n",
      "[epoch: 24, i:  1478]  train_loss: 0.565  |  valid_loss: 0.585\n",
      "[epoch: 24, i:  1565]  train_loss: 0.605  |  valid_loss: 0.745\n",
      "[epoch: 24, i:  1652]  train_loss: 0.530  |  valid_loss: 0.583\n",
      "[epoch: 24, i:  1739]  train_loss: 0.495  |  valid_loss: 0.921\n",
      "[epoch: 24, i:  1826]  train_loss: 0.545  |  valid_loss: 0.774\n",
      "[epoch: 24, i:  1913]  train_loss: 0.525  |  valid_loss: 0.586\n",
      "[epoch: 24, i:  2000]  train_loss: 0.544  |  valid_loss: 0.683\n",
      "[epoch: 24, i:  2087]  train_loss: 0.555  |  valid_loss: 0.783\n",
      "[epoch: 24, i:  2174]  train_loss: 0.584  |  valid_loss: 0.525\n",
      "[epoch: 24, i:  2261]  train_loss: 0.537  |  valid_loss: 0.877\n",
      "[epoch: 24, i:  2348]  train_loss: 0.630  |  valid_loss: 0.525\n",
      "[epoch: 24, i:  2435]  train_loss: 0.529  |  valid_loss: 0.700\n",
      "[epoch: 24, i:  2522]  train_loss: 0.583  |  valid_loss: 0.523\n",
      "[epoch: 24, i:  2609]  train_loss: 0.578  |  valid_loss: 0.574\n",
      "[epoch: 24, i:  2696]  train_loss: 0.666  |  valid_loss: 0.747\n",
      "[epoch: 24, i:  2783]  train_loss: 0.534  |  valid_loss: 0.479\n",
      "[epoch: 24, i:  2870]  train_loss: 0.566  |  valid_loss: 0.669\n",
      "[epoch: 24, i:  2957]  train_loss: 0.565  |  valid_loss: 0.800\n",
      "[epoch: 24, i:  3044]  train_loss: 0.552  |  valid_loss: 0.706\n",
      "[epoch: 24, i:  3131]  train_loss: 0.549  |  valid_loss: 0.610\n",
      "[epoch: 24, i:  3218]  train_loss: 0.544  |  valid_loss: 0.716\n",
      "[epoch: 24, i:  3305]  train_loss: 0.566  |  valid_loss: 0.576\n",
      "[epoch: 24, i:  3392]  train_loss: 0.552  |  valid_loss: 0.571\n",
      "[epoch: 24, i:  3479]  train_loss: 0.566  |  valid_loss: 0.497\n",
      "[epoch: 24, i:  3566]  train_loss: 0.637  |  valid_loss: 0.593\n",
      "[epoch: 24, i:  3653]  train_loss: 0.538  |  valid_loss: 0.731\n",
      "[epoch: 24, i:  3740]  train_loss: 0.625  |  valid_loss: 0.441\n",
      "[epoch: 24, i:  3827]  train_loss: 0.562  |  valid_loss: 0.801\n",
      "[epoch: 24, i:  3914]  train_loss: 0.629  |  valid_loss: 0.496\n",
      "[epoch: 24, i:  4001]  train_loss: 0.539  |  valid_loss: 0.658\n",
      "[epoch: 24, i:  4088]  train_loss: 0.603  |  valid_loss: 0.601\n",
      "[epoch: 24, i:  4175]  train_loss: 0.602  |  valid_loss: 0.553\n",
      "[epoch: 24, i:  4262]  train_loss: 0.603  |  valid_loss: 0.450\n",
      "[epoch: 24, i:  4349]  train_loss: 0.541  |  valid_loss: 0.586\n",
      "[epoch: 24, i:  4436]  train_loss: 0.559  |  valid_loss: 0.614\n",
      "[epoch: 24, i:  4523]  train_loss: 0.664  |  valid_loss: 0.734\n",
      "[epoch: 24, i:  4610]  train_loss: 0.578  |  valid_loss: 0.577\n",
      "[epoch: 24, i:  4697]  train_loss: 0.539  |  valid_loss: 0.660\n",
      "[epoch: 24, i:  4784]  train_loss: 0.570  |  valid_loss: 0.662\n",
      "[epoch: 24, i:  4871]  train_loss: 0.642  |  valid_loss: 0.709\n",
      "[epoch: 24, i:  4958]  train_loss: 0.617  |  valid_loss: 0.777\n",
      "[epoch: 24, i:  5045]  train_loss: 0.610  |  valid_loss: 0.453\n",
      "[epoch: 24, i:  5132]  train_loss: 0.583  |  valid_loss: 0.668\n",
      "[epoch: 24, i:  5219]  train_loss: 0.557  |  valid_loss: 0.766\n",
      "[epoch: 24, i:  5306]  train_loss: 0.588  |  valid_loss: 0.686\n",
      "[epoch: 24, i:  5393]  train_loss: 0.613  |  valid_loss: 0.509\n",
      "[epoch: 24, i:  5480]  train_loss: 0.564  |  valid_loss: 0.732\n",
      "[epoch: 24, i:  5567]  train_loss: 0.590  |  valid_loss: 0.363\n",
      "[epoch: 24, i:  5654]  train_loss: 0.660  |  valid_loss: 0.622\n",
      "[epoch: 24, i:  5741]  train_loss: 0.514  |  valid_loss: 0.695\n",
      "[epoch: 24, i:  5828]  train_loss: 0.606  |  valid_loss: 0.624\n",
      "[epoch: 24, i:  5915]  train_loss: 0.609  |  valid_loss: 0.652\n",
      "[epoch: 24, i:  6002]  train_loss: 0.575  |  valid_loss: 0.589\n",
      "[epoch: 24, i:  6089]  train_loss: 0.660  |  valid_loss: 0.797\n",
      "[epoch: 24, i:  6176]  train_loss: 0.596  |  valid_loss: 0.669\n",
      "[epoch: 24, i:  6263]  train_loss: 0.578  |  valid_loss: 0.553\n",
      "[epoch: 24, i:  6350]  train_loss: 0.591  |  valid_loss: 0.581\n",
      "[epoch: 24, i:  6437]  train_loss: 0.517  |  valid_loss: 0.331\n",
      "[epoch: 24, i:  6524]  train_loss: 0.557  |  valid_loss: 0.787\n",
      "[epoch: 24, i:  6611]  train_loss: 0.585  |  valid_loss: 0.438\n",
      "[epoch: 24, i:  6698]  train_loss: 0.581  |  valid_loss: 0.752\n",
      "[epoch: 24, i:  6785]  train_loss: 0.541  |  valid_loss: 0.529\n",
      "[epoch: 24, i:  6872]  train_loss: 0.591  |  valid_loss: 0.681\n",
      "[epoch: 24, i:  6959]  train_loss: 0.517  |  valid_loss: 0.712\n",
      "[epoch: 24, i:  7046]  train_loss: 0.623  |  valid_loss: 0.610\n",
      "[epoch: 24, i:  7133]  train_loss: 0.578  |  valid_loss: 0.501\n",
      "[epoch: 24, i:  7220]  train_loss: 0.675  |  valid_loss: 0.729\n",
      "[epoch: 24, i:  7307]  train_loss: 0.532  |  valid_loss: 0.777\n",
      "[epoch: 24, i:  7394]  train_loss: 0.654  |  valid_loss: 0.567\n",
      "[epoch: 24, i:  7481]  train_loss: 0.590  |  valid_loss: 0.617\n",
      "[epoch: 24, i:  7568]  train_loss: 0.642  |  valid_loss: 0.841\n",
      "[epoch: 24, i:  7655]  train_loss: 0.624  |  valid_loss: 0.665\n",
      "[epoch: 24, i:  7742]  train_loss: 0.638  |  valid_loss: 0.634\n",
      "[epoch: 24, i:  7829]  train_loss: 0.532  |  valid_loss: 0.462\n",
      "[epoch: 24, i:  7916]  train_loss: 0.581  |  valid_loss: 0.702\n",
      "[epoch: 24, i:  8003]  train_loss: 0.542  |  valid_loss: 0.512\n",
      "[epoch: 24, i:  8090]  train_loss: 0.538  |  valid_loss: 0.507\n",
      "[epoch: 24, i:  8177]  train_loss: 0.579  |  valid_loss: 0.583\n",
      "[epoch: 24, i:  8264]  train_loss: 0.590  |  valid_loss: 0.632\n",
      "[epoch: 24, i:  8351]  train_loss: 0.601  |  valid_loss: 0.723\n",
      "[epoch: 24, i:  8438]  train_loss: 0.568  |  valid_loss: 0.466\n",
      "[epoch: 24, i:  8525]  train_loss: 0.550  |  valid_loss: 0.602\n",
      "[epoch: 24, i:  8612]  train_loss: 0.628  |  valid_loss: 0.834\n",
      "[epoch: 24, i:  8699]  train_loss: 0.593  |  valid_loss: 0.622\n",
      "--> [End of epoch 24] train_accuracy: 79.89%  |  valid_accuracy: 78.71%\n",
      "--> [Start of epoch 25]  lr: 0.000500\n",
      "[epoch: 25, i:    86]  train_loss: 0.585  |  valid_loss: 0.540\n",
      "[epoch: 25, i:   173]  train_loss: 0.531  |  valid_loss: 0.589\n",
      "[epoch: 25, i:   260]  train_loss: 0.560  |  valid_loss: 0.692\n",
      "[epoch: 25, i:   347]  train_loss: 0.605  |  valid_loss: 0.510\n",
      "[epoch: 25, i:   434]  train_loss: 0.590  |  valid_loss: 0.729\n",
      "[epoch: 25, i:   521]  train_loss: 0.582  |  valid_loss: 0.437\n",
      "[epoch: 25, i:   608]  train_loss: 0.497  |  valid_loss: 0.696\n",
      "[epoch: 25, i:   695]  train_loss: 0.488  |  valid_loss: 0.636\n",
      "[epoch: 25, i:   782]  train_loss: 0.626  |  valid_loss: 0.708\n",
      "[epoch: 25, i:   869]  train_loss: 0.560  |  valid_loss: 0.755\n",
      "[epoch: 25, i:   956]  train_loss: 0.549  |  valid_loss: 0.530\n",
      "[epoch: 25, i:  1043]  train_loss: 0.560  |  valid_loss: 0.568\n",
      "[epoch: 25, i:  1130]  train_loss: 0.611  |  valid_loss: 0.587\n",
      "[epoch: 25, i:  1217]  train_loss: 0.563  |  valid_loss: 0.716\n",
      "[epoch: 25, i:  1304]  train_loss: 0.569  |  valid_loss: 0.401\n",
      "[epoch: 25, i:  1391]  train_loss: 0.548  |  valid_loss: 0.644\n",
      "[epoch: 25, i:  1478]  train_loss: 0.546  |  valid_loss: 0.625\n",
      "[epoch: 25, i:  1565]  train_loss: 0.609  |  valid_loss: 0.793\n",
      "[epoch: 25, i:  1652]  train_loss: 0.543  |  valid_loss: 0.613\n",
      "[epoch: 25, i:  1739]  train_loss: 0.551  |  valid_loss: 0.911\n",
      "[epoch: 25, i:  1826]  train_loss: 0.536  |  valid_loss: 0.792\n",
      "[epoch: 25, i:  1913]  train_loss: 0.551  |  valid_loss: 0.646\n",
      "[epoch: 25, i:  2000]  train_loss: 0.548  |  valid_loss: 0.638\n",
      "[epoch: 25, i:  2087]  train_loss: 0.581  |  valid_loss: 0.789\n",
      "[epoch: 25, i:  2174]  train_loss: 0.575  |  valid_loss: 0.499\n",
      "[epoch: 25, i:  2261]  train_loss: 0.621  |  valid_loss: 0.832\n",
      "[epoch: 25, i:  2348]  train_loss: 0.523  |  valid_loss: 0.534\n",
      "[epoch: 25, i:  2435]  train_loss: 0.581  |  valid_loss: 0.709\n",
      "[epoch: 25, i:  2522]  train_loss: 0.561  |  valid_loss: 0.477\n",
      "[epoch: 25, i:  2609]  train_loss: 0.585  |  valid_loss: 0.523\n",
      "[epoch: 25, i:  2696]  train_loss: 0.518  |  valid_loss: 0.725\n",
      "[epoch: 25, i:  2783]  train_loss: 0.559  |  valid_loss: 0.510\n",
      "[epoch: 25, i:  2870]  train_loss: 0.612  |  valid_loss: 0.708\n",
      "[epoch: 25, i:  2957]  train_loss: 0.579  |  valid_loss: 0.710\n",
      "[epoch: 25, i:  3044]  train_loss: 0.571  |  valid_loss: 0.798\n",
      "[epoch: 25, i:  3131]  train_loss: 0.542  |  valid_loss: 0.675\n",
      "[epoch: 25, i:  3218]  train_loss: 0.634  |  valid_loss: 0.677\n",
      "[epoch: 25, i:  3305]  train_loss: 0.599  |  valid_loss: 0.718\n",
      "[epoch: 25, i:  3392]  train_loss: 0.557  |  valid_loss: 0.602\n",
      "[epoch: 25, i:  3479]  train_loss: 0.509  |  valid_loss: 0.520\n",
      "[epoch: 25, i:  3566]  train_loss: 0.523  |  valid_loss: 0.569\n",
      "[epoch: 25, i:  3653]  train_loss: 0.556  |  valid_loss: 0.648\n",
      "[epoch: 25, i:  3740]  train_loss: 0.570  |  valid_loss: 0.408\n",
      "[epoch: 25, i:  3827]  train_loss: 0.544  |  valid_loss: 0.879\n",
      "[epoch: 25, i:  3914]  train_loss: 0.577  |  valid_loss: 0.510\n",
      "[epoch: 25, i:  4001]  train_loss: 0.532  |  valid_loss: 0.634\n",
      "[epoch: 25, i:  4088]  train_loss: 0.694  |  valid_loss: 0.687\n",
      "[epoch: 25, i:  4175]  train_loss: 0.579  |  valid_loss: 0.567\n",
      "[epoch: 25, i:  4262]  train_loss: 0.568  |  valid_loss: 0.527\n",
      "[epoch: 25, i:  4349]  train_loss: 0.596  |  valid_loss: 0.563\n",
      "[epoch: 25, i:  4436]  train_loss: 0.605  |  valid_loss: 0.585\n",
      "[epoch: 25, i:  4523]  train_loss: 0.518  |  valid_loss: 0.728\n",
      "[epoch: 25, i:  4610]  train_loss: 0.588  |  valid_loss: 0.550\n",
      "[epoch: 25, i:  4697]  train_loss: 0.601  |  valid_loss: 0.586\n",
      "[epoch: 25, i:  4784]  train_loss: 0.601  |  valid_loss: 0.628\n",
      "[epoch: 25, i:  4871]  train_loss: 0.539  |  valid_loss: 0.715\n",
      "[epoch: 25, i:  4958]  train_loss: 0.488  |  valid_loss: 0.809\n",
      "[epoch: 25, i:  5045]  train_loss: 0.585  |  valid_loss: 0.455\n",
      "[epoch: 25, i:  5132]  train_loss: 0.542  |  valid_loss: 0.601\n",
      "[epoch: 25, i:  5219]  train_loss: 0.560  |  valid_loss: 0.769\n",
      "[epoch: 25, i:  5306]  train_loss: 0.555  |  valid_loss: 0.710\n",
      "[epoch: 25, i:  5393]  train_loss: 0.545  |  valid_loss: 0.539\n",
      "[epoch: 25, i:  5480]  train_loss: 0.612  |  valid_loss: 0.758\n",
      "[epoch: 25, i:  5567]  train_loss: 0.574  |  valid_loss: 0.346\n",
      "[epoch: 25, i:  5654]  train_loss: 0.583  |  valid_loss: 0.608\n",
      "[epoch: 25, i:  5741]  train_loss: 0.563  |  valid_loss: 0.694\n",
      "[epoch: 25, i:  5828]  train_loss: 0.546  |  valid_loss: 0.614\n",
      "[epoch: 25, i:  5915]  train_loss: 0.622  |  valid_loss: 0.726\n",
      "[epoch: 25, i:  6002]  train_loss: 0.645  |  valid_loss: 0.531\n",
      "[epoch: 25, i:  6089]  train_loss: 0.640  |  valid_loss: 0.757\n",
      "[epoch: 25, i:  6176]  train_loss: 0.625  |  valid_loss: 0.673\n",
      "[epoch: 25, i:  6263]  train_loss: 0.582  |  valid_loss: 0.627\n",
      "[epoch: 25, i:  6350]  train_loss: 0.539  |  valid_loss: 0.483\n",
      "[epoch: 25, i:  6437]  train_loss: 0.583  |  valid_loss: 0.387\n",
      "[epoch: 25, i:  6524]  train_loss: 0.573  |  valid_loss: 0.754\n",
      "[epoch: 25, i:  6611]  train_loss: 0.553  |  valid_loss: 0.519\n",
      "[epoch: 25, i:  6698]  train_loss: 0.687  |  valid_loss: 0.636\n",
      "[epoch: 25, i:  6785]  train_loss: 0.531  |  valid_loss: 0.506\n",
      "[epoch: 25, i:  6872]  train_loss: 0.541  |  valid_loss: 0.753\n",
      "[epoch: 25, i:  6959]  train_loss: 0.546  |  valid_loss: 0.712\n",
      "[epoch: 25, i:  7046]  train_loss: 0.590  |  valid_loss: 0.674\n",
      "[epoch: 25, i:  7133]  train_loss: 0.643  |  valid_loss: 0.586\n",
      "[epoch: 25, i:  7220]  train_loss: 0.560  |  valid_loss: 0.756\n",
      "[epoch: 25, i:  7307]  train_loss: 0.614  |  valid_loss: 0.749\n",
      "[epoch: 25, i:  7394]  train_loss: 0.618  |  valid_loss: 0.593\n",
      "[epoch: 25, i:  7481]  train_loss: 0.547  |  valid_loss: 0.642\n",
      "[epoch: 25, i:  7568]  train_loss: 0.630  |  valid_loss: 0.796\n",
      "[epoch: 25, i:  7655]  train_loss: 0.563  |  valid_loss: 0.591\n",
      "[epoch: 25, i:  7742]  train_loss: 0.546  |  valid_loss: 0.573\n",
      "[epoch: 25, i:  7829]  train_loss: 0.527  |  valid_loss: 0.417\n",
      "[epoch: 25, i:  7916]  train_loss: 0.621  |  valid_loss: 0.665\n",
      "[epoch: 25, i:  8003]  train_loss: 0.549  |  valid_loss: 0.528\n",
      "[epoch: 25, i:  8090]  train_loss: 0.573  |  valid_loss: 0.489\n",
      "[epoch: 25, i:  8177]  train_loss: 0.580  |  valid_loss: 0.649\n",
      "[epoch: 25, i:  8264]  train_loss: 0.653  |  valid_loss: 0.682\n",
      "[epoch: 25, i:  8351]  train_loss: 0.555  |  valid_loss: 0.662\n",
      "[epoch: 25, i:  8438]  train_loss: 0.556  |  valid_loss: 0.436\n",
      "[epoch: 25, i:  8525]  train_loss: 0.571  |  valid_loss: 0.628\n",
      "[epoch: 25, i:  8612]  train_loss: 0.507  |  valid_loss: 0.821\n",
      "[epoch: 25, i:  8699]  train_loss: 0.567  |  valid_loss: 0.638\n",
      "--> [End of epoch 25] train_accuracy: 80.25%  |  valid_accuracy: 78.94%\n",
      "--> [Start of epoch 26]  lr: 0.000500\n",
      "[epoch: 26, i:    86]  train_loss: 0.531  |  valid_loss: 0.544\n",
      "[epoch: 26, i:   173]  train_loss: 0.575  |  valid_loss: 0.591\n",
      "[epoch: 26, i:   260]  train_loss: 0.497  |  valid_loss: 0.658\n",
      "[epoch: 26, i:   347]  train_loss: 0.499  |  valid_loss: 0.506\n",
      "[epoch: 26, i:   434]  train_loss: 0.507  |  valid_loss: 0.713\n",
      "[epoch: 26, i:   521]  train_loss: 0.531  |  valid_loss: 0.378\n",
      "[epoch: 26, i:   608]  train_loss: 0.519  |  valid_loss: 0.692\n",
      "[epoch: 26, i:   695]  train_loss: 0.579  |  valid_loss: 0.712\n",
      "[epoch: 26, i:   782]  train_loss: 0.531  |  valid_loss: 0.757\n",
      "[epoch: 26, i:   869]  train_loss: 0.566  |  valid_loss: 0.678\n",
      "[epoch: 26, i:   956]  train_loss: 0.557  |  valid_loss: 0.530\n",
      "[epoch: 26, i:  1043]  train_loss: 0.557  |  valid_loss: 0.605\n",
      "[epoch: 26, i:  1130]  train_loss: 0.531  |  valid_loss: 0.510\n",
      "[epoch: 26, i:  1217]  train_loss: 0.554  |  valid_loss: 0.609\n",
      "[epoch: 26, i:  1304]  train_loss: 0.584  |  valid_loss: 0.442\n",
      "[epoch: 26, i:  1391]  train_loss: 0.574  |  valid_loss: 0.707\n",
      "[epoch: 26, i:  1478]  train_loss: 0.523  |  valid_loss: 0.647\n",
      "[epoch: 26, i:  1565]  train_loss: 0.590  |  valid_loss: 0.767\n",
      "[epoch: 26, i:  1652]  train_loss: 0.549  |  valid_loss: 0.595\n",
      "[epoch: 26, i:  1739]  train_loss: 0.564  |  valid_loss: 0.865\n",
      "[epoch: 26, i:  1826]  train_loss: 0.575  |  valid_loss: 0.753\n",
      "[epoch: 26, i:  1913]  train_loss: 0.554  |  valid_loss: 0.643\n",
      "[epoch: 26, i:  2000]  train_loss: 0.611  |  valid_loss: 0.681\n",
      "[epoch: 26, i:  2087]  train_loss: 0.573  |  valid_loss: 0.804\n",
      "[epoch: 26, i:  2174]  train_loss: 0.551  |  valid_loss: 0.552\n",
      "[epoch: 26, i:  2261]  train_loss: 0.525  |  valid_loss: 0.947\n",
      "[epoch: 26, i:  2348]  train_loss: 0.543  |  valid_loss: 0.497\n",
      "[epoch: 26, i:  2435]  train_loss: 0.519  |  valid_loss: 0.686\n",
      "[epoch: 26, i:  2522]  train_loss: 0.575  |  valid_loss: 0.461\n",
      "[epoch: 26, i:  2609]  train_loss: 0.567  |  valid_loss: 0.626\n",
      "[epoch: 26, i:  2696]  train_loss: 0.572  |  valid_loss: 0.701\n",
      "[epoch: 26, i:  2783]  train_loss: 0.564  |  valid_loss: 0.440\n",
      "[epoch: 26, i:  2870]  train_loss: 0.567  |  valid_loss: 0.722\n",
      "[epoch: 26, i:  2957]  train_loss: 0.538  |  valid_loss: 0.788\n",
      "[epoch: 26, i:  3044]  train_loss: 0.594  |  valid_loss: 0.725\n",
      "[epoch: 26, i:  3131]  train_loss: 0.550  |  valid_loss: 0.648\n",
      "[epoch: 26, i:  3218]  train_loss: 0.544  |  valid_loss: 0.710\n",
      "[epoch: 26, i:  3305]  train_loss: 0.586  |  valid_loss: 0.675\n",
      "[epoch: 26, i:  3392]  train_loss: 0.594  |  valid_loss: 0.596\n",
      "[epoch: 26, i:  3479]  train_loss: 0.581  |  valid_loss: 0.524\n",
      "[epoch: 26, i:  3566]  train_loss: 0.582  |  valid_loss: 0.633\n",
      "[epoch: 26, i:  3653]  train_loss: 0.571  |  valid_loss: 0.748\n",
      "[epoch: 26, i:  3740]  train_loss: 0.473  |  valid_loss: 0.469\n",
      "[epoch: 26, i:  3827]  train_loss: 0.582  |  valid_loss: 0.855\n",
      "[epoch: 26, i:  3914]  train_loss: 0.618  |  valid_loss: 0.488\n",
      "[epoch: 26, i:  4001]  train_loss: 0.597  |  valid_loss: 0.634\n",
      "[epoch: 26, i:  4088]  train_loss: 0.600  |  valid_loss: 0.556\n",
      "[epoch: 26, i:  4175]  train_loss: 0.506  |  valid_loss: 0.551\n",
      "[epoch: 26, i:  4262]  train_loss: 0.532  |  valid_loss: 0.490\n",
      "[epoch: 26, i:  4349]  train_loss: 0.594  |  valid_loss: 0.579\n",
      "[epoch: 26, i:  4436]  train_loss: 0.583  |  valid_loss: 0.585\n",
      "[epoch: 26, i:  4523]  train_loss: 0.517  |  valid_loss: 0.640\n",
      "[epoch: 26, i:  4610]  train_loss: 0.600  |  valid_loss: 0.525\n",
      "[epoch: 26, i:  4697]  train_loss: 0.638  |  valid_loss: 0.550\n",
      "[epoch: 26, i:  4784]  train_loss: 0.554  |  valid_loss: 0.634\n",
      "[epoch: 26, i:  4871]  train_loss: 0.614  |  valid_loss: 0.733\n",
      "[epoch: 26, i:  4958]  train_loss: 0.603  |  valid_loss: 0.737\n",
      "[epoch: 26, i:  5045]  train_loss: 0.578  |  valid_loss: 0.454\n",
      "[epoch: 26, i:  5132]  train_loss: 0.557  |  valid_loss: 0.585\n",
      "[epoch: 26, i:  5219]  train_loss: 0.514  |  valid_loss: 0.762\n",
      "[epoch: 26, i:  5306]  train_loss: 0.534  |  valid_loss: 0.701\n",
      "[epoch: 26, i:  5393]  train_loss: 0.563  |  valid_loss: 0.569\n",
      "[epoch: 26, i:  5480]  train_loss: 0.589  |  valid_loss: 0.823\n",
      "[epoch: 26, i:  5567]  train_loss: 0.534  |  valid_loss: 0.418\n",
      "[epoch: 26, i:  5654]  train_loss: 0.606  |  valid_loss: 0.587\n",
      "[epoch: 26, i:  5741]  train_loss: 0.601  |  valid_loss: 0.737\n",
      "[epoch: 26, i:  5828]  train_loss: 0.565  |  valid_loss: 0.626\n",
      "[epoch: 26, i:  5915]  train_loss: 0.584  |  valid_loss: 0.753\n",
      "[epoch: 26, i:  6002]  train_loss: 0.556  |  valid_loss: 0.526\n",
      "[epoch: 26, i:  6089]  train_loss: 0.549  |  valid_loss: 0.766\n",
      "[epoch: 26, i:  6176]  train_loss: 0.578  |  valid_loss: 0.725\n",
      "[epoch: 26, i:  6263]  train_loss: 0.517  |  valid_loss: 0.558\n",
      "[epoch: 26, i:  6350]  train_loss: 0.562  |  valid_loss: 0.593\n",
      "[epoch: 26, i:  6437]  train_loss: 0.612  |  valid_loss: 0.413\n",
      "[epoch: 26, i:  6524]  train_loss: 0.594  |  valid_loss: 0.766\n",
      "[epoch: 26, i:  6611]  train_loss: 0.545  |  valid_loss: 0.437\n",
      "[epoch: 26, i:  6698]  train_loss: 0.609  |  valid_loss: 0.698\n",
      "[epoch: 26, i:  6785]  train_loss: 0.557  |  valid_loss: 0.445\n",
      "[epoch: 26, i:  6872]  train_loss: 0.594  |  valid_loss: 0.750\n",
      "[epoch: 26, i:  6959]  train_loss: 0.517  |  valid_loss: 0.750\n",
      "[epoch: 26, i:  7046]  train_loss: 0.641  |  valid_loss: 0.619\n",
      "[epoch: 26, i:  7133]  train_loss: 0.564  |  valid_loss: 0.565\n",
      "[epoch: 26, i:  7220]  train_loss: 0.628  |  valid_loss: 0.705\n",
      "[epoch: 26, i:  7307]  train_loss: 0.618  |  valid_loss: 0.775\n",
      "[epoch: 26, i:  7394]  train_loss: 0.557  |  valid_loss: 0.567\n",
      "[epoch: 26, i:  7481]  train_loss: 0.627  |  valid_loss: 0.603\n",
      "[epoch: 26, i:  7568]  train_loss: 0.554  |  valid_loss: 0.740\n",
      "[epoch: 26, i:  7655]  train_loss: 0.575  |  valid_loss: 0.684\n",
      "[epoch: 26, i:  7742]  train_loss: 0.549  |  valid_loss: 0.624\n",
      "[epoch: 26, i:  7829]  train_loss: 0.571  |  valid_loss: 0.457\n",
      "[epoch: 26, i:  7916]  train_loss: 0.576  |  valid_loss: 0.741\n",
      "[epoch: 26, i:  8003]  train_loss: 0.607  |  valid_loss: 0.558\n",
      "[epoch: 26, i:  8090]  train_loss: 0.602  |  valid_loss: 0.498\n",
      "[epoch: 26, i:  8177]  train_loss: 0.597  |  valid_loss: 0.618\n",
      "[epoch: 26, i:  8264]  train_loss: 0.582  |  valid_loss: 0.647\n",
      "[epoch: 26, i:  8351]  train_loss: 0.579  |  valid_loss: 0.653\n",
      "[epoch: 26, i:  8438]  train_loss: 0.588  |  valid_loss: 0.459\n",
      "[epoch: 26, i:  8525]  train_loss: 0.619  |  valid_loss: 0.603\n",
      "[epoch: 26, i:  8612]  train_loss: 0.560  |  valid_loss: 0.852\n",
      "[epoch: 26, i:  8699]  train_loss: 0.622  |  valid_loss: 0.661\n",
      "--> [End of epoch 26] train_accuracy: 80.21%  |  valid_accuracy: 78.68%\n",
      "--> [Start of epoch 27]  lr: 0.000500\n",
      "[epoch: 27, i:    86]  train_loss: 0.492  |  valid_loss: 0.504\n",
      "[epoch: 27, i:   173]  train_loss: 0.578  |  valid_loss: 0.563\n",
      "[epoch: 27, i:   260]  train_loss: 0.563  |  valid_loss: 0.719\n",
      "[epoch: 27, i:   347]  train_loss: 0.534  |  valid_loss: 0.527\n",
      "[epoch: 27, i:   434]  train_loss: 0.455  |  valid_loss: 0.687\n",
      "[epoch: 27, i:   521]  train_loss: 0.603  |  valid_loss: 0.412\n",
      "[epoch: 27, i:   608]  train_loss: 0.482  |  valid_loss: 0.666\n",
      "[epoch: 27, i:   695]  train_loss: 0.577  |  valid_loss: 0.598\n",
      "[epoch: 27, i:   782]  train_loss: 0.526  |  valid_loss: 0.791\n",
      "[epoch: 27, i:   869]  train_loss: 0.526  |  valid_loss: 0.688\n",
      "[epoch: 27, i:   956]  train_loss: 0.508  |  valid_loss: 0.589\n",
      "[epoch: 27, i:  1043]  train_loss: 0.559  |  valid_loss: 0.573\n",
      "[epoch: 27, i:  1130]  train_loss: 0.531  |  valid_loss: 0.607\n",
      "[epoch: 27, i:  1217]  train_loss: 0.621  |  valid_loss: 0.608\n",
      "[epoch: 27, i:  1304]  train_loss: 0.616  |  valid_loss: 0.432\n",
      "[epoch: 27, i:  1391]  train_loss: 0.573  |  valid_loss: 0.692\n",
      "[epoch: 27, i:  1478]  train_loss: 0.516  |  valid_loss: 0.608\n",
      "[epoch: 27, i:  1565]  train_loss: 0.570  |  valid_loss: 0.781\n",
      "[epoch: 27, i:  1652]  train_loss: 0.555  |  valid_loss: 0.568\n",
      "[epoch: 27, i:  1739]  train_loss: 0.553  |  valid_loss: 0.824\n",
      "[epoch: 27, i:  1826]  train_loss: 0.539  |  valid_loss: 0.790\n",
      "[epoch: 27, i:  1913]  train_loss: 0.621  |  valid_loss: 0.668\n",
      "[epoch: 27, i:  2000]  train_loss: 0.502  |  valid_loss: 0.595\n",
      "[epoch: 27, i:  2087]  train_loss: 0.570  |  valid_loss: 0.723\n",
      "[epoch: 27, i:  2174]  train_loss: 0.591  |  valid_loss: 0.540\n",
      "[epoch: 27, i:  2261]  train_loss: 0.605  |  valid_loss: 0.898\n",
      "[epoch: 27, i:  2348]  train_loss: 0.591  |  valid_loss: 0.556\n",
      "[epoch: 27, i:  2435]  train_loss: 0.542  |  valid_loss: 0.640\n",
      "[epoch: 27, i:  2522]  train_loss: 0.601  |  valid_loss: 0.479\n",
      "[epoch: 27, i:  2609]  train_loss: 0.551  |  valid_loss: 0.553\n",
      "[epoch: 27, i:  2696]  train_loss: 0.623  |  valid_loss: 0.675\n",
      "[epoch: 27, i:  2783]  train_loss: 0.617  |  valid_loss: 0.477\n",
      "[epoch: 27, i:  2870]  train_loss: 0.579  |  valid_loss: 0.765\n",
      "[epoch: 27, i:  2957]  train_loss: 0.554  |  valid_loss: 0.645\n",
      "[epoch: 27, i:  3044]  train_loss: 0.538  |  valid_loss: 0.765\n",
      "[epoch: 27, i:  3131]  train_loss: 0.518  |  valid_loss: 0.658\n",
      "[epoch: 27, i:  3218]  train_loss: 0.603  |  valid_loss: 0.715\n",
      "[epoch: 27, i:  3305]  train_loss: 0.545  |  valid_loss: 0.604\n",
      "[epoch: 27, i:  3392]  train_loss: 0.555  |  valid_loss: 0.627\n",
      "[epoch: 27, i:  3479]  train_loss: 0.589  |  valid_loss: 0.480\n",
      "[epoch: 27, i:  3566]  train_loss: 0.584  |  valid_loss: 0.653\n",
      "[epoch: 27, i:  3653]  train_loss: 0.576  |  valid_loss: 0.683\n",
      "[epoch: 27, i:  3740]  train_loss: 0.543  |  valid_loss: 0.366\n",
      "[epoch: 27, i:  3827]  train_loss: 0.556  |  valid_loss: 0.812\n",
      "[epoch: 27, i:  3914]  train_loss: 0.572  |  valid_loss: 0.460\n",
      "[epoch: 27, i:  4001]  train_loss: 0.573  |  valid_loss: 0.640\n",
      "[epoch: 27, i:  4088]  train_loss: 0.568  |  valid_loss: 0.570\n",
      "[epoch: 27, i:  4175]  train_loss: 0.596  |  valid_loss: 0.574\n",
      "[epoch: 27, i:  4262]  train_loss: 0.591  |  valid_loss: 0.590\n",
      "[epoch: 27, i:  4349]  train_loss: 0.575  |  valid_loss: 0.675\n",
      "[epoch: 27, i:  4436]  train_loss: 0.575  |  valid_loss: 0.541\n",
      "[epoch: 27, i:  4523]  train_loss: 0.582  |  valid_loss: 0.725\n",
      "[epoch: 27, i:  4610]  train_loss: 0.586  |  valid_loss: 0.586\n",
      "[epoch: 27, i:  4697]  train_loss: 0.554  |  valid_loss: 0.600\n",
      "[epoch: 27, i:  4784]  train_loss: 0.569  |  valid_loss: 0.686\n",
      "[epoch: 27, i:  4871]  train_loss: 0.555  |  valid_loss: 0.755\n",
      "[epoch: 27, i:  4958]  train_loss: 0.515  |  valid_loss: 0.776\n",
      "[epoch: 27, i:  5045]  train_loss: 0.610  |  valid_loss: 0.442\n",
      "[epoch: 27, i:  5132]  train_loss: 0.589  |  valid_loss: 0.675\n",
      "[epoch: 27, i:  5219]  train_loss: 0.588  |  valid_loss: 0.678\n",
      "[epoch: 27, i:  5306]  train_loss: 0.615  |  valid_loss: 0.682\n",
      "[epoch: 27, i:  5393]  train_loss: 0.620  |  valid_loss: 0.578\n",
      "[epoch: 27, i:  5480]  train_loss: 0.584  |  valid_loss: 0.866\n",
      "[epoch: 27, i:  5567]  train_loss: 0.624  |  valid_loss: 0.381\n",
      "[epoch: 27, i:  5654]  train_loss: 0.494  |  valid_loss: 0.614\n",
      "[epoch: 27, i:  5741]  train_loss: 0.593  |  valid_loss: 0.682\n",
      "[epoch: 27, i:  5828]  train_loss: 0.601  |  valid_loss: 0.687\n",
      "[epoch: 27, i:  5915]  train_loss: 0.552  |  valid_loss: 0.724\n",
      "[epoch: 27, i:  6002]  train_loss: 0.577  |  valid_loss: 0.480\n",
      "[epoch: 27, i:  6089]  train_loss: 0.570  |  valid_loss: 0.837\n",
      "[epoch: 27, i:  6176]  train_loss: 0.603  |  valid_loss: 0.660\n",
      "[epoch: 27, i:  6263]  train_loss: 0.643  |  valid_loss: 0.561\n",
      "[epoch: 27, i:  6350]  train_loss: 0.577  |  valid_loss: 0.558\n",
      "[epoch: 27, i:  6437]  train_loss: 0.568  |  valid_loss: 0.373\n",
      "[epoch: 27, i:  6524]  train_loss: 0.534  |  valid_loss: 0.798\n",
      "[epoch: 27, i:  6611]  train_loss: 0.585  |  valid_loss: 0.421\n",
      "[epoch: 27, i:  6698]  train_loss: 0.564  |  valid_loss: 0.772\n",
      "[epoch: 27, i:  6785]  train_loss: 0.634  |  valid_loss: 0.518\n",
      "[epoch: 27, i:  6872]  train_loss: 0.528  |  valid_loss: 0.695\n",
      "[epoch: 27, i:  6959]  train_loss: 0.581  |  valid_loss: 0.690\n",
      "[epoch: 27, i:  7046]  train_loss: 0.562  |  valid_loss: 0.651\n",
      "[epoch: 27, i:  7133]  train_loss: 0.526  |  valid_loss: 0.571\n",
      "[epoch: 27, i:  7220]  train_loss: 0.584  |  valid_loss: 0.755\n",
      "[epoch: 27, i:  7307]  train_loss: 0.573  |  valid_loss: 0.741\n",
      "[epoch: 27, i:  7394]  train_loss: 0.517  |  valid_loss: 0.609\n",
      "[epoch: 27, i:  7481]  train_loss: 0.539  |  valid_loss: 0.538\n",
      "[epoch: 27, i:  7568]  train_loss: 0.576  |  valid_loss: 0.749\n",
      "[epoch: 27, i:  7655]  train_loss: 0.567  |  valid_loss: 0.619\n",
      "[epoch: 27, i:  7742]  train_loss: 0.538  |  valid_loss: 0.731\n",
      "[epoch: 27, i:  7829]  train_loss: 0.637  |  valid_loss: 0.454\n",
      "[epoch: 27, i:  7916]  train_loss: 0.581  |  valid_loss: 0.683\n",
      "[epoch: 27, i:  8003]  train_loss: 0.537  |  valid_loss: 0.518\n",
      "[epoch: 27, i:  8090]  train_loss: 0.579  |  valid_loss: 0.517\n",
      "[epoch: 27, i:  8177]  train_loss: 0.555  |  valid_loss: 0.571\n",
      "[epoch: 27, i:  8264]  train_loss: 0.559  |  valid_loss: 0.614\n",
      "[epoch: 27, i:  8351]  train_loss: 0.575  |  valid_loss: 0.749\n",
      "[epoch: 27, i:  8438]  train_loss: 0.596  |  valid_loss: 0.484\n",
      "[epoch: 27, i:  8525]  train_loss: 0.536  |  valid_loss: 0.611\n",
      "[epoch: 27, i:  8612]  train_loss: 0.600  |  valid_loss: 0.892\n",
      "[epoch: 27, i:  8699]  train_loss: 0.570  |  valid_loss: 0.636\n",
      "--> [End of epoch 27] train_accuracy: 80.35%  |  valid_accuracy: 78.82%\n",
      "--> [Start of epoch 28]  lr: 0.000500\n",
      "[epoch: 28, i:    86]  train_loss: 0.536  |  valid_loss: 0.486\n",
      "[epoch: 28, i:   173]  train_loss: 0.489  |  valid_loss: 0.518\n",
      "[epoch: 28, i:   260]  train_loss: 0.561  |  valid_loss: 0.649\n",
      "[epoch: 28, i:   347]  train_loss: 0.584  |  valid_loss: 0.547\n",
      "[epoch: 28, i:   434]  train_loss: 0.551  |  valid_loss: 0.689\n",
      "[epoch: 28, i:   521]  train_loss: 0.585  |  valid_loss: 0.426\n",
      "[epoch: 28, i:   608]  train_loss: 0.528  |  valid_loss: 0.651\n",
      "[epoch: 28, i:   695]  train_loss: 0.563  |  valid_loss: 0.569\n",
      "[epoch: 28, i:   782]  train_loss: 0.556  |  valid_loss: 0.760\n",
      "[epoch: 28, i:   869]  train_loss: 0.572  |  valid_loss: 0.673\n",
      "[epoch: 28, i:   956]  train_loss: 0.530  |  valid_loss: 0.561\n",
      "[epoch: 28, i:  1043]  train_loss: 0.520  |  valid_loss: 0.561\n",
      "[epoch: 28, i:  1130]  train_loss: 0.528  |  valid_loss: 0.522\n",
      "[epoch: 28, i:  1217]  train_loss: 0.492  |  valid_loss: 0.590\n",
      "[epoch: 28, i:  1304]  train_loss: 0.566  |  valid_loss: 0.535\n",
      "[epoch: 28, i:  1391]  train_loss: 0.556  |  valid_loss: 0.645\n",
      "[epoch: 28, i:  1478]  train_loss: 0.548  |  valid_loss: 0.691\n",
      "[epoch: 28, i:  1565]  train_loss: 0.490  |  valid_loss: 0.725\n",
      "[epoch: 28, i:  1652]  train_loss: 0.550  |  valid_loss: 0.588\n",
      "[epoch: 28, i:  1739]  train_loss: 0.545  |  valid_loss: 0.850\n",
      "[epoch: 28, i:  1826]  train_loss: 0.616  |  valid_loss: 0.810\n",
      "[epoch: 28, i:  1913]  train_loss: 0.560  |  valid_loss: 0.641\n",
      "[epoch: 28, i:  2000]  train_loss: 0.505  |  valid_loss: 0.654\n",
      "[epoch: 28, i:  2087]  train_loss: 0.512  |  valid_loss: 0.781\n",
      "[epoch: 28, i:  2174]  train_loss: 0.468  |  valid_loss: 0.582\n",
      "[epoch: 28, i:  2261]  train_loss: 0.538  |  valid_loss: 0.837\n",
      "[epoch: 28, i:  2348]  train_loss: 0.569  |  valid_loss: 0.490\n",
      "[epoch: 28, i:  2435]  train_loss: 0.522  |  valid_loss: 0.610\n",
      "[epoch: 28, i:  2522]  train_loss: 0.572  |  valid_loss: 0.538\n",
      "[epoch: 28, i:  2609]  train_loss: 0.558  |  valid_loss: 0.553\n",
      "[epoch: 28, i:  2696]  train_loss: 0.576  |  valid_loss: 0.698\n",
      "[epoch: 28, i:  2783]  train_loss: 0.494  |  valid_loss: 0.445\n",
      "[epoch: 28, i:  2870]  train_loss: 0.561  |  valid_loss: 0.720\n",
      "[epoch: 28, i:  2957]  train_loss: 0.554  |  valid_loss: 0.631\n",
      "[epoch: 28, i:  3044]  train_loss: 0.547  |  valid_loss: 0.740\n",
      "[epoch: 28, i:  3131]  train_loss: 0.591  |  valid_loss: 0.602\n",
      "[epoch: 28, i:  3218]  train_loss: 0.483  |  valid_loss: 0.669\n",
      "[epoch: 28, i:  3305]  train_loss: 0.607  |  valid_loss: 0.543\n",
      "[epoch: 28, i:  3392]  train_loss: 0.623  |  valid_loss: 0.503\n",
      "[epoch: 28, i:  3479]  train_loss: 0.518  |  valid_loss: 0.500\n",
      "[epoch: 28, i:  3566]  train_loss: 0.534  |  valid_loss: 0.554\n",
      "[epoch: 28, i:  3653]  train_loss: 0.516  |  valid_loss: 0.704\n",
      "[epoch: 28, i:  3740]  train_loss: 0.614  |  valid_loss: 0.463\n",
      "[epoch: 28, i:  3827]  train_loss: 0.561  |  valid_loss: 0.792\n",
      "[epoch: 28, i:  3914]  train_loss: 0.554  |  valid_loss: 0.565\n",
      "[epoch: 28, i:  4001]  train_loss: 0.613  |  valid_loss: 0.580\n",
      "[epoch: 28, i:  4088]  train_loss: 0.572  |  valid_loss: 0.616\n",
      "[epoch: 28, i:  4175]  train_loss: 0.538  |  valid_loss: 0.602\n",
      "[epoch: 28, i:  4262]  train_loss: 0.573  |  valid_loss: 0.490\n",
      "[epoch: 28, i:  4349]  train_loss: 0.525  |  valid_loss: 0.504\n",
      "[epoch: 28, i:  4436]  train_loss: 0.597  |  valid_loss: 0.594\n",
      "[epoch: 28, i:  4523]  train_loss: 0.600  |  valid_loss: 0.715\n",
      "[epoch: 28, i:  4610]  train_loss: 0.586  |  valid_loss: 0.553\n",
      "[epoch: 28, i:  4697]  train_loss: 0.608  |  valid_loss: 0.561\n",
      "[epoch: 28, i:  4784]  train_loss: 0.554  |  valid_loss: 0.614\n",
      "[epoch: 28, i:  4871]  train_loss: 0.629  |  valid_loss: 0.709\n",
      "[epoch: 28, i:  4958]  train_loss: 0.597  |  valid_loss: 0.831\n",
      "[epoch: 28, i:  5045]  train_loss: 0.569  |  valid_loss: 0.457\n",
      "[epoch: 28, i:  5132]  train_loss: 0.596  |  valid_loss: 0.672\n",
      "[epoch: 28, i:  5219]  train_loss: 0.660  |  valid_loss: 0.769\n",
      "[epoch: 28, i:  5306]  train_loss: 0.561  |  valid_loss: 0.647\n",
      "[epoch: 28, i:  5393]  train_loss: 0.577  |  valid_loss: 0.578\n",
      "[epoch: 28, i:  5480]  train_loss: 0.543  |  valid_loss: 0.777\n",
      "[epoch: 28, i:  5567]  train_loss: 0.577  |  valid_loss: 0.350\n",
      "[epoch: 28, i:  5654]  train_loss: 0.595  |  valid_loss: 0.659\n",
      "[epoch: 28, i:  5741]  train_loss: 0.623  |  valid_loss: 0.725\n",
      "[epoch: 28, i:  5828]  train_loss: 0.534  |  valid_loss: 0.631\n",
      "[epoch: 28, i:  5915]  train_loss: 0.567  |  valid_loss: 0.763\n",
      "[epoch: 28, i:  6002]  train_loss: 0.576  |  valid_loss: 0.501\n",
      "[epoch: 28, i:  6089]  train_loss: 0.550  |  valid_loss: 0.713\n",
      "[epoch: 28, i:  6176]  train_loss: 0.575  |  valid_loss: 0.631\n",
      "[epoch: 28, i:  6263]  train_loss: 0.574  |  valid_loss: 0.525\n",
      "[epoch: 28, i:  6350]  train_loss: 0.634  |  valid_loss: 0.569\n",
      "[epoch: 28, i:  6437]  train_loss: 0.611  |  valid_loss: 0.400\n",
      "[epoch: 28, i:  6524]  train_loss: 0.595  |  valid_loss: 0.807\n",
      "[epoch: 28, i:  6611]  train_loss: 0.556  |  valid_loss: 0.409\n",
      "[epoch: 28, i:  6698]  train_loss: 0.575  |  valid_loss: 0.725\n",
      "[epoch: 28, i:  6785]  train_loss: 0.545  |  valid_loss: 0.492\n",
      "[epoch: 28, i:  6872]  train_loss: 0.559  |  valid_loss: 0.748\n",
      "[epoch: 28, i:  6959]  train_loss: 0.511  |  valid_loss: 0.676\n",
      "[epoch: 28, i:  7046]  train_loss: 0.582  |  valid_loss: 0.589\n",
      "[epoch: 28, i:  7133]  train_loss: 0.571  |  valid_loss: 0.523\n",
      "[epoch: 28, i:  7220]  train_loss: 0.576  |  valid_loss: 0.689\n",
      "[epoch: 28, i:  7307]  train_loss: 0.594  |  valid_loss: 0.719\n",
      "[epoch: 28, i:  7394]  train_loss: 0.526  |  valid_loss: 0.555\n",
      "[epoch: 28, i:  7481]  train_loss: 0.564  |  valid_loss: 0.545\n",
      "[epoch: 28, i:  7568]  train_loss: 0.609  |  valid_loss: 0.717\n",
      "[epoch: 28, i:  7655]  train_loss: 0.525  |  valid_loss: 0.602\n",
      "[epoch: 28, i:  7742]  train_loss: 0.556  |  valid_loss: 0.603\n",
      "[epoch: 28, i:  7829]  train_loss: 0.539  |  valid_loss: 0.461\n",
      "[epoch: 28, i:  7916]  train_loss: 0.521  |  valid_loss: 0.700\n",
      "[epoch: 28, i:  8003]  train_loss: 0.677  |  valid_loss: 0.469\n",
      "[epoch: 28, i:  8090]  train_loss: 0.533  |  valid_loss: 0.552\n",
      "[epoch: 28, i:  8177]  train_loss: 0.651  |  valid_loss: 0.564\n",
      "[epoch: 28, i:  8264]  train_loss: 0.588  |  valid_loss: 0.571\n",
      "[epoch: 28, i:  8351]  train_loss: 0.557  |  valid_loss: 0.670\n",
      "[epoch: 28, i:  8438]  train_loss: 0.564  |  valid_loss: 0.506\n",
      "[epoch: 28, i:  8525]  train_loss: 0.525  |  valid_loss: 0.594\n",
      "[epoch: 28, i:  8612]  train_loss: 0.579  |  valid_loss: 0.823\n",
      "[epoch: 28, i:  8699]  train_loss: 0.617  |  valid_loss: 0.656\n",
      "--> [End of epoch 28] train_accuracy: 80.39%  |  valid_accuracy: 78.82%\n",
      "--> [Start of epoch 29]  lr: 0.000500\n",
      "[epoch: 29, i:    86]  train_loss: 0.542  |  valid_loss: 0.581\n",
      "[epoch: 29, i:   173]  train_loss: 0.585  |  valid_loss: 0.595\n",
      "[epoch: 29, i:   260]  train_loss: 0.536  |  valid_loss: 0.688\n",
      "[epoch: 29, i:   347]  train_loss: 0.505  |  valid_loss: 0.558\n",
      "[epoch: 29, i:   434]  train_loss: 0.482  |  valid_loss: 0.704\n",
      "[epoch: 29, i:   521]  train_loss: 0.547  |  valid_loss: 0.425\n",
      "[epoch: 29, i:   608]  train_loss: 0.629  |  valid_loss: 0.632\n",
      "[epoch: 29, i:   695]  train_loss: 0.593  |  valid_loss: 0.678\n",
      "[epoch: 29, i:   782]  train_loss: 0.512  |  valid_loss: 0.686\n",
      "[epoch: 29, i:   869]  train_loss: 0.603  |  valid_loss: 0.692\n",
      "[epoch: 29, i:   956]  train_loss: 0.524  |  valid_loss: 0.536\n",
      "[epoch: 29, i:  1043]  train_loss: 0.513  |  valid_loss: 0.666\n",
      "[epoch: 29, i:  1130]  train_loss: 0.524  |  valid_loss: 0.551\n",
      "[epoch: 29, i:  1217]  train_loss: 0.514  |  valid_loss: 0.585\n",
      "[epoch: 29, i:  1304]  train_loss: 0.524  |  valid_loss: 0.465\n",
      "[epoch: 29, i:  1391]  train_loss: 0.501  |  valid_loss: 0.643\n",
      "[epoch: 29, i:  1478]  train_loss: 0.545  |  valid_loss: 0.639\n",
      "[epoch: 29, i:  1565]  train_loss: 0.593  |  valid_loss: 0.737\n",
      "[epoch: 29, i:  1652]  train_loss: 0.562  |  valid_loss: 0.625\n",
      "[epoch: 29, i:  1739]  train_loss: 0.609  |  valid_loss: 0.855\n",
      "[epoch: 29, i:  1826]  train_loss: 0.511  |  valid_loss: 0.752\n",
      "[epoch: 29, i:  1913]  train_loss: 0.505  |  valid_loss: 0.724\n",
      "[epoch: 29, i:  2000]  train_loss: 0.547  |  valid_loss: 0.707\n",
      "[epoch: 29, i:  2087]  train_loss: 0.555  |  valid_loss: 0.744\n",
      "[epoch: 29, i:  2174]  train_loss: 0.546  |  valid_loss: 0.581\n",
      "[epoch: 29, i:  2261]  train_loss: 0.525  |  valid_loss: 0.913\n",
      "[epoch: 29, i:  2348]  train_loss: 0.537  |  valid_loss: 0.515\n",
      "[epoch: 29, i:  2435]  train_loss: 0.558  |  valid_loss: 0.662\n",
      "[epoch: 29, i:  2522]  train_loss: 0.562  |  valid_loss: 0.510\n",
      "[epoch: 29, i:  2609]  train_loss: 0.554  |  valid_loss: 0.547\n",
      "[epoch: 29, i:  2696]  train_loss: 0.508  |  valid_loss: 0.664\n",
      "[epoch: 29, i:  2783]  train_loss: 0.575  |  valid_loss: 0.477\n",
      "[epoch: 29, i:  2870]  train_loss: 0.641  |  valid_loss: 0.693\n",
      "[epoch: 29, i:  2957]  train_loss: 0.513  |  valid_loss: 0.705\n",
      "[epoch: 29, i:  3044]  train_loss: 0.532  |  valid_loss: 0.699\n",
      "[epoch: 29, i:  3131]  train_loss: 0.549  |  valid_loss: 0.649\n",
      "[epoch: 29, i:  3218]  train_loss: 0.524  |  valid_loss: 0.673\n",
      "[epoch: 29, i:  3305]  train_loss: 0.503  |  valid_loss: 0.695\n",
      "[epoch: 29, i:  3392]  train_loss: 0.535  |  valid_loss: 0.571\n",
      "[epoch: 29, i:  3479]  train_loss: 0.501  |  valid_loss: 0.518\n",
      "[epoch: 29, i:  3566]  train_loss: 0.604  |  valid_loss: 0.583\n",
      "[epoch: 29, i:  3653]  train_loss: 0.543  |  valid_loss: 0.579\n",
      "[epoch: 29, i:  3740]  train_loss: 0.530  |  valid_loss: 0.438\n",
      "[epoch: 29, i:  3827]  train_loss: 0.560  |  valid_loss: 0.755\n",
      "[epoch: 29, i:  3914]  train_loss: 0.588  |  valid_loss: 0.459\n",
      "[epoch: 29, i:  4001]  train_loss: 0.562  |  valid_loss: 0.656\n",
      "[epoch: 29, i:  4088]  train_loss: 0.577  |  valid_loss: 0.658\n",
      "[epoch: 29, i:  4175]  train_loss: 0.601  |  valid_loss: 0.595\n",
      "[epoch: 29, i:  4262]  train_loss: 0.621  |  valid_loss: 0.480\n",
      "[epoch: 29, i:  4349]  train_loss: 0.574  |  valid_loss: 0.558\n",
      "[epoch: 29, i:  4436]  train_loss: 0.537  |  valid_loss: 0.611\n",
      "[epoch: 29, i:  4523]  train_loss: 0.563  |  valid_loss: 0.735\n",
      "[epoch: 29, i:  4610]  train_loss: 0.558  |  valid_loss: 0.555\n",
      "[epoch: 29, i:  4697]  train_loss: 0.568  |  valid_loss: 0.581\n",
      "[epoch: 29, i:  4784]  train_loss: 0.576  |  valid_loss: 0.676\n",
      "[epoch: 29, i:  4871]  train_loss: 0.528  |  valid_loss: 0.728\n",
      "[epoch: 29, i:  4958]  train_loss: 0.546  |  valid_loss: 0.831\n",
      "[epoch: 29, i:  5045]  train_loss: 0.579  |  valid_loss: 0.408\n",
      "[epoch: 29, i:  5132]  train_loss: 0.611  |  valid_loss: 0.584\n",
      "[epoch: 29, i:  5219]  train_loss: 0.545  |  valid_loss: 0.658\n",
      "[epoch: 29, i:  5306]  train_loss: 0.574  |  valid_loss: 0.631\n",
      "[epoch: 29, i:  5393]  train_loss: 0.595  |  valid_loss: 0.464\n",
      "[epoch: 29, i:  5480]  train_loss: 0.506  |  valid_loss: 0.851\n",
      "[epoch: 29, i:  5567]  train_loss: 0.505  |  valid_loss: 0.395\n",
      "[epoch: 29, i:  5654]  train_loss: 0.571  |  valid_loss: 0.594\n",
      "[epoch: 29, i:  5741]  train_loss: 0.514  |  valid_loss: 0.720\n",
      "[epoch: 29, i:  5828]  train_loss: 0.527  |  valid_loss: 0.557\n",
      "[epoch: 29, i:  5915]  train_loss: 0.553  |  valid_loss: 0.698\n",
      "[epoch: 29, i:  6002]  train_loss: 0.622  |  valid_loss: 0.537\n",
      "[epoch: 29, i:  6089]  train_loss: 0.563  |  valid_loss: 0.768\n",
      "[epoch: 29, i:  6176]  train_loss: 0.535  |  valid_loss: 0.727\n",
      "[epoch: 29, i:  6263]  train_loss: 0.516  |  valid_loss: 0.595\n",
      "[epoch: 29, i:  6350]  train_loss: 0.601  |  valid_loss: 0.582\n",
      "[epoch: 29, i:  6437]  train_loss: 0.507  |  valid_loss: 0.362\n",
      "[epoch: 29, i:  6524]  train_loss: 0.648  |  valid_loss: 0.798\n",
      "[epoch: 29, i:  6611]  train_loss: 0.670  |  valid_loss: 0.412\n",
      "[epoch: 29, i:  6698]  train_loss: 0.615  |  valid_loss: 0.736\n",
      "[epoch: 29, i:  6785]  train_loss: 0.602  |  valid_loss: 0.501\n",
      "[epoch: 29, i:  6872]  train_loss: 0.602  |  valid_loss: 0.698\n",
      "[epoch: 29, i:  6959]  train_loss: 0.522  |  valid_loss: 0.694\n",
      "[epoch: 29, i:  7046]  train_loss: 0.608  |  valid_loss: 0.640\n",
      "[epoch: 29, i:  7133]  train_loss: 0.587  |  valid_loss: 0.549\n",
      "[epoch: 29, i:  7220]  train_loss: 0.580  |  valid_loss: 0.729\n",
      "[epoch: 29, i:  7307]  train_loss: 0.551  |  valid_loss: 0.735\n",
      "[epoch: 29, i:  7394]  train_loss: 0.556  |  valid_loss: 0.499\n",
      "[epoch: 29, i:  7481]  train_loss: 0.599  |  valid_loss: 0.652\n",
      "[epoch: 29, i:  7568]  train_loss: 0.556  |  valid_loss: 0.812\n",
      "[epoch: 29, i:  7655]  train_loss: 0.589  |  valid_loss: 0.605\n",
      "[epoch: 29, i:  7742]  train_loss: 0.571  |  valid_loss: 0.634\n",
      "[epoch: 29, i:  7829]  train_loss: 0.571  |  valid_loss: 0.423\n",
      "[epoch: 29, i:  7916]  train_loss: 0.519  |  valid_loss: 0.672\n",
      "[epoch: 29, i:  8003]  train_loss: 0.614  |  valid_loss: 0.460\n",
      "[epoch: 29, i:  8090]  train_loss: 0.569  |  valid_loss: 0.500\n",
      "[epoch: 29, i:  8177]  train_loss: 0.608  |  valid_loss: 0.546\n",
      "[epoch: 29, i:  8264]  train_loss: 0.559  |  valid_loss: 0.683\n",
      "[epoch: 29, i:  8351]  train_loss: 0.523  |  valid_loss: 0.698\n",
      "[epoch: 29, i:  8438]  train_loss: 0.533  |  valid_loss: 0.521\n",
      "[epoch: 29, i:  8525]  train_loss: 0.570  |  valid_loss: 0.645\n",
      "[epoch: 29, i:  8612]  train_loss: 0.579  |  valid_loss: 0.952\n",
      "[epoch: 29, i:  8699]  train_loss: 0.502  |  valid_loss: 0.646\n",
      "--> [End of epoch 29] train_accuracy: 80.64%  |  valid_accuracy: 79.15%\n",
      "--> [Start of epoch 30]  lr: 0.000500\n",
      "[epoch: 30, i:    86]  train_loss: 0.585  |  valid_loss: 0.604\n",
      "[epoch: 30, i:   173]  train_loss: 0.536  |  valid_loss: 0.606\n",
      "[epoch: 30, i:   260]  train_loss: 0.524  |  valid_loss: 0.632\n",
      "[epoch: 30, i:   347]  train_loss: 0.490  |  valid_loss: 0.564\n",
      "[epoch: 30, i:   434]  train_loss: 0.532  |  valid_loss: 0.688\n",
      "[epoch: 30, i:   521]  train_loss: 0.526  |  valid_loss: 0.460\n",
      "[epoch: 30, i:   608]  train_loss: 0.559  |  valid_loss: 0.664\n",
      "[epoch: 30, i:   695]  train_loss: 0.548  |  valid_loss: 0.678\n",
      "[epoch: 30, i:   782]  train_loss: 0.529  |  valid_loss: 0.720\n",
      "[epoch: 30, i:   869]  train_loss: 0.542  |  valid_loss: 0.677\n",
      "[epoch: 30, i:   956]  train_loss: 0.504  |  valid_loss: 0.543\n",
      "[epoch: 30, i:  1043]  train_loss: 0.519  |  valid_loss: 0.634\n",
      "[epoch: 30, i:  1130]  train_loss: 0.564  |  valid_loss: 0.524\n",
      "[epoch: 30, i:  1217]  train_loss: 0.544  |  valid_loss: 0.614\n",
      "[epoch: 30, i:  1304]  train_loss: 0.582  |  valid_loss: 0.428\n",
      "[epoch: 30, i:  1391]  train_loss: 0.577  |  valid_loss: 0.692\n",
      "[epoch: 30, i:  1478]  train_loss: 0.501  |  valid_loss: 0.565\n",
      "[epoch: 30, i:  1565]  train_loss: 0.505  |  valid_loss: 0.764\n",
      "[epoch: 30, i:  1652]  train_loss: 0.620  |  valid_loss: 0.614\n",
      "[epoch: 30, i:  1739]  train_loss: 0.527  |  valid_loss: 0.802\n",
      "[epoch: 30, i:  1826]  train_loss: 0.516  |  valid_loss: 0.851\n",
      "[epoch: 30, i:  1913]  train_loss: 0.607  |  valid_loss: 0.633\n",
      "[epoch: 30, i:  2000]  train_loss: 0.524  |  valid_loss: 0.616\n",
      "[epoch: 30, i:  2087]  train_loss: 0.515  |  valid_loss: 0.794\n",
      "[epoch: 30, i:  2174]  train_loss: 0.600  |  valid_loss: 0.598\n",
      "[epoch: 30, i:  2261]  train_loss: 0.561  |  valid_loss: 0.969\n",
      "[epoch: 30, i:  2348]  train_loss: 0.607  |  valid_loss: 0.462\n",
      "[epoch: 30, i:  2435]  train_loss: 0.572  |  valid_loss: 0.646\n",
      "[epoch: 30, i:  2522]  train_loss: 0.477  |  valid_loss: 0.461\n",
      "[epoch: 30, i:  2609]  train_loss: 0.612  |  valid_loss: 0.593\n",
      "[epoch: 30, i:  2696]  train_loss: 0.594  |  valid_loss: 0.699\n",
      "[epoch: 30, i:  2783]  train_loss: 0.497  |  valid_loss: 0.437\n",
      "[epoch: 30, i:  2870]  train_loss: 0.570  |  valid_loss: 0.705\n",
      "[epoch: 30, i:  2957]  train_loss: 0.542  |  valid_loss: 0.740\n",
      "[epoch: 30, i:  3044]  train_loss: 0.538  |  valid_loss: 0.711\n",
      "[epoch: 30, i:  3131]  train_loss: 0.578  |  valid_loss: 0.634\n",
      "[epoch: 30, i:  3218]  train_loss: 0.484  |  valid_loss: 0.704\n",
      "[epoch: 30, i:  3305]  train_loss: 0.577  |  valid_loss: 0.625\n",
      "[epoch: 30, i:  3392]  train_loss: 0.546  |  valid_loss: 0.543\n",
      "[epoch: 30, i:  3479]  train_loss: 0.577  |  valid_loss: 0.545\n",
      "[epoch: 30, i:  3566]  train_loss: 0.595  |  valid_loss: 0.639\n",
      "[epoch: 30, i:  3653]  train_loss: 0.567  |  valid_loss: 0.651\n",
      "[epoch: 30, i:  3740]  train_loss: 0.519  |  valid_loss: 0.410\n",
      "[epoch: 30, i:  3827]  train_loss: 0.569  |  valid_loss: 0.794\n",
      "[epoch: 30, i:  3914]  train_loss: 0.601  |  valid_loss: 0.488\n",
      "[epoch: 30, i:  4001]  train_loss: 0.585  |  valid_loss: 0.698\n",
      "[epoch: 30, i:  4088]  train_loss: 0.602  |  valid_loss: 0.552\n",
      "[epoch: 30, i:  4175]  train_loss: 0.570  |  valid_loss: 0.582\n",
      "[epoch: 30, i:  4262]  train_loss: 0.709  |  valid_loss: 0.513\n",
      "[epoch: 30, i:  4349]  train_loss: 0.587  |  valid_loss: 0.616\n",
      "[epoch: 30, i:  4436]  train_loss: 0.572  |  valid_loss: 0.591\n",
      "[epoch: 30, i:  4523]  train_loss: 0.597  |  valid_loss: 0.726\n",
      "[epoch: 30, i:  4610]  train_loss: 0.566  |  valid_loss: 0.613\n",
      "[epoch: 30, i:  4697]  train_loss: 0.579  |  valid_loss: 0.550\n",
      "[epoch: 30, i:  4784]  train_loss: 0.573  |  valid_loss: 0.690\n",
      "[epoch: 30, i:  4871]  train_loss: 0.589  |  valid_loss: 0.677\n",
      "[epoch: 30, i:  4958]  train_loss: 0.519  |  valid_loss: 0.841\n",
      "[epoch: 30, i:  5045]  train_loss: 0.532  |  valid_loss: 0.455\n",
      "[epoch: 30, i:  5132]  train_loss: 0.589  |  valid_loss: 0.609\n",
      "[epoch: 30, i:  5219]  train_loss: 0.567  |  valid_loss: 0.736\n",
      "[epoch: 30, i:  5306]  train_loss: 0.509  |  valid_loss: 0.651\n",
      "[epoch: 30, i:  5393]  train_loss: 0.552  |  valid_loss: 0.620\n",
      "[epoch: 30, i:  5480]  train_loss: 0.545  |  valid_loss: 0.830\n",
      "[epoch: 30, i:  5567]  train_loss: 0.579  |  valid_loss: 0.361\n",
      "[epoch: 30, i:  5654]  train_loss: 0.577  |  valid_loss: 0.633\n",
      "[epoch: 30, i:  5741]  train_loss: 0.501  |  valid_loss: 0.713\n",
      "[epoch: 30, i:  5828]  train_loss: 0.570  |  valid_loss: 0.517\n",
      "[epoch: 30, i:  5915]  train_loss: 0.585  |  valid_loss: 0.722\n",
      "[epoch: 30, i:  6002]  train_loss: 0.605  |  valid_loss: 0.522\n",
      "[epoch: 30, i:  6089]  train_loss: 0.563  |  valid_loss: 0.788\n",
      "[epoch: 30, i:  6176]  train_loss: 0.539  |  valid_loss: 0.694\n",
      "[epoch: 30, i:  6263]  train_loss: 0.519  |  valid_loss: 0.569\n",
      "[epoch: 30, i:  6350]  train_loss: 0.504  |  valid_loss: 0.553\n",
      "[epoch: 30, i:  6437]  train_loss: 0.578  |  valid_loss: 0.462\n",
      "[epoch: 30, i:  6524]  train_loss: 0.511  |  valid_loss: 0.785\n",
      "[epoch: 30, i:  6611]  train_loss: 0.556  |  valid_loss: 0.416\n",
      "[epoch: 30, i:  6698]  train_loss: 0.527  |  valid_loss: 0.740\n",
      "[epoch: 30, i:  6785]  train_loss: 0.598  |  valid_loss: 0.447\n",
      "[epoch: 30, i:  6872]  train_loss: 0.531  |  valid_loss: 0.715\n",
      "[epoch: 30, i:  6959]  train_loss: 0.626  |  valid_loss: 0.700\n",
      "[epoch: 30, i:  7046]  train_loss: 0.554  |  valid_loss: 0.644\n",
      "[epoch: 30, i:  7133]  train_loss: 0.555  |  valid_loss: 0.530\n",
      "[epoch: 30, i:  7220]  train_loss: 0.598  |  valid_loss: 0.740\n",
      "[epoch: 30, i:  7307]  train_loss: 0.607  |  valid_loss: 0.719\n",
      "[epoch: 30, i:  7394]  train_loss: 0.546  |  valid_loss: 0.589\n",
      "[epoch: 30, i:  7481]  train_loss: 0.597  |  valid_loss: 0.611\n",
      "[epoch: 30, i:  7568]  train_loss: 0.540  |  valid_loss: 0.823\n",
      "[epoch: 30, i:  7655]  train_loss: 0.588  |  valid_loss: 0.642\n",
      "[epoch: 30, i:  7742]  train_loss: 0.582  |  valid_loss: 0.596\n",
      "[epoch: 30, i:  7829]  train_loss: 0.589  |  valid_loss: 0.496\n",
      "[epoch: 30, i:  7916]  train_loss: 0.565  |  valid_loss: 0.742\n",
      "[epoch: 30, i:  8003]  train_loss: 0.544  |  valid_loss: 0.463\n",
      "[epoch: 30, i:  8090]  train_loss: 0.539  |  valid_loss: 0.525\n",
      "[epoch: 30, i:  8177]  train_loss: 0.539  |  valid_loss: 0.566\n",
      "[epoch: 30, i:  8264]  train_loss: 0.541  |  valid_loss: 0.670\n",
      "[epoch: 30, i:  8351]  train_loss: 0.585  |  valid_loss: 0.730\n",
      "[epoch: 30, i:  8438]  train_loss: 0.630  |  valid_loss: 0.445\n",
      "[epoch: 30, i:  8525]  train_loss: 0.606  |  valid_loss: 0.595\n",
      "[epoch: 30, i:  8612]  train_loss: 0.598  |  valid_loss: 0.881\n",
      "[epoch: 30, i:  8699]  train_loss: 0.558  |  valid_loss: 0.603\n",
      "--> [End of epoch 30] train_accuracy: 80.59%  |  valid_accuracy: 78.86%\n",
      "--> [Start of epoch 31]  lr: 0.000500\n",
      "[epoch: 31, i:    86]  train_loss: 0.532  |  valid_loss: 0.588\n",
      "[epoch: 31, i:   173]  train_loss: 0.495  |  valid_loss: 0.581\n",
      "[epoch: 31, i:   260]  train_loss: 0.559  |  valid_loss: 0.691\n",
      "[epoch: 31, i:   347]  train_loss: 0.515  |  valid_loss: 0.505\n",
      "[epoch: 31, i:   434]  train_loss: 0.502  |  valid_loss: 0.568\n",
      "[epoch: 31, i:   521]  train_loss: 0.585  |  valid_loss: 0.429\n",
      "[epoch: 31, i:   608]  train_loss: 0.538  |  valid_loss: 0.649\n",
      "[epoch: 31, i:   695]  train_loss: 0.552  |  valid_loss: 0.640\n",
      "[epoch: 31, i:   782]  train_loss: 0.554  |  valid_loss: 0.746\n",
      "[epoch: 31, i:   869]  train_loss: 0.583  |  valid_loss: 0.614\n",
      "[epoch: 31, i:   956]  train_loss: 0.520  |  valid_loss: 0.569\n",
      "[epoch: 31, i:  1043]  train_loss: 0.500  |  valid_loss: 0.623\n",
      "[epoch: 31, i:  1130]  train_loss: 0.553  |  valid_loss: 0.473\n",
      "[epoch: 31, i:  1217]  train_loss: 0.555  |  valid_loss: 0.637\n",
      "[epoch: 31, i:  1304]  train_loss: 0.551  |  valid_loss: 0.426\n",
      "[epoch: 31, i:  1391]  train_loss: 0.586  |  valid_loss: 0.674\n",
      "[epoch: 31, i:  1478]  train_loss: 0.499  |  valid_loss: 0.636\n",
      "[epoch: 31, i:  1565]  train_loss: 0.543  |  valid_loss: 0.781\n",
      "[epoch: 31, i:  1652]  train_loss: 0.537  |  valid_loss: 0.592\n",
      "[epoch: 31, i:  1739]  train_loss: 0.483  |  valid_loss: 0.868\n",
      "[epoch: 31, i:  1826]  train_loss: 0.562  |  valid_loss: 0.781\n",
      "[epoch: 31, i:  1913]  train_loss: 0.582  |  valid_loss: 0.608\n",
      "[epoch: 31, i:  2000]  train_loss: 0.521  |  valid_loss: 0.605\n",
      "[epoch: 31, i:  2087]  train_loss: 0.514  |  valid_loss: 0.860\n",
      "[epoch: 31, i:  2174]  train_loss: 0.607  |  valid_loss: 0.562\n",
      "[epoch: 31, i:  2261]  train_loss: 0.517  |  valid_loss: 0.937\n",
      "[epoch: 31, i:  2348]  train_loss: 0.520  |  valid_loss: 0.527\n",
      "[epoch: 31, i:  2435]  train_loss: 0.494  |  valid_loss: 0.653\n",
      "[epoch: 31, i:  2522]  train_loss: 0.609  |  valid_loss: 0.493\n",
      "[epoch: 31, i:  2609]  train_loss: 0.597  |  valid_loss: 0.565\n",
      "[epoch: 31, i:  2696]  train_loss: 0.553  |  valid_loss: 0.697\n",
      "[epoch: 31, i:  2783]  train_loss: 0.553  |  valid_loss: 0.422\n",
      "[epoch: 31, i:  2870]  train_loss: 0.611  |  valid_loss: 0.755\n",
      "[epoch: 31, i:  2957]  train_loss: 0.633  |  valid_loss: 0.715\n",
      "[epoch: 31, i:  3044]  train_loss: 0.595  |  valid_loss: 0.789\n",
      "[epoch: 31, i:  3131]  train_loss: 0.574  |  valid_loss: 0.632\n",
      "[epoch: 31, i:  3218]  train_loss: 0.529  |  valid_loss: 0.674\n",
      "[epoch: 31, i:  3305]  train_loss: 0.571  |  valid_loss: 0.627\n",
      "[epoch: 31, i:  3392]  train_loss: 0.562  |  valid_loss: 0.575\n",
      "[epoch: 31, i:  3479]  train_loss: 0.568  |  valid_loss: 0.499\n",
      "[epoch: 31, i:  3566]  train_loss: 0.624  |  valid_loss: 0.657\n",
      "[epoch: 31, i:  3653]  train_loss: 0.505  |  valid_loss: 0.681\n",
      "[epoch: 31, i:  3740]  train_loss: 0.527  |  valid_loss: 0.446\n",
      "[epoch: 31, i:  3827]  train_loss: 0.507  |  valid_loss: 0.856\n",
      "[epoch: 31, i:  3914]  train_loss: 0.520  |  valid_loss: 0.480\n",
      "[epoch: 31, i:  4001]  train_loss: 0.604  |  valid_loss: 0.625\n",
      "[epoch: 31, i:  4088]  train_loss: 0.601  |  valid_loss: 0.621\n",
      "[epoch: 31, i:  4175]  train_loss: 0.563  |  valid_loss: 0.632\n",
      "[epoch: 31, i:  4262]  train_loss: 0.560  |  valid_loss: 0.450\n",
      "[epoch: 31, i:  4349]  train_loss: 0.622  |  valid_loss: 0.612\n",
      "[epoch: 31, i:  4436]  train_loss: 0.523  |  valid_loss: 0.642\n",
      "[epoch: 31, i:  4523]  train_loss: 0.535  |  valid_loss: 0.692\n",
      "[epoch: 31, i:  4610]  train_loss: 0.542  |  valid_loss: 0.500\n",
      "[epoch: 31, i:  4697]  train_loss: 0.512  |  valid_loss: 0.637\n",
      "[epoch: 31, i:  4784]  train_loss: 0.618  |  valid_loss: 0.680\n",
      "[epoch: 31, i:  4871]  train_loss: 0.550  |  valid_loss: 0.748\n",
      "[epoch: 31, i:  4958]  train_loss: 0.563  |  valid_loss: 0.755\n",
      "[epoch: 31, i:  5045]  train_loss: 0.535  |  valid_loss: 0.445\n",
      "[epoch: 31, i:  5132]  train_loss: 0.599  |  valid_loss: 0.600\n",
      "[epoch: 31, i:  5219]  train_loss: 0.551  |  valid_loss: 0.715\n",
      "[epoch: 31, i:  5306]  train_loss: 0.507  |  valid_loss: 0.796\n",
      "[epoch: 31, i:  5393]  train_loss: 0.616  |  valid_loss: 0.549\n",
      "[epoch: 31, i:  5480]  train_loss: 0.607  |  valid_loss: 0.861\n",
      "[epoch: 31, i:  5567]  train_loss: 0.547  |  valid_loss: 0.425\n",
      "[epoch: 31, i:  5654]  train_loss: 0.654  |  valid_loss: 0.561\n",
      "[epoch: 31, i:  5741]  train_loss: 0.567  |  valid_loss: 0.631\n",
      "[epoch: 31, i:  5828]  train_loss: 0.526  |  valid_loss: 0.577\n",
      "[epoch: 31, i:  5915]  train_loss: 0.554  |  valid_loss: 0.696\n",
      "[epoch: 31, i:  6002]  train_loss: 0.586  |  valid_loss: 0.493\n",
      "[epoch: 31, i:  6089]  train_loss: 0.530  |  valid_loss: 0.763\n",
      "[epoch: 31, i:  6176]  train_loss: 0.592  |  valid_loss: 0.607\n",
      "[epoch: 31, i:  6263]  train_loss: 0.514  |  valid_loss: 0.554\n",
      "[epoch: 31, i:  6350]  train_loss: 0.549  |  valid_loss: 0.605\n",
      "[epoch: 31, i:  6437]  train_loss: 0.547  |  valid_loss: 0.459\n",
      "[epoch: 31, i:  6524]  train_loss: 0.599  |  valid_loss: 0.772\n",
      "[epoch: 31, i:  6611]  train_loss: 0.552  |  valid_loss: 0.404\n",
      "[epoch: 31, i:  6698]  train_loss: 0.539  |  valid_loss: 0.757\n",
      "[epoch: 31, i:  6785]  train_loss: 0.547  |  valid_loss: 0.416\n",
      "[epoch: 31, i:  6872]  train_loss: 0.582  |  valid_loss: 0.643\n",
      "[epoch: 31, i:  6959]  train_loss: 0.616  |  valid_loss: 0.648\n",
      "[epoch: 31, i:  7046]  train_loss: 0.581  |  valid_loss: 0.661\n",
      "[epoch: 31, i:  7133]  train_loss: 0.503  |  valid_loss: 0.509\n",
      "[epoch: 31, i:  7220]  train_loss: 0.538  |  valid_loss: 0.683\n",
      "[epoch: 31, i:  7307]  train_loss: 0.631  |  valid_loss: 0.777\n",
      "[epoch: 31, i:  7394]  train_loss: 0.588  |  valid_loss: 0.537\n",
      "[epoch: 31, i:  7481]  train_loss: 0.545  |  valid_loss: 0.574\n",
      "[epoch: 31, i:  7568]  train_loss: 0.542  |  valid_loss: 0.863\n",
      "[epoch: 31, i:  7655]  train_loss: 0.506  |  valid_loss: 0.643\n",
      "[epoch: 31, i:  7742]  train_loss: 0.591  |  valid_loss: 0.675\n",
      "[epoch: 31, i:  7829]  train_loss: 0.510  |  valid_loss: 0.420\n",
      "[epoch: 31, i:  7916]  train_loss: 0.582  |  valid_loss: 0.624\n",
      "[epoch: 31, i:  8003]  train_loss: 0.631  |  valid_loss: 0.564\n",
      "[epoch: 31, i:  8090]  train_loss: 0.506  |  valid_loss: 0.540\n",
      "[epoch: 31, i:  8177]  train_loss: 0.521  |  valid_loss: 0.620\n",
      "[epoch: 31, i:  8264]  train_loss: 0.505  |  valid_loss: 0.650\n",
      "[epoch: 31, i:  8351]  train_loss: 0.552  |  valid_loss: 0.710\n",
      "[epoch: 31, i:  8438]  train_loss: 0.528  |  valid_loss: 0.462\n",
      "[epoch: 31, i:  8525]  train_loss: 0.548  |  valid_loss: 0.632\n",
      "[epoch: 31, i:  8612]  train_loss: 0.589  |  valid_loss: 0.850\n",
      "[epoch: 31, i:  8699]  train_loss: 0.552  |  valid_loss: 0.601\n",
      "--> [End of epoch 31] train_accuracy: 80.80%  |  valid_accuracy: 79.00%\n",
      "--> [Start of epoch 32]  lr: 0.000500\n",
      "[epoch: 32, i:    86]  train_loss: 0.643  |  valid_loss: 0.587\n",
      "[epoch: 32, i:   173]  train_loss: 0.512  |  valid_loss: 0.611\n",
      "[epoch: 32, i:   260]  train_loss: 0.542  |  valid_loss: 0.727\n",
      "[epoch: 32, i:   347]  train_loss: 0.535  |  valid_loss: 0.479\n",
      "[epoch: 32, i:   434]  train_loss: 0.527  |  valid_loss: 0.654\n",
      "[epoch: 32, i:   521]  train_loss: 0.507  |  valid_loss: 0.411\n",
      "[epoch: 32, i:   608]  train_loss: 0.534  |  valid_loss: 0.683\n",
      "[epoch: 32, i:   695]  train_loss: 0.541  |  valid_loss: 0.552\n",
      "[epoch: 32, i:   782]  train_loss: 0.530  |  valid_loss: 0.746\n",
      "[epoch: 32, i:   869]  train_loss: 0.528  |  valid_loss: 0.662\n",
      "[epoch: 32, i:   956]  train_loss: 0.560  |  valid_loss: 0.575\n",
      "[epoch: 32, i:  1043]  train_loss: 0.534  |  valid_loss: 0.587\n",
      "[epoch: 32, i:  1130]  train_loss: 0.511  |  valid_loss: 0.531\n",
      "[epoch: 32, i:  1217]  train_loss: 0.570  |  valid_loss: 0.654\n",
      "[epoch: 32, i:  1304]  train_loss: 0.567  |  valid_loss: 0.356\n",
      "[epoch: 32, i:  1391]  train_loss: 0.553  |  valid_loss: 0.659\n",
      "[epoch: 32, i:  1478]  train_loss: 0.560  |  valid_loss: 0.571\n",
      "[epoch: 32, i:  1565]  train_loss: 0.533  |  valid_loss: 0.773\n",
      "[epoch: 32, i:  1652]  train_loss: 0.569  |  valid_loss: 0.571\n",
      "[epoch: 32, i:  1739]  train_loss: 0.535  |  valid_loss: 0.841\n",
      "[epoch: 32, i:  1826]  train_loss: 0.514  |  valid_loss: 0.741\n",
      "[epoch: 32, i:  1913]  train_loss: 0.505  |  valid_loss: 0.550\n",
      "[epoch: 32, i:  2000]  train_loss: 0.550  |  valid_loss: 0.583\n",
      "[epoch: 32, i:  2087]  train_loss: 0.584  |  valid_loss: 0.786\n",
      "[epoch: 32, i:  2174]  train_loss: 0.534  |  valid_loss: 0.622\n",
      "[epoch: 32, i:  2261]  train_loss: 0.517  |  valid_loss: 0.915\n",
      "[epoch: 32, i:  2348]  train_loss: 0.485  |  valid_loss: 0.475\n",
      "[epoch: 32, i:  2435]  train_loss: 0.554  |  valid_loss: 0.681\n",
      "[epoch: 32, i:  2522]  train_loss: 0.490  |  valid_loss: 0.475\n",
      "[epoch: 32, i:  2609]  train_loss: 0.549  |  valid_loss: 0.547\n",
      "[epoch: 32, i:  2696]  train_loss: 0.531  |  valid_loss: 0.707\n",
      "[epoch: 32, i:  2783]  train_loss: 0.575  |  valid_loss: 0.440\n",
      "[epoch: 32, i:  2870]  train_loss: 0.515  |  valid_loss: 0.687\n",
      "[epoch: 32, i:  2957]  train_loss: 0.593  |  valid_loss: 0.739\n",
      "[epoch: 32, i:  3044]  train_loss: 0.624  |  valid_loss: 0.714\n",
      "[epoch: 32, i:  3131]  train_loss: 0.513  |  valid_loss: 0.623\n",
      "[epoch: 32, i:  3218]  train_loss: 0.579  |  valid_loss: 0.774\n",
      "[epoch: 32, i:  3305]  train_loss: 0.563  |  valid_loss: 0.611\n",
      "[epoch: 32, i:  3392]  train_loss: 0.556  |  valid_loss: 0.664\n",
      "[epoch: 32, i:  3479]  train_loss: 0.569  |  valid_loss: 0.631\n",
      "[epoch: 32, i:  3566]  train_loss: 0.582  |  valid_loss: 0.560\n",
      "[epoch: 32, i:  3653]  train_loss: 0.576  |  valid_loss: 0.670\n",
      "[epoch: 32, i:  3740]  train_loss: 0.546  |  valid_loss: 0.389\n",
      "[epoch: 32, i:  3827]  train_loss: 0.550  |  valid_loss: 0.755\n",
      "[epoch: 32, i:  3914]  train_loss: 0.559  |  valid_loss: 0.497\n",
      "[epoch: 32, i:  4001]  train_loss: 0.504  |  valid_loss: 0.639\n",
      "[epoch: 32, i:  4088]  train_loss: 0.587  |  valid_loss: 0.622\n",
      "[epoch: 32, i:  4175]  train_loss: 0.504  |  valid_loss: 0.652\n",
      "[epoch: 32, i:  4262]  train_loss: 0.566  |  valid_loss: 0.555\n",
      "[epoch: 32, i:  4349]  train_loss: 0.509  |  valid_loss: 0.546\n",
      "[epoch: 32, i:  4436]  train_loss: 0.499  |  valid_loss: 0.661\n",
      "[epoch: 32, i:  4523]  train_loss: 0.565  |  valid_loss: 0.764\n",
      "[epoch: 32, i:  4610]  train_loss: 0.565  |  valid_loss: 0.485\n",
      "[epoch: 32, i:  4697]  train_loss: 0.498  |  valid_loss: 0.692\n",
      "[epoch: 32, i:  4784]  train_loss: 0.600  |  valid_loss: 0.673\n",
      "[epoch: 32, i:  4871]  train_loss: 0.580  |  valid_loss: 0.735\n",
      "[epoch: 32, i:  4958]  train_loss: 0.530  |  valid_loss: 0.760\n",
      "[epoch: 32, i:  5045]  train_loss: 0.537  |  valid_loss: 0.430\n",
      "[epoch: 32, i:  5132]  train_loss: 0.496  |  valid_loss: 0.642\n",
      "[epoch: 32, i:  5219]  train_loss: 0.583  |  valid_loss: 0.705\n",
      "[epoch: 32, i:  5306]  train_loss: 0.546  |  valid_loss: 0.638\n",
      "[epoch: 32, i:  5393]  train_loss: 0.568  |  valid_loss: 0.522\n",
      "[epoch: 32, i:  5480]  train_loss: 0.580  |  valid_loss: 0.750\n",
      "[epoch: 32, i:  5567]  train_loss: 0.547  |  valid_loss: 0.359\n",
      "[epoch: 32, i:  5654]  train_loss: 0.557  |  valid_loss: 0.625\n",
      "[epoch: 32, i:  5741]  train_loss: 0.603  |  valid_loss: 0.741\n",
      "[epoch: 32, i:  5828]  train_loss: 0.557  |  valid_loss: 0.582\n",
      "[epoch: 32, i:  5915]  train_loss: 0.524  |  valid_loss: 0.717\n",
      "[epoch: 32, i:  6002]  train_loss: 0.628  |  valid_loss: 0.490\n",
      "[epoch: 32, i:  6089]  train_loss: 0.600  |  valid_loss: 0.854\n",
      "[epoch: 32, i:  6176]  train_loss: 0.584  |  valid_loss: 0.625\n",
      "[epoch: 32, i:  6263]  train_loss: 0.538  |  valid_loss: 0.601\n",
      "[epoch: 32, i:  6350]  train_loss: 0.630  |  valid_loss: 0.550\n",
      "[epoch: 32, i:  6437]  train_loss: 0.580  |  valid_loss: 0.389\n",
      "[epoch: 32, i:  6524]  train_loss: 0.578  |  valid_loss: 0.748\n",
      "[epoch: 32, i:  6611]  train_loss: 0.585  |  valid_loss: 0.436\n",
      "[epoch: 32, i:  6698]  train_loss: 0.524  |  valid_loss: 0.763\n",
      "[epoch: 32, i:  6785]  train_loss: 0.544  |  valid_loss: 0.467\n",
      "[epoch: 32, i:  6872]  train_loss: 0.572  |  valid_loss: 0.721\n",
      "[epoch: 32, i:  6959]  train_loss: 0.548  |  valid_loss: 0.652\n",
      "[epoch: 32, i:  7046]  train_loss: 0.536  |  valid_loss: 0.592\n",
      "[epoch: 32, i:  7133]  train_loss: 0.546  |  valid_loss: 0.519\n",
      "[epoch: 32, i:  7220]  train_loss: 0.616  |  valid_loss: 0.659\n",
      "[epoch: 32, i:  7307]  train_loss: 0.580  |  valid_loss: 0.732\n",
      "[epoch: 32, i:  7394]  train_loss: 0.603  |  valid_loss: 0.590\n",
      "[epoch: 32, i:  7481]  train_loss: 0.579  |  valid_loss: 0.597\n",
      "[epoch: 32, i:  7568]  train_loss: 0.572  |  valid_loss: 0.785\n",
      "[epoch: 32, i:  7655]  train_loss: 0.538  |  valid_loss: 0.695\n",
      "[epoch: 32, i:  7742]  train_loss: 0.635  |  valid_loss: 0.693\n",
      "[epoch: 32, i:  7829]  train_loss: 0.589  |  valid_loss: 0.496\n",
      "[epoch: 32, i:  7916]  train_loss: 0.533  |  valid_loss: 0.712\n",
      "[epoch: 32, i:  8003]  train_loss: 0.588  |  valid_loss: 0.475\n",
      "[epoch: 32, i:  8090]  train_loss: 0.508  |  valid_loss: 0.556\n",
      "[epoch: 32, i:  8177]  train_loss: 0.599  |  valid_loss: 0.602\n",
      "[epoch: 32, i:  8264]  train_loss: 0.543  |  valid_loss: 0.580\n",
      "[epoch: 32, i:  8351]  train_loss: 0.604  |  valid_loss: 0.722\n",
      "[epoch: 32, i:  8438]  train_loss: 0.550  |  valid_loss: 0.431\n",
      "[epoch: 32, i:  8525]  train_loss: 0.531  |  valid_loss: 0.603\n",
      "[epoch: 32, i:  8612]  train_loss: 0.610  |  valid_loss: 0.857\n",
      "[epoch: 32, i:  8699]  train_loss: 0.536  |  valid_loss: 0.615\n",
      "--> [End of epoch 32] train_accuracy: 80.65%  |  valid_accuracy: 78.72%\n",
      "--> [Start of epoch 33]  lr: 0.000500\n",
      "[epoch: 33, i:    86]  train_loss: 0.546  |  valid_loss: 0.554\n",
      "[epoch: 33, i:   173]  train_loss: 0.530  |  valid_loss: 0.607\n",
      "[epoch: 33, i:   260]  train_loss: 0.458  |  valid_loss: 0.743\n",
      "[epoch: 33, i:   347]  train_loss: 0.482  |  valid_loss: 0.510\n",
      "[epoch: 33, i:   434]  train_loss: 0.512  |  valid_loss: 0.600\n",
      "[epoch: 33, i:   521]  train_loss: 0.561  |  valid_loss: 0.401\n",
      "[epoch: 33, i:   608]  train_loss: 0.493  |  valid_loss: 0.621\n",
      "[epoch: 33, i:   695]  train_loss: 0.504  |  valid_loss: 0.648\n",
      "[epoch: 33, i:   782]  train_loss: 0.502  |  valid_loss: 0.730\n",
      "[epoch: 33, i:   869]  train_loss: 0.507  |  valid_loss: 0.670\n",
      "[epoch: 33, i:   956]  train_loss: 0.495  |  valid_loss: 0.548\n",
      "[epoch: 33, i:  1043]  train_loss: 0.517  |  valid_loss: 0.624\n",
      "[epoch: 33, i:  1130]  train_loss: 0.537  |  valid_loss: 0.511\n",
      "[epoch: 33, i:  1217]  train_loss: 0.601  |  valid_loss: 0.684\n",
      "[epoch: 33, i:  1304]  train_loss: 0.571  |  valid_loss: 0.463\n",
      "[epoch: 33, i:  1391]  train_loss: 0.611  |  valid_loss: 0.698\n",
      "[epoch: 33, i:  1478]  train_loss: 0.557  |  valid_loss: 0.534\n",
      "[epoch: 33, i:  1565]  train_loss: 0.508  |  valid_loss: 0.743\n",
      "[epoch: 33, i:  1652]  train_loss: 0.595  |  valid_loss: 0.588\n",
      "[epoch: 33, i:  1739]  train_loss: 0.500  |  valid_loss: 0.879\n",
      "[epoch: 33, i:  1826]  train_loss: 0.503  |  valid_loss: 0.797\n",
      "[epoch: 33, i:  1913]  train_loss: 0.545  |  valid_loss: 0.649\n",
      "[epoch: 33, i:  2000]  train_loss: 0.559  |  valid_loss: 0.616\n",
      "[epoch: 33, i:  2087]  train_loss: 0.524  |  valid_loss: 0.789\n",
      "[epoch: 33, i:  2174]  train_loss: 0.585  |  valid_loss: 0.590\n",
      "[epoch: 33, i:  2261]  train_loss: 0.528  |  valid_loss: 0.878\n",
      "[epoch: 33, i:  2348]  train_loss: 0.593  |  valid_loss: 0.489\n",
      "[epoch: 33, i:  2435]  train_loss: 0.557  |  valid_loss: 0.713\n",
      "[epoch: 33, i:  2522]  train_loss: 0.574  |  valid_loss: 0.463\n",
      "[epoch: 33, i:  2609]  train_loss: 0.575  |  valid_loss: 0.521\n",
      "[epoch: 33, i:  2696]  train_loss: 0.535  |  valid_loss: 0.689\n",
      "[epoch: 33, i:  2783]  train_loss: 0.575  |  valid_loss: 0.421\n",
      "[epoch: 33, i:  2870]  train_loss: 0.520  |  valid_loss: 0.739\n",
      "[epoch: 33, i:  2957]  train_loss: 0.555  |  valid_loss: 0.782\n",
      "[epoch: 33, i:  3044]  train_loss: 0.562  |  valid_loss: 0.713\n",
      "[epoch: 33, i:  3131]  train_loss: 0.553  |  valid_loss: 0.589\n",
      "[epoch: 33, i:  3218]  train_loss: 0.473  |  valid_loss: 0.713\n",
      "[epoch: 33, i:  3305]  train_loss: 0.600  |  valid_loss: 0.638\n",
      "[epoch: 33, i:  3392]  train_loss: 0.580  |  valid_loss: 0.630\n",
      "[epoch: 33, i:  3479]  train_loss: 0.611  |  valid_loss: 0.581\n",
      "[epoch: 33, i:  3566]  train_loss: 0.519  |  valid_loss: 0.675\n",
      "[epoch: 33, i:  3653]  train_loss: 0.578  |  valid_loss: 0.647\n",
      "[epoch: 33, i:  3740]  train_loss: 0.530  |  valid_loss: 0.428\n",
      "[epoch: 33, i:  3827]  train_loss: 0.561  |  valid_loss: 0.783\n",
      "[epoch: 33, i:  3914]  train_loss: 0.586  |  valid_loss: 0.427\n",
      "[epoch: 33, i:  4001]  train_loss: 0.579  |  valid_loss: 0.694\n",
      "[epoch: 33, i:  4088]  train_loss: 0.577  |  valid_loss: 0.563\n",
      "[epoch: 33, i:  4175]  train_loss: 0.536  |  valid_loss: 0.595\n",
      "[epoch: 33, i:  4262]  train_loss: 0.550  |  valid_loss: 0.450\n",
      "[epoch: 33, i:  4349]  train_loss: 0.603  |  valid_loss: 0.584\n",
      "[epoch: 33, i:  4436]  train_loss: 0.653  |  valid_loss: 0.534\n",
      "[epoch: 33, i:  4523]  train_loss: 0.537  |  valid_loss: 0.726\n",
      "[epoch: 33, i:  4610]  train_loss: 0.672  |  valid_loss: 0.503\n",
      "[epoch: 33, i:  4697]  train_loss: 0.514  |  valid_loss: 0.613\n",
      "[epoch: 33, i:  4784]  train_loss: 0.512  |  valid_loss: 0.634\n",
      "[epoch: 33, i:  4871]  train_loss: 0.585  |  valid_loss: 0.781\n",
      "[epoch: 33, i:  4958]  train_loss: 0.524  |  valid_loss: 0.858\n",
      "[epoch: 33, i:  5045]  train_loss: 0.644  |  valid_loss: 0.403\n",
      "[epoch: 33, i:  5132]  train_loss: 0.523  |  valid_loss: 0.655\n",
      "[epoch: 33, i:  5219]  train_loss: 0.568  |  valid_loss: 0.710\n",
      "[epoch: 33, i:  5306]  train_loss: 0.562  |  valid_loss: 0.709\n",
      "[epoch: 33, i:  5393]  train_loss: 0.579  |  valid_loss: 0.542\n",
      "[epoch: 33, i:  5480]  train_loss: 0.525  |  valid_loss: 0.747\n",
      "[epoch: 33, i:  5567]  train_loss: 0.584  |  valid_loss: 0.374\n",
      "[epoch: 33, i:  5654]  train_loss: 0.541  |  valid_loss: 0.570\n",
      "[epoch: 33, i:  5741]  train_loss: 0.553  |  valid_loss: 0.614\n",
      "[epoch: 33, i:  5828]  train_loss: 0.575  |  valid_loss: 0.636\n",
      "[epoch: 33, i:  5915]  train_loss: 0.550  |  valid_loss: 0.710\n",
      "[epoch: 33, i:  6002]  train_loss: 0.542  |  valid_loss: 0.563\n",
      "[epoch: 33, i:  6089]  train_loss: 0.508  |  valid_loss: 0.845\n",
      "[epoch: 33, i:  6176]  train_loss: 0.527  |  valid_loss: 0.608\n",
      "[epoch: 33, i:  6263]  train_loss: 0.497  |  valid_loss: 0.508\n",
      "[epoch: 33, i:  6350]  train_loss: 0.555  |  valid_loss: 0.522\n",
      "[epoch: 33, i:  6437]  train_loss: 0.513  |  valid_loss: 0.528\n",
      "[epoch: 33, i:  6524]  train_loss: 0.577  |  valid_loss: 0.832\n",
      "[epoch: 33, i:  6611]  train_loss: 0.566  |  valid_loss: 0.404\n",
      "[epoch: 33, i:  6698]  train_loss: 0.565  |  valid_loss: 0.649\n",
      "[epoch: 33, i:  6785]  train_loss: 0.550  |  valid_loss: 0.517\n",
      "[epoch: 33, i:  6872]  train_loss: 0.526  |  valid_loss: 0.788\n",
      "[epoch: 33, i:  6959]  train_loss: 0.603  |  valid_loss: 0.681\n",
      "[epoch: 33, i:  7046]  train_loss: 0.584  |  valid_loss: 0.652\n",
      "[epoch: 33, i:  7133]  train_loss: 0.572  |  valid_loss: 0.531\n",
      "[epoch: 33, i:  7220]  train_loss: 0.597  |  valid_loss: 0.653\n",
      "[epoch: 33, i:  7307]  train_loss: 0.526  |  valid_loss: 0.810\n",
      "[epoch: 33, i:  7394]  train_loss: 0.560  |  valid_loss: 0.649\n",
      "[epoch: 33, i:  7481]  train_loss: 0.509  |  valid_loss: 0.610\n",
      "[epoch: 33, i:  7568]  train_loss: 0.547  |  valid_loss: 0.749\n",
      "[epoch: 33, i:  7655]  train_loss: 0.572  |  valid_loss: 0.623\n",
      "[epoch: 33, i:  7742]  train_loss: 0.605  |  valid_loss: 0.705\n",
      "[epoch: 33, i:  7829]  train_loss: 0.562  |  valid_loss: 0.468\n",
      "[epoch: 33, i:  7916]  train_loss: 0.536  |  valid_loss: 0.697\n",
      "[epoch: 33, i:  8003]  train_loss: 0.562  |  valid_loss: 0.533\n",
      "[epoch: 33, i:  8090]  train_loss: 0.628  |  valid_loss: 0.507\n",
      "[epoch: 33, i:  8177]  train_loss: 0.616  |  valid_loss: 0.610\n",
      "[epoch: 33, i:  8264]  train_loss: 0.506  |  valid_loss: 0.609\n",
      "[epoch: 33, i:  8351]  train_loss: 0.562  |  valid_loss: 0.667\n",
      "[epoch: 33, i:  8438]  train_loss: 0.531  |  valid_loss: 0.473\n",
      "[epoch: 33, i:  8525]  train_loss: 0.563  |  valid_loss: 0.595\n",
      "[epoch: 33, i:  8612]  train_loss: 0.583  |  valid_loss: 0.902\n",
      "[epoch: 33, i:  8699]  train_loss: 0.526  |  valid_loss: 0.612\n",
      "--> [End of epoch 33] train_accuracy: 80.88%  |  valid_accuracy: 79.03%\n",
      "--> [Start of epoch 34]  lr: 0.000500\n",
      "[epoch: 34, i:    86]  train_loss: 0.575  |  valid_loss: 0.568\n",
      "[epoch: 34, i:   173]  train_loss: 0.535  |  valid_loss: 0.597\n",
      "[epoch: 34, i:   260]  train_loss: 0.571  |  valid_loss: 0.625\n",
      "[epoch: 34, i:   347]  train_loss: 0.457  |  valid_loss: 0.626\n",
      "[epoch: 34, i:   434]  train_loss: 0.506  |  valid_loss: 0.687\n",
      "[epoch: 34, i:   521]  train_loss: 0.536  |  valid_loss: 0.431\n",
      "[epoch: 34, i:   608]  train_loss: 0.568  |  valid_loss: 0.727\n",
      "[epoch: 34, i:   695]  train_loss: 0.485  |  valid_loss: 0.654\n",
      "[epoch: 34, i:   782]  train_loss: 0.489  |  valid_loss: 0.694\n",
      "[epoch: 34, i:   869]  train_loss: 0.471  |  valid_loss: 0.618\n",
      "[epoch: 34, i:   956]  train_loss: 0.602  |  valid_loss: 0.513\n",
      "[epoch: 34, i:  1043]  train_loss: 0.579  |  valid_loss: 0.579\n",
      "[epoch: 34, i:  1130]  train_loss: 0.465  |  valid_loss: 0.515\n",
      "[epoch: 34, i:  1217]  train_loss: 0.507  |  valid_loss: 0.709\n",
      "[epoch: 34, i:  1304]  train_loss: 0.613  |  valid_loss: 0.486\n",
      "[epoch: 34, i:  1391]  train_loss: 0.561  |  valid_loss: 0.693\n",
      "[epoch: 34, i:  1478]  train_loss: 0.567  |  valid_loss: 0.537\n",
      "[epoch: 34, i:  1565]  train_loss: 0.574  |  valid_loss: 0.736\n",
      "[epoch: 34, i:  1652]  train_loss: 0.576  |  valid_loss: 0.635\n",
      "[epoch: 34, i:  1739]  train_loss: 0.541  |  valid_loss: 0.863\n",
      "[epoch: 34, i:  1826]  train_loss: 0.502  |  valid_loss: 0.762\n",
      "[epoch: 34, i:  1913]  train_loss: 0.576  |  valid_loss: 0.585\n",
      "[epoch: 34, i:  2000]  train_loss: 0.484  |  valid_loss: 0.618\n",
      "[epoch: 34, i:  2087]  train_loss: 0.554  |  valid_loss: 0.760\n",
      "[epoch: 34, i:  2174]  train_loss: 0.547  |  valid_loss: 0.533\n",
      "[epoch: 34, i:  2261]  train_loss: 0.561  |  valid_loss: 0.798\n",
      "[epoch: 34, i:  2348]  train_loss: 0.554  |  valid_loss: 0.569\n",
      "[epoch: 34, i:  2435]  train_loss: 0.533  |  valid_loss: 0.727\n",
      "[epoch: 34, i:  2522]  train_loss: 0.607  |  valid_loss: 0.487\n",
      "[epoch: 34, i:  2609]  train_loss: 0.571  |  valid_loss: 0.578\n",
      "[epoch: 34, i:  2696]  train_loss: 0.577  |  valid_loss: 0.722\n",
      "[epoch: 34, i:  2783]  train_loss: 0.549  |  valid_loss: 0.430\n",
      "[epoch: 34, i:  2870]  train_loss: 0.589  |  valid_loss: 0.784\n",
      "[epoch: 34, i:  2957]  train_loss: 0.498  |  valid_loss: 0.726\n",
      "[epoch: 34, i:  3044]  train_loss: 0.526  |  valid_loss: 0.765\n",
      "[epoch: 34, i:  3131]  train_loss: 0.549  |  valid_loss: 0.611\n",
      "[epoch: 34, i:  3218]  train_loss: 0.505  |  valid_loss: 0.676\n",
      "[epoch: 34, i:  3305]  train_loss: 0.499  |  valid_loss: 0.644\n",
      "[epoch: 34, i:  3392]  train_loss: 0.587  |  valid_loss: 0.548\n",
      "[epoch: 34, i:  3479]  train_loss: 0.542  |  valid_loss: 0.538\n",
      "[epoch: 34, i:  3566]  train_loss: 0.486  |  valid_loss: 0.535\n",
      "[epoch: 34, i:  3653]  train_loss: 0.615  |  valid_loss: 0.524\n",
      "[epoch: 34, i:  3740]  train_loss: 0.550  |  valid_loss: 0.480\n",
      "[epoch: 34, i:  3827]  train_loss: 0.528  |  valid_loss: 0.771\n",
      "[epoch: 34, i:  3914]  train_loss: 0.552  |  valid_loss: 0.481\n",
      "[epoch: 34, i:  4001]  train_loss: 0.545  |  valid_loss: 0.685\n",
      "[epoch: 34, i:  4088]  train_loss: 0.466  |  valid_loss: 0.673\n",
      "[epoch: 34, i:  4175]  train_loss: 0.612  |  valid_loss: 0.560\n",
      "[epoch: 34, i:  4262]  train_loss: 0.534  |  valid_loss: 0.467\n",
      "[epoch: 34, i:  4349]  train_loss: 0.562  |  valid_loss: 0.564\n",
      "[epoch: 34, i:  4436]  train_loss: 0.625  |  valid_loss: 0.620\n",
      "[epoch: 34, i:  4523]  train_loss: 0.560  |  valid_loss: 0.739\n",
      "[epoch: 34, i:  4610]  train_loss: 0.614  |  valid_loss: 0.505\n",
      "[epoch: 34, i:  4697]  train_loss: 0.568  |  valid_loss: 0.559\n",
      "[epoch: 34, i:  4784]  train_loss: 0.600  |  valid_loss: 0.677\n",
      "[epoch: 34, i:  4871]  train_loss: 0.518  |  valid_loss: 0.776\n",
      "[epoch: 34, i:  4958]  train_loss: 0.581  |  valid_loss: 0.860\n",
      "[epoch: 34, i:  5045]  train_loss: 0.628  |  valid_loss: 0.450\n",
      "[epoch: 34, i:  5132]  train_loss: 0.542  |  valid_loss: 0.592\n",
      "[epoch: 34, i:  5219]  train_loss: 0.542  |  valid_loss: 0.826\n",
      "[epoch: 34, i:  5306]  train_loss: 0.491  |  valid_loss: 0.682\n",
      "[epoch: 34, i:  5393]  train_loss: 0.558  |  valid_loss: 0.560\n",
      "[epoch: 34, i:  5480]  train_loss: 0.514  |  valid_loss: 0.774\n",
      "[epoch: 34, i:  5567]  train_loss: 0.531  |  valid_loss: 0.335\n",
      "[epoch: 34, i:  5654]  train_loss: 0.596  |  valid_loss: 0.655\n",
      "[epoch: 34, i:  5741]  train_loss: 0.523  |  valid_loss: 0.666\n",
      "[epoch: 34, i:  5828]  train_loss: 0.562  |  valid_loss: 0.571\n",
      "[epoch: 34, i:  5915]  train_loss: 0.568  |  valid_loss: 0.740\n",
      "[epoch: 34, i:  6002]  train_loss: 0.598  |  valid_loss: 0.573\n",
      "[epoch: 34, i:  6089]  train_loss: 0.586  |  valid_loss: 0.831\n",
      "[epoch: 34, i:  6176]  train_loss: 0.553  |  valid_loss: 0.667\n",
      "[epoch: 34, i:  6263]  train_loss: 0.516  |  valid_loss: 0.560\n",
      "[epoch: 34, i:  6350]  train_loss: 0.619  |  valid_loss: 0.542\n",
      "[epoch: 34, i:  6437]  train_loss: 0.524  |  valid_loss: 0.437\n",
      "[epoch: 34, i:  6524]  train_loss: 0.554  |  valid_loss: 0.790\n",
      "[epoch: 34, i:  6611]  train_loss: 0.572  |  valid_loss: 0.384\n",
      "[epoch: 34, i:  6698]  train_loss: 0.514  |  valid_loss: 0.709\n",
      "[epoch: 34, i:  6785]  train_loss: 0.504  |  valid_loss: 0.440\n",
      "[epoch: 34, i:  6872]  train_loss: 0.506  |  valid_loss: 0.778\n",
      "[epoch: 34, i:  6959]  train_loss: 0.531  |  valid_loss: 0.637\n",
      "[epoch: 34, i:  7046]  train_loss: 0.566  |  valid_loss: 0.629\n",
      "[epoch: 34, i:  7133]  train_loss: 0.538  |  valid_loss: 0.471\n",
      "[epoch: 34, i:  7220]  train_loss: 0.523  |  valid_loss: 0.693\n",
      "[epoch: 34, i:  7307]  train_loss: 0.552  |  valid_loss: 0.740\n",
      "[epoch: 34, i:  7394]  train_loss: 0.556  |  valid_loss: 0.555\n",
      "[epoch: 34, i:  7481]  train_loss: 0.531  |  valid_loss: 0.606\n",
      "[epoch: 34, i:  7568]  train_loss: 0.531  |  valid_loss: 0.757\n",
      "[epoch: 34, i:  7655]  train_loss: 0.591  |  valid_loss: 0.667\n",
      "[epoch: 34, i:  7742]  train_loss: 0.582  |  valid_loss: 0.662\n",
      "[epoch: 34, i:  7829]  train_loss: 0.517  |  valid_loss: 0.449\n",
      "[epoch: 34, i:  7916]  train_loss: 0.603  |  valid_loss: 0.626\n",
      "[epoch: 34, i:  8003]  train_loss: 0.522  |  valid_loss: 0.455\n",
      "[epoch: 34, i:  8090]  train_loss: 0.549  |  valid_loss: 0.522\n",
      "[epoch: 34, i:  8177]  train_loss: 0.571  |  valid_loss: 0.630\n",
      "[epoch: 34, i:  8264]  train_loss: 0.475  |  valid_loss: 0.602\n",
      "[epoch: 34, i:  8351]  train_loss: 0.576  |  valid_loss: 0.701\n",
      "[epoch: 34, i:  8438]  train_loss: 0.557  |  valid_loss: 0.487\n",
      "[epoch: 34, i:  8525]  train_loss: 0.570  |  valid_loss: 0.651\n",
      "[epoch: 34, i:  8612]  train_loss: 0.564  |  valid_loss: 0.824\n",
      "[epoch: 34, i:  8699]  train_loss: 0.571  |  valid_loss: 0.618\n",
      "--> [End of epoch 34] train_accuracy: 80.82%  |  valid_accuracy: 79.00%\n",
      "--> [Start of epoch 35]  lr: 0.000050\n",
      "[epoch: 35, i:    86]  train_loss: 0.556  |  valid_loss: 0.616\n",
      "[epoch: 35, i:   173]  train_loss: 0.485  |  valid_loss: 0.627\n",
      "[epoch: 35, i:   260]  train_loss: 0.467  |  valid_loss: 0.692\n",
      "[epoch: 35, i:   347]  train_loss: 0.526  |  valid_loss: 0.604\n",
      "[epoch: 35, i:   434]  train_loss: 0.553  |  valid_loss: 0.570\n",
      "[epoch: 35, i:   521]  train_loss: 0.501  |  valid_loss: 0.412\n",
      "[epoch: 35, i:   608]  train_loss: 0.488  |  valid_loss: 0.659\n",
      "[epoch: 35, i:   695]  train_loss: 0.499  |  valid_loss: 0.597\n",
      "[epoch: 35, i:   782]  train_loss: 0.518  |  valid_loss: 0.706\n",
      "[epoch: 35, i:   869]  train_loss: 0.509  |  valid_loss: 0.719\n",
      "[epoch: 35, i:   956]  train_loss: 0.551  |  valid_loss: 0.555\n",
      "[epoch: 35, i:  1043]  train_loss: 0.485  |  valid_loss: 0.502\n",
      "[epoch: 35, i:  1130]  train_loss: 0.496  |  valid_loss: 0.493\n",
      "[epoch: 35, i:  1217]  train_loss: 0.549  |  valid_loss: 0.667\n",
      "[epoch: 35, i:  1304]  train_loss: 0.531  |  valid_loss: 0.422\n",
      "[epoch: 35, i:  1391]  train_loss: 0.524  |  valid_loss: 0.630\n",
      "[epoch: 35, i:  1478]  train_loss: 0.520  |  valid_loss: 0.500\n",
      "[epoch: 35, i:  1565]  train_loss: 0.485  |  valid_loss: 0.735\n",
      "[epoch: 35, i:  1652]  train_loss: 0.526  |  valid_loss: 0.560\n",
      "[epoch: 35, i:  1739]  train_loss: 0.556  |  valid_loss: 0.938\n",
      "[epoch: 35, i:  1826]  train_loss: 0.521  |  valid_loss: 0.748\n",
      "[epoch: 35, i:  1913]  train_loss: 0.484  |  valid_loss: 0.660\n",
      "[epoch: 35, i:  2000]  train_loss: 0.520  |  valid_loss: 0.640\n",
      "[epoch: 35, i:  2087]  train_loss: 0.547  |  valid_loss: 0.763\n",
      "[epoch: 35, i:  2174]  train_loss: 0.532  |  valid_loss: 0.550\n",
      "[epoch: 35, i:  2261]  train_loss: 0.512  |  valid_loss: 0.878\n",
      "[epoch: 35, i:  2348]  train_loss: 0.491  |  valid_loss: 0.483\n",
      "[epoch: 35, i:  2435]  train_loss: 0.509  |  valid_loss: 0.697\n",
      "[epoch: 35, i:  2522]  train_loss: 0.525  |  valid_loss: 0.428\n",
      "[epoch: 35, i:  2609]  train_loss: 0.472  |  valid_loss: 0.575\n",
      "[epoch: 35, i:  2696]  train_loss: 0.522  |  valid_loss: 0.627\n",
      "[epoch: 35, i:  2783]  train_loss: 0.462  |  valid_loss: 0.401\n",
      "[epoch: 35, i:  2870]  train_loss: 0.480  |  valid_loss: 0.797\n",
      "[epoch: 35, i:  2957]  train_loss: 0.440  |  valid_loss: 0.733\n",
      "[epoch: 35, i:  3044]  train_loss: 0.495  |  valid_loss: 0.671\n",
      "[epoch: 35, i:  3131]  train_loss: 0.540  |  valid_loss: 0.596\n",
      "[epoch: 35, i:  3218]  train_loss: 0.530  |  valid_loss: 0.689\n",
      "[epoch: 35, i:  3305]  train_loss: 0.495  |  valid_loss: 0.609\n",
      "[epoch: 35, i:  3392]  train_loss: 0.443  |  valid_loss: 0.582\n",
      "[epoch: 35, i:  3479]  train_loss: 0.490  |  valid_loss: 0.587\n",
      "[epoch: 35, i:  3566]  train_loss: 0.482  |  valid_loss: 0.546\n",
      "[epoch: 35, i:  3653]  train_loss: 0.506  |  valid_loss: 0.582\n",
      "[epoch: 35, i:  3740]  train_loss: 0.481  |  valid_loss: 0.386\n",
      "[epoch: 35, i:  3827]  train_loss: 0.526  |  valid_loss: 0.771\n",
      "[epoch: 35, i:  3914]  train_loss: 0.543  |  valid_loss: 0.495\n",
      "[epoch: 35, i:  4001]  train_loss: 0.462  |  valid_loss: 0.595\n",
      "[epoch: 35, i:  4088]  train_loss: 0.503  |  valid_loss: 0.562\n",
      "[epoch: 35, i:  4175]  train_loss: 0.445  |  valid_loss: 0.569\n",
      "[epoch: 35, i:  4262]  train_loss: 0.489  |  valid_loss: 0.495\n",
      "[epoch: 35, i:  4349]  train_loss: 0.597  |  valid_loss: 0.596\n",
      "[epoch: 35, i:  4436]  train_loss: 0.518  |  valid_loss: 0.581\n",
      "[epoch: 35, i:  4523]  train_loss: 0.498  |  valid_loss: 0.682\n",
      "[epoch: 35, i:  4610]  train_loss: 0.453  |  valid_loss: 0.511\n",
      "[epoch: 35, i:  4697]  train_loss: 0.501  |  valid_loss: 0.634\n",
      "[epoch: 35, i:  4784]  train_loss: 0.492  |  valid_loss: 0.640\n",
      "[epoch: 35, i:  4871]  train_loss: 0.498  |  valid_loss: 0.716\n",
      "[epoch: 35, i:  4958]  train_loss: 0.431  |  valid_loss: 0.790\n",
      "[epoch: 35, i:  5045]  train_loss: 0.433  |  valid_loss: 0.414\n",
      "[epoch: 35, i:  5132]  train_loss: 0.491  |  valid_loss: 0.562\n",
      "[epoch: 35, i:  5219]  train_loss: 0.477  |  valid_loss: 0.736\n",
      "[epoch: 35, i:  5306]  train_loss: 0.454  |  valid_loss: 0.626\n",
      "[epoch: 35, i:  5393]  train_loss: 0.480  |  valid_loss: 0.507\n",
      "[epoch: 35, i:  5480]  train_loss: 0.528  |  valid_loss: 0.738\n",
      "[epoch: 35, i:  5567]  train_loss: 0.447  |  valid_loss: 0.312\n",
      "[epoch: 35, i:  5654]  train_loss: 0.510  |  valid_loss: 0.561\n",
      "[epoch: 35, i:  5741]  train_loss: 0.525  |  valid_loss: 0.674\n",
      "[epoch: 35, i:  5828]  train_loss: 0.390  |  valid_loss: 0.572\n",
      "[epoch: 35, i:  5915]  train_loss: 0.474  |  valid_loss: 0.703\n",
      "[epoch: 35, i:  6002]  train_loss: 0.498  |  valid_loss: 0.520\n",
      "[epoch: 35, i:  6089]  train_loss: 0.520  |  valid_loss: 0.741\n",
      "[epoch: 35, i:  6176]  train_loss: 0.423  |  valid_loss: 0.613\n",
      "[epoch: 35, i:  6263]  train_loss: 0.526  |  valid_loss: 0.568\n",
      "[epoch: 35, i:  6350]  train_loss: 0.440  |  valid_loss: 0.511\n",
      "[epoch: 35, i:  6437]  train_loss: 0.484  |  valid_loss: 0.437\n",
      "[epoch: 35, i:  6524]  train_loss: 0.466  |  valid_loss: 0.739\n",
      "[epoch: 35, i:  6611]  train_loss: 0.456  |  valid_loss: 0.386\n",
      "[epoch: 35, i:  6698]  train_loss: 0.495  |  valid_loss: 0.684\n",
      "[epoch: 35, i:  6785]  train_loss: 0.464  |  valid_loss: 0.461\n",
      "[epoch: 35, i:  6872]  train_loss: 0.493  |  valid_loss: 0.717\n",
      "[epoch: 35, i:  6959]  train_loss: 0.501  |  valid_loss: 0.648\n",
      "[epoch: 35, i:  7046]  train_loss: 0.491  |  valid_loss: 0.580\n",
      "[epoch: 35, i:  7133]  train_loss: 0.533  |  valid_loss: 0.441\n",
      "[epoch: 35, i:  7220]  train_loss: 0.475  |  valid_loss: 0.741\n",
      "[epoch: 35, i:  7307]  train_loss: 0.557  |  valid_loss: 0.734\n",
      "[epoch: 35, i:  7394]  train_loss: 0.414  |  valid_loss: 0.531\n",
      "[epoch: 35, i:  7481]  train_loss: 0.535  |  valid_loss: 0.562\n",
      "[epoch: 35, i:  7568]  train_loss: 0.495  |  valid_loss: 0.709\n",
      "[epoch: 35, i:  7655]  train_loss: 0.509  |  valid_loss: 0.640\n",
      "[epoch: 35, i:  7742]  train_loss: 0.485  |  valid_loss: 0.583\n",
      "[epoch: 35, i:  7829]  train_loss: 0.498  |  valid_loss: 0.428\n",
      "[epoch: 35, i:  7916]  train_loss: 0.457  |  valid_loss: 0.585\n",
      "[epoch: 35, i:  8003]  train_loss: 0.475  |  valid_loss: 0.436\n",
      "[epoch: 35, i:  8090]  train_loss: 0.487  |  valid_loss: 0.455\n",
      "[epoch: 35, i:  8177]  train_loss: 0.482  |  valid_loss: 0.562\n",
      "[epoch: 35, i:  8264]  train_loss: 0.453  |  valid_loss: 0.602\n",
      "[epoch: 35, i:  8351]  train_loss: 0.526  |  valid_loss: 0.664\n",
      "[epoch: 35, i:  8438]  train_loss: 0.536  |  valid_loss: 0.446\n",
      "[epoch: 35, i:  8525]  train_loss: 0.519  |  valid_loss: 0.593\n",
      "[epoch: 35, i:  8612]  train_loss: 0.483  |  valid_loss: 0.840\n",
      "[epoch: 35, i:  8699]  train_loss: 0.458  |  valid_loss: 0.589\n",
      "--> [End of epoch 35] train_accuracy: 82.73%  |  valid_accuracy: 79.71%\n",
      "--> [Start of epoch 36]  lr: 0.000050\n",
      "[epoch: 36, i:    86]  train_loss: 0.490  |  valid_loss: 0.560\n",
      "[epoch: 36, i:   173]  train_loss: 0.476  |  valid_loss: 0.593\n",
      "[epoch: 36, i:   260]  train_loss: 0.493  |  valid_loss: 0.691\n",
      "[epoch: 36, i:   347]  train_loss: 0.452  |  valid_loss: 0.515\n",
      "[epoch: 36, i:   434]  train_loss: 0.456  |  valid_loss: 0.563\n",
      "[epoch: 36, i:   521]  train_loss: 0.461  |  valid_loss: 0.363\n",
      "[epoch: 36, i:   608]  train_loss: 0.494  |  valid_loss: 0.663\n",
      "[epoch: 36, i:   695]  train_loss: 0.506  |  valid_loss: 0.654\n",
      "[epoch: 36, i:   782]  train_loss: 0.479  |  valid_loss: 0.694\n",
      "[epoch: 36, i:   869]  train_loss: 0.449  |  valid_loss: 0.672\n",
      "[epoch: 36, i:   956]  train_loss: 0.479  |  valid_loss: 0.549\n",
      "[epoch: 36, i:  1043]  train_loss: 0.520  |  valid_loss: 0.532\n",
      "[epoch: 36, i:  1130]  train_loss: 0.477  |  valid_loss: 0.494\n",
      "[epoch: 36, i:  1217]  train_loss: 0.480  |  valid_loss: 0.596\n",
      "[epoch: 36, i:  1304]  train_loss: 0.511  |  valid_loss: 0.425\n",
      "[epoch: 36, i:  1391]  train_loss: 0.444  |  valid_loss: 0.629\n",
      "[epoch: 36, i:  1478]  train_loss: 0.429  |  valid_loss: 0.518\n",
      "[epoch: 36, i:  1565]  train_loss: 0.498  |  valid_loss: 0.778\n",
      "[epoch: 36, i:  1652]  train_loss: 0.448  |  valid_loss: 0.551\n",
      "[epoch: 36, i:  1739]  train_loss: 0.424  |  valid_loss: 0.926\n",
      "[epoch: 36, i:  1826]  train_loss: 0.488  |  valid_loss: 0.719\n",
      "[epoch: 36, i:  1913]  train_loss: 0.521  |  valid_loss: 0.596\n",
      "[epoch: 36, i:  2000]  train_loss: 0.539  |  valid_loss: 0.618\n",
      "[epoch: 36, i:  2087]  train_loss: 0.496  |  valid_loss: 0.766\n",
      "[epoch: 36, i:  2174]  train_loss: 0.447  |  valid_loss: 0.519\n",
      "[epoch: 36, i:  2261]  train_loss: 0.509  |  valid_loss: 0.832\n",
      "[epoch: 36, i:  2348]  train_loss: 0.469  |  valid_loss: 0.493\n",
      "[epoch: 36, i:  2435]  train_loss: 0.535  |  valid_loss: 0.677\n",
      "[epoch: 36, i:  2522]  train_loss: 0.488  |  valid_loss: 0.432\n",
      "[epoch: 36, i:  2609]  train_loss: 0.490  |  valid_loss: 0.530\n",
      "[epoch: 36, i:  2696]  train_loss: 0.457  |  valid_loss: 0.635\n",
      "[epoch: 36, i:  2783]  train_loss: 0.471  |  valid_loss: 0.385\n",
      "[epoch: 36, i:  2870]  train_loss: 0.467  |  valid_loss: 0.752\n",
      "[epoch: 36, i:  2957]  train_loss: 0.572  |  valid_loss: 0.703\n",
      "[epoch: 36, i:  3044]  train_loss: 0.489  |  valid_loss: 0.641\n",
      "[epoch: 36, i:  3131]  train_loss: 0.460  |  valid_loss: 0.602\n",
      "[epoch: 36, i:  3218]  train_loss: 0.487  |  valid_loss: 0.649\n",
      "[epoch: 36, i:  3305]  train_loss: 0.435  |  valid_loss: 0.563\n",
      "[epoch: 36, i:  3392]  train_loss: 0.458  |  valid_loss: 0.509\n",
      "[epoch: 36, i:  3479]  train_loss: 0.534  |  valid_loss: 0.580\n",
      "[epoch: 36, i:  3566]  train_loss: 0.553  |  valid_loss: 0.521\n",
      "[epoch: 36, i:  3653]  train_loss: 0.517  |  valid_loss: 0.574\n",
      "[epoch: 36, i:  3740]  train_loss: 0.470  |  valid_loss: 0.394\n",
      "[epoch: 36, i:  3827]  train_loss: 0.493  |  valid_loss: 0.746\n",
      "[epoch: 36, i:  3914]  train_loss: 0.510  |  valid_loss: 0.453\n",
      "[epoch: 36, i:  4001]  train_loss: 0.431  |  valid_loss: 0.594\n",
      "[epoch: 36, i:  4088]  train_loss: 0.425  |  valid_loss: 0.568\n",
      "[epoch: 36, i:  4175]  train_loss: 0.511  |  valid_loss: 0.554\n",
      "[epoch: 36, i:  4262]  train_loss: 0.443  |  valid_loss: 0.450\n",
      "[epoch: 36, i:  4349]  train_loss: 0.495  |  valid_loss: 0.583\n",
      "[epoch: 36, i:  4436]  train_loss: 0.412  |  valid_loss: 0.549\n",
      "[epoch: 36, i:  4523]  train_loss: 0.476  |  valid_loss: 0.707\n",
      "[epoch: 36, i:  4610]  train_loss: 0.467  |  valid_loss: 0.520\n",
      "[epoch: 36, i:  4697]  train_loss: 0.514  |  valid_loss: 0.625\n",
      "[epoch: 36, i:  4784]  train_loss: 0.520  |  valid_loss: 0.658\n",
      "[epoch: 36, i:  4871]  train_loss: 0.449  |  valid_loss: 0.676\n",
      "[epoch: 36, i:  4958]  train_loss: 0.456  |  valid_loss: 0.758\n",
      "[epoch: 36, i:  5045]  train_loss: 0.446  |  valid_loss: 0.400\n",
      "[epoch: 36, i:  5132]  train_loss: 0.519  |  valid_loss: 0.599\n",
      "[epoch: 36, i:  5219]  train_loss: 0.480  |  valid_loss: 0.754\n",
      "[epoch: 36, i:  5306]  train_loss: 0.463  |  valid_loss: 0.622\n",
      "[epoch: 36, i:  5393]  train_loss: 0.461  |  valid_loss: 0.546\n",
      "[epoch: 36, i:  5480]  train_loss: 0.492  |  valid_loss: 0.737\n",
      "[epoch: 36, i:  5567]  train_loss: 0.505  |  valid_loss: 0.330\n",
      "[epoch: 36, i:  5654]  train_loss: 0.507  |  valid_loss: 0.556\n",
      "[epoch: 36, i:  5741]  train_loss: 0.471  |  valid_loss: 0.643\n",
      "[epoch: 36, i:  5828]  train_loss: 0.474  |  valid_loss: 0.551\n",
      "[epoch: 36, i:  5915]  train_loss: 0.417  |  valid_loss: 0.730\n",
      "[epoch: 36, i:  6002]  train_loss: 0.492  |  valid_loss: 0.480\n",
      "[epoch: 36, i:  6089]  train_loss: 0.486  |  valid_loss: 0.753\n",
      "[epoch: 36, i:  6176]  train_loss: 0.482  |  valid_loss: 0.609\n",
      "[epoch: 36, i:  6263]  train_loss: 0.547  |  valid_loss: 0.569\n",
      "[epoch: 36, i:  6350]  train_loss: 0.405  |  valid_loss: 0.506\n",
      "[epoch: 36, i:  6437]  train_loss: 0.494  |  valid_loss: 0.437\n",
      "[epoch: 36, i:  6524]  train_loss: 0.507  |  valid_loss: 0.757\n",
      "[epoch: 36, i:  6611]  train_loss: 0.461  |  valid_loss: 0.400\n",
      "[epoch: 36, i:  6698]  train_loss: 0.454  |  valid_loss: 0.679\n",
      "[epoch: 36, i:  6785]  train_loss: 0.466  |  valid_loss: 0.416\n",
      "[epoch: 36, i:  6872]  train_loss: 0.455  |  valid_loss: 0.721\n",
      "[epoch: 36, i:  6959]  train_loss: 0.499  |  valid_loss: 0.639\n",
      "[epoch: 36, i:  7046]  train_loss: 0.473  |  valid_loss: 0.600\n",
      "[epoch: 36, i:  7133]  train_loss: 0.494  |  valid_loss: 0.448\n",
      "[epoch: 36, i:  7220]  train_loss: 0.464  |  valid_loss: 0.693\n",
      "[epoch: 36, i:  7307]  train_loss: 0.465  |  valid_loss: 0.695\n",
      "[epoch: 36, i:  7394]  train_loss: 0.450  |  valid_loss: 0.543\n",
      "[epoch: 36, i:  7481]  train_loss: 0.537  |  valid_loss: 0.598\n",
      "[epoch: 36, i:  7568]  train_loss: 0.477  |  valid_loss: 0.676\n",
      "[epoch: 36, i:  7655]  train_loss: 0.483  |  valid_loss: 0.627\n",
      "[epoch: 36, i:  7742]  train_loss: 0.435  |  valid_loss: 0.596\n",
      "[epoch: 36, i:  7829]  train_loss: 0.448  |  valid_loss: 0.408\n",
      "[epoch: 36, i:  7916]  train_loss: 0.461  |  valid_loss: 0.596\n",
      "[epoch: 36, i:  8003]  train_loss: 0.432  |  valid_loss: 0.438\n",
      "[epoch: 36, i:  8090]  train_loss: 0.463  |  valid_loss: 0.452\n",
      "[epoch: 36, i:  8177]  train_loss: 0.443  |  valid_loss: 0.547\n",
      "[epoch: 36, i:  8264]  train_loss: 0.491  |  valid_loss: 0.574\n",
      "[epoch: 36, i:  8351]  train_loss: 0.451  |  valid_loss: 0.659\n",
      "[epoch: 36, i:  8438]  train_loss: 0.474  |  valid_loss: 0.451\n",
      "[epoch: 36, i:  8525]  train_loss: 0.500  |  valid_loss: 0.556\n",
      "[epoch: 36, i:  8612]  train_loss: 0.413  |  valid_loss: 0.860\n",
      "[epoch: 36, i:  8699]  train_loss: 0.486  |  valid_loss: 0.585\n",
      "--> [End of epoch 36] train_accuracy: 83.45%  |  valid_accuracy: 80.52%\n",
      "--> [Start of epoch 37]  lr: 0.000050\n",
      "[epoch: 37, i:    86]  train_loss: 0.485  |  valid_loss: 0.565\n",
      "[epoch: 37, i:   173]  train_loss: 0.467  |  valid_loss: 0.596\n",
      "[epoch: 37, i:   260]  train_loss: 0.512  |  valid_loss: 0.645\n",
      "[epoch: 37, i:   347]  train_loss: 0.425  |  valid_loss: 0.561\n",
      "[epoch: 37, i:   434]  train_loss: 0.496  |  valid_loss: 0.586\n",
      "[epoch: 37, i:   521]  train_loss: 0.493  |  valid_loss: 0.361\n",
      "[epoch: 37, i:   608]  train_loss: 0.493  |  valid_loss: 0.633\n",
      "[epoch: 37, i:   695]  train_loss: 0.548  |  valid_loss: 0.651\n",
      "[epoch: 37, i:   782]  train_loss: 0.525  |  valid_loss: 0.670\n",
      "[epoch: 37, i:   869]  train_loss: 0.462  |  valid_loss: 0.677\n",
      "[epoch: 37, i:   956]  train_loss: 0.419  |  valid_loss: 0.531\n",
      "[epoch: 37, i:  1043]  train_loss: 0.432  |  valid_loss: 0.534\n",
      "[epoch: 37, i:  1130]  train_loss: 0.485  |  valid_loss: 0.456\n",
      "[epoch: 37, i:  1217]  train_loss: 0.468  |  valid_loss: 0.603\n",
      "[epoch: 37, i:  1304]  train_loss: 0.444  |  valid_loss: 0.403\n",
      "[epoch: 37, i:  1391]  train_loss: 0.393  |  valid_loss: 0.642\n",
      "[epoch: 37, i:  1478]  train_loss: 0.498  |  valid_loss: 0.516\n",
      "[epoch: 37, i:  1565]  train_loss: 0.484  |  valid_loss: 0.759\n",
      "[epoch: 37, i:  1652]  train_loss: 0.505  |  valid_loss: 0.562\n",
      "[epoch: 37, i:  1739]  train_loss: 0.441  |  valid_loss: 0.903\n",
      "[epoch: 37, i:  1826]  train_loss: 0.459  |  valid_loss: 0.690\n",
      "[epoch: 37, i:  1913]  train_loss: 0.498  |  valid_loss: 0.624\n",
      "[epoch: 37, i:  2000]  train_loss: 0.505  |  valid_loss: 0.604\n",
      "[epoch: 37, i:  2087]  train_loss: 0.466  |  valid_loss: 0.728\n",
      "[epoch: 37, i:  2174]  train_loss: 0.518  |  valid_loss: 0.521\n",
      "[epoch: 37, i:  2261]  train_loss: 0.447  |  valid_loss: 0.834\n",
      "[epoch: 37, i:  2348]  train_loss: 0.441  |  valid_loss: 0.449\n",
      "[epoch: 37, i:  2435]  train_loss: 0.509  |  valid_loss: 0.660\n",
      "[epoch: 37, i:  2522]  train_loss: 0.443  |  valid_loss: 0.430\n",
      "[epoch: 37, i:  2609]  train_loss: 0.447  |  valid_loss: 0.545\n",
      "[epoch: 37, i:  2696]  train_loss: 0.477  |  valid_loss: 0.648\n",
      "[epoch: 37, i:  2783]  train_loss: 0.551  |  valid_loss: 0.396\n",
      "[epoch: 37, i:  2870]  train_loss: 0.434  |  valid_loss: 0.753\n",
      "[epoch: 37, i:  2957]  train_loss: 0.511  |  valid_loss: 0.688\n",
      "[epoch: 37, i:  3044]  train_loss: 0.415  |  valid_loss: 0.650\n",
      "[epoch: 37, i:  3131]  train_loss: 0.450  |  valid_loss: 0.554\n",
      "[epoch: 37, i:  3218]  train_loss: 0.534  |  valid_loss: 0.674\n",
      "[epoch: 37, i:  3305]  train_loss: 0.511  |  valid_loss: 0.615\n",
      "[epoch: 37, i:  3392]  train_loss: 0.486  |  valid_loss: 0.521\n",
      "[epoch: 37, i:  3479]  train_loss: 0.461  |  valid_loss: 0.574\n",
      "[epoch: 37, i:  3566]  train_loss: 0.453  |  valid_loss: 0.511\n",
      "[epoch: 37, i:  3653]  train_loss: 0.433  |  valid_loss: 0.573\n",
      "[epoch: 37, i:  3740]  train_loss: 0.437  |  valid_loss: 0.391\n",
      "[epoch: 37, i:  3827]  train_loss: 0.478  |  valid_loss: 0.753\n",
      "[epoch: 37, i:  3914]  train_loss: 0.479  |  valid_loss: 0.445\n",
      "[epoch: 37, i:  4001]  train_loss: 0.479  |  valid_loss: 0.602\n",
      "[epoch: 37, i:  4088]  train_loss: 0.466  |  valid_loss: 0.540\n",
      "[epoch: 37, i:  4175]  train_loss: 0.509  |  valid_loss: 0.539\n",
      "[epoch: 37, i:  4262]  train_loss: 0.508  |  valid_loss: 0.463\n",
      "[epoch: 37, i:  4349]  train_loss: 0.544  |  valid_loss: 0.575\n",
      "[epoch: 37, i:  4436]  train_loss: 0.456  |  valid_loss: 0.555\n",
      "[epoch: 37, i:  4523]  train_loss: 0.482  |  valid_loss: 0.679\n",
      "[epoch: 37, i:  4610]  train_loss: 0.428  |  valid_loss: 0.484\n",
      "[epoch: 37, i:  4697]  train_loss: 0.455  |  valid_loss: 0.581\n",
      "[epoch: 37, i:  4784]  train_loss: 0.508  |  valid_loss: 0.648\n",
      "[epoch: 37, i:  4871]  train_loss: 0.477  |  valid_loss: 0.724\n",
      "[epoch: 37, i:  4958]  train_loss: 0.466  |  valid_loss: 0.757\n",
      "[epoch: 37, i:  5045]  train_loss: 0.433  |  valid_loss: 0.418\n",
      "[epoch: 37, i:  5132]  train_loss: 0.460  |  valid_loss: 0.578\n",
      "[epoch: 37, i:  5219]  train_loss: 0.476  |  valid_loss: 0.774\n",
      "[epoch: 37, i:  5306]  train_loss: 0.486  |  valid_loss: 0.624\n",
      "[epoch: 37, i:  5393]  train_loss: 0.483  |  valid_loss: 0.551\n",
      "[epoch: 37, i:  5480]  train_loss: 0.422  |  valid_loss: 0.739\n",
      "[epoch: 37, i:  5567]  train_loss: 0.452  |  valid_loss: 0.322\n",
      "[epoch: 37, i:  5654]  train_loss: 0.466  |  valid_loss: 0.535\n",
      "[epoch: 37, i:  5741]  train_loss: 0.484  |  valid_loss: 0.648\n",
      "[epoch: 37, i:  5828]  train_loss: 0.535  |  valid_loss: 0.590\n",
      "[epoch: 37, i:  5915]  train_loss: 0.427  |  valid_loss: 0.752\n",
      "[epoch: 37, i:  6002]  train_loss: 0.476  |  valid_loss: 0.505\n",
      "[epoch: 37, i:  6089]  train_loss: 0.449  |  valid_loss: 0.793\n",
      "[epoch: 37, i:  6176]  train_loss: 0.490  |  valid_loss: 0.587\n",
      "[epoch: 37, i:  6263]  train_loss: 0.448  |  valid_loss: 0.567\n",
      "[epoch: 37, i:  6350]  train_loss: 0.473  |  valid_loss: 0.517\n",
      "[epoch: 37, i:  6437]  train_loss: 0.482  |  valid_loss: 0.429\n",
      "[epoch: 37, i:  6524]  train_loss: 0.491  |  valid_loss: 0.763\n",
      "[epoch: 37, i:  6611]  train_loss: 0.463  |  valid_loss: 0.415\n",
      "[epoch: 37, i:  6698]  train_loss: 0.507  |  valid_loss: 0.688\n",
      "[epoch: 37, i:  6785]  train_loss: 0.483  |  valid_loss: 0.433\n",
      "[epoch: 37, i:  6872]  train_loss: 0.447  |  valid_loss: 0.732\n",
      "[epoch: 37, i:  6959]  train_loss: 0.513  |  valid_loss: 0.641\n",
      "[epoch: 37, i:  7046]  train_loss: 0.473  |  valid_loss: 0.586\n",
      "[epoch: 37, i:  7133]  train_loss: 0.479  |  valid_loss: 0.469\n",
      "[epoch: 37, i:  7220]  train_loss: 0.523  |  valid_loss: 0.705\n",
      "[epoch: 37, i:  7307]  train_loss: 0.462  |  valid_loss: 0.732\n",
      "[epoch: 37, i:  7394]  train_loss: 0.503  |  valid_loss: 0.506\n",
      "[epoch: 37, i:  7481]  train_loss: 0.460  |  valid_loss: 0.540\n",
      "[epoch: 37, i:  7568]  train_loss: 0.439  |  valid_loss: 0.723\n",
      "[epoch: 37, i:  7655]  train_loss: 0.490  |  valid_loss: 0.620\n",
      "[epoch: 37, i:  7742]  train_loss: 0.436  |  valid_loss: 0.601\n",
      "[epoch: 37, i:  7829]  train_loss: 0.465  |  valid_loss: 0.399\n",
      "[epoch: 37, i:  7916]  train_loss: 0.403  |  valid_loss: 0.589\n",
      "[epoch: 37, i:  8003]  train_loss: 0.461  |  valid_loss: 0.436\n",
      "[epoch: 37, i:  8090]  train_loss: 0.427  |  valid_loss: 0.484\n",
      "[epoch: 37, i:  8177]  train_loss: 0.441  |  valid_loss: 0.505\n",
      "[epoch: 37, i:  8264]  train_loss: 0.450  |  valid_loss: 0.616\n",
      "[epoch: 37, i:  8351]  train_loss: 0.386  |  valid_loss: 0.653\n",
      "[epoch: 37, i:  8438]  train_loss: 0.493  |  valid_loss: 0.455\n",
      "[epoch: 37, i:  8525]  train_loss: 0.425  |  valid_loss: 0.553\n",
      "[epoch: 37, i:  8612]  train_loss: 0.455  |  valid_loss: 0.844\n",
      "[epoch: 37, i:  8699]  train_loss: 0.467  |  valid_loss: 0.608\n",
      "--> [End of epoch 37] train_accuracy: 83.83%  |  valid_accuracy: 80.56%\n",
      "--> [Start of epoch 38]  lr: 0.000050\n",
      "[epoch: 38, i:    86]  train_loss: 0.397  |  valid_loss: 0.557\n",
      "[epoch: 38, i:   173]  train_loss: 0.436  |  valid_loss: 0.600\n",
      "[epoch: 38, i:   260]  train_loss: 0.447  |  valid_loss: 0.664\n",
      "[epoch: 38, i:   347]  train_loss: 0.436  |  valid_loss: 0.504\n",
      "[epoch: 38, i:   434]  train_loss: 0.482  |  valid_loss: 0.559\n",
      "[epoch: 38, i:   521]  train_loss: 0.451  |  valid_loss: 0.365\n",
      "[epoch: 38, i:   608]  train_loss: 0.544  |  valid_loss: 0.601\n",
      "[epoch: 38, i:   695]  train_loss: 0.460  |  valid_loss: 0.622\n",
      "[epoch: 38, i:   782]  train_loss: 0.450  |  valid_loss: 0.713\n",
      "[epoch: 38, i:   869]  train_loss: 0.438  |  valid_loss: 0.686\n",
      "[epoch: 38, i:   956]  train_loss: 0.400  |  valid_loss: 0.502\n",
      "[epoch: 38, i:  1043]  train_loss: 0.443  |  valid_loss: 0.536\n",
      "[epoch: 38, i:  1130]  train_loss: 0.421  |  valid_loss: 0.495\n",
      "[epoch: 38, i:  1217]  train_loss: 0.478  |  valid_loss: 0.643\n",
      "[epoch: 38, i:  1304]  train_loss: 0.423  |  valid_loss: 0.428\n",
      "[epoch: 38, i:  1391]  train_loss: 0.526  |  valid_loss: 0.689\n",
      "[epoch: 38, i:  1478]  train_loss: 0.435  |  valid_loss: 0.499\n",
      "[epoch: 38, i:  1565]  train_loss: 0.451  |  valid_loss: 0.769\n",
      "[epoch: 38, i:  1652]  train_loss: 0.454  |  valid_loss: 0.616\n",
      "[epoch: 38, i:  1739]  train_loss: 0.441  |  valid_loss: 0.894\n",
      "[epoch: 38, i:  1826]  train_loss: 0.485  |  valid_loss: 0.690\n",
      "[epoch: 38, i:  1913]  train_loss: 0.513  |  valid_loss: 0.603\n",
      "[epoch: 38, i:  2000]  train_loss: 0.473  |  valid_loss: 0.580\n",
      "[epoch: 38, i:  2087]  train_loss: 0.480  |  valid_loss: 0.736\n",
      "[epoch: 38, i:  2174]  train_loss: 0.453  |  valid_loss: 0.562\n",
      "[epoch: 38, i:  2261]  train_loss: 0.447  |  valid_loss: 0.822\n",
      "[epoch: 38, i:  2348]  train_loss: 0.432  |  valid_loss: 0.482\n",
      "[epoch: 38, i:  2435]  train_loss: 0.436  |  valid_loss: 0.663\n",
      "[epoch: 38, i:  2522]  train_loss: 0.499  |  valid_loss: 0.419\n",
      "[epoch: 38, i:  2609]  train_loss: 0.414  |  valid_loss: 0.547\n",
      "[epoch: 38, i:  2696]  train_loss: 0.411  |  valid_loss: 0.645\n",
      "[epoch: 38, i:  2783]  train_loss: 0.470  |  valid_loss: 0.375\n",
      "[epoch: 38, i:  2870]  train_loss: 0.472  |  valid_loss: 0.695\n",
      "[epoch: 38, i:  2957]  train_loss: 0.462  |  valid_loss: 0.697\n",
      "[epoch: 38, i:  3044]  train_loss: 0.460  |  valid_loss: 0.675\n",
      "[epoch: 38, i:  3131]  train_loss: 0.508  |  valid_loss: 0.558\n",
      "[epoch: 38, i:  3218]  train_loss: 0.447  |  valid_loss: 0.632\n",
      "[epoch: 38, i:  3305]  train_loss: 0.443  |  valid_loss: 0.597\n",
      "[epoch: 38, i:  3392]  train_loss: 0.473  |  valid_loss: 0.499\n",
      "[epoch: 38, i:  3479]  train_loss: 0.458  |  valid_loss: 0.554\n",
      "[epoch: 38, i:  3566]  train_loss: 0.465  |  valid_loss: 0.556\n",
      "[epoch: 38, i:  3653]  train_loss: 0.477  |  valid_loss: 0.611\n",
      "[epoch: 38, i:  3740]  train_loss: 0.445  |  valid_loss: 0.393\n",
      "[epoch: 38, i:  3827]  train_loss: 0.436  |  valid_loss: 0.827\n",
      "[epoch: 38, i:  3914]  train_loss: 0.520  |  valid_loss: 0.414\n",
      "[epoch: 38, i:  4001]  train_loss: 0.483  |  valid_loss: 0.618\n",
      "[epoch: 38, i:  4088]  train_loss: 0.487  |  valid_loss: 0.503\n",
      "[epoch: 38, i:  4175]  train_loss: 0.473  |  valid_loss: 0.560\n",
      "[epoch: 38, i:  4262]  train_loss: 0.527  |  valid_loss: 0.455\n",
      "[epoch: 38, i:  4349]  train_loss: 0.502  |  valid_loss: 0.583\n",
      "[epoch: 38, i:  4436]  train_loss: 0.454  |  valid_loss: 0.550\n",
      "[epoch: 38, i:  4523]  train_loss: 0.489  |  valid_loss: 0.704\n",
      "[epoch: 38, i:  4610]  train_loss: 0.490  |  valid_loss: 0.497\n",
      "[epoch: 38, i:  4697]  train_loss: 0.445  |  valid_loss: 0.598\n",
      "[epoch: 38, i:  4784]  train_loss: 0.465  |  valid_loss: 0.635\n",
      "[epoch: 38, i:  4871]  train_loss: 0.463  |  valid_loss: 0.685\n",
      "[epoch: 38, i:  4958]  train_loss: 0.450  |  valid_loss: 0.755\n",
      "[epoch: 38, i:  5045]  train_loss: 0.434  |  valid_loss: 0.414\n",
      "[epoch: 38, i:  5132]  train_loss: 0.498  |  valid_loss: 0.587\n",
      "[epoch: 38, i:  5219]  train_loss: 0.522  |  valid_loss: 0.754\n",
      "[epoch: 38, i:  5306]  train_loss: 0.461  |  valid_loss: 0.592\n",
      "[epoch: 38, i:  5393]  train_loss: 0.471  |  valid_loss: 0.475\n",
      "[epoch: 38, i:  5480]  train_loss: 0.505  |  valid_loss: 0.800\n",
      "[epoch: 38, i:  5567]  train_loss: 0.441  |  valid_loss: 0.315\n",
      "[epoch: 38, i:  5654]  train_loss: 0.465  |  valid_loss: 0.560\n",
      "[epoch: 38, i:  5741]  train_loss: 0.418  |  valid_loss: 0.653\n",
      "[epoch: 38, i:  5828]  train_loss: 0.412  |  valid_loss: 0.561\n",
      "[epoch: 38, i:  5915]  train_loss: 0.508  |  valid_loss: 0.733\n",
      "[epoch: 38, i:  6002]  train_loss: 0.473  |  valid_loss: 0.486\n",
      "[epoch: 38, i:  6089]  train_loss: 0.428  |  valid_loss: 0.746\n",
      "[epoch: 38, i:  6176]  train_loss: 0.496  |  valid_loss: 0.602\n",
      "[epoch: 38, i:  6263]  train_loss: 0.444  |  valid_loss: 0.551\n",
      "[epoch: 38, i:  6350]  train_loss: 0.436  |  valid_loss: 0.507\n",
      "[epoch: 38, i:  6437]  train_loss: 0.488  |  valid_loss: 0.427\n",
      "[epoch: 38, i:  6524]  train_loss: 0.419  |  valid_loss: 0.754\n",
      "[epoch: 38, i:  6611]  train_loss: 0.484  |  valid_loss: 0.383\n",
      "[epoch: 38, i:  6698]  train_loss: 0.448  |  valid_loss: 0.678\n",
      "[epoch: 38, i:  6785]  train_loss: 0.478  |  valid_loss: 0.443\n",
      "[epoch: 38, i:  6872]  train_loss: 0.416  |  valid_loss: 0.744\n",
      "[epoch: 38, i:  6959]  train_loss: 0.456  |  valid_loss: 0.646\n",
      "[epoch: 38, i:  7046]  train_loss: 0.500  |  valid_loss: 0.573\n",
      "[epoch: 38, i:  7133]  train_loss: 0.438  |  valid_loss: 0.430\n",
      "[epoch: 38, i:  7220]  train_loss: 0.493  |  valid_loss: 0.727\n",
      "[epoch: 38, i:  7307]  train_loss: 0.439  |  valid_loss: 0.717\n",
      "[epoch: 38, i:  7394]  train_loss: 0.500  |  valid_loss: 0.539\n",
      "[epoch: 38, i:  7481]  train_loss: 0.433  |  valid_loss: 0.575\n",
      "[epoch: 38, i:  7568]  train_loss: 0.441  |  valid_loss: 0.707\n",
      "[epoch: 38, i:  7655]  train_loss: 0.496  |  valid_loss: 0.617\n",
      "[epoch: 38, i:  7742]  train_loss: 0.446  |  valid_loss: 0.578\n",
      "[epoch: 38, i:  7829]  train_loss: 0.475  |  valid_loss: 0.408\n",
      "[epoch: 38, i:  7916]  train_loss: 0.438  |  valid_loss: 0.610\n",
      "[epoch: 38, i:  8003]  train_loss: 0.425  |  valid_loss: 0.436\n",
      "[epoch: 38, i:  8090]  train_loss: 0.484  |  valid_loss: 0.477\n",
      "[epoch: 38, i:  8177]  train_loss: 0.492  |  valid_loss: 0.542\n",
      "[epoch: 38, i:  8264]  train_loss: 0.526  |  valid_loss: 0.633\n",
      "[epoch: 38, i:  8351]  train_loss: 0.485  |  valid_loss: 0.664\n",
      "[epoch: 38, i:  8438]  train_loss: 0.492  |  valid_loss: 0.453\n",
      "[epoch: 38, i:  8525]  train_loss: 0.442  |  valid_loss: 0.548\n",
      "[epoch: 38, i:  8612]  train_loss: 0.465  |  valid_loss: 0.839\n",
      "[epoch: 38, i:  8699]  train_loss: 0.483  |  valid_loss: 0.598\n",
      "--> [End of epoch 38] train_accuracy: 84.03%  |  valid_accuracy: 80.78%\n",
      "--> [Start of epoch 39]  lr: 0.000050\n",
      "[epoch: 39, i:    86]  train_loss: 0.419  |  valid_loss: 0.570\n",
      "[epoch: 39, i:   173]  train_loss: 0.429  |  valid_loss: 0.613\n",
      "[epoch: 39, i:   260]  train_loss: 0.465  |  valid_loss: 0.727\n",
      "[epoch: 39, i:   347]  train_loss: 0.481  |  valid_loss: 0.518\n",
      "[epoch: 39, i:   434]  train_loss: 0.422  |  valid_loss: 0.587\n",
      "[epoch: 39, i:   521]  train_loss: 0.463  |  valid_loss: 0.362\n",
      "[epoch: 39, i:   608]  train_loss: 0.466  |  valid_loss: 0.635\n",
      "[epoch: 39, i:   695]  train_loss: 0.474  |  valid_loss: 0.616\n",
      "[epoch: 39, i:   782]  train_loss: 0.423  |  valid_loss: 0.675\n",
      "[epoch: 39, i:   869]  train_loss: 0.469  |  valid_loss: 0.650\n",
      "[epoch: 39, i:   956]  train_loss: 0.452  |  valid_loss: 0.540\n",
      "[epoch: 39, i:  1043]  train_loss: 0.420  |  valid_loss: 0.543\n",
      "[epoch: 39, i:  1130]  train_loss: 0.498  |  valid_loss: 0.511\n",
      "[epoch: 39, i:  1217]  train_loss: 0.473  |  valid_loss: 0.593\n",
      "[epoch: 39, i:  1304]  train_loss: 0.471  |  valid_loss: 0.409\n",
      "[epoch: 39, i:  1391]  train_loss: 0.444  |  valid_loss: 0.645\n",
      "[epoch: 39, i:  1478]  train_loss: 0.422  |  valid_loss: 0.505\n",
      "[epoch: 39, i:  1565]  train_loss: 0.436  |  valid_loss: 0.759\n",
      "[epoch: 39, i:  1652]  train_loss: 0.467  |  valid_loss: 0.569\n",
      "[epoch: 39, i:  1739]  train_loss: 0.520  |  valid_loss: 0.861\n",
      "[epoch: 39, i:  1826]  train_loss: 0.442  |  valid_loss: 0.720\n",
      "[epoch: 39, i:  1913]  train_loss: 0.462  |  valid_loss: 0.597\n",
      "[epoch: 39, i:  2000]  train_loss: 0.453  |  valid_loss: 0.631\n",
      "[epoch: 39, i:  2087]  train_loss: 0.508  |  valid_loss: 0.777\n",
      "[epoch: 39, i:  2174]  train_loss: 0.470  |  valid_loss: 0.509\n",
      "[epoch: 39, i:  2261]  train_loss: 0.405  |  valid_loss: 0.843\n",
      "[epoch: 39, i:  2348]  train_loss: 0.485  |  valid_loss: 0.480\n",
      "[epoch: 39, i:  2435]  train_loss: 0.468  |  valid_loss: 0.645\n",
      "[epoch: 39, i:  2522]  train_loss: 0.399  |  valid_loss: 0.427\n",
      "[epoch: 39, i:  2609]  train_loss: 0.462  |  valid_loss: 0.558\n",
      "[epoch: 39, i:  2696]  train_loss: 0.445  |  valid_loss: 0.649\n",
      "[epoch: 39, i:  2783]  train_loss: 0.511  |  valid_loss: 0.395\n",
      "[epoch: 39, i:  2870]  train_loss: 0.482  |  valid_loss: 0.707\n",
      "[epoch: 39, i:  2957]  train_loss: 0.444  |  valid_loss: 0.738\n",
      "[epoch: 39, i:  3044]  train_loss: 0.448  |  valid_loss: 0.656\n",
      "[epoch: 39, i:  3131]  train_loss: 0.459  |  valid_loss: 0.542\n",
      "[epoch: 39, i:  3218]  train_loss: 0.473  |  valid_loss: 0.665\n",
      "[epoch: 39, i:  3305]  train_loss: 0.535  |  valid_loss: 0.604\n",
      "[epoch: 39, i:  3392]  train_loss: 0.411  |  valid_loss: 0.504\n",
      "[epoch: 39, i:  3479]  train_loss: 0.478  |  valid_loss: 0.538\n",
      "[epoch: 39, i:  3566]  train_loss: 0.474  |  valid_loss: 0.506\n",
      "[epoch: 39, i:  3653]  train_loss: 0.535  |  valid_loss: 0.600\n",
      "[epoch: 39, i:  3740]  train_loss: 0.444  |  valid_loss: 0.390\n",
      "[epoch: 39, i:  3827]  train_loss: 0.495  |  valid_loss: 0.792\n",
      "[epoch: 39, i:  3914]  train_loss: 0.460  |  valid_loss: 0.403\n",
      "[epoch: 39, i:  4001]  train_loss: 0.463  |  valid_loss: 0.609\n",
      "[epoch: 39, i:  4088]  train_loss: 0.480  |  valid_loss: 0.542\n",
      "[epoch: 39, i:  4175]  train_loss: 0.493  |  valid_loss: 0.556\n",
      "[epoch: 39, i:  4262]  train_loss: 0.462  |  valid_loss: 0.470\n",
      "[epoch: 39, i:  4349]  train_loss: 0.433  |  valid_loss: 0.577\n",
      "[epoch: 39, i:  4436]  train_loss: 0.422  |  valid_loss: 0.573\n",
      "[epoch: 39, i:  4523]  train_loss: 0.467  |  valid_loss: 0.680\n",
      "[epoch: 39, i:  4610]  train_loss: 0.421  |  valid_loss: 0.490\n",
      "[epoch: 39, i:  4697]  train_loss: 0.443  |  valid_loss: 0.595\n",
      "[epoch: 39, i:  4784]  train_loss: 0.482  |  valid_loss: 0.653\n",
      "[epoch: 39, i:  4871]  train_loss: 0.471  |  valid_loss: 0.688\n",
      "[epoch: 39, i:  4958]  train_loss: 0.475  |  valid_loss: 0.792\n",
      "[epoch: 39, i:  5045]  train_loss: 0.455  |  valid_loss: 0.420\n",
      "[epoch: 39, i:  5132]  train_loss: 0.421  |  valid_loss: 0.599\n",
      "[epoch: 39, i:  5219]  train_loss: 0.376  |  valid_loss: 0.719\n",
      "[epoch: 39, i:  5306]  train_loss: 0.459  |  valid_loss: 0.602\n",
      "[epoch: 39, i:  5393]  train_loss: 0.477  |  valid_loss: 0.502\n",
      "[epoch: 39, i:  5480]  train_loss: 0.462  |  valid_loss: 0.777\n",
      "[epoch: 39, i:  5567]  train_loss: 0.483  |  valid_loss: 0.324\n",
      "[epoch: 39, i:  5654]  train_loss: 0.443  |  valid_loss: 0.539\n",
      "[epoch: 39, i:  5741]  train_loss: 0.468  |  valid_loss: 0.593\n",
      "[epoch: 39, i:  5828]  train_loss: 0.469  |  valid_loss: 0.563\n",
      "[epoch: 39, i:  5915]  train_loss: 0.409  |  valid_loss: 0.713\n",
      "[epoch: 39, i:  6002]  train_loss: 0.487  |  valid_loss: 0.477\n",
      "[epoch: 39, i:  6089]  train_loss: 0.441  |  valid_loss: 0.785\n",
      "[epoch: 39, i:  6176]  train_loss: 0.417  |  valid_loss: 0.610\n",
      "[epoch: 39, i:  6263]  train_loss: 0.436  |  valid_loss: 0.564\n",
      "[epoch: 39, i:  6350]  train_loss: 0.422  |  valid_loss: 0.486\n",
      "[epoch: 39, i:  6437]  train_loss: 0.478  |  valid_loss: 0.418\n",
      "[epoch: 39, i:  6524]  train_loss: 0.444  |  valid_loss: 0.738\n",
      "[epoch: 39, i:  6611]  train_loss: 0.433  |  valid_loss: 0.378\n",
      "[epoch: 39, i:  6698]  train_loss: 0.403  |  valid_loss: 0.671\n",
      "[epoch: 39, i:  6785]  train_loss: 0.479  |  valid_loss: 0.440\n",
      "[epoch: 39, i:  6872]  train_loss: 0.473  |  valid_loss: 0.725\n",
      "[epoch: 39, i:  6959]  train_loss: 0.488  |  valid_loss: 0.631\n",
      "[epoch: 39, i:  7046]  train_loss: 0.442  |  valid_loss: 0.557\n",
      "[epoch: 39, i:  7133]  train_loss: 0.550  |  valid_loss: 0.460\n",
      "[epoch: 39, i:  7220]  train_loss: 0.496  |  valid_loss: 0.732\n",
      "[epoch: 39, i:  7307]  train_loss: 0.446  |  valid_loss: 0.720\n",
      "[epoch: 39, i:  7394]  train_loss: 0.472  |  valid_loss: 0.562\n",
      "[epoch: 39, i:  7481]  train_loss: 0.436  |  valid_loss: 0.582\n",
      "[epoch: 39, i:  7568]  train_loss: 0.496  |  valid_loss: 0.710\n",
      "[epoch: 39, i:  7655]  train_loss: 0.469  |  valid_loss: 0.661\n",
      "[epoch: 39, i:  7742]  train_loss: 0.444  |  valid_loss: 0.599\n",
      "[epoch: 39, i:  7829]  train_loss: 0.473  |  valid_loss: 0.411\n",
      "[epoch: 39, i:  7916]  train_loss: 0.479  |  valid_loss: 0.618\n",
      "[epoch: 39, i:  8003]  train_loss: 0.455  |  valid_loss: 0.416\n",
      "[epoch: 39, i:  8090]  train_loss: 0.418  |  valid_loss: 0.471\n",
      "[epoch: 39, i:  8177]  train_loss: 0.528  |  valid_loss: 0.539\n",
      "[epoch: 39, i:  8264]  train_loss: 0.479  |  valid_loss: 0.619\n",
      "[epoch: 39, i:  8351]  train_loss: 0.512  |  valid_loss: 0.674\n",
      "[epoch: 39, i:  8438]  train_loss: 0.458  |  valid_loss: 0.478\n",
      "[epoch: 39, i:  8525]  train_loss: 0.474  |  valid_loss: 0.570\n",
      "[epoch: 39, i:  8612]  train_loss: 0.458  |  valid_loss: 0.855\n",
      "[epoch: 39, i:  8699]  train_loss: 0.457  |  valid_loss: 0.554\n",
      "--> [End of epoch 39] train_accuracy: 83.99%  |  valid_accuracy: 80.57%\n",
      "--> [Start of epoch 40]  lr: 0.000050\n",
      "[epoch: 40, i:    86]  train_loss: 0.435  |  valid_loss: 0.571\n",
      "[epoch: 40, i:   173]  train_loss: 0.467  |  valid_loss: 0.620\n",
      "[epoch: 40, i:   260]  train_loss: 0.447  |  valid_loss: 0.670\n",
      "[epoch: 40, i:   347]  train_loss: 0.435  |  valid_loss: 0.525\n",
      "[epoch: 40, i:   434]  train_loss: 0.478  |  valid_loss: 0.577\n",
      "[epoch: 40, i:   521]  train_loss: 0.462  |  valid_loss: 0.369\n",
      "[epoch: 40, i:   608]  train_loss: 0.498  |  valid_loss: 0.652\n",
      "[epoch: 40, i:   695]  train_loss: 0.474  |  valid_loss: 0.581\n",
      "[epoch: 40, i:   782]  train_loss: 0.468  |  valid_loss: 0.674\n",
      "[epoch: 40, i:   869]  train_loss: 0.479  |  valid_loss: 0.652\n",
      "[epoch: 40, i:   956]  train_loss: 0.503  |  valid_loss: 0.556\n",
      "[epoch: 40, i:  1043]  train_loss: 0.441  |  valid_loss: 0.546\n",
      "[epoch: 40, i:  1130]  train_loss: 0.534  |  valid_loss: 0.517\n",
      "[epoch: 40, i:  1217]  train_loss: 0.460  |  valid_loss: 0.622\n",
      "[epoch: 40, i:  1304]  train_loss: 0.507  |  valid_loss: 0.406\n",
      "[epoch: 40, i:  1391]  train_loss: 0.441  |  valid_loss: 0.642\n",
      "[epoch: 40, i:  1478]  train_loss: 0.444  |  valid_loss: 0.540\n",
      "[epoch: 40, i:  1565]  train_loss: 0.441  |  valid_loss: 0.754\n",
      "[epoch: 40, i:  1652]  train_loss: 0.528  |  valid_loss: 0.539\n",
      "[epoch: 40, i:  1739]  train_loss: 0.439  |  valid_loss: 0.868\n",
      "[epoch: 40, i:  1826]  train_loss: 0.447  |  valid_loss: 0.725\n",
      "[epoch: 40, i:  1913]  train_loss: 0.503  |  valid_loss: 0.627\n",
      "[epoch: 40, i:  2000]  train_loss: 0.460  |  valid_loss: 0.577\n",
      "[epoch: 40, i:  2087]  train_loss: 0.489  |  valid_loss: 0.767\n",
      "[epoch: 40, i:  2174]  train_loss: 0.492  |  valid_loss: 0.525\n",
      "[epoch: 40, i:  2261]  train_loss: 0.468  |  valid_loss: 0.821\n",
      "[epoch: 40, i:  2348]  train_loss: 0.462  |  valid_loss: 0.434\n",
      "[epoch: 40, i:  2435]  train_loss: 0.435  |  valid_loss: 0.624\n",
      "[epoch: 40, i:  2522]  train_loss: 0.473  |  valid_loss: 0.439\n",
      "[epoch: 40, i:  2609]  train_loss: 0.408  |  valid_loss: 0.529\n",
      "[epoch: 40, i:  2696]  train_loss: 0.398  |  valid_loss: 0.663\n",
      "[epoch: 40, i:  2783]  train_loss: 0.474  |  valid_loss: 0.401\n",
      "[epoch: 40, i:  2870]  train_loss: 0.442  |  valid_loss: 0.719\n",
      "[epoch: 40, i:  2957]  train_loss: 0.494  |  valid_loss: 0.704\n",
      "[epoch: 40, i:  3044]  train_loss: 0.463  |  valid_loss: 0.654\n",
      "[epoch: 40, i:  3131]  train_loss: 0.453  |  valid_loss: 0.549\n",
      "[epoch: 40, i:  3218]  train_loss: 0.404  |  valid_loss: 0.675\n",
      "[epoch: 40, i:  3305]  train_loss: 0.440  |  valid_loss: 0.600\n",
      "[epoch: 40, i:  3392]  train_loss: 0.426  |  valid_loss: 0.520\n",
      "[epoch: 40, i:  3479]  train_loss: 0.410  |  valid_loss: 0.537\n",
      "[epoch: 40, i:  3566]  train_loss: 0.461  |  valid_loss: 0.500\n",
      "[epoch: 40, i:  3653]  train_loss: 0.428  |  valid_loss: 0.594\n",
      "[epoch: 40, i:  3740]  train_loss: 0.477  |  valid_loss: 0.409\n",
      "[epoch: 40, i:  3827]  train_loss: 0.440  |  valid_loss: 0.776\n",
      "[epoch: 40, i:  3914]  train_loss: 0.477  |  valid_loss: 0.419\n",
      "[epoch: 40, i:  4001]  train_loss: 0.515  |  valid_loss: 0.608\n",
      "[epoch: 40, i:  4088]  train_loss: 0.486  |  valid_loss: 0.564\n",
      "[epoch: 40, i:  4175]  train_loss: 0.494  |  valid_loss: 0.577\n",
      "[epoch: 40, i:  4262]  train_loss: 0.433  |  valid_loss: 0.440\n",
      "[epoch: 40, i:  4349]  train_loss: 0.448  |  valid_loss: 0.551\n",
      "[epoch: 40, i:  4436]  train_loss: 0.423  |  valid_loss: 0.549\n",
      "[epoch: 40, i:  4523]  train_loss: 0.424  |  valid_loss: 0.677\n",
      "[epoch: 40, i:  4610]  train_loss: 0.476  |  valid_loss: 0.470\n",
      "[epoch: 40, i:  4697]  train_loss: 0.449  |  valid_loss: 0.585\n",
      "[epoch: 40, i:  4784]  train_loss: 0.451  |  valid_loss: 0.646\n",
      "[epoch: 40, i:  4871]  train_loss: 0.441  |  valid_loss: 0.640\n",
      "[epoch: 40, i:  4958]  train_loss: 0.482  |  valid_loss: 0.743\n",
      "[epoch: 40, i:  5045]  train_loss: 0.437  |  valid_loss: 0.388\n",
      "[epoch: 40, i:  5132]  train_loss: 0.497  |  valid_loss: 0.571\n",
      "[epoch: 40, i:  5219]  train_loss: 0.539  |  valid_loss: 0.715\n",
      "[epoch: 40, i:  5306]  train_loss: 0.469  |  valid_loss: 0.668\n",
      "[epoch: 40, i:  5393]  train_loss: 0.484  |  valid_loss: 0.526\n",
      "[epoch: 40, i:  5480]  train_loss: 0.413  |  valid_loss: 0.756\n",
      "[epoch: 40, i:  5567]  train_loss: 0.476  |  valid_loss: 0.342\n",
      "[epoch: 40, i:  5654]  train_loss: 0.505  |  valid_loss: 0.547\n",
      "[epoch: 40, i:  5741]  train_loss: 0.471  |  valid_loss: 0.615\n",
      "[epoch: 40, i:  5828]  train_loss: 0.456  |  valid_loss: 0.589\n",
      "[epoch: 40, i:  5915]  train_loss: 0.533  |  valid_loss: 0.703\n",
      "[epoch: 40, i:  6002]  train_loss: 0.455  |  valid_loss: 0.457\n",
      "[epoch: 40, i:  6089]  train_loss: 0.449  |  valid_loss: 0.812\n",
      "[epoch: 40, i:  6176]  train_loss: 0.452  |  valid_loss: 0.572\n",
      "[epoch: 40, i:  6263]  train_loss: 0.491  |  valid_loss: 0.513\n",
      "[epoch: 40, i:  6350]  train_loss: 0.406  |  valid_loss: 0.508\n",
      "[epoch: 40, i:  6437]  train_loss: 0.465  |  valid_loss: 0.429\n",
      "[epoch: 40, i:  6524]  train_loss: 0.409  |  valid_loss: 0.741\n",
      "[epoch: 40, i:  6611]  train_loss: 0.469  |  valid_loss: 0.391\n",
      "[epoch: 40, i:  6698]  train_loss: 0.524  |  valid_loss: 0.638\n",
      "[epoch: 40, i:  6785]  train_loss: 0.434  |  valid_loss: 0.448\n",
      "[epoch: 40, i:  6872]  train_loss: 0.438  |  valid_loss: 0.671\n",
      "[epoch: 40, i:  6959]  train_loss: 0.422  |  valid_loss: 0.622\n",
      "[epoch: 40, i:  7046]  train_loss: 0.381  |  valid_loss: 0.583\n",
      "[epoch: 40, i:  7133]  train_loss: 0.483  |  valid_loss: 0.470\n",
      "[epoch: 40, i:  7220]  train_loss: 0.469  |  valid_loss: 0.741\n",
      "[epoch: 40, i:  7307]  train_loss: 0.471  |  valid_loss: 0.669\n",
      "[epoch: 40, i:  7394]  train_loss: 0.488  |  valid_loss: 0.575\n",
      "[epoch: 40, i:  7481]  train_loss: 0.469  |  valid_loss: 0.590\n",
      "[epoch: 40, i:  7568]  train_loss: 0.451  |  valid_loss: 0.728\n",
      "[epoch: 40, i:  7655]  train_loss: 0.490  |  valid_loss: 0.615\n",
      "[epoch: 40, i:  7742]  train_loss: 0.436  |  valid_loss: 0.614\n",
      "[epoch: 40, i:  7829]  train_loss: 0.460  |  valid_loss: 0.398\n",
      "[epoch: 40, i:  7916]  train_loss: 0.468  |  valid_loss: 0.576\n",
      "[epoch: 40, i:  8003]  train_loss: 0.405  |  valid_loss: 0.412\n",
      "[epoch: 40, i:  8090]  train_loss: 0.455  |  valid_loss: 0.452\n",
      "[epoch: 40, i:  8177]  train_loss: 0.475  |  valid_loss: 0.541\n",
      "[epoch: 40, i:  8264]  train_loss: 0.485  |  valid_loss: 0.602\n",
      "[epoch: 40, i:  8351]  train_loss: 0.466  |  valid_loss: 0.668\n",
      "[epoch: 40, i:  8438]  train_loss: 0.414  |  valid_loss: 0.455\n",
      "[epoch: 40, i:  8525]  train_loss: 0.454  |  valid_loss: 0.546\n",
      "[epoch: 40, i:  8612]  train_loss: 0.454  |  valid_loss: 0.848\n",
      "[epoch: 40, i:  8699]  train_loss: 0.467  |  valid_loss: 0.577\n",
      "--> [End of epoch 40] train_accuracy: 84.02%  |  valid_accuracy: 80.56%\n",
      "--> [Start of epoch 41]  lr: 0.000050\n",
      "[epoch: 41, i:    86]  train_loss: 0.438  |  valid_loss: 0.571\n",
      "[epoch: 41, i:   173]  train_loss: 0.452  |  valid_loss: 0.627\n",
      "[epoch: 41, i:   260]  train_loss: 0.431  |  valid_loss: 0.681\n",
      "[epoch: 41, i:   347]  train_loss: 0.400  |  valid_loss: 0.521\n",
      "[epoch: 41, i:   434]  train_loss: 0.452  |  valid_loss: 0.573\n",
      "[epoch: 41, i:   521]  train_loss: 0.413  |  valid_loss: 0.350\n",
      "[epoch: 41, i:   608]  train_loss: 0.413  |  valid_loss: 0.593\n",
      "[epoch: 41, i:   695]  train_loss: 0.450  |  valid_loss: 0.611\n",
      "[epoch: 41, i:   782]  train_loss: 0.420  |  valid_loss: 0.709\n",
      "[epoch: 41, i:   869]  train_loss: 0.439  |  valid_loss: 0.643\n",
      "[epoch: 41, i:   956]  train_loss: 0.462  |  valid_loss: 0.563\n",
      "[epoch: 41, i:  1043]  train_loss: 0.461  |  valid_loss: 0.540\n",
      "[epoch: 41, i:  1130]  train_loss: 0.461  |  valid_loss: 0.502\n",
      "[epoch: 41, i:  1217]  train_loss: 0.426  |  valid_loss: 0.618\n",
      "[epoch: 41, i:  1304]  train_loss: 0.464  |  valid_loss: 0.414\n",
      "[epoch: 41, i:  1391]  train_loss: 0.444  |  valid_loss: 0.651\n",
      "[epoch: 41, i:  1478]  train_loss: 0.445  |  valid_loss: 0.520\n",
      "[epoch: 41, i:  1565]  train_loss: 0.494  |  valid_loss: 0.769\n",
      "[epoch: 41, i:  1652]  train_loss: 0.476  |  valid_loss: 0.581\n",
      "[epoch: 41, i:  1739]  train_loss: 0.449  |  valid_loss: 0.902\n",
      "[epoch: 41, i:  1826]  train_loss: 0.455  |  valid_loss: 0.705\n",
      "[epoch: 41, i:  1913]  train_loss: 0.491  |  valid_loss: 0.582\n",
      "[epoch: 41, i:  2000]  train_loss: 0.425  |  valid_loss: 0.591\n",
      "[epoch: 41, i:  2087]  train_loss: 0.451  |  valid_loss: 0.782\n",
      "[epoch: 41, i:  2174]  train_loss: 0.469  |  valid_loss: 0.502\n",
      "[epoch: 41, i:  2261]  train_loss: 0.499  |  valid_loss: 0.857\n",
      "[epoch: 41, i:  2348]  train_loss: 0.453  |  valid_loss: 0.456\n",
      "[epoch: 41, i:  2435]  train_loss: 0.463  |  valid_loss: 0.656\n",
      "[epoch: 41, i:  2522]  train_loss: 0.491  |  valid_loss: 0.442\n",
      "[epoch: 41, i:  2609]  train_loss: 0.417  |  valid_loss: 0.536\n",
      "[epoch: 41, i:  2696]  train_loss: 0.487  |  valid_loss: 0.679\n",
      "[epoch: 41, i:  2783]  train_loss: 0.485  |  valid_loss: 0.423\n",
      "[epoch: 41, i:  2870]  train_loss: 0.468  |  valid_loss: 0.717\n",
      "[epoch: 41, i:  2957]  train_loss: 0.434  |  valid_loss: 0.656\n",
      "[epoch: 41, i:  3044]  train_loss: 0.473  |  valid_loss: 0.667\n",
      "[epoch: 41, i:  3131]  train_loss: 0.446  |  valid_loss: 0.546\n",
      "[epoch: 41, i:  3218]  train_loss: 0.500  |  valid_loss: 0.681\n",
      "[epoch: 41, i:  3305]  train_loss: 0.480  |  valid_loss: 0.569\n",
      "[epoch: 41, i:  3392]  train_loss: 0.463  |  valid_loss: 0.528\n",
      "[epoch: 41, i:  3479]  train_loss: 0.468  |  valid_loss: 0.538\n",
      "[epoch: 41, i:  3566]  train_loss: 0.469  |  valid_loss: 0.526\n",
      "[epoch: 41, i:  3653]  train_loss: 0.451  |  valid_loss: 0.582\n",
      "[epoch: 41, i:  3740]  train_loss: 0.468  |  valid_loss: 0.373\n",
      "[epoch: 41, i:  3827]  train_loss: 0.412  |  valid_loss: 0.807\n",
      "[epoch: 41, i:  3914]  train_loss: 0.442  |  valid_loss: 0.427\n",
      "[epoch: 41, i:  4001]  train_loss: 0.457  |  valid_loss: 0.622\n",
      "[epoch: 41, i:  4088]  train_loss: 0.463  |  valid_loss: 0.544\n",
      "[epoch: 41, i:  4175]  train_loss: 0.462  |  valid_loss: 0.542\n",
      "[epoch: 41, i:  4262]  train_loss: 0.438  |  valid_loss: 0.404\n",
      "[epoch: 41, i:  4349]  train_loss: 0.423  |  valid_loss: 0.598\n",
      "[epoch: 41, i:  4436]  train_loss: 0.491  |  valid_loss: 0.554\n",
      "[epoch: 41, i:  4523]  train_loss: 0.433  |  valid_loss: 0.695\n",
      "[epoch: 41, i:  4610]  train_loss: 0.470  |  valid_loss: 0.475\n",
      "[epoch: 41, i:  4697]  train_loss: 0.448  |  valid_loss: 0.583\n",
      "[epoch: 41, i:  4784]  train_loss: 0.500  |  valid_loss: 0.627\n",
      "[epoch: 41, i:  4871]  train_loss: 0.452  |  valid_loss: 0.709\n",
      "[epoch: 41, i:  4958]  train_loss: 0.438  |  valid_loss: 0.744\n",
      "[epoch: 41, i:  5045]  train_loss: 0.433  |  valid_loss: 0.408\n",
      "[epoch: 41, i:  5132]  train_loss: 0.490  |  valid_loss: 0.625\n",
      "[epoch: 41, i:  5219]  train_loss: 0.452  |  valid_loss: 0.735\n",
      "[epoch: 41, i:  5306]  train_loss: 0.464  |  valid_loss: 0.613\n",
      "[epoch: 41, i:  5393]  train_loss: 0.474  |  valid_loss: 0.483\n",
      "[epoch: 41, i:  5480]  train_loss: 0.437  |  valid_loss: 0.789\n",
      "[epoch: 41, i:  5567]  train_loss: 0.448  |  valid_loss: 0.328\n",
      "[epoch: 41, i:  5654]  train_loss: 0.494  |  valid_loss: 0.538\n",
      "[epoch: 41, i:  5741]  train_loss: 0.449  |  valid_loss: 0.616\n",
      "[epoch: 41, i:  5828]  train_loss: 0.420  |  valid_loss: 0.581\n",
      "[epoch: 41, i:  5915]  train_loss: 0.468  |  valid_loss: 0.716\n",
      "[epoch: 41, i:  6002]  train_loss: 0.461  |  valid_loss: 0.451\n",
      "[epoch: 41, i:  6089]  train_loss: 0.451  |  valid_loss: 0.773\n",
      "[epoch: 41, i:  6176]  train_loss: 0.461  |  valid_loss: 0.599\n",
      "[epoch: 41, i:  6263]  train_loss: 0.446  |  valid_loss: 0.553\n",
      "[epoch: 41, i:  6350]  train_loss: 0.444  |  valid_loss: 0.486\n",
      "[epoch: 41, i:  6437]  train_loss: 0.476  |  valid_loss: 0.419\n",
      "[epoch: 41, i:  6524]  train_loss: 0.415  |  valid_loss: 0.750\n",
      "[epoch: 41, i:  6611]  train_loss: 0.503  |  valid_loss: 0.387\n",
      "[epoch: 41, i:  6698]  train_loss: 0.467  |  valid_loss: 0.669\n",
      "[epoch: 41, i:  6785]  train_loss: 0.484  |  valid_loss: 0.438\n",
      "[epoch: 41, i:  6872]  train_loss: 0.441  |  valid_loss: 0.736\n",
      "[epoch: 41, i:  6959]  train_loss: 0.482  |  valid_loss: 0.663\n",
      "[epoch: 41, i:  7046]  train_loss: 0.432  |  valid_loss: 0.565\n",
      "[epoch: 41, i:  7133]  train_loss: 0.437  |  valid_loss: 0.453\n",
      "[epoch: 41, i:  7220]  train_loss: 0.428  |  valid_loss: 0.719\n",
      "[epoch: 41, i:  7307]  train_loss: 0.460  |  valid_loss: 0.742\n",
      "[epoch: 41, i:  7394]  train_loss: 0.467  |  valid_loss: 0.580\n",
      "[epoch: 41, i:  7481]  train_loss: 0.471  |  valid_loss: 0.566\n",
      "[epoch: 41, i:  7568]  train_loss: 0.469  |  valid_loss: 0.694\n",
      "[epoch: 41, i:  7655]  train_loss: 0.432  |  valid_loss: 0.645\n",
      "[epoch: 41, i:  7742]  train_loss: 0.424  |  valid_loss: 0.589\n",
      "[epoch: 41, i:  7829]  train_loss: 0.390  |  valid_loss: 0.417\n",
      "[epoch: 41, i:  7916]  train_loss: 0.510  |  valid_loss: 0.590\n",
      "[epoch: 41, i:  8003]  train_loss: 0.434  |  valid_loss: 0.404\n",
      "[epoch: 41, i:  8090]  train_loss: 0.439  |  valid_loss: 0.469\n",
      "[epoch: 41, i:  8177]  train_loss: 0.454  |  valid_loss: 0.534\n",
      "[epoch: 41, i:  8264]  train_loss: 0.458  |  valid_loss: 0.613\n",
      "[epoch: 41, i:  8351]  train_loss: 0.480  |  valid_loss: 0.645\n",
      "[epoch: 41, i:  8438]  train_loss: 0.420  |  valid_loss: 0.449\n",
      "[epoch: 41, i:  8525]  train_loss: 0.430  |  valid_loss: 0.539\n",
      "[epoch: 41, i:  8612]  train_loss: 0.450  |  valid_loss: 0.853\n",
      "[epoch: 41, i:  8699]  train_loss: 0.525  |  valid_loss: 0.569\n",
      "--> [End of epoch 41] train_accuracy: 84.24%  |  valid_accuracy: 80.62%\n",
      "--> [Start of epoch 42]  lr: 0.000050\n",
      "[epoch: 42, i:    86]  train_loss: 0.391  |  valid_loss: 0.597\n",
      "[epoch: 42, i:   173]  train_loss: 0.442  |  valid_loss: 0.649\n",
      "[epoch: 42, i:   260]  train_loss: 0.447  |  valid_loss: 0.672\n",
      "[epoch: 42, i:   347]  train_loss: 0.536  |  valid_loss: 0.530\n",
      "[epoch: 42, i:   434]  train_loss: 0.478  |  valid_loss: 0.580\n",
      "[epoch: 42, i:   521]  train_loss: 0.537  |  valid_loss: 0.356\n",
      "[epoch: 42, i:   608]  train_loss: 0.487  |  valid_loss: 0.624\n",
      "[epoch: 42, i:   695]  train_loss: 0.495  |  valid_loss: 0.624\n",
      "[epoch: 42, i:   782]  train_loss: 0.452  |  valid_loss: 0.664\n",
      "[epoch: 42, i:   869]  train_loss: 0.405  |  valid_loss: 0.682\n",
      "[epoch: 42, i:   956]  train_loss: 0.421  |  valid_loss: 0.525\n",
      "[epoch: 42, i:  1043]  train_loss: 0.482  |  valid_loss: 0.589\n",
      "[epoch: 42, i:  1130]  train_loss: 0.433  |  valid_loss: 0.495\n",
      "[epoch: 42, i:  1217]  train_loss: 0.483  |  valid_loss: 0.682\n",
      "[epoch: 42, i:  1304]  train_loss: 0.463  |  valid_loss: 0.404\n",
      "[epoch: 42, i:  1391]  train_loss: 0.424  |  valid_loss: 0.651\n",
      "[epoch: 42, i:  1478]  train_loss: 0.438  |  valid_loss: 0.527\n",
      "[epoch: 42, i:  1565]  train_loss: 0.432  |  valid_loss: 0.764\n",
      "[epoch: 42, i:  1652]  train_loss: 0.446  |  valid_loss: 0.598\n",
      "[epoch: 42, i:  1739]  train_loss: 0.423  |  valid_loss: 0.879\n",
      "[epoch: 42, i:  1826]  train_loss: 0.428  |  valid_loss: 0.706\n",
      "[epoch: 42, i:  1913]  train_loss: 0.384  |  valid_loss: 0.618\n",
      "[epoch: 42, i:  2000]  train_loss: 0.471  |  valid_loss: 0.593\n",
      "[epoch: 42, i:  2087]  train_loss: 0.413  |  valid_loss: 0.782\n",
      "[epoch: 42, i:  2174]  train_loss: 0.433  |  valid_loss: 0.519\n",
      "[epoch: 42, i:  2261]  train_loss: 0.441  |  valid_loss: 0.808\n",
      "[epoch: 42, i:  2348]  train_loss: 0.509  |  valid_loss: 0.484\n",
      "[epoch: 42, i:  2435]  train_loss: 0.407  |  valid_loss: 0.664\n",
      "[epoch: 42, i:  2522]  train_loss: 0.437  |  valid_loss: 0.452\n",
      "[epoch: 42, i:  2609]  train_loss: 0.527  |  valid_loss: 0.535\n",
      "[epoch: 42, i:  2696]  train_loss: 0.467  |  valid_loss: 0.653\n",
      "[epoch: 42, i:  2783]  train_loss: 0.451  |  valid_loss: 0.385\n",
      "[epoch: 42, i:  2870]  train_loss: 0.481  |  valid_loss: 0.704\n",
      "[epoch: 42, i:  2957]  train_loss: 0.471  |  valid_loss: 0.715\n",
      "[epoch: 42, i:  3044]  train_loss: 0.459  |  valid_loss: 0.662\n",
      "[epoch: 42, i:  3131]  train_loss: 0.453  |  valid_loss: 0.559\n",
      "[epoch: 42, i:  3218]  train_loss: 0.484  |  valid_loss: 0.668\n",
      "[epoch: 42, i:  3305]  train_loss: 0.467  |  valid_loss: 0.550\n",
      "[epoch: 42, i:  3392]  train_loss: 0.521  |  valid_loss: 0.524\n",
      "[epoch: 42, i:  3479]  train_loss: 0.398  |  valid_loss: 0.572\n",
      "[epoch: 42, i:  3566]  train_loss: 0.447  |  valid_loss: 0.523\n",
      "[epoch: 42, i:  3653]  train_loss: 0.446  |  valid_loss: 0.579\n",
      "[epoch: 42, i:  3740]  train_loss: 0.439  |  valid_loss: 0.426\n",
      "[epoch: 42, i:  3827]  train_loss: 0.410  |  valid_loss: 0.789\n",
      "[epoch: 42, i:  3914]  train_loss: 0.493  |  valid_loss: 0.414\n",
      "[epoch: 42, i:  4001]  train_loss: 0.358  |  valid_loss: 0.629\n",
      "[epoch: 42, i:  4088]  train_loss: 0.476  |  valid_loss: 0.515\n",
      "[epoch: 42, i:  4175]  train_loss: 0.439  |  valid_loss: 0.566\n",
      "[epoch: 42, i:  4262]  train_loss: 0.457  |  valid_loss: 0.413\n",
      "[epoch: 42, i:  4349]  train_loss: 0.494  |  valid_loss: 0.568\n",
      "[epoch: 42, i:  4436]  train_loss: 0.448  |  valid_loss: 0.536\n",
      "[epoch: 42, i:  4523]  train_loss: 0.477  |  valid_loss: 0.715\n",
      "[epoch: 42, i:  4610]  train_loss: 0.438  |  valid_loss: 0.482\n",
      "[epoch: 42, i:  4697]  train_loss: 0.438  |  valid_loss: 0.574\n",
      "[epoch: 42, i:  4784]  train_loss: 0.405  |  valid_loss: 0.661\n",
      "[epoch: 42, i:  4871]  train_loss: 0.484  |  valid_loss: 0.704\n",
      "[epoch: 42, i:  4958]  train_loss: 0.435  |  valid_loss: 0.778\n",
      "[epoch: 42, i:  5045]  train_loss: 0.428  |  valid_loss: 0.412\n",
      "[epoch: 42, i:  5132]  train_loss: 0.411  |  valid_loss: 0.584\n",
      "[epoch: 42, i:  5219]  train_loss: 0.428  |  valid_loss: 0.717\n",
      "[epoch: 42, i:  5306]  train_loss: 0.476  |  valid_loss: 0.643\n",
      "[epoch: 42, i:  5393]  train_loss: 0.447  |  valid_loss: 0.536\n",
      "[epoch: 42, i:  5480]  train_loss: 0.438  |  valid_loss: 0.745\n",
      "[epoch: 42, i:  5567]  train_loss: 0.508  |  valid_loss: 0.308\n",
      "[epoch: 42, i:  5654]  train_loss: 0.432  |  valid_loss: 0.544\n",
      "[epoch: 42, i:  5741]  train_loss: 0.482  |  valid_loss: 0.628\n",
      "[epoch: 42, i:  5828]  train_loss: 0.434  |  valid_loss: 0.569\n",
      "[epoch: 42, i:  5915]  train_loss: 0.479  |  valid_loss: 0.664\n",
      "[epoch: 42, i:  6002]  train_loss: 0.526  |  valid_loss: 0.457\n",
      "[epoch: 42, i:  6089]  train_loss: 0.495  |  valid_loss: 0.812\n",
      "[epoch: 42, i:  6176]  train_loss: 0.467  |  valid_loss: 0.539\n",
      "[epoch: 42, i:  6263]  train_loss: 0.480  |  valid_loss: 0.604\n",
      "[epoch: 42, i:  6350]  train_loss: 0.438  |  valid_loss: 0.528\n",
      "[epoch: 42, i:  6437]  train_loss: 0.446  |  valid_loss: 0.421\n",
      "[epoch: 42, i:  6524]  train_loss: 0.414  |  valid_loss: 0.758\n",
      "[epoch: 42, i:  6611]  train_loss: 0.412  |  valid_loss: 0.375\n",
      "[epoch: 42, i:  6698]  train_loss: 0.518  |  valid_loss: 0.672\n",
      "[epoch: 42, i:  6785]  train_loss: 0.434  |  valid_loss: 0.439\n",
      "[epoch: 42, i:  6872]  train_loss: 0.441  |  valid_loss: 0.764\n",
      "[epoch: 42, i:  6959]  train_loss: 0.451  |  valid_loss: 0.644\n",
      "[epoch: 42, i:  7046]  train_loss: 0.434  |  valid_loss: 0.587\n",
      "[epoch: 42, i:  7133]  train_loss: 0.429  |  valid_loss: 0.460\n",
      "[epoch: 42, i:  7220]  train_loss: 0.455  |  valid_loss: 0.681\n",
      "[epoch: 42, i:  7307]  train_loss: 0.405  |  valid_loss: 0.708\n",
      "[epoch: 42, i:  7394]  train_loss: 0.443  |  valid_loss: 0.548\n",
      "[epoch: 42, i:  7481]  train_loss: 0.355  |  valid_loss: 0.621\n",
      "[epoch: 42, i:  7568]  train_loss: 0.453  |  valid_loss: 0.719\n",
      "[epoch: 42, i:  7655]  train_loss: 0.415  |  valid_loss: 0.609\n",
      "[epoch: 42, i:  7742]  train_loss: 0.402  |  valid_loss: 0.555\n",
      "[epoch: 42, i:  7829]  train_loss: 0.452  |  valid_loss: 0.407\n",
      "[epoch: 42, i:  7916]  train_loss: 0.447  |  valid_loss: 0.645\n",
      "[epoch: 42, i:  8003]  train_loss: 0.449  |  valid_loss: 0.426\n",
      "[epoch: 42, i:  8090]  train_loss: 0.426  |  valid_loss: 0.491\n",
      "[epoch: 42, i:  8177]  train_loss: 0.539  |  valid_loss: 0.561\n",
      "[epoch: 42, i:  8264]  train_loss: 0.448  |  valid_loss: 0.625\n",
      "[epoch: 42, i:  8351]  train_loss: 0.516  |  valid_loss: 0.681\n",
      "[epoch: 42, i:  8438]  train_loss: 0.512  |  valid_loss: 0.472\n",
      "[epoch: 42, i:  8525]  train_loss: 0.417  |  valid_loss: 0.532\n",
      "[epoch: 42, i:  8612]  train_loss: 0.461  |  valid_loss: 0.842\n",
      "[epoch: 42, i:  8699]  train_loss: 0.513  |  valid_loss: 0.616\n",
      "--> [End of epoch 42] train_accuracy: 84.40%  |  valid_accuracy: 80.75%\n",
      "--> [Start of epoch 43]  lr: 0.000050\n",
      "[epoch: 43, i:    86]  train_loss: 0.496  |  valid_loss: 0.571\n",
      "[epoch: 43, i:   173]  train_loss: 0.450  |  valid_loss: 0.656\n",
      "[epoch: 43, i:   260]  train_loss: 0.386  |  valid_loss: 0.707\n",
      "[epoch: 43, i:   347]  train_loss: 0.433  |  valid_loss: 0.521\n",
      "[epoch: 43, i:   434]  train_loss: 0.449  |  valid_loss: 0.586\n",
      "[epoch: 43, i:   521]  train_loss: 0.417  |  valid_loss: 0.357\n",
      "[epoch: 43, i:   608]  train_loss: 0.446  |  valid_loss: 0.608\n",
      "[epoch: 43, i:   695]  train_loss: 0.451  |  valid_loss: 0.579\n",
      "[epoch: 43, i:   782]  train_loss: 0.417  |  valid_loss: 0.683\n",
      "[epoch: 43, i:   869]  train_loss: 0.529  |  valid_loss: 0.709\n",
      "[epoch: 43, i:   956]  train_loss: 0.479  |  valid_loss: 0.496\n",
      "[epoch: 43, i:  1043]  train_loss: 0.473  |  valid_loss: 0.568\n",
      "[epoch: 43, i:  1130]  train_loss: 0.428  |  valid_loss: 0.509\n",
      "[epoch: 43, i:  1217]  train_loss: 0.461  |  valid_loss: 0.612\n",
      "[epoch: 43, i:  1304]  train_loss: 0.407  |  valid_loss: 0.438\n",
      "[epoch: 43, i:  1391]  train_loss: 0.451  |  valid_loss: 0.643\n",
      "[epoch: 43, i:  1478]  train_loss: 0.459  |  valid_loss: 0.535\n",
      "[epoch: 43, i:  1565]  train_loss: 0.460  |  valid_loss: 0.813\n",
      "[epoch: 43, i:  1652]  train_loss: 0.486  |  valid_loss: 0.580\n",
      "[epoch: 43, i:  1739]  train_loss: 0.448  |  valid_loss: 0.893\n",
      "[epoch: 43, i:  1826]  train_loss: 0.448  |  valid_loss: 0.725\n",
      "[epoch: 43, i:  1913]  train_loss: 0.459  |  valid_loss: 0.626\n",
      "[epoch: 43, i:  2000]  train_loss: 0.515  |  valid_loss: 0.633\n",
      "[epoch: 43, i:  2087]  train_loss: 0.402  |  valid_loss: 0.762\n",
      "[epoch: 43, i:  2174]  train_loss: 0.417  |  valid_loss: 0.504\n",
      "[epoch: 43, i:  2261]  train_loss: 0.446  |  valid_loss: 0.814\n",
      "[epoch: 43, i:  2348]  train_loss: 0.477  |  valid_loss: 0.448\n",
      "[epoch: 43, i:  2435]  train_loss: 0.477  |  valid_loss: 0.632\n",
      "[epoch: 43, i:  2522]  train_loss: 0.391  |  valid_loss: 0.423\n",
      "[epoch: 43, i:  2609]  train_loss: 0.546  |  valid_loss: 0.520\n",
      "[epoch: 43, i:  2696]  train_loss: 0.491  |  valid_loss: 0.655\n",
      "[epoch: 43, i:  2783]  train_loss: 0.452  |  valid_loss: 0.415\n",
      "[epoch: 43, i:  2870]  train_loss: 0.472  |  valid_loss: 0.712\n",
      "[epoch: 43, i:  2957]  train_loss: 0.469  |  valid_loss: 0.753\n",
      "[epoch: 43, i:  3044]  train_loss: 0.440  |  valid_loss: 0.656\n",
      "[epoch: 43, i:  3131]  train_loss: 0.432  |  valid_loss: 0.545\n",
      "[epoch: 43, i:  3218]  train_loss: 0.483  |  valid_loss: 0.648\n",
      "[epoch: 43, i:  3305]  train_loss: 0.451  |  valid_loss: 0.560\n",
      "[epoch: 43, i:  3392]  train_loss: 0.455  |  valid_loss: 0.497\n",
      "[epoch: 43, i:  3479]  train_loss: 0.490  |  valid_loss: 0.571\n",
      "[epoch: 43, i:  3566]  train_loss: 0.462  |  valid_loss: 0.557\n",
      "[epoch: 43, i:  3653]  train_loss: 0.465  |  valid_loss: 0.545\n",
      "[epoch: 43, i:  3740]  train_loss: 0.450  |  valid_loss: 0.414\n",
      "[epoch: 43, i:  3827]  train_loss: 0.451  |  valid_loss: 0.768\n",
      "[epoch: 43, i:  3914]  train_loss: 0.428  |  valid_loss: 0.446\n",
      "[epoch: 43, i:  4001]  train_loss: 0.449  |  valid_loss: 0.647\n",
      "[epoch: 43, i:  4088]  train_loss: 0.496  |  valid_loss: 0.498\n",
      "[epoch: 43, i:  4175]  train_loss: 0.479  |  valid_loss: 0.552\n",
      "[epoch: 43, i:  4262]  train_loss: 0.484  |  valid_loss: 0.423\n",
      "[epoch: 43, i:  4349]  train_loss: 0.386  |  valid_loss: 0.571\n",
      "[epoch: 43, i:  4436]  train_loss: 0.454  |  valid_loss: 0.524\n",
      "[epoch: 43, i:  4523]  train_loss: 0.395  |  valid_loss: 0.691\n",
      "[epoch: 43, i:  4610]  train_loss: 0.499  |  valid_loss: 0.535\n",
      "[epoch: 43, i:  4697]  train_loss: 0.395  |  valid_loss: 0.603\n",
      "[epoch: 43, i:  4784]  train_loss: 0.449  |  valid_loss: 0.673\n",
      "[epoch: 43, i:  4871]  train_loss: 0.402  |  valid_loss: 0.691\n",
      "[epoch: 43, i:  4958]  train_loss: 0.478  |  valid_loss: 0.774\n",
      "[epoch: 43, i:  5045]  train_loss: 0.471  |  valid_loss: 0.396\n",
      "[epoch: 43, i:  5132]  train_loss: 0.402  |  valid_loss: 0.568\n",
      "[epoch: 43, i:  5219]  train_loss: 0.487  |  valid_loss: 0.735\n",
      "[epoch: 43, i:  5306]  train_loss: 0.433  |  valid_loss: 0.600\n",
      "[epoch: 43, i:  5393]  train_loss: 0.477  |  valid_loss: 0.497\n",
      "[epoch: 43, i:  5480]  train_loss: 0.458  |  valid_loss: 0.764\n",
      "[epoch: 43, i:  5567]  train_loss: 0.447  |  valid_loss: 0.337\n",
      "[epoch: 43, i:  5654]  train_loss: 0.446  |  valid_loss: 0.545\n",
      "[epoch: 43, i:  5741]  train_loss: 0.422  |  valid_loss: 0.650\n",
      "[epoch: 43, i:  5828]  train_loss: 0.463  |  valid_loss: 0.567\n",
      "[epoch: 43, i:  5915]  train_loss: 0.451  |  valid_loss: 0.705\n",
      "[epoch: 43, i:  6002]  train_loss: 0.411  |  valid_loss: 0.476\n",
      "[epoch: 43, i:  6089]  train_loss: 0.457  |  valid_loss: 0.773\n",
      "[epoch: 43, i:  6176]  train_loss: 0.436  |  valid_loss: 0.565\n",
      "[epoch: 43, i:  6263]  train_loss: 0.543  |  valid_loss: 0.576\n",
      "[epoch: 43, i:  6350]  train_loss: 0.444  |  valid_loss: 0.495\n",
      "[epoch: 43, i:  6437]  train_loss: 0.422  |  valid_loss: 0.418\n",
      "[epoch: 43, i:  6524]  train_loss: 0.464  |  valid_loss: 0.746\n",
      "[epoch: 43, i:  6611]  train_loss: 0.471  |  valid_loss: 0.373\n",
      "[epoch: 43, i:  6698]  train_loss: 0.446  |  valid_loss: 0.677\n",
      "[epoch: 43, i:  6785]  train_loss: 0.398  |  valid_loss: 0.449\n",
      "[epoch: 43, i:  6872]  train_loss: 0.478  |  valid_loss: 0.759\n",
      "[epoch: 43, i:  6959]  train_loss: 0.472  |  valid_loss: 0.647\n",
      "[epoch: 43, i:  7046]  train_loss: 0.496  |  valid_loss: 0.552\n",
      "[epoch: 43, i:  7133]  train_loss: 0.372  |  valid_loss: 0.424\n",
      "[epoch: 43, i:  7220]  train_loss: 0.466  |  valid_loss: 0.705\n",
      "[epoch: 43, i:  7307]  train_loss: 0.432  |  valid_loss: 0.707\n",
      "[epoch: 43, i:  7394]  train_loss: 0.414  |  valid_loss: 0.559\n",
      "[epoch: 43, i:  7481]  train_loss: 0.413  |  valid_loss: 0.574\n",
      "[epoch: 43, i:  7568]  train_loss: 0.412  |  valid_loss: 0.689\n",
      "[epoch: 43, i:  7655]  train_loss: 0.449  |  valid_loss: 0.638\n",
      "[epoch: 43, i:  7742]  train_loss: 0.451  |  valid_loss: 0.588\n",
      "[epoch: 43, i:  7829]  train_loss: 0.484  |  valid_loss: 0.381\n",
      "[epoch: 43, i:  7916]  train_loss: 0.484  |  valid_loss: 0.623\n",
      "[epoch: 43, i:  8003]  train_loss: 0.420  |  valid_loss: 0.428\n",
      "[epoch: 43, i:  8090]  train_loss: 0.449  |  valid_loss: 0.449\n",
      "[epoch: 43, i:  8177]  train_loss: 0.496  |  valid_loss: 0.528\n",
      "[epoch: 43, i:  8264]  train_loss: 0.528  |  valid_loss: 0.574\n",
      "[epoch: 43, i:  8351]  train_loss: 0.440  |  valid_loss: 0.677\n",
      "[epoch: 43, i:  8438]  train_loss: 0.430  |  valid_loss: 0.447\n",
      "[epoch: 43, i:  8525]  train_loss: 0.526  |  valid_loss: 0.569\n",
      "[epoch: 43, i:  8612]  train_loss: 0.376  |  valid_loss: 0.865\n",
      "[epoch: 43, i:  8699]  train_loss: 0.412  |  valid_loss: 0.617\n",
      "--> [End of epoch 43] train_accuracy: 84.27%  |  valid_accuracy: 80.71%\n",
      "--> [Start of epoch 44]  lr: 0.000005\n",
      "[epoch: 44, i:    86]  train_loss: 0.474  |  valid_loss: 0.574\n",
      "[epoch: 44, i:   173]  train_loss: 0.413  |  valid_loss: 0.623\n",
      "[epoch: 44, i:   260]  train_loss: 0.445  |  valid_loss: 0.670\n",
      "[epoch: 44, i:   347]  train_loss: 0.417  |  valid_loss: 0.521\n",
      "[epoch: 44, i:   434]  train_loss: 0.402  |  valid_loss: 0.566\n",
      "[epoch: 44, i:   521]  train_loss: 0.467  |  valid_loss: 0.347\n",
      "[epoch: 44, i:   608]  train_loss: 0.427  |  valid_loss: 0.605\n",
      "[epoch: 44, i:   695]  train_loss: 0.443  |  valid_loss: 0.582\n",
      "[epoch: 44, i:   782]  train_loss: 0.467  |  valid_loss: 0.701\n",
      "[epoch: 44, i:   869]  train_loss: 0.488  |  valid_loss: 0.670\n",
      "[epoch: 44, i:   956]  train_loss: 0.435  |  valid_loss: 0.524\n",
      "[epoch: 44, i:  1043]  train_loss: 0.407  |  valid_loss: 0.567\n",
      "[epoch: 44, i:  1130]  train_loss: 0.444  |  valid_loss: 0.498\n",
      "[epoch: 44, i:  1217]  train_loss: 0.403  |  valid_loss: 0.632\n",
      "[epoch: 44, i:  1304]  train_loss: 0.470  |  valid_loss: 0.419\n",
      "[epoch: 44, i:  1391]  train_loss: 0.417  |  valid_loss: 0.639\n",
      "[epoch: 44, i:  1478]  train_loss: 0.488  |  valid_loss: 0.518\n",
      "[epoch: 44, i:  1565]  train_loss: 0.491  |  valid_loss: 0.790\n",
      "[epoch: 44, i:  1652]  train_loss: 0.443  |  valid_loss: 0.563\n",
      "[epoch: 44, i:  1739]  train_loss: 0.416  |  valid_loss: 0.872\n",
      "[epoch: 44, i:  1826]  train_loss: 0.451  |  valid_loss: 0.672\n",
      "[epoch: 44, i:  1913]  train_loss: 0.448  |  valid_loss: 0.604\n",
      "[epoch: 44, i:  2000]  train_loss: 0.444  |  valid_loss: 0.647\n",
      "[epoch: 44, i:  2087]  train_loss: 0.513  |  valid_loss: 0.765\n",
      "[epoch: 44, i:  2174]  train_loss: 0.447  |  valid_loss: 0.508\n",
      "[epoch: 44, i:  2261]  train_loss: 0.466  |  valid_loss: 0.826\n",
      "[epoch: 44, i:  2348]  train_loss: 0.458  |  valid_loss: 0.489\n",
      "[epoch: 44, i:  2435]  train_loss: 0.428  |  valid_loss: 0.637\n",
      "[epoch: 44, i:  2522]  train_loss: 0.425  |  valid_loss: 0.428\n",
      "[epoch: 44, i:  2609]  train_loss: 0.445  |  valid_loss: 0.539\n",
      "[epoch: 44, i:  2696]  train_loss: 0.426  |  valid_loss: 0.613\n",
      "[epoch: 44, i:  2783]  train_loss: 0.450  |  valid_loss: 0.400\n",
      "[epoch: 44, i:  2870]  train_loss: 0.505  |  valid_loss: 0.712\n",
      "[epoch: 44, i:  2957]  train_loss: 0.386  |  valid_loss: 0.696\n",
      "[epoch: 44, i:  3044]  train_loss: 0.451  |  valid_loss: 0.652\n",
      "[epoch: 44, i:  3131]  train_loss: 0.374  |  valid_loss: 0.584\n",
      "[epoch: 44, i:  3218]  train_loss: 0.438  |  valid_loss: 0.662\n",
      "[epoch: 44, i:  3305]  train_loss: 0.406  |  valid_loss: 0.569\n",
      "[epoch: 44, i:  3392]  train_loss: 0.481  |  valid_loss: 0.515\n",
      "[epoch: 44, i:  3479]  train_loss: 0.435  |  valid_loss: 0.586\n",
      "[epoch: 44, i:  3566]  train_loss: 0.493  |  valid_loss: 0.499\n",
      "[epoch: 44, i:  3653]  train_loss: 0.423  |  valid_loss: 0.582\n",
      "[epoch: 44, i:  3740]  train_loss: 0.456  |  valid_loss: 0.393\n",
      "[epoch: 44, i:  3827]  train_loss: 0.471  |  valid_loss: 0.831\n",
      "[epoch: 44, i:  3914]  train_loss: 0.457  |  valid_loss: 0.430\n",
      "[epoch: 44, i:  4001]  train_loss: 0.414  |  valid_loss: 0.624\n",
      "[epoch: 44, i:  4088]  train_loss: 0.379  |  valid_loss: 0.534\n",
      "[epoch: 44, i:  4175]  train_loss: 0.445  |  valid_loss: 0.562\n",
      "[epoch: 44, i:  4262]  train_loss: 0.439  |  valid_loss: 0.426\n",
      "[epoch: 44, i:  4349]  train_loss: 0.438  |  valid_loss: 0.579\n",
      "[epoch: 44, i:  4436]  train_loss: 0.452  |  valid_loss: 0.528\n",
      "[epoch: 44, i:  4523]  train_loss: 0.440  |  valid_loss: 0.701\n",
      "[epoch: 44, i:  4610]  train_loss: 0.425  |  valid_loss: 0.474\n",
      "[epoch: 44, i:  4697]  train_loss: 0.429  |  valid_loss: 0.650\n",
      "[epoch: 44, i:  4784]  train_loss: 0.452  |  valid_loss: 0.687\n",
      "[epoch: 44, i:  4871]  train_loss: 0.410  |  valid_loss: 0.680\n",
      "[epoch: 44, i:  4958]  train_loss: 0.476  |  valid_loss: 0.739\n",
      "[epoch: 44, i:  5045]  train_loss: 0.542  |  valid_loss: 0.397\n",
      "[epoch: 44, i:  5132]  train_loss: 0.454  |  valid_loss: 0.606\n",
      "[epoch: 44, i:  5219]  train_loss: 0.424  |  valid_loss: 0.727\n",
      "[epoch: 44, i:  5306]  train_loss: 0.470  |  valid_loss: 0.560\n",
      "[epoch: 44, i:  5393]  train_loss: 0.421  |  valid_loss: 0.497\n",
      "[epoch: 44, i:  5480]  train_loss: 0.440  |  valid_loss: 0.784\n",
      "[epoch: 44, i:  5567]  train_loss: 0.424  |  valid_loss: 0.321\n",
      "[epoch: 44, i:  5654]  train_loss: 0.417  |  valid_loss: 0.517\n",
      "[epoch: 44, i:  5741]  train_loss: 0.419  |  valid_loss: 0.656\n",
      "[epoch: 44, i:  5828]  train_loss: 0.427  |  valid_loss: 0.564\n",
      "[epoch: 44, i:  5915]  train_loss: 0.465  |  valid_loss: 0.673\n",
      "[epoch: 44, i:  6002]  train_loss: 0.466  |  valid_loss: 0.491\n",
      "[epoch: 44, i:  6089]  train_loss: 0.445  |  valid_loss: 0.752\n",
      "[epoch: 44, i:  6176]  train_loss: 0.459  |  valid_loss: 0.587\n",
      "[epoch: 44, i:  6263]  train_loss: 0.429  |  valid_loss: 0.551\n",
      "[epoch: 44, i:  6350]  train_loss: 0.455  |  valid_loss: 0.504\n",
      "[epoch: 44, i:  6437]  train_loss: 0.456  |  valid_loss: 0.401\n",
      "[epoch: 44, i:  6524]  train_loss: 0.411  |  valid_loss: 0.735\n",
      "[epoch: 44, i:  6611]  train_loss: 0.433  |  valid_loss: 0.362\n",
      "[epoch: 44, i:  6698]  train_loss: 0.498  |  valid_loss: 0.684\n",
      "[epoch: 44, i:  6785]  train_loss: 0.448  |  valid_loss: 0.424\n",
      "[epoch: 44, i:  6872]  train_loss: 0.432  |  valid_loss: 0.737\n",
      "[epoch: 44, i:  6959]  train_loss: 0.454  |  valid_loss: 0.644\n",
      "[epoch: 44, i:  7046]  train_loss: 0.524  |  valid_loss: 0.556\n",
      "[epoch: 44, i:  7133]  train_loss: 0.504  |  valid_loss: 0.446\n",
      "[epoch: 44, i:  7220]  train_loss: 0.382  |  valid_loss: 0.678\n",
      "[epoch: 44, i:  7307]  train_loss: 0.499  |  valid_loss: 0.698\n",
      "[epoch: 44, i:  7394]  train_loss: 0.441  |  valid_loss: 0.555\n",
      "[epoch: 44, i:  7481]  train_loss: 0.429  |  valid_loss: 0.592\n",
      "[epoch: 44, i:  7568]  train_loss: 0.538  |  valid_loss: 0.693\n",
      "[epoch: 44, i:  7655]  train_loss: 0.416  |  valid_loss: 0.593\n",
      "[epoch: 44, i:  7742]  train_loss: 0.476  |  valid_loss: 0.600\n",
      "[epoch: 44, i:  7829]  train_loss: 0.399  |  valid_loss: 0.407\n",
      "[epoch: 44, i:  7916]  train_loss: 0.440  |  valid_loss: 0.587\n",
      "[epoch: 44, i:  8003]  train_loss: 0.437  |  valid_loss: 0.411\n",
      "[epoch: 44, i:  8090]  train_loss: 0.430  |  valid_loss: 0.480\n",
      "[epoch: 44, i:  8177]  train_loss: 0.396  |  valid_loss: 0.522\n",
      "[epoch: 44, i:  8264]  train_loss: 0.509  |  valid_loss: 0.599\n",
      "[epoch: 44, i:  8351]  train_loss: 0.408  |  valid_loss: 0.670\n",
      "[epoch: 44, i:  8438]  train_loss: 0.438  |  valid_loss: 0.437\n",
      "[epoch: 44, i:  8525]  train_loss: 0.394  |  valid_loss: 0.535\n",
      "[epoch: 44, i:  8612]  train_loss: 0.422  |  valid_loss: 0.880\n",
      "[epoch: 44, i:  8699]  train_loss: 0.447  |  valid_loss: 0.583\n",
      "--> [End of epoch 44] train_accuracy: 84.63%  |  valid_accuracy: 80.73%\n",
      "--> [Start of epoch 45]  lr: 0.000005\n",
      "[epoch: 45, i:    86]  train_loss: 0.442  |  valid_loss: 0.599\n",
      "[epoch: 45, i:   173]  train_loss: 0.445  |  valid_loss: 0.634\n",
      "[epoch: 45, i:   260]  train_loss: 0.459  |  valid_loss: 0.661\n",
      "[epoch: 45, i:   347]  train_loss: 0.434  |  valid_loss: 0.533\n",
      "[epoch: 45, i:   434]  train_loss: 0.421  |  valid_loss: 0.575\n",
      "[epoch: 45, i:   521]  train_loss: 0.435  |  valid_loss: 0.334\n",
      "[epoch: 45, i:   608]  train_loss: 0.407  |  valid_loss: 0.598\n",
      "[epoch: 45, i:   695]  train_loss: 0.446  |  valid_loss: 0.566\n",
      "[epoch: 45, i:   782]  train_loss: 0.454  |  valid_loss: 0.700\n",
      "[epoch: 45, i:   869]  train_loss: 0.409  |  valid_loss: 0.660\n",
      "[epoch: 45, i:   956]  train_loss: 0.500  |  valid_loss: 0.518\n",
      "[epoch: 45, i:  1043]  train_loss: 0.466  |  valid_loss: 0.578\n",
      "[epoch: 45, i:  1130]  train_loss: 0.408  |  valid_loss: 0.475\n",
      "[epoch: 45, i:  1217]  train_loss: 0.414  |  valid_loss: 0.629\n",
      "[epoch: 45, i:  1304]  train_loss: 0.415  |  valid_loss: 0.416\n",
      "[epoch: 45, i:  1391]  train_loss: 0.384  |  valid_loss: 0.656\n",
      "[epoch: 45, i:  1478]  train_loss: 0.428  |  valid_loss: 0.533\n",
      "[epoch: 45, i:  1565]  train_loss: 0.397  |  valid_loss: 0.761\n",
      "[epoch: 45, i:  1652]  train_loss: 0.440  |  valid_loss: 0.556\n",
      "[epoch: 45, i:  1739]  train_loss: 0.478  |  valid_loss: 0.881\n",
      "[epoch: 45, i:  1826]  train_loss: 0.406  |  valid_loss: 0.681\n",
      "[epoch: 45, i:  1913]  train_loss: 0.471  |  valid_loss: 0.618\n",
      "[epoch: 45, i:  2000]  train_loss: 0.377  |  valid_loss: 0.634\n",
      "[epoch: 45, i:  2087]  train_loss: 0.410  |  valid_loss: 0.754\n",
      "[epoch: 45, i:  2174]  train_loss: 0.473  |  valid_loss: 0.520\n",
      "[epoch: 45, i:  2261]  train_loss: 0.431  |  valid_loss: 0.831\n",
      "[epoch: 45, i:  2348]  train_loss: 0.427  |  valid_loss: 0.456\n",
      "[epoch: 45, i:  2435]  train_loss: 0.416  |  valid_loss: 0.621\n",
      "[epoch: 45, i:  2522]  train_loss: 0.421  |  valid_loss: 0.438\n",
      "[epoch: 45, i:  2609]  train_loss: 0.457  |  valid_loss: 0.533\n",
      "[epoch: 45, i:  2696]  train_loss: 0.485  |  valid_loss: 0.618\n",
      "[epoch: 45, i:  2783]  train_loss: 0.439  |  valid_loss: 0.392\n",
      "[epoch: 45, i:  2870]  train_loss: 0.503  |  valid_loss: 0.678\n",
      "[epoch: 45, i:  2957]  train_loss: 0.472  |  valid_loss: 0.691\n",
      "[epoch: 45, i:  3044]  train_loss: 0.436  |  valid_loss: 0.657\n",
      "[epoch: 45, i:  3131]  train_loss: 0.405  |  valid_loss: 0.536\n",
      "[epoch: 45, i:  3218]  train_loss: 0.463  |  valid_loss: 0.667\n",
      "[epoch: 45, i:  3305]  train_loss: 0.462  |  valid_loss: 0.582\n",
      "[epoch: 45, i:  3392]  train_loss: 0.437  |  valid_loss: 0.504\n",
      "[epoch: 45, i:  3479]  train_loss: 0.488  |  valid_loss: 0.588\n",
      "[epoch: 45, i:  3566]  train_loss: 0.420  |  valid_loss: 0.517\n",
      "[epoch: 45, i:  3653]  train_loss: 0.453  |  valid_loss: 0.580\n",
      "[epoch: 45, i:  3740]  train_loss: 0.482  |  valid_loss: 0.392\n",
      "[epoch: 45, i:  3827]  train_loss: 0.437  |  valid_loss: 0.793\n",
      "[epoch: 45, i:  3914]  train_loss: 0.448  |  valid_loss: 0.465\n",
      "[epoch: 45, i:  4001]  train_loss: 0.488  |  valid_loss: 0.650\n",
      "[epoch: 45, i:  4088]  train_loss: 0.456  |  valid_loss: 0.528\n",
      "[epoch: 45, i:  4175]  train_loss: 0.403  |  valid_loss: 0.545\n",
      "[epoch: 45, i:  4262]  train_loss: 0.475  |  valid_loss: 0.427\n",
      "[epoch: 45, i:  4349]  train_loss: 0.509  |  valid_loss: 0.576\n",
      "[epoch: 45, i:  4436]  train_loss: 0.442  |  valid_loss: 0.527\n",
      "[epoch: 45, i:  4523]  train_loss: 0.489  |  valid_loss: 0.706\n",
      "[epoch: 45, i:  4610]  train_loss: 0.523  |  valid_loss: 0.469\n",
      "[epoch: 45, i:  4697]  train_loss: 0.419  |  valid_loss: 0.622\n",
      "[epoch: 45, i:  4784]  train_loss: 0.444  |  valid_loss: 0.652\n",
      "[epoch: 45, i:  4871]  train_loss: 0.397  |  valid_loss: 0.671\n",
      "[epoch: 45, i:  4958]  train_loss: 0.437  |  valid_loss: 0.725\n",
      "[epoch: 45, i:  5045]  train_loss: 0.423  |  valid_loss: 0.400\n",
      "[epoch: 45, i:  5132]  train_loss: 0.435  |  valid_loss: 0.581\n",
      "[epoch: 45, i:  5219]  train_loss: 0.437  |  valid_loss: 0.747\n",
      "[epoch: 45, i:  5306]  train_loss: 0.449  |  valid_loss: 0.601\n",
      "[epoch: 45, i:  5393]  train_loss: 0.428  |  valid_loss: 0.474\n",
      "[epoch: 45, i:  5480]  train_loss: 0.453  |  valid_loss: 0.804\n",
      "[epoch: 45, i:  5567]  train_loss: 0.474  |  valid_loss: 0.320\n",
      "[epoch: 45, i:  5654]  train_loss: 0.446  |  valid_loss: 0.509\n",
      "[epoch: 45, i:  5741]  train_loss: 0.452  |  valid_loss: 0.634\n",
      "[epoch: 45, i:  5828]  train_loss: 0.433  |  valid_loss: 0.559\n",
      "[epoch: 45, i:  5915]  train_loss: 0.494  |  valid_loss: 0.685\n",
      "[epoch: 45, i:  6002]  train_loss: 0.433  |  valid_loss: 0.487\n",
      "[epoch: 45, i:  6089]  train_loss: 0.489  |  valid_loss: 0.781\n",
      "[epoch: 45, i:  6176]  train_loss: 0.419  |  valid_loss: 0.575\n",
      "[epoch: 45, i:  6263]  train_loss: 0.404  |  valid_loss: 0.564\n",
      "[epoch: 45, i:  6350]  train_loss: 0.457  |  valid_loss: 0.508\n",
      "[epoch: 45, i:  6437]  train_loss: 0.470  |  valid_loss: 0.419\n",
      "[epoch: 45, i:  6524]  train_loss: 0.481  |  valid_loss: 0.746\n",
      "[epoch: 45, i:  6611]  train_loss: 0.464  |  valid_loss: 0.365\n",
      "[epoch: 45, i:  6698]  train_loss: 0.406  |  valid_loss: 0.707\n",
      "[epoch: 45, i:  6785]  train_loss: 0.460  |  valid_loss: 0.439\n",
      "[epoch: 45, i:  6872]  train_loss: 0.451  |  valid_loss: 0.716\n",
      "[epoch: 45, i:  6959]  train_loss: 0.455  |  valid_loss: 0.661\n",
      "[epoch: 45, i:  7046]  train_loss: 0.446  |  valid_loss: 0.572\n",
      "[epoch: 45, i:  7133]  train_loss: 0.512  |  valid_loss: 0.458\n",
      "[epoch: 45, i:  7220]  train_loss: 0.433  |  valid_loss: 0.681\n",
      "[epoch: 45, i:  7307]  train_loss: 0.392  |  valid_loss: 0.715\n",
      "[epoch: 45, i:  7394]  train_loss: 0.401  |  valid_loss: 0.536\n",
      "[epoch: 45, i:  7481]  train_loss: 0.444  |  valid_loss: 0.602\n",
      "[epoch: 45, i:  7568]  train_loss: 0.443  |  valid_loss: 0.702\n",
      "[epoch: 45, i:  7655]  train_loss: 0.425  |  valid_loss: 0.590\n",
      "[epoch: 45, i:  7742]  train_loss: 0.439  |  valid_loss: 0.575\n",
      "[epoch: 45, i:  7829]  train_loss: 0.481  |  valid_loss: 0.426\n",
      "[epoch: 45, i:  7916]  train_loss: 0.475  |  valid_loss: 0.620\n",
      "[epoch: 45, i:  8003]  train_loss: 0.429  |  valid_loss: 0.441\n",
      "[epoch: 45, i:  8090]  train_loss: 0.379  |  valid_loss: 0.486\n",
      "[epoch: 45, i:  8177]  train_loss: 0.427  |  valid_loss: 0.559\n",
      "[epoch: 45, i:  8264]  train_loss: 0.495  |  valid_loss: 0.593\n",
      "[epoch: 45, i:  8351]  train_loss: 0.456  |  valid_loss: 0.656\n",
      "[epoch: 45, i:  8438]  train_loss: 0.353  |  valid_loss: 0.416\n",
      "[epoch: 45, i:  8525]  train_loss: 0.513  |  valid_loss: 0.535\n",
      "[epoch: 45, i:  8612]  train_loss: 0.428  |  valid_loss: 0.851\n",
      "[epoch: 45, i:  8699]  train_loss: 0.503  |  valid_loss: 0.586\n",
      "--> [End of epoch 45] train_accuracy: 84.57%  |  valid_accuracy: 80.92%\n",
      "--> [Start of epoch 46]  lr: 0.000005\n",
      "[epoch: 46, i:    86]  train_loss: 0.421  |  valid_loss: 0.570\n",
      "[epoch: 46, i:   173]  train_loss: 0.452  |  valid_loss: 0.605\n",
      "[epoch: 46, i:   260]  train_loss: 0.444  |  valid_loss: 0.649\n",
      "[epoch: 46, i:   347]  train_loss: 0.442  |  valid_loss: 0.506\n",
      "[epoch: 46, i:   434]  train_loss: 0.451  |  valid_loss: 0.577\n",
      "[epoch: 46, i:   521]  train_loss: 0.440  |  valid_loss: 0.355\n",
      "[epoch: 46, i:   608]  train_loss: 0.421  |  valid_loss: 0.595\n",
      "[epoch: 46, i:   695]  train_loss: 0.423  |  valid_loss: 0.569\n",
      "[epoch: 46, i:   782]  train_loss: 0.431  |  valid_loss: 0.689\n",
      "[epoch: 46, i:   869]  train_loss: 0.481  |  valid_loss: 0.688\n",
      "[epoch: 46, i:   956]  train_loss: 0.437  |  valid_loss: 0.522\n",
      "[epoch: 46, i:  1043]  train_loss: 0.436  |  valid_loss: 0.557\n",
      "[epoch: 46, i:  1130]  train_loss: 0.435  |  valid_loss: 0.494\n",
      "[epoch: 46, i:  1217]  train_loss: 0.482  |  valid_loss: 0.594\n",
      "[epoch: 46, i:  1304]  train_loss: 0.401  |  valid_loss: 0.428\n",
      "[epoch: 46, i:  1391]  train_loss: 0.461  |  valid_loss: 0.679\n",
      "[epoch: 46, i:  1478]  train_loss: 0.460  |  valid_loss: 0.532\n",
      "[epoch: 46, i:  1565]  train_loss: 0.405  |  valid_loss: 0.815\n",
      "[epoch: 46, i:  1652]  train_loss: 0.421  |  valid_loss: 0.567\n",
      "[epoch: 46, i:  1739]  train_loss: 0.412  |  valid_loss: 0.878\n",
      "[epoch: 46, i:  1826]  train_loss: 0.453  |  valid_loss: 0.701\n",
      "[epoch: 46, i:  1913]  train_loss: 0.434  |  valid_loss: 0.590\n",
      "[epoch: 46, i:  2000]  train_loss: 0.488  |  valid_loss: 0.637\n",
      "[epoch: 46, i:  2087]  train_loss: 0.471  |  valid_loss: 0.733\n",
      "[epoch: 46, i:  2174]  train_loss: 0.495  |  valid_loss: 0.525\n",
      "[epoch: 46, i:  2261]  train_loss: 0.424  |  valid_loss: 0.817\n",
      "[epoch: 46, i:  2348]  train_loss: 0.444  |  valid_loss: 0.450\n",
      "[epoch: 46, i:  2435]  train_loss: 0.447  |  valid_loss: 0.640\n",
      "[epoch: 46, i:  2522]  train_loss: 0.452  |  valid_loss: 0.422\n",
      "[epoch: 46, i:  2609]  train_loss: 0.397  |  valid_loss: 0.531\n",
      "[epoch: 46, i:  2696]  train_loss: 0.401  |  valid_loss: 0.650\n",
      "[epoch: 46, i:  2783]  train_loss: 0.497  |  valid_loss: 0.402\n",
      "[epoch: 46, i:  2870]  train_loss: 0.444  |  valid_loss: 0.704\n",
      "[epoch: 46, i:  2957]  train_loss: 0.409  |  valid_loss: 0.711\n",
      "[epoch: 46, i:  3044]  train_loss: 0.452  |  valid_loss: 0.667\n",
      "[epoch: 46, i:  3131]  train_loss: 0.453  |  valid_loss: 0.584\n",
      "[epoch: 46, i:  3218]  train_loss: 0.474  |  valid_loss: 0.666\n",
      "[epoch: 46, i:  3305]  train_loss: 0.416  |  valid_loss: 0.571\n",
      "[epoch: 46, i:  3392]  train_loss: 0.439  |  valid_loss: 0.509\n",
      "[epoch: 46, i:  3479]  train_loss: 0.432  |  valid_loss: 0.562\n",
      "[epoch: 46, i:  3566]  train_loss: 0.409  |  valid_loss: 0.532\n",
      "[epoch: 46, i:  3653]  train_loss: 0.445  |  valid_loss: 0.597\n",
      "[epoch: 46, i:  3740]  train_loss: 0.460  |  valid_loss: 0.371\n",
      "[epoch: 46, i:  3827]  train_loss: 0.430  |  valid_loss: 0.794\n",
      "[epoch: 46, i:  3914]  train_loss: 0.448  |  valid_loss: 0.440\n",
      "[epoch: 46, i:  4001]  train_loss: 0.496  |  valid_loss: 0.638\n",
      "[epoch: 46, i:  4088]  train_loss: 0.409  |  valid_loss: 0.489\n",
      "[epoch: 46, i:  4175]  train_loss: 0.454  |  valid_loss: 0.583\n",
      "[epoch: 46, i:  4262]  train_loss: 0.461  |  valid_loss: 0.433\n",
      "[epoch: 46, i:  4349]  train_loss: 0.474  |  valid_loss: 0.582\n",
      "[epoch: 46, i:  4436]  train_loss: 0.424  |  valid_loss: 0.512\n",
      "[epoch: 46, i:  4523]  train_loss: 0.475  |  valid_loss: 0.692\n",
      "[epoch: 46, i:  4610]  train_loss: 0.438  |  valid_loss: 0.499\n",
      "[epoch: 46, i:  4697]  train_loss: 0.401  |  valid_loss: 0.596\n",
      "[epoch: 46, i:  4784]  train_loss: 0.444  |  valid_loss: 0.638\n",
      "[epoch: 46, i:  4871]  train_loss: 0.497  |  valid_loss: 0.692\n",
      "[epoch: 46, i:  4958]  train_loss: 0.424  |  valid_loss: 0.748\n",
      "[epoch: 46, i:  5045]  train_loss: 0.445  |  valid_loss: 0.392\n",
      "[epoch: 46, i:  5132]  train_loss: 0.459  |  valid_loss: 0.557\n",
      "[epoch: 46, i:  5219]  train_loss: 0.481  |  valid_loss: 0.732\n",
      "[epoch: 46, i:  5306]  train_loss: 0.459  |  valid_loss: 0.588\n",
      "[epoch: 46, i:  5393]  train_loss: 0.410  |  valid_loss: 0.470\n",
      "[epoch: 46, i:  5480]  train_loss: 0.465  |  valid_loss: 0.789\n",
      "[epoch: 46, i:  5567]  train_loss: 0.497  |  valid_loss: 0.310\n",
      "[epoch: 46, i:  5654]  train_loss: 0.433  |  valid_loss: 0.531\n",
      "[epoch: 46, i:  5741]  train_loss: 0.468  |  valid_loss: 0.629\n",
      "[epoch: 46, i:  5828]  train_loss: 0.443  |  valid_loss: 0.542\n",
      "[epoch: 46, i:  5915]  train_loss: 0.422  |  valid_loss: 0.683\n",
      "[epoch: 46, i:  6002]  train_loss: 0.466  |  valid_loss: 0.483\n",
      "[epoch: 46, i:  6089]  train_loss: 0.425  |  valid_loss: 0.758\n",
      "[epoch: 46, i:  6176]  train_loss: 0.449  |  valid_loss: 0.592\n",
      "[epoch: 46, i:  6263]  train_loss: 0.471  |  valid_loss: 0.570\n",
      "[epoch: 46, i:  6350]  train_loss: 0.429  |  valid_loss: 0.557\n",
      "[epoch: 46, i:  6437]  train_loss: 0.463  |  valid_loss: 0.393\n",
      "[epoch: 46, i:  6524]  train_loss: 0.486  |  valid_loss: 0.761\n",
      "[epoch: 46, i:  6611]  train_loss: 0.422  |  valid_loss: 0.368\n",
      "[epoch: 46, i:  6698]  train_loss: 0.409  |  valid_loss: 0.668\n",
      "[epoch: 46, i:  6785]  train_loss: 0.428  |  valid_loss: 0.455\n",
      "[epoch: 46, i:  6872]  train_loss: 0.415  |  valid_loss: 0.735\n",
      "[epoch: 46, i:  6959]  train_loss: 0.436  |  valid_loss: 0.649\n",
      "[epoch: 46, i:  7046]  train_loss: 0.384  |  valid_loss: 0.559\n",
      "[epoch: 46, i:  7133]  train_loss: 0.451  |  valid_loss: 0.451\n",
      "[epoch: 46, i:  7220]  train_loss: 0.401  |  valid_loss: 0.687\n",
      "[epoch: 46, i:  7307]  train_loss: 0.443  |  valid_loss: 0.690\n",
      "[epoch: 46, i:  7394]  train_loss: 0.453  |  valid_loss: 0.585\n",
      "[epoch: 46, i:  7481]  train_loss: 0.443  |  valid_loss: 0.596\n",
      "[epoch: 46, i:  7568]  train_loss: 0.386  |  valid_loss: 0.746\n",
      "[epoch: 46, i:  7655]  train_loss: 0.406  |  valid_loss: 0.622\n",
      "[epoch: 46, i:  7742]  train_loss: 0.429  |  valid_loss: 0.562\n",
      "[epoch: 46, i:  7829]  train_loss: 0.455  |  valid_loss: 0.396\n",
      "[epoch: 46, i:  7916]  train_loss: 0.441  |  valid_loss: 0.608\n",
      "[epoch: 46, i:  8003]  train_loss: 0.424  |  valid_loss: 0.408\n",
      "[epoch: 46, i:  8090]  train_loss: 0.418  |  valid_loss: 0.491\n",
      "[epoch: 46, i:  8177]  train_loss: 0.431  |  valid_loss: 0.564\n",
      "[epoch: 46, i:  8264]  train_loss: 0.448  |  valid_loss: 0.612\n",
      "[epoch: 46, i:  8351]  train_loss: 0.462  |  valid_loss: 0.683\n",
      "[epoch: 46, i:  8438]  train_loss: 0.417  |  valid_loss: 0.458\n",
      "[epoch: 46, i:  8525]  train_loss: 0.472  |  valid_loss: 0.573\n",
      "[epoch: 46, i:  8612]  train_loss: 0.408  |  valid_loss: 0.844\n",
      "[epoch: 46, i:  8699]  train_loss: 0.411  |  valid_loss: 0.599\n",
      "--> [End of epoch 46] train_accuracy: 84.70%  |  valid_accuracy: 80.58%\n",
      "--> [Start of epoch 47]  lr: 0.000005\n",
      "[epoch: 47, i:    86]  train_loss: 0.425  |  valid_loss: 0.562\n",
      "[epoch: 47, i:   173]  train_loss: 0.465  |  valid_loss: 0.644\n",
      "[epoch: 47, i:   260]  train_loss: 0.381  |  valid_loss: 0.684\n",
      "[epoch: 47, i:   347]  train_loss: 0.493  |  valid_loss: 0.516\n",
      "[epoch: 47, i:   434]  train_loss: 0.460  |  valid_loss: 0.601\n",
      "[epoch: 47, i:   521]  train_loss: 0.476  |  valid_loss: 0.344\n",
      "[epoch: 47, i:   608]  train_loss: 0.517  |  valid_loss: 0.613\n",
      "[epoch: 47, i:   695]  train_loss: 0.437  |  valid_loss: 0.574\n",
      "[epoch: 47, i:   782]  train_loss: 0.475  |  valid_loss: 0.716\n",
      "[epoch: 47, i:   869]  train_loss: 0.425  |  valid_loss: 0.679\n",
      "[epoch: 47, i:   956]  train_loss: 0.458  |  valid_loss: 0.498\n",
      "[epoch: 47, i:  1043]  train_loss: 0.479  |  valid_loss: 0.538\n",
      "[epoch: 47, i:  1130]  train_loss: 0.440  |  valid_loss: 0.482\n",
      "[epoch: 47, i:  1217]  train_loss: 0.415  |  valid_loss: 0.624\n",
      "[epoch: 47, i:  1304]  train_loss: 0.423  |  valid_loss: 0.422\n",
      "[epoch: 47, i:  1391]  train_loss: 0.393  |  valid_loss: 0.662\n",
      "[epoch: 47, i:  1478]  train_loss: 0.445  |  valid_loss: 0.549\n",
      "[epoch: 47, i:  1565]  train_loss: 0.423  |  valid_loss: 0.783\n",
      "[epoch: 47, i:  1652]  train_loss: 0.479  |  valid_loss: 0.569\n",
      "[epoch: 47, i:  1739]  train_loss: 0.400  |  valid_loss: 0.860\n",
      "[epoch: 47, i:  1826]  train_loss: 0.403  |  valid_loss: 0.695\n",
      "[epoch: 47, i:  1913]  train_loss: 0.335  |  valid_loss: 0.621\n",
      "[epoch: 47, i:  2000]  train_loss: 0.451  |  valid_loss: 0.617\n",
      "[epoch: 47, i:  2087]  train_loss: 0.427  |  valid_loss: 0.772\n",
      "[epoch: 47, i:  2174]  train_loss: 0.456  |  valid_loss: 0.509\n",
      "[epoch: 47, i:  2261]  train_loss: 0.472  |  valid_loss: 0.796\n",
      "[epoch: 47, i:  2348]  train_loss: 0.421  |  valid_loss: 0.465\n",
      "[epoch: 47, i:  2435]  train_loss: 0.451  |  valid_loss: 0.631\n",
      "[epoch: 47, i:  2522]  train_loss: 0.449  |  valid_loss: 0.421\n",
      "[epoch: 47, i:  2609]  train_loss: 0.418  |  valid_loss: 0.555\n",
      "[epoch: 47, i:  2696]  train_loss: 0.460  |  valid_loss: 0.626\n",
      "[epoch: 47, i:  2783]  train_loss: 0.496  |  valid_loss: 0.410\n",
      "[epoch: 47, i:  2870]  train_loss: 0.480  |  valid_loss: 0.708\n",
      "[epoch: 47, i:  2957]  train_loss: 0.489  |  valid_loss: 0.716\n",
      "[epoch: 47, i:  3044]  train_loss: 0.398  |  valid_loss: 0.687\n",
      "[epoch: 47, i:  3131]  train_loss: 0.473  |  valid_loss: 0.541\n",
      "[epoch: 47, i:  3218]  train_loss: 0.430  |  valid_loss: 0.633\n",
      "[epoch: 47, i:  3305]  train_loss: 0.441  |  valid_loss: 0.608\n",
      "[epoch: 47, i:  3392]  train_loss: 0.408  |  valid_loss: 0.510\n",
      "[epoch: 47, i:  3479]  train_loss: 0.452  |  valid_loss: 0.559\n",
      "[epoch: 47, i:  3566]  train_loss: 0.437  |  valid_loss: 0.504\n",
      "[epoch: 47, i:  3653]  train_loss: 0.411  |  valid_loss: 0.581\n",
      "[epoch: 47, i:  3740]  train_loss: 0.407  |  valid_loss: 0.379\n",
      "[epoch: 47, i:  3827]  train_loss: 0.434  |  valid_loss: 0.811\n",
      "[epoch: 47, i:  3914]  train_loss: 0.454  |  valid_loss: 0.413\n",
      "[epoch: 47, i:  4001]  train_loss: 0.382  |  valid_loss: 0.637\n",
      "[epoch: 47, i:  4088]  train_loss: 0.417  |  valid_loss: 0.501\n",
      "[epoch: 47, i:  4175]  train_loss: 0.450  |  valid_loss: 0.576\n",
      "[epoch: 47, i:  4262]  train_loss: 0.396  |  valid_loss: 0.437\n",
      "[epoch: 47, i:  4349]  train_loss: 0.481  |  valid_loss: 0.571\n",
      "[epoch: 47, i:  4436]  train_loss: 0.433  |  valid_loss: 0.546\n",
      "[epoch: 47, i:  4523]  train_loss: 0.497  |  valid_loss: 0.710\n",
      "[epoch: 47, i:  4610]  train_loss: 0.486  |  valid_loss: 0.466\n",
      "[epoch: 47, i:  4697]  train_loss: 0.415  |  valid_loss: 0.588\n",
      "[epoch: 47, i:  4784]  train_loss: 0.432  |  valid_loss: 0.659\n",
      "[epoch: 47, i:  4871]  train_loss: 0.423  |  valid_loss: 0.691\n",
      "[epoch: 47, i:  4958]  train_loss: 0.443  |  valid_loss: 0.739\n",
      "[epoch: 47, i:  5045]  train_loss: 0.511  |  valid_loss: 0.423\n",
      "[epoch: 47, i:  5132]  train_loss: 0.457  |  valid_loss: 0.594\n",
      "[epoch: 47, i:  5219]  train_loss: 0.494  |  valid_loss: 0.743\n",
      "[epoch: 47, i:  5306]  train_loss: 0.459  |  valid_loss: 0.615\n",
      "[epoch: 47, i:  5393]  train_loss: 0.506  |  valid_loss: 0.493\n",
      "[epoch: 47, i:  5480]  train_loss: 0.414  |  valid_loss: 0.824\n",
      "[epoch: 47, i:  5567]  train_loss: 0.419  |  valid_loss: 0.320\n",
      "[epoch: 47, i:  5654]  train_loss: 0.552  |  valid_loss: 0.520\n",
      "[epoch: 47, i:  5741]  train_loss: 0.466  |  valid_loss: 0.633\n",
      "[epoch: 47, i:  5828]  train_loss: 0.444  |  valid_loss: 0.581\n",
      "[epoch: 47, i:  5915]  train_loss: 0.426  |  valid_loss: 0.659\n",
      "[epoch: 47, i:  6002]  train_loss: 0.415  |  valid_loss: 0.481\n",
      "[epoch: 47, i:  6089]  train_loss: 0.441  |  valid_loss: 0.787\n",
      "[epoch: 47, i:  6176]  train_loss: 0.386  |  valid_loss: 0.567\n",
      "[epoch: 47, i:  6263]  train_loss: 0.416  |  valid_loss: 0.565\n",
      "[epoch: 47, i:  6350]  train_loss: 0.479  |  valid_loss: 0.512\n",
      "[epoch: 47, i:  6437]  train_loss: 0.443  |  valid_loss: 0.425\n",
      "[epoch: 47, i:  6524]  train_loss: 0.409  |  valid_loss: 0.756\n",
      "[epoch: 47, i:  6611]  train_loss: 0.439  |  valid_loss: 0.390\n",
      "[epoch: 47, i:  6698]  train_loss: 0.455  |  valid_loss: 0.682\n",
      "[epoch: 47, i:  6785]  train_loss: 0.432  |  valid_loss: 0.434\n",
      "[epoch: 47, i:  6872]  train_loss: 0.481  |  valid_loss: 0.761\n",
      "[epoch: 47, i:  6959]  train_loss: 0.404  |  valid_loss: 0.626\n",
      "[epoch: 47, i:  7046]  train_loss: 0.393  |  valid_loss: 0.548\n",
      "[epoch: 47, i:  7133]  train_loss: 0.392  |  valid_loss: 0.455\n",
      "[epoch: 47, i:  7220]  train_loss: 0.414  |  valid_loss: 0.674\n",
      "[epoch: 47, i:  7307]  train_loss: 0.438  |  valid_loss: 0.668\n",
      "[epoch: 47, i:  7394]  train_loss: 0.464  |  valid_loss: 0.585\n",
      "[epoch: 47, i:  7481]  train_loss: 0.428  |  valid_loss: 0.580\n",
      "[epoch: 47, i:  7568]  train_loss: 0.460  |  valid_loss: 0.725\n",
      "[epoch: 47, i:  7655]  train_loss: 0.450  |  valid_loss: 0.623\n",
      "[epoch: 47, i:  7742]  train_loss: 0.464  |  valid_loss: 0.586\n",
      "[epoch: 47, i:  7829]  train_loss: 0.412  |  valid_loss: 0.404\n",
      "[epoch: 47, i:  7916]  train_loss: 0.445  |  valid_loss: 0.606\n",
      "[epoch: 47, i:  8003]  train_loss: 0.427  |  valid_loss: 0.416\n",
      "[epoch: 47, i:  8090]  train_loss: 0.418  |  valid_loss: 0.476\n",
      "[epoch: 47, i:  8177]  train_loss: 0.477  |  valid_loss: 0.567\n",
      "[epoch: 47, i:  8264]  train_loss: 0.383  |  valid_loss: 0.585\n",
      "[epoch: 47, i:  8351]  train_loss: 0.433  |  valid_loss: 0.703\n",
      "[epoch: 47, i:  8438]  train_loss: 0.435  |  valid_loss: 0.442\n",
      "[epoch: 47, i:  8525]  train_loss: 0.500  |  valid_loss: 0.535\n",
      "[epoch: 47, i:  8612]  train_loss: 0.426  |  valid_loss: 0.867\n",
      "[epoch: 47, i:  8699]  train_loss: 0.411  |  valid_loss: 0.597\n",
      "--> [End of epoch 47] train_accuracy: 84.84%  |  valid_accuracy: 80.55%\n",
      "--> [Start of epoch 48]  lr: 0.000005\n",
      "[epoch: 48, i:    86]  train_loss: 0.424  |  valid_loss: 0.605\n",
      "[epoch: 48, i:   173]  train_loss: 0.468  |  valid_loss: 0.634\n",
      "[epoch: 48, i:   260]  train_loss: 0.413  |  valid_loss: 0.667\n",
      "[epoch: 48, i:   347]  train_loss: 0.384  |  valid_loss: 0.525\n",
      "[epoch: 48, i:   434]  train_loss: 0.421  |  valid_loss: 0.556\n",
      "[epoch: 48, i:   521]  train_loss: 0.495  |  valid_loss: 0.360\n",
      "[epoch: 48, i:   608]  train_loss: 0.449  |  valid_loss: 0.576\n",
      "[epoch: 48, i:   695]  train_loss: 0.468  |  valid_loss: 0.580\n",
      "[epoch: 48, i:   782]  train_loss: 0.475  |  valid_loss: 0.703\n",
      "[epoch: 48, i:   869]  train_loss: 0.405  |  valid_loss: 0.673\n",
      "[epoch: 48, i:   956]  train_loss: 0.436  |  valid_loss: 0.530\n",
      "[epoch: 48, i:  1043]  train_loss: 0.415  |  valid_loss: 0.558\n",
      "[epoch: 48, i:  1130]  train_loss: 0.450  |  valid_loss: 0.495\n",
      "[epoch: 48, i:  1217]  train_loss: 0.429  |  valid_loss: 0.587\n",
      "[epoch: 48, i:  1304]  train_loss: 0.481  |  valid_loss: 0.419\n",
      "[epoch: 48, i:  1391]  train_loss: 0.447  |  valid_loss: 0.637\n",
      "[epoch: 48, i:  1478]  train_loss: 0.427  |  valid_loss: 0.527\n",
      "[epoch: 48, i:  1565]  train_loss: 0.419  |  valid_loss: 0.772\n",
      "[epoch: 48, i:  1652]  train_loss: 0.464  |  valid_loss: 0.557\n",
      "[epoch: 48, i:  1739]  train_loss: 0.422  |  valid_loss: 0.882\n",
      "[epoch: 48, i:  1826]  train_loss: 0.465  |  valid_loss: 0.736\n",
      "[epoch: 48, i:  1913]  train_loss: 0.463  |  valid_loss: 0.614\n",
      "[epoch: 48, i:  2000]  train_loss: 0.438  |  valid_loss: 0.639\n",
      "[epoch: 48, i:  2087]  train_loss: 0.455  |  valid_loss: 0.759\n",
      "[epoch: 48, i:  2174]  train_loss: 0.457  |  valid_loss: 0.520\n",
      "[epoch: 48, i:  2261]  train_loss: 0.471  |  valid_loss: 0.814\n",
      "[epoch: 48, i:  2348]  train_loss: 0.432  |  valid_loss: 0.453\n",
      "[epoch: 48, i:  2435]  train_loss: 0.382  |  valid_loss: 0.636\n",
      "[epoch: 48, i:  2522]  train_loss: 0.438  |  valid_loss: 0.432\n",
      "[epoch: 48, i:  2609]  train_loss: 0.387  |  valid_loss: 0.548\n",
      "[epoch: 48, i:  2696]  train_loss: 0.426  |  valid_loss: 0.633\n",
      "[epoch: 48, i:  2783]  train_loss: 0.392  |  valid_loss: 0.404\n",
      "[epoch: 48, i:  2870]  train_loss: 0.450  |  valid_loss: 0.680\n",
      "[epoch: 48, i:  2957]  train_loss: 0.416  |  valid_loss: 0.663\n",
      "[epoch: 48, i:  3044]  train_loss: 0.384  |  valid_loss: 0.653\n",
      "[epoch: 48, i:  3131]  train_loss: 0.431  |  valid_loss: 0.586\n",
      "[epoch: 48, i:  3218]  train_loss: 0.468  |  valid_loss: 0.653\n",
      "[epoch: 48, i:  3305]  train_loss: 0.475  |  valid_loss: 0.571\n",
      "[epoch: 48, i:  3392]  train_loss: 0.415  |  valid_loss: 0.515\n",
      "[epoch: 48, i:  3479]  train_loss: 0.392  |  valid_loss: 0.572\n",
      "[epoch: 48, i:  3566]  train_loss: 0.362  |  valid_loss: 0.497\n",
      "[epoch: 48, i:  3653]  train_loss: 0.491  |  valid_loss: 0.552\n",
      "[epoch: 48, i:  3740]  train_loss: 0.383  |  valid_loss: 0.385\n",
      "[epoch: 48, i:  3827]  train_loss: 0.398  |  valid_loss: 0.813\n",
      "[epoch: 48, i:  3914]  train_loss: 0.427  |  valid_loss: 0.445\n",
      "[epoch: 48, i:  4001]  train_loss: 0.461  |  valid_loss: 0.619\n",
      "[epoch: 48, i:  4088]  train_loss: 0.424  |  valid_loss: 0.525\n",
      "[epoch: 48, i:  4175]  train_loss: 0.476  |  valid_loss: 0.545\n",
      "[epoch: 48, i:  4262]  train_loss: 0.474  |  valid_loss: 0.408\n",
      "[epoch: 48, i:  4349]  train_loss: 0.382  |  valid_loss: 0.587\n",
      "[epoch: 48, i:  4436]  train_loss: 0.418  |  valid_loss: 0.501\n",
      "[epoch: 48, i:  4523]  train_loss: 0.439  |  valid_loss: 0.706\n",
      "[epoch: 48, i:  4610]  train_loss: 0.429  |  valid_loss: 0.458\n",
      "[epoch: 48, i:  4697]  train_loss: 0.425  |  valid_loss: 0.591\n",
      "[epoch: 48, i:  4784]  train_loss: 0.430  |  valid_loss: 0.654\n",
      "[epoch: 48, i:  4871]  train_loss: 0.463  |  valid_loss: 0.722\n",
      "[epoch: 48, i:  4958]  train_loss: 0.479  |  valid_loss: 0.792\n",
      "[epoch: 48, i:  5045]  train_loss: 0.441  |  valid_loss: 0.420\n",
      "[epoch: 48, i:  5132]  train_loss: 0.450  |  valid_loss: 0.601\n",
      "[epoch: 48, i:  5219]  train_loss: 0.488  |  valid_loss: 0.743\n",
      "[epoch: 48, i:  5306]  train_loss: 0.483  |  valid_loss: 0.614\n",
      "[epoch: 48, i:  5393]  train_loss: 0.369  |  valid_loss: 0.480\n",
      "[epoch: 48, i:  5480]  train_loss: 0.451  |  valid_loss: 0.818\n",
      "[epoch: 48, i:  5567]  train_loss: 0.431  |  valid_loss: 0.343\n",
      "[epoch: 48, i:  5654]  train_loss: 0.452  |  valid_loss: 0.528\n",
      "[epoch: 48, i:  5741]  train_loss: 0.472  |  valid_loss: 0.621\n",
      "[epoch: 48, i:  5828]  train_loss: 0.415  |  valid_loss: 0.549\n",
      "[epoch: 48, i:  5915]  train_loss: 0.474  |  valid_loss: 0.697\n",
      "[epoch: 48, i:  6002]  train_loss: 0.444  |  valid_loss: 0.497\n",
      "[epoch: 48, i:  6089]  train_loss: 0.487  |  valid_loss: 0.750\n",
      "[epoch: 48, i:  6176]  train_loss: 0.431  |  valid_loss: 0.578\n",
      "[epoch: 48, i:  6263]  train_loss: 0.444  |  valid_loss: 0.554\n",
      "[epoch: 48, i:  6350]  train_loss: 0.398  |  valid_loss: 0.520\n",
      "[epoch: 48, i:  6437]  train_loss: 0.411  |  valid_loss: 0.412\n",
      "[epoch: 48, i:  6524]  train_loss: 0.425  |  valid_loss: 0.762\n",
      "[epoch: 48, i:  6611]  train_loss: 0.519  |  valid_loss: 0.359\n",
      "[epoch: 48, i:  6698]  train_loss: 0.463  |  valid_loss: 0.656\n",
      "[epoch: 48, i:  6785]  train_loss: 0.493  |  valid_loss: 0.424\n",
      "[epoch: 48, i:  6872]  train_loss: 0.455  |  valid_loss: 0.733\n",
      "[epoch: 48, i:  6959]  train_loss: 0.441  |  valid_loss: 0.606\n",
      "[epoch: 48, i:  7046]  train_loss: 0.462  |  valid_loss: 0.553\n",
      "[epoch: 48, i:  7133]  train_loss: 0.433  |  valid_loss: 0.461\n",
      "[epoch: 48, i:  7220]  train_loss: 0.451  |  valid_loss: 0.679\n",
      "[epoch: 48, i:  7307]  train_loss: 0.460  |  valid_loss: 0.678\n",
      "[epoch: 48, i:  7394]  train_loss: 0.415  |  valid_loss: 0.567\n",
      "[epoch: 48, i:  7481]  train_loss: 0.452  |  valid_loss: 0.568\n",
      "[epoch: 48, i:  7568]  train_loss: 0.397  |  valid_loss: 0.731\n",
      "[epoch: 48, i:  7655]  train_loss: 0.405  |  valid_loss: 0.607\n",
      "[epoch: 48, i:  7742]  train_loss: 0.408  |  valid_loss: 0.558\n",
      "[epoch: 48, i:  7829]  train_loss: 0.464  |  valid_loss: 0.396\n",
      "[epoch: 48, i:  7916]  train_loss: 0.436  |  valid_loss: 0.640\n",
      "[epoch: 48, i:  8003]  train_loss: 0.401  |  valid_loss: 0.434\n",
      "[epoch: 48, i:  8090]  train_loss: 0.426  |  valid_loss: 0.486\n",
      "[epoch: 48, i:  8177]  train_loss: 0.461  |  valid_loss: 0.531\n",
      "[epoch: 48, i:  8264]  train_loss: 0.450  |  valid_loss: 0.575\n",
      "[epoch: 48, i:  8351]  train_loss: 0.471  |  valid_loss: 0.652\n",
      "[epoch: 48, i:  8438]  train_loss: 0.407  |  valid_loss: 0.453\n",
      "[epoch: 48, i:  8525]  train_loss: 0.424  |  valid_loss: 0.550\n",
      "[epoch: 48, i:  8612]  train_loss: 0.416  |  valid_loss: 0.835\n",
      "[epoch: 48, i:  8699]  train_loss: 0.398  |  valid_loss: 0.590\n",
      "--> [End of epoch 48] train_accuracy: 84.87%  |  valid_accuracy: 80.77%\n",
      "--> [Start of epoch 49]  lr: 0.000005\n",
      "[epoch: 49, i:    86]  train_loss: 0.470  |  valid_loss: 0.588\n",
      "[epoch: 49, i:   173]  train_loss: 0.473  |  valid_loss: 0.619\n",
      "[epoch: 49, i:   260]  train_loss: 0.449  |  valid_loss: 0.671\n",
      "[epoch: 49, i:   347]  train_loss: 0.420  |  valid_loss: 0.497\n",
      "[epoch: 49, i:   434]  train_loss: 0.491  |  valid_loss: 0.559\n",
      "[epoch: 49, i:   521]  train_loss: 0.440  |  valid_loss: 0.356\n",
      "[epoch: 49, i:   608]  train_loss: 0.514  |  valid_loss: 0.612\n",
      "[epoch: 49, i:   695]  train_loss: 0.462  |  valid_loss: 0.578\n",
      "[epoch: 49, i:   782]  train_loss: 0.364  |  valid_loss: 0.687\n",
      "[epoch: 49, i:   869]  train_loss: 0.437  |  valid_loss: 0.675\n",
      "[epoch: 49, i:   956]  train_loss: 0.488  |  valid_loss: 0.535\n",
      "[epoch: 49, i:  1043]  train_loss: 0.451  |  valid_loss: 0.572\n",
      "[epoch: 49, i:  1130]  train_loss: 0.366  |  valid_loss: 0.506\n",
      "[epoch: 49, i:  1217]  train_loss: 0.496  |  valid_loss: 0.595\n",
      "[epoch: 49, i:  1304]  train_loss: 0.420  |  valid_loss: 0.405\n",
      "[epoch: 49, i:  1391]  train_loss: 0.406  |  valid_loss: 0.655\n",
      "[epoch: 49, i:  1478]  train_loss: 0.453  |  valid_loss: 0.533\n",
      "[epoch: 49, i:  1565]  train_loss: 0.446  |  valid_loss: 0.771\n",
      "[epoch: 49, i:  1652]  train_loss: 0.404  |  valid_loss: 0.564\n",
      "[epoch: 49, i:  1739]  train_loss: 0.449  |  valid_loss: 0.877\n",
      "[epoch: 49, i:  1826]  train_loss: 0.422  |  valid_loss: 0.706\n",
      "[epoch: 49, i:  1913]  train_loss: 0.462  |  valid_loss: 0.599\n",
      "[epoch: 49, i:  2000]  train_loss: 0.486  |  valid_loss: 0.625\n",
      "[epoch: 49, i:  2087]  train_loss: 0.456  |  valid_loss: 0.742\n",
      "[epoch: 49, i:  2174]  train_loss: 0.436  |  valid_loss: 0.499\n",
      "[epoch: 49, i:  2261]  train_loss: 0.499  |  valid_loss: 0.822\n",
      "[epoch: 49, i:  2348]  train_loss: 0.469  |  valid_loss: 0.457\n",
      "[epoch: 49, i:  2435]  train_loss: 0.470  |  valid_loss: 0.633\n",
      "[epoch: 49, i:  2522]  train_loss: 0.390  |  valid_loss: 0.434\n",
      "[epoch: 49, i:  2609]  train_loss: 0.421  |  valid_loss: 0.526\n",
      "[epoch: 49, i:  2696]  train_loss: 0.455  |  valid_loss: 0.642\n",
      "[epoch: 49, i:  2783]  train_loss: 0.430  |  valid_loss: 0.382\n",
      "[epoch: 49, i:  2870]  train_loss: 0.461  |  valid_loss: 0.700\n",
      "[epoch: 49, i:  2957]  train_loss: 0.432  |  valid_loss: 0.672\n",
      "[epoch: 49, i:  3044]  train_loss: 0.471  |  valid_loss: 0.681\n",
      "[epoch: 49, i:  3131]  train_loss: 0.452  |  valid_loss: 0.552\n",
      "[epoch: 49, i:  3218]  train_loss: 0.419  |  valid_loss: 0.666\n",
      "[epoch: 49, i:  3305]  train_loss: 0.380  |  valid_loss: 0.554\n",
      "[epoch: 49, i:  3392]  train_loss: 0.475  |  valid_loss: 0.509\n",
      "[epoch: 49, i:  3479]  train_loss: 0.472  |  valid_loss: 0.559\n",
      "[epoch: 49, i:  3566]  train_loss: 0.419  |  valid_loss: 0.510\n",
      "[epoch: 49, i:  3653]  train_loss: 0.415  |  valid_loss: 0.565\n",
      "[epoch: 49, i:  3740]  train_loss: 0.387  |  valid_loss: 0.386\n",
      "[epoch: 49, i:  3827]  train_loss: 0.438  |  valid_loss: 0.782\n",
      "[epoch: 49, i:  3914]  train_loss: 0.459  |  valid_loss: 0.446\n",
      "[epoch: 49, i:  4001]  train_loss: 0.469  |  valid_loss: 0.656\n",
      "[epoch: 49, i:  4088]  train_loss: 0.435  |  valid_loss: 0.508\n",
      "[epoch: 49, i:  4175]  train_loss: 0.466  |  valid_loss: 0.544\n",
      "[epoch: 49, i:  4262]  train_loss: 0.438  |  valid_loss: 0.427\n",
      "[epoch: 49, i:  4349]  train_loss: 0.493  |  valid_loss: 0.576\n",
      "[epoch: 49, i:  4436]  train_loss: 0.420  |  valid_loss: 0.522\n",
      "[epoch: 49, i:  4523]  train_loss: 0.498  |  valid_loss: 0.712\n",
      "[epoch: 49, i:  4610]  train_loss: 0.428  |  valid_loss: 0.461\n",
      "[epoch: 49, i:  4697]  train_loss: 0.443  |  valid_loss: 0.601\n",
      "[epoch: 49, i:  4784]  train_loss: 0.410  |  valid_loss: 0.662\n",
      "[epoch: 49, i:  4871]  train_loss: 0.446  |  valid_loss: 0.644\n",
      "[epoch: 49, i:  4958]  train_loss: 0.448  |  valid_loss: 0.774\n",
      "[epoch: 49, i:  5045]  train_loss: 0.414  |  valid_loss: 0.388\n",
      "[epoch: 49, i:  5132]  train_loss: 0.474  |  valid_loss: 0.542\n",
      "[epoch: 49, i:  5219]  train_loss: 0.428  |  valid_loss: 0.733\n",
      "[epoch: 49, i:  5306]  train_loss: 0.467  |  valid_loss: 0.603\n",
      "[epoch: 49, i:  5393]  train_loss: 0.462  |  valid_loss: 0.494\n",
      "[epoch: 49, i:  5480]  train_loss: 0.491  |  valid_loss: 0.787\n",
      "[epoch: 49, i:  5567]  train_loss: 0.414  |  valid_loss: 0.323\n",
      "[epoch: 49, i:  5654]  train_loss: 0.420  |  valid_loss: 0.523\n",
      "[epoch: 49, i:  5741]  train_loss: 0.406  |  valid_loss: 0.623\n",
      "[epoch: 49, i:  5828]  train_loss: 0.408  |  valid_loss: 0.567\n",
      "[epoch: 49, i:  5915]  train_loss: 0.426  |  valid_loss: 0.673\n",
      "[epoch: 49, i:  6002]  train_loss: 0.458  |  valid_loss: 0.484\n",
      "[epoch: 49, i:  6089]  train_loss: 0.448  |  valid_loss: 0.759\n",
      "[epoch: 49, i:  6176]  train_loss: 0.439  |  valid_loss: 0.587\n",
      "[epoch: 49, i:  6263]  train_loss: 0.511  |  valid_loss: 0.563\n",
      "[epoch: 49, i:  6350]  train_loss: 0.394  |  valid_loss: 0.521\n",
      "[epoch: 49, i:  6437]  train_loss: 0.402  |  valid_loss: 0.414\n",
      "[epoch: 49, i:  6524]  train_loss: 0.434  |  valid_loss: 0.740\n",
      "[epoch: 49, i:  6611]  train_loss: 0.398  |  valid_loss: 0.376\n",
      "[epoch: 49, i:  6698]  train_loss: 0.456  |  valid_loss: 0.684\n",
      "[epoch: 49, i:  6785]  train_loss: 0.448  |  valid_loss: 0.456\n",
      "[epoch: 49, i:  6872]  train_loss: 0.478  |  valid_loss: 0.775\n",
      "[epoch: 49, i:  6959]  train_loss: 0.401  |  valid_loss: 0.632\n",
      "[epoch: 49, i:  7046]  train_loss: 0.407  |  valid_loss: 0.544\n",
      "[epoch: 49, i:  7133]  train_loss: 0.448  |  valid_loss: 0.455\n",
      "[epoch: 49, i:  7220]  train_loss: 0.460  |  valid_loss: 0.678\n",
      "[epoch: 49, i:  7307]  train_loss: 0.440  |  valid_loss: 0.684\n",
      "[epoch: 49, i:  7394]  train_loss: 0.392  |  valid_loss: 0.535\n",
      "[epoch: 49, i:  7481]  train_loss: 0.424  |  valid_loss: 0.572\n",
      "[epoch: 49, i:  7568]  train_loss: 0.406  |  valid_loss: 0.709\n",
      "[epoch: 49, i:  7655]  train_loss: 0.445  |  valid_loss: 0.605\n",
      "[epoch: 49, i:  7742]  train_loss: 0.470  |  valid_loss: 0.565\n",
      "[epoch: 49, i:  7829]  train_loss: 0.419  |  valid_loss: 0.437\n",
      "[epoch: 49, i:  7916]  train_loss: 0.460  |  valid_loss: 0.597\n",
      "[epoch: 49, i:  8003]  train_loss: 0.413  |  valid_loss: 0.440\n",
      "[epoch: 49, i:  8090]  train_loss: 0.486  |  valid_loss: 0.445\n",
      "[epoch: 49, i:  8177]  train_loss: 0.410  |  valid_loss: 0.553\n",
      "[epoch: 49, i:  8264]  train_loss: 0.429  |  valid_loss: 0.623\n",
      "[epoch: 49, i:  8351]  train_loss: 0.491  |  valid_loss: 0.678\n",
      "[epoch: 49, i:  8438]  train_loss: 0.470  |  valid_loss: 0.447\n",
      "[epoch: 49, i:  8525]  train_loss: 0.404  |  valid_loss: 0.543\n",
      "[epoch: 49, i:  8612]  train_loss: 0.420  |  valid_loss: 0.835\n",
      "[epoch: 49, i:  8699]  train_loss: 0.439  |  valid_loss: 0.576\n",
      "--> [End of epoch 49] train_accuracy: 84.67%  |  valid_accuracy: 80.66%\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "epochs = 50  # Total epochs.\n",
    "\n",
    "for epoch in range(epoch_start, epoch_start + epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    running_val_loss = 0.0     # Initialize running train_loss for validation set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    valid_total = 0   \n",
    "    valid_correct = 0\n",
    "    \n",
    "    print('--> [Start of epoch {}]'.format(epoch) +\n",
    "          '  lr: {:.6f}'.format(opt.param_groups[0]['lr']))\n",
    "    \n",
    "    # print('--> [Start of epoch {}]'.format(epoch))\n",
    "    \n",
    "    validiter = iter(validloader)\n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Set the model to training mode.\n",
    "        dense_max.train()\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = dense_max(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "        \n",
    "        dense_max.eval()\n",
    "        \n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, train_predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "        \n",
    "        # only iterate through validation set according to train_per_valid ratio\n",
    "        if i % train_per_valid == train_per_valid - 1:\n",
    "            # Set the model to evaluation mode.\n",
    "            with torch.no_grad():\n",
    "                valid_inputs, valid_labels = next(validiter)\n",
    "                valid_inputs, valid_labels = valid_inputs.to(device), valid_labels.to(device)\n",
    "                valid_output = dense_max(valid_inputs)\n",
    "                valid_loss = loss_func(valid_output, valid_labels)\n",
    "                running_val_loss += valid_loss.item()\n",
    "                \n",
    "                _, valid_predicted = torch.max(valid_output.data, 1)\n",
    "                valid_total += valid_labels.size(0)\n",
    "                valid_correct += (valid_predicted == valid_labels).sum().item()\n",
    "            \n",
    "        # Record training/validation loss every several mini-batches.\n",
    "        if i % iter_n_per_record == iter_n_per_record - 1: \n",
    "            avg_train_loss = running_train_loss / iter_n_per_record\n",
    "            avg_train_losses.append(avg_train_loss)\n",
    "            avg_valid_loss = train_per_valid * running_val_loss / iter_n_per_record\n",
    "            avg_valid_losses.append(avg_valid_loss)\n",
    "            running_train_loss, running_val_loss = 0.0, 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % iter_n_per_print == iter_n_per_print - 1:\n",
    "                print('[epoch: {}, i: {:5d}]'.format(epoch, i) +\n",
    "                      '  train_loss: {:.3f}'.format(avg_train_loss) + \n",
    "                      '  |  valid_loss: {:.3f}'.format(avg_valid_loss))\n",
    "                            \n",
    "\n",
    "    # exponential scheduling\n",
    "    # scheduler.step()\n",
    "                   \n",
    "    # calculating train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    valid_accuracy = 100 * valid_correct / valid_total\n",
    "    valid_accuracies.append(valid_accuracy)     \n",
    "    \n",
    "    # reduce on plateau scheduling\n",
    "    scheduler.step(valid_accuracy)\n",
    "    \n",
    "    # Store the networks after each epochs.\n",
    "    # in case we want to do simple average or weighted average\n",
    "    file_name = f'epoch_{epoch:04d}.pth'\n",
    "    save_path = directory_path / file_name\n",
    "    \n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': dense_max.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'avg_train_losses': avg_train_losses[epoch * iter_n_per_record : (epoch + 1) * iter_n_per_record],\n",
    "            'avg_valid_losses': avg_valid_losses[epoch * iter_n_per_record : (epoch + 1) * iter_n_per_record],\n",
    "            'train_accuracy': train_accuracies[epoch],\n",
    "            'valid_accuracy': valid_accuracies[epoch],\n",
    "            }, save_path)\n",
    "    \n",
    "    print('--> [End of epoch {}]'.format(epoch) +\n",
    "                      ' train_accuracy: {:.2f}%'.format(train_accuracy) + \n",
    "                      '  |  valid_accuracy: {:.2f}%'.format(valid_accuracy))\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACZNElEQVR4nOzdd1QUVxsH4N/SQarSFQFBsZegIvaCIpZYEltMFFuM3dgxsX8JaowlidFY0STGEkuMXVE0UexixRoUC8UGCCplud8f4647W2dhG/A+5+yBnb1z585se/dWEWOMgRBCCCGESJkZuwCEEEIIIaaGAiRCCCGEEDkUIBFCCCGEyKEAiRBCCCFEDgVIhBBCCCFyKEAihBBCCJFDARIhhBBCiBwKkAghhBBC5FCARAghhBAihwIkohdxcXEQiUSIi4szdlGIjtFzK9z9+/chEomwaNEivR8rJiYGIpEI9+/f13pfZc9pZGQk/Pz8dFY+Yykt56FJcZ5/dVq3bo3WrVvrNE9TPq6sMh0gSV5QkpuNjQ28vb0RHh6OH374Aa9evTJ2EbXWunVriEQidO3aVeGx4nxYv379GrNnz6YvRVIs+/btw+zZs41dDFKGPX/+HN999x1atmwJNzc3ODs7o0mTJtiyZYuxi1bm3LhxA7Nnz9Z5UKcrZTpAkpg7dy5+/fVXrFixAmPGjAEAjB8/HnXq1MGVK1eMXLqi2bNnDy5cuKCz/F6/fo05c+ZQgESKZd++fZgzZ46xi0EEWL16NW7dumXsYuhcfHw8vvrqK5QvXx5ff/01vvnmG9jZ2aFv376YNWuWsYtncg4dOoRDhw7pJe8bN25gzpw5SgMkfR5XKAqQAERERODTTz/FoEGDEBUVhYMHD+LIkSNIT0/Hhx9+iDdv3hi7iFqpXLkyXFxc6IvICN6+fYvCwkKjHV/SVGKqv8hIyWFpaQlra2tjFwPA+9pvXfxAq1WrFu7cuYNdu3Zh3LhxGDVqFGJjY9G2bVssWLAAOTk5Wudp7Pe9Prx+/RoAYGVlBSsrK4Mf31jHlUUBkgpt27bFjBkz8ODBA/z222+8x27evImPP/4Y5cuXh42NDRo2bIjdu3fz0kia706ePIkJEybAzc0N5cqVQ48ePfD06VNe2vPnzyM8PByurq6wtbWFv78/Bg8ezEtTWFiIpUuXolatWrCxsYGHhweGDx+Oly9fKpTdwcEBX375Jf7++29cvHhR47lmZGRg/Pjx8PHxgbW1NQIDA7FgwQLpG/7+/ftwc3MDAMyZM0faJFmUppJt27YhODgYtra2cHV1xaefforHjx/z0qSmpmLQoEGoVKkSrK2t4eXlhW7duvG+9IVcM1X279+PVq1awcHBAY6OjmjUqBE2bdokfdzPzw+RkZEK+8m3iUuCkc2bN+Prr79GxYoVYWdnh4sXL0IkEmHDhg0KeRw8eBAikQh79uyRbnv8+DEGDx4MDw8PWFtbo1atWli3bp2gc9ElPz8/dOnSBYcOHUL9+vVhY2ODmjVrYseOHRr3/eeff9CrVy9UrlwZ1tbW8PHxwZdffsn7cREZGYnly5cDAK9pW0Loa/yvv/5C586d4e3tDWtrawQEBGDevHkQi8UK5yPkeVTl8OHDaN68OZydnWFvb4+goCBMnz6dl+bt27eYPXs2qlWrBhsbG3h5eaFnz564d++eQn6rVq1CQEAArK2t0ahRI5w7d04hjZDPFgC4fv062rZtC1tbW1SqVAn/+9//lH5Bq3qfqro2suT77sg20Qs5l23btqFmzZqwsbFB7dq1sXPnTpPoD+Tv7w9fX1/eNpFIhO7duyM3Nxf//fef2v1Vve+zsrIAAGfOnEHHjh3h5OQEOzs7tGrVCidPnlSaT8OGDWFjY4OAgAD88ssvmD17Nu89IbnmMTExCvsL+QwW+l5p3bo1ateujQsXLqBly5aws7OTvtbl3y9+fn6896/sTRLAPnjwACNHjkRQUBBsbW1RoUIF9OrVi/cZHhMTg169egEA2rRpo5CHsvdpeno6hgwZAg8PD9jY2KBevXoKn7Pavk7VsdAqdRnz2WefYfr06Th06BCGDRsGgPtgatasGSpWrIhp06ahXLly2Lp1K7p3747t27ejR48evDzGjBkDFxcXzJo1C/fv38fSpUsxevRoaXt3eno6OnToADc3N0ybNg3Ozs64f/++wpfS8OHDERMTg0GDBmHs2LFISkrCTz/9hEuXLuHkyZOwtLTkpR83bhyWLFmC2bNnK/2AlXj9+jVatWqFx48fY/jw4ahcuTJOnTqFqKgopKSkYOnSpXBzc8OKFSswYsQI9OjRAz179gQA1K1bV6vrKSl/o0aNEB0djbS0NCxbtgwnT57EpUuX4OzsDAD46KOPcP36dYwZMwZ+fn5IT0/H4cOHkZycLL0v5JqpKsPgwYNRq1YtREVFwdnZGZcuXcKBAwfwySefaHU+EvPmzYOVlRUmTZqE3Nxc1KxZE1WqVMHWrVsxcOBAXtotW7bAxcUF4eHhAIC0tDQ0adIEIpEIo0ePhpubG/bv348hQ4YgKysL48ePL1KZiurOnTvo06cPvvjiCwwcOBDr169Hr169cODAAbRv317lftu2bcPr168xYsQIVKhQAWfPnsWPP/6IR48eYdu2bQC41/CTJ09w+PBh/Prrrwp5CH2Nx8TEwN7eHhMmTIC9vT2OHj2KmTNnIisrC999951OrsP169fRpUsX1K1bF3PnzoW1tTXu3r3L+6ITi8Xo0qULYmNj0bdvX4wbNw6vXr3C4cOHce3aNQQEBEjTbtq0Ca9evcLw4cMhEomwcOFC9OzZE//995/0vIR+tqSmpqJNmzYoKCiQplu1ahVsbW11cu6aCDmXvXv3ok+fPqhTpw6io6Px8uVLDBkyBBUrVjRIGYsiNTUVAODq6ioovfz73srKCkePHkVERASCg4Mxa9YsmJmZYf369Wjbti3++ecfNG7cGABw6dIldOzYEV5eXpgzZw7EYjHmzp0r/SGqK9q8V54/f46IiAj07dsXn376KTw8PJTmuXTpUmRnZ/O2LVmyBAkJCahQoQIA4Ny5czh16hT69u2LSpUq4f79+1ixYgVat26NGzduwM7ODi1btsTYsWPxww8/YPr06ahRowYASP/Ke/PmDVq3bo27d+9i9OjR8Pf3x7Zt2xAZGYmMjAyMGzeOl17I61QjVoatX7+eAWDnzp1TmcbJyYk1aNBAer9du3asTp067O3bt9JthYWFrGnTpqxq1aoKeYeFhbHCwkLp9i+//JKZm5uzjIwMxhhjO3fu1FiGf/75hwFgv//+O2/7gQMHFLa3atWK1apVizHG2Jw5cxgAduHCBcYYY0lJSQwA++6776Tp582bx8qVK8du377Ny3vatGnM3NycJScnM8YYe/r0KQPAZs2apbKcso4dO8YAsGPHjjHGGMvLy2Pu7u6sdu3a7M2bN9J0e/bsYQDYzJkzGWOMvXz5UqGM8oRcM2UyMjKYg4MDCwkJ4ZWBMcZ7jnx9fdnAgQMV9m/VqhVr1aqVwjlWqVKFvX79mpc2KiqKWVpashcvXki35ebmMmdnZzZ48GDptiFDhjAvLy/27Nkz3v59+/ZlTk5OCvlqIilTUlKSVvsxxp03ALZ9+3bptszMTObl5cV7D8g/t4wxpeWMjo5mIpGIPXjwQLpt1KhRTNnHjjavcWXHGj58OLOzs+O9L4U+j8osWbKEAWBPnz5VmWbdunUMAFu8eLHCY5LXk+Q9V6FCBd5r4a+//mIA2N9//y3dJvSzZfz48QwAO3PmjHRbeno6c3JyUnjuVb1n5a+Nsud04MCBzNfXV3pfm3OpU6cOq1SpEnv16pV0W1xcHAPAy1MoybFlyyeU/Hko8/z5c+bu7s5atGihMT9V7/vCwkJWtWpVFh4ezvs8ef36NfP392ft27eXbuvatSuzs7Njjx8/lm67c+cOs7Cw4L0/JOe9fv16hXLIP7eS7xzZ51/oe6VVq1YMAFu5cqVCek3vl61btzIAbO7cuWqPGx8fzwCwjRs3Srdt27ZN5fMqf9ylS5cyAOy3336TbsvLy2OhoaHM3t6eZWVlMca0e51qQk1sGtjb20tHs7148QJHjx5F79698erVKzx79gzPnj3D8+fPER4ejjt37ig0F33++ee8KtMWLVpALBbjwYMHACCtNdmzZw/y8/OVlmHbtm1wcnJC+/btpcd89uwZgoODYW9vj2PHjindb9y4cRr7Im3btg0tWrSAi4sLL++wsDCIxWKcOHFC8LVS5/z580hPT8fIkSNhY2Mj3d65c2dUr14de/fuBQDY2trCysoKcXFxSpsPAWHXTJnDhw/j1atXmDZtGq8MAHjPkbYGDhyo8Ou9T58+yM/P59VqHTp0CBkZGejTpw8AgDGG7du3o2vXrmCM8a5/eHg4MjMzNTaRZmZm8vbLzMwEALx8+ZK3Xf4Xnyre3t68WlBHR0cMGDAAly5dkv7CVkb2/HNycvDs2TM0bdoUjDFcunRJ43G1eY3LHkvyPmzRogVev36NmzdvCjpPTSSvsb/++ktl35Lt27fD1dVVOrBDlvzrqU+fPnBxcZHeb9GiBQBIm3O0+WzZt28fmjRpIq2NAAA3Nzf079+/6CesBU3n8uTJE1y9ehUDBgyAvb29NF2rVq1Qp04dQcfIzs7mvQ4knwWqXu/FUVhYiP79+yMjIwM//vij4P3k3/cJCQm4c+cOPvnkEzx//lxaxpycHLRr1w4nTpxAYWEhxGIxjhw5gu7du8Pb21u6f2BgICIiIop9PrK0ea9YW1tj0KBBWuV/48YNDB48GN26dcPXX3+t9Lj5+fl4/vw5AgMD4ezsLKjbhzL79u2Dp6cn+vXrJ91maWmJsWPHIjs7G8ePH+el1/Q6FYICJA2ys7Ph4OAAALh79y4YY5gxYwbc3Nx4N8noh/T0dN7+lStX5t2XPGGSN3yrVq3w0UcfYc6cOXB1dUW3bt2wfv165ObmSve5c+cOMjMz4e7urnDc7OxshWNKODk5Yfz48di9e7fKL6k7d+7gwIEDCvmGhYUpPZ+ikgSEQUFBCo9Vr15d+ri1tTUWLFiA/fv3w8PDAy1btsTChQt5X85Crpkykn4htWvX1sk5Sfj7+ytsq1evHqpXr84bOrxlyxa4urqibdu2AICnT58iIyMDq1atUrj+kg8qTde/W7duvP26d+8OAPjggw9420ePHi3oXAIDAxW+3KtVqwYAajt+JycnIzIyEuXLl4e9vT3c3NzQqlUrABD0JabNa/z69evo0aMHnJyc4OjoCDc3N3z66aeCjyVEnz590KxZMwwdOhQeHh7o27cvtm7dyguW7t27h6CgIFhYaO6poOlzQJvPlgcPHqBq1aoKx1D23tIHTecieS8HBgYq7KtsmzKS5mbJ7YMPPgAAdO/enbe9W7duRT4PiTFjxuDAgQNYs2YN6tWrJ3g/+ff9nTt3AHCBk/xzuGbNGuTm5iIzMxPp6el48+ZNsa6PUNq8VypWrKhVp+isrCz07NkTFStWxMaNG3mfG2/evMHMmTOl/VpdXV3h5uaGjIyMIr9HJa97MzN+2CJpkpO87iQ0vU6FoD5Iajx69AiZmZnSF63kw3HSpEnSPiTy5F/g5ubmStMxxgBwvzT//PNPnD59Gn///TcOHjyIwYMH4/vvv8fp06dhb2+PwsJCuLu74/fff1eal7p2a0lfpDlz5mDp0qUKjxcWFqJ9+/aYMmWK0v0lX46GNH78eHTt2hW7du3CwYMHMWPGDERHR+Po0aNo0KCBoGtWHKpqk8RisdLnU1Xfjz59+uCbb77Bs2fP4ODggN27d6Nfv37SL1TJ6+nTTz9V6Kskoamf1/fff897w1++fBmTJk3Cb7/9xutDIPtLVdfEYjHat2+PFy9eYOrUqahevTrKlSuHx48fIzIyUtDoHqGv8YyMDLRq1QqOjo6YO3cuAgICYGNjg4sXL2Lq1Km8Y2n7PMqytbXFiRMncOzYMezduxcHDhzAli1b0LZtWxw6dEjj/vI0fQ4U5bOlOOQ76WpD07nowpQpU6Rf5ADXV+/TTz/FokWLeEGMbA1BUcyZMwc///wz5s+fj88++0yrfeXf95Ln8LvvvkP9+vWV7mNvb4+3b98KPoa617Am2rxXANWfY6pERkbiyZMnOHv2LBwdHXmPjRkzBuvXr8f48eMRGhoKJycniEQi9O3b12Cj/XTxOqUASQ1JR1LJB1aVKlUAcNV6khoWXWnSpAmaNGmCb775Bps2bUL//v2xefNmDB06FAEBAThy5AiaNWum9YtYUos0e/ZspV/CAQEByM7O1ng+xWmCAiAdNXLr1i1pDYrErVu3FEaVBAQEYOLEiZg4cSLu3LmD+vXr4/vvv+eNKFR3zZSRdJq9du2a2i8bFxcXZGRkKGx/8OCB9DUgRJ8+fTBnzhxs374dHh4eyMrKQt++faWPu7m5wcHBAWKxuMivp+DgYN59SfDVrFmzIo0WktRkyD7ft2/fBgCV+V29ehW3b9/Ghg0bMGDAAOn2w4cPK6RV9ToS+hqPi4vD8+fPsWPHDrRs2VK6PSkpSSFtcZ9HMzMztGvXDu3atcPixYvx7bff4quvvsKxY8cQFhaGgIAAnDlzBvn5+cI7faqgzWeLr6+vtLZClrI5i5Rdg7y8PKSkpBS9sBpI3st3795VeEzZNmVq1qyJmjVrSu9Lai+Dg4N1Nrvy8uXLMXv2bIwfPx5Tp04tdn6SzxdHR0e1z6G7uztsbGwEXR9JACj/HMrXliijzXtFW/Pnz8euXbuwY8cOVK9eXeHxP//8EwMHDsT3338v3fb27VuF89Dme8XX1xdXrlxBYWEhrxZJ0lQo/x2iC9TEpsLRo0cxb948+Pv7S9v23d3d0bp1a/zyyy9KP2Dkh+8L8fLlS4WIVvLrQ9Jk1Lt3b4jFYsybN09h/4KCAqVfArLGjx8PZ2dnzJ07V+Gx3r17Iz4+HgcPHlR4LCMjAwUFBQAAOzs76baiaNiwIdzd3bFy5UpeU9j+/fuRmJiIzp07A+BG1cn/wgoICICDg4N0PyHXTJkOHTrAwcEB0dHRCseQzS8gIACnT59GXl6edNuePXvw8OFDLc6Yq/qtU6cOtmzZgi1btsDLy4v3QWVubo6PPvoI27dvx7Vr1xT2L8rrqbiePHmCnTt3Su9nZWVh48aNqF+/Pjw9PZXuI/mlJnsNGWNYtmyZQtpy5coBUHwdCX2NKztWXl4efv75Z4X9ivM8vnjxQmGb/Gvso48+wrNnz/DTTz8ppNW2NkWbz5ZOnTrh9OnTOHv2LO9xZbVvAQEBCv0IV61aVawaJE28vb1Ru3ZtbNy4kdf37fjx47h69arejquNLVu2YOzYsejfvz8WL16skzyDg4MREBCARYsWKe3zJ3kOzc3NERYWhl27duHJkyfSx+/evYv9+/fz9nF0dISrq6vCc6js9S5Pm/eKNo4cOYKvv/4aX331lbRJX9mx5d8DP/74o8LrTtXngTKdOnVCamoqr9tCQUEBfvzxR9jb20ub9HWJapDAfUnfvHkTBQUFSEtLw9GjR3H48GH4+vpi9+7dvA69y5cvR/PmzVGnTh0MGzYMVapUQVpaGuLj4/Ho0SNcvnxZq2Nv2LABP//8M3r06IGAgAC8evUKq1evhqOjIzp16gSA63MzfPhwREdHIyEhAR06dIClpSXu3LmDbdu2YdmyZfj4449VHsPJyQnjxo1T2ll78uTJ2L17N7p06YLIyEgEBwcjJycHV69exZ9//on79+9L5xqqWbMmtmzZgmrVqqF8+fKoXbu24P48lpaWWLBgAQYNGoRWrVqhX79+0mH+fn5++PLLLwFwtRXt2rVD7969UbNmTVhYWGDnzp1IS0uT1r4IuWbKODo6YsmSJRg6dCgaNWqETz75BC4uLrh8+TJev34tnU9j6NCh+PPPP9GxY0f07t0b9+7dw2+//cYbti1Unz59MHPmTNjY2GDIkCEK7efz58/HsWPHEBISgmHDhqFmzZp48eIFLl68iCNHjij9otanatWqYciQITh37hw8PDywbt06pKWlYf369Sr3qV69OgICAjBp0iQ8fvwYjo6O2L59u9K2fkmN19ixYxEeHg5zc3P07dtX8Gu8adOmcHFxwcCBAzF27FiIRCL8+uuvSgOS4jyPc+fOxYkTJ9C5c2f4+voiPT0dP//8MypVqoTmzZsDAAYMGICNGzdiwoQJOHv2LFq0aIGcnBwcOXIEI0eO1Lp/jNDPlilTpuDXX39Fx44dMW7cOOkwf8kvbPlr8MUXX+Cjjz5C+/btcfnyZRw8eFDwUPai+vbbb9GtWzc0a9YMgwYNwsuXL/HTTz+hdu3aggcM6MvZs2cxYMAAVKhQAe3atVMILJs2bapVTbGEmZkZ1qxZg4iICNSqVQuDBg1CxYoV8fjxYxw7dgyOjo74+++/AQCzZ8/GoUOH0KxZM4wYMQJisVh6fRISEnj5Dh06FPPnz8fQoUPRsGFDnDhxQlqrq4427xVt9OvXD25ubqhatarCHIHt27eHh4cHunTpgl9//RVOTk6oWbMm4uPjceTIEek0ABL169eHubk5FixYgMzMTFhbW6Nt27Zwd3dXOO7nn3+OX375BZGRkbhw4QL8/Pzw559/4uTJk1i6dKm0r7BOCR7vVgpJhkVKblZWVszT05O1b9+eLVu2TDpsUN69e/fYgAEDmKenJ7O0tGQVK1ZkXbp0YX/++adC3vJD0eWH0168eJH169ePVa5cmVlbWzN3d3fWpUsXdv78eYXjrlq1igUHBzNbW1vm4ODA6tSpw6ZMmcKePHkiTSM7zF/Wy5cvpcOA5YfQv3r1ikVFRbHAwEBmZWXFXF1dWdOmTdmiRYtYXl6eNN2pU6dYcHAws7Ky0jjkX9mwYcYY27JlC2vQoAGztrZm5cuXZ/3792ePHj2SPv7s2TM2atQoVr16dVauXDnm5OTEQkJC2NatW6VptLlmyuzevZs1bdqU2draMkdHR9a4cWP2xx9/8NJ8//33rGLFisza2po1a9aMnT9/XuUw/23btqk81p07d6Svr3///VdpmrS0NDZq1Cjm4+PDLC0tmaenJ2vXrh1btWqVoPORVdxh/p07d2YHDx5kdevWZdbW1qx69eoK56fsub1x4wYLCwtj9vb2zNXVlQ0bNoxdvnxZYYhyQUEBGzNmDHNzc2MikUhhyL+Q1/jJkydZkyZNmK2tLfP29mZTpkxhBw8eVPp6E/I8KhMbG8u6devGvL29mZWVFfP29mb9+vVTmA7j9evX7KuvvmL+/v7S5+7jjz9m9+7dY4wpn1pDQtl7SMhnC2OMXblyhbVq1YrZ2NiwihUrsnnz5rG1a9cqPPdisZhNnTqVubq6Mjs7OxYeHs7u3r1brGH+Qs9l8+bNrHr16sza2prVrl2b7d69m3300UesevXqSq64eroc5i//uS9/UzakXpam9/2lS5dYz549WYUKFZi1tTXz9fVlvXv3ZrGxsbx0sbGxrEGDBszKyooFBASwNWvWsIkTJzIbGxteutevX7MhQ4YwJycn5uDgwHr37s3S09MFDfMX+l5R9b0heUz2/aLu2knyfPnyJRs0aBBzdXVl9vb2LDw8nN28eVPp1BurV69mVapUYebm5rw8lL1P09LSpPlaWVmxOnXqKDxf2r5O1RG924kQUsb5+fmhdu3avFm+CdGl+vXrw83NTWn/NMKN0rt+/brSPmbE8KgPEiGEEJ3Kz8+X9l+UiIuLw+XLl3XWybqkk1/j886dO9i3bx9dHxNCfZAIIYTo1OPHjxEWFoZPP/0U3t7euHnzJlauXAlPT0988cUXxi6eSahSpQoiIyNRpUoVPHjwACtWrICVlZXKKVeI4VGARAghRKdcXFwQHByMNWvW4OnTpyhXrhw6d+6M+fPnK3TULas6duyIP/74A6mpqbC2tkZoaCi+/fZbpZOAEuOgPkiEEEIIIXKoDxIhhBBCiBwKkAghhBBC5FAfJCUKCwvx5MkTODg4FHuJDUIIIYQYBmMMr169gre3t8LEvNqiAEmJJ0+ewMfHx9jFIIQQQkgRPHz4EJUqVSpWHhQgKSGZsvzhw4cKqxQTQgghxDRlZWXBx8dHJ0uPUICkhKRZzdHRkQIkQgghpITRRfcY6qRNCCGEECKHAiRCCCGEEDkUIBFCCCGEyKE+SIQQQvROLBYjPz/f2MUgJZylpSXMzc0NciwKkAghhOgNYwypqanIyMgwdlFIKeHs7AxPT0+9z1No1AApOjoaO3bswM2bN2Fra4umTZtiwYIFCAoKUrnP6tWrsXHjRly7dg0AEBwcjG+//RaNGzeWpomMjMSGDRt4+4WHh+PAgQP6ORFCCCFKSYIjd3d32NnZ0eS7pMgYY3j9+jXS09MBAF5eXno9nlEDpOPHj2PUqFFo1KgRCgoKMH36dHTo0AE3btxAuXLllO4TFxeHfv36oWnTprCxscGCBQvQoUMHXL9+HRUrVpSm69ixI9avXy+9b21trffzIYQQ8p5YLJYGRxUqVDB2cUgpYGtrCwBIT0+Hu7u7XpvbjBogydfoxMTEwN3dHRcuXEDLli2V7vP777/z7q9Zswbbt29HbGwsBgwYIN1ubW0NT09P3ReaEEKIIJI+R3Z2dkYuCSlNJK+n/Px8vQZIJjWKLTMzEwBQvnx5wfu8fv0a+fn5CvvExcXB3d0dQUFBGDFiBJ4/f64yj9zcXGRlZfFuhBBCdIOa1YguGer1ZDIBUmFhIcaPH49mzZqhdu3agvebOnUqvL29ERYWJt3WsWNHbNy4EbGxsViwYAGOHz+OiIgIiMVipXlER0fDyclJeqN12AghhJCyzWQCpFGjRuHatWvYvHmz4H3mz5+PzZs3Y+fOnbCxsZFu79u3Lz788EPUqVMH3bt3x549e3Du3DnExcUpzScqKgqZmZnS28OHD4t7OoQQQoiUn58fli5dKjh9XFwcRCKR3kf/xcTEwNnZWa/HKKlMYpj/6NGjsWfPHpw4cULw6ruLFi3C/PnzceTIEdStW1dt2ipVqsDV1RV3795Fu3btFB63tramTtyEEEKkWrdujfr162sV1Khz7tw5lYOPlGnatClSUlLg5OSkk+MT7Rk1QGKMYcyYMdi5cyfi4uLg7+8vaL+FCxfim2++wcGDB9GwYUON6R89eoTnz5/rfUigRm8zuZtlOaAcjegghJCSjDEGsVgMCwvNX6Vubm5a5W1lZUUDjYzMqE1so0aNwm+//YZNmzbBwcEBqampSE1NxZs3b6RpBgwYgKioKOn9BQsWYMaMGVi3bh38/Pyk+2RnZwMAsrOzMXnyZJw+fRr3799HbGwsunXrhsDAQISHhxv8HHnOrQGW1gGOzDRuOQghhKgUGRmJ48ePY9myZRCJRBCJRLh//7602Wv//v0IDg6GtbU1/v33X9y7dw/dunWDh4cH7O3t0ahRIxw5coSXp3wTm0gkwpo1a9CjRw/Y2dmhatWq2L17t/Rx+SY2SVPYwYMHUaNGDdjb26Njx45ISUmR7lNQUICxY8fC2dkZFSpUwNSpUzFw4EB0795dq/NfsWIFAgICYGVlhaCgIPz666/SxxhjmD17NipXrgxra2t4e3tj7Nix0sd//vlnVK1aFTY2NvDw8MDHH3+s1bFNiVEDpBUrViAzMxOtW7eGl5eX9LZlyxZpmuTkZN4LYMWKFcjLy8PHH3/M22fRokUAAHNzc1y5cgUffvghqlWrhiFDhiA4OBj//POP6TSjMWMXgBBCjIMxhtd5BUa5MSbsw3fZsmUIDQ3FsGHDkJKSgpSUFN7gnWnTpmH+/PlITExE3bp1kZ2djU6dOiE2NhaXLl1Cx44d0bVrVyQnJ6s9zpw5c9C7d29cuXIFnTp1Qv/+/fHixQuV6V+/fo1Fixbh119/xYkTJ5CcnIxJkyZJH1+wYAF+//13rF+/HidPnkRWVhZ27dol6Jwldu7ciXHjxmHixIm4du0ahg8fjkGDBuHYsWMAgO3bt2PJkiX45ZdfcOfOHezatQt16tQBAJw/fx5jx47F3LlzcevWLRw4cEDllD0lgdGb2DSR71h9//59teltbW1x8ODBYpRKnyRDEylCIoSUTW/yxag50zif0TfmhsPOSvPXnpOTE6ysrGBnZ6e0mWvu3Llo37699H758uVRr1496f158+Zh586d2L17N0aPHq3yOJGRkejXrx8A4Ntvv8UPP/yAs2fPomPHjkrT5+fnY+XKlQgICADA9d+dO3eu9PEff/wRUVFR6NGjBwDgp59+wr59+zSer6xFixYhMjISI0eOBABMmDABp0+fxqJFi9CmTRskJyfD09MTYWFhsLS0ROXKlaUrWSQnJ6NcuXLo0qULHBwc4OvriwYNGmh1fFNiMqPYygTJ3A0Cf8UQQggxPfJ9X7OzszFp0iTUqFEDzs7OsLe3R2JiosYaJNkBRuXKlYOjo6N0GQ1l7OzspMERwC21IUmfmZmJtLQ03rJb5ubmCA4O1urcEhMT0axZM962Zs2aITExEQDQq1cvvHnzBlWqVMGwYcOwc+dOFBQUAADat28PX19fVKlSBZ999hl+//13vH79WqvjmxKTGMVWdtBkaYSQss3W0hw35hqnP6itpW5mXZYfjTZp0iQcPnwYixYtQmBgIGxtbfHxxx8jLy9PbT6Wlpa8+yKRCIWFhVqlF9psqCs+Pj64desWjhw5gsOHD2PkyJH47rvvcPz4cTg4OODixYuIi4vDoUOHMHPmTMyePRvnzp0rkVMJUA2SUVANEiGkbBKJRLCzsjDKTZsZmK2srFROLizv5MmTiIyMRI8ePVCnTh14enpq7A6ia05OTvDw8MC5c+ek28RiMS5evKhVPjVq1MDJkyd5206ePImaNWtK79va2qJr16744YcfEBcXh/j4eFy9ehUAYGFhgbCwMCxcuBBXrlzB/fv3cfTo0WKcmfFQDZIhURMbIYSUCH5+fjhz5gzu378Pe3t7tUtgVa1aFTt27EDXrl0hEokwY8YMtTVB+jJmzBhER0cjMDAQ1atXx48//oiXL19qFRhOnjwZvXv3RoMGDRAWFoa///4bO3bskI7Ki4mJgVgsRkhICOzs7PDbb7/B1tYWvr6+2LNnD/777z+0bNkSLi4u2LdvHwoLCxEUFKSvU9YrqkEyKOqkTQghJcGkSZNgbm6OmjVrws3NTW1/osWLF8PFxQVNmzZF165dER4ejg8++MCApeVMnToV/fr1w4ABAxAaGgp7e3uEh4fzVprQpHv37li2bBkWLVqEWrVq4ZdffsH69evRunVrAICzszNWr16NZs2aoW7dujhy5Aj+/vtvVKhQAc7OztixYwfatm2LGjVqYOXKlfjjjz9Qq1YtPZ2xfomYoRswS4CsrCw4OTkhMzMTjo6Ousv41I/Aoa+Bun2Anqt0ly8hhJigt2/fIikpCf7+/lp9SRPdKCwsRI0aNdC7d2/MmzfP2MXRGXWvK11+f1MTmzFQTEoIIUTHHjx4gEOHDqFVq1bIzc3FTz/9hKSkJHzyySfGLlqJRE1sBkVNbIQQQvTDzMwMMTExaNSoEZo1a4arV6/iyJEjqFGjhrGLViJRDZIhUSdtQggheuLj46MwAo0UHdUgGRTNg0QIIYSUBBQgGQXVIBFCCCGmjAIkQ6ImNkIIIaREoADJoKiTNiGEEFISUIBkSFrMZkoIIYQQ46EAyRioiY0QQggxaRQgGRQ1sRFCSFnh5+eHpUuXSu+LRCLs2rVLZfr79+9DJBIhISGhWMfVVT6aREZGonv37no9hjHRPEiGRJ20CSGkzEpJSYGLi4tO84yMjERGRgYv8PLx8UFKSgpcXV11eqyyhgIkQgghxAA8PT0Nchxzc3ODHas0oyY2o6AaJEIIMVWrVq2Ct7c3CgsLedu7deuGwYMHAwDu3buHbt26wcPDA/b29mjUqBGOHDmiNl/5JrazZ8+iQYMGsLGxQcOGDXHp0iVeerFYjCFDhsDf3x+2trYICgrCsmXLpI/Pnj0bGzZswF9//QWRSASRSIS4uDilTWzHjx9H48aNYW1tDS8vL0ybNg0FBQXSx1u3bo2xY8diypQpKF++PDw9PTF79mytrltubi7Gjh0Ld3d32NjYoHnz5jh37pz08ZcvX6J///5wc3ODra0tqlativXr1wMA8vLyMHr0aHh5ecHGxga+vr6Ijo7W6vi6RjVIhkRNbISQso4xIP+1cY5taSdoNHGvXr0wZswYHDt2DO3atQMAvHjxAgcOHMC+ffsAANnZ2ejUqRO++eYbWFtbY+PGjejatStu3bqFypUrazxGdnY2unTpgvbt2+O3335DUlISxo0bx0tTWFiISpUqYdu2bahQoQJOnTqFzz//HF5eXujduzcmTZqExMREZGVlSQON8uXL48mTJ7x8Hj9+jE6dOiEyMhIbN27EzZs3MWzYMNjY2PCCoA0bNmDChAk4c+YM4uPjERkZiWbNmqF9+/YazwcApkyZgu3bt2PDhg3w9fXFwoULER4ejrt376J8+fKYMWMGbty4gf3798PV1RV3797FmzdvAAA//PADdu/eja1bt6Jy5cp4+PAhHj58KOi4+kIBkkHRMH9CSBmX/xr41ts4x57+BLAqpzGZi4sLIiIisGnTJmmA9Oeff8LV1RVt2rQBANSrVw/16tWT7jNv3jzs3LkTu3fvxujRozUeY9OmTSgsLMTatWthY2ODWrVq4dGjRxgxYoQ0jaWlJebMmSO97+/vj/j4eGzduhW9e/eGvb09bG1tkZubq7ZJ7eeff4aPjw9++ukniEQiVK9eHU+ePMHUqVMxc+ZMmJlxjUl169bFrFmzAABVq1bFTz/9hNjYWEEBUk5ODlasWIGYmBhEREQAAFavXo3Dhw9j7dq1mDx5MpKTk9GgQQM0bNgQANeJXSI5ORlVq1ZF8+bNIRKJ4Ovrq/GY+kZNbAb08g1XnZmdW6AhJSGEEGPq378/tm/fjtzcXADA77//jr59+0qDiezsbEyaNAk1atSAs7Mz7O3tkZiYiOTkZEH5JyYmom7durCxsZFuCw0NVUi3fPlyBAcHw83NDfb29li1apXgY8geKzQ0FCKZ2rNmzZohOzsbjx49km6rW7cubz8vLy+kp6cLOsa9e/eQn5+PZs2aSbdZWlqicePGSExMBACMGDECmzdvRv369TFlyhScOnVKmjYyMhIJCQkICgrC2LFjcejQIa3OUR+oBsmALj/MQGsA959lo7axC0MIIcZgacfV5Bjr2AJ17doVjDHs3bsXjRo1wj///IMlS5ZIH580aRIOHz6MRYsWITAwELa2tvj444+Rl5ens+Ju3rwZkyZNwvfff4/Q0FA4ODjgu+++w5kzZ3R2DFmWlpa8+yKRSKEfVnFERETgwYMH2LdvHw4fPox27dph1KhRWLRoET744AMkJSVh//79OHLkCHr37o2wsDD8+eefOju+tihAMqR30buIOmkTQsoqkUhQM5ex2djYoGfPnvj9999x9+5dBAUF4YMPPpA+fvLkSURGRqJHjx4AuBql+/fvC86/Ro0a+PXXX/H27VtpLdLp06d5aU6ePImmTZti5MiR0m337t3jpbGysoJYLNZ4rO3bt4MxJq1FOnnyJBwcHFCpUiXBZVYnICAAVlZWOHnypLR5LD8/H+fOncP48eOl6dzc3DBw4EAMHDgQLVq0wOTJk7Fo0SIAgKOjI/r06YM+ffrg448/RseOHfHixQuUL19eJ2XUFjWxGRBT8h8hhBDT1L9/f+zduxfr1q1D//79eY9VrVoVO3bsQEJCAi5fvoxPPvlEq9qWTz75BCKRCMOGDcONGzewb98+aaAge4zz58/j4MGDuH37NmbMmMEbFQZw/XiuXLmCW7du4dmzZ8jPz1c41siRI/Hw4UOMGTMGN2/exF9//YVZs2ZhwoQJ0ibD4ipXrhxGjBiByZMn48CBA7hx4waGDRuG169fY8iQIQCAmTNn4q+//sLdu3dx/fp17NmzBzVq1AAALF68GH/88Qdu3ryJ27dvY9u2bfD09ISzs7NOylcUFCAZkEhyuSk+IoQQk9e2bVuUL18et27dwieffMJ7bPHixXBxcUHTpk3RtWtXhIeH82qYNLG3t8fff/+Nq1evokGDBvjqq6+wYMECXprhw4ejZ8+e6NOnD0JCQvD8+XNebRIADBs2DEFBQWjYsCHc3Nxw8uRJhWNVrFgR+/btw9mzZ1GvXj188cUXGDJkCL7++mstroZm8+fPx0cffYTPPvsMH3zwAe7evYuDBw9KJ8e0srJCVFQU6tati5YtW8Lc3BybN28GADg4OGDhwoVo2LAhGjVqhPv372Pfvn06C+CKQsQYjTmXl5WVBScnJ2RmZsLR0VFn+cb9sQitb83DdftQ1Jp0QGf5EkKIKXr79i2SkpLg7+/P64xMSHGoe13p8vubapAMiob5E0IIISUBBUgGJBlhKaJKO0IIIcSkUYBkUHS5CSGEkJKAvrGNgmqQCCGEEFNGAZIhSWcxpQCJEFJ20FggokuGej1RgGRI1EebEFKGSGZmfv3aSIvTklJJ8nqSn/lb14w6k3Z0dDR27NiBmzdvwtbWFk2bNsWCBQsQFBSkdr9t27ZhxowZuH//PqpWrYoFCxagU6dO0scZY5g1axZWr16NjIwMNGvWDCtWrEDVqlX1fUoavIuQ6NcUIaQMMDc3h7Ozs3Q9Lzs7O956YIRogzGG169fIz09Hc7OzjA3N9fr8YwaIB0/fhyjRo1Co0aNUFBQgOnTp6NDhw64ceMGypVTPhX9qVOn0K9fP0RHR6NLly7YtGkTunfvjosXL6J2bW6Fs4ULF+KHH37Ahg0b4O/vjxkzZiA8PBw3btww6lwcItBSI4SQskWyyrzQRU8J0cTZ2Vn6utInk5oo8unTp3B3d8fx48fRsmVLpWn69OmDnJwc7NmzR7qtSZMmqF+/PlauXAnGGLy9vTFx4kRMmjQJAJCZmQkPDw/ExMSgb9++Gsuhr4kiT2z7ES2vf41Eu4aoMSVWZ/kSQoipE4vFSpfBIEQblpaWamuOdPn9bVKL1WZmZgKA2oXp4uPjMWHCBN628PBw7Nq1CwCQlJSE1NRUhIWFSR93cnJCSEgI4uPjlQZIubm5yM3Nld7PysoqzmmoRlXLhJAyytzcXO9NIoToksl00i4sLMT48ePRrFkzaVOZMqmpqfDw8OBt8/DwQGpqqvRxyTZVaeRFR0fDyclJevPx8SnOqWhmOpV2hBBCCFHCZAKkUaNG4dq1a9KF6wwpKioKmZmZ0tvDhw/1cyAR9UEihBBCSgKTaGIbPXo09uzZgxMnTqBSpUpq03p6eiItLY23LS0tTdphS/I3LS0NXl5evDT169dXmqe1tTWsra2LcQbCiEDzIBFCCCElgVFrkBhjGD16NHbu3ImjR4/C399f4z6hoaGIjeV3cD58+DBCQ0MBAP7+/vD09OSlycrKwpkzZ6RpjIb6IBFCCCElglFrkEaNGoVNmzbhr7/+goODg7SPkJOTE2xtbQEAAwYMQMWKFREdHQ0AGDduHFq1aoXvv/8enTt3xubNm3H+/HmsWrUKACASiTB+/Hj873//Q9WqVaXD/L29vdG9e3ejnKcC6oNECCGEmDSjBkgrVqwAALRu3Zq3ff369YiMjAQAJCcnw8zsfUVX06ZNsWnTJnz99deYPn06qlatil27dvE6dk+ZMgU5OTn4/PPPkZGRgebNm+PAgQNGnQMJAPVBIoQQQkoIk5oHyVToax6kf3b+ghaXp+CWTT0ETTuhs3wJIYQQotvvb5MZxVYmUB8kQgghpESgAMmA3odHVGlHCCGEmDIKkAxJ0geJWjUJIYQQk0YBkkHRPEiEEEJISUABkgGJqA8SIYQQUiJQgGRQNMyfEEIIKQkoQDIKCpAIIYQQU0YBkiFRExshhBBSIlCAZEiSAIkqkAghhBCTRgGSAYmoDxIhhBBSIlCAZEgiGuZPCCGElAQUIBmQJD6iGiRCCCHEtFGAZEjUSZsQQggpEShAMgaqQCKEEEJMGgVIBiW53BQhEUIIIaaMAiQDkiw1Qn2QCCGEENNGAZIBUVhECCGElAwUIBmQiIb5E0IIISUCBUgGRBNFEkIIISUDBUgGxGipEUIIIaREoADJgEQ0DxIhhBBSIlCAZATUxEYIIYSYNgqQDIg6aRNCCCElAwVIBsUFSOaswMjlIIQQQog6FCAZkHlhLgDAR/zQyCUhhBBCiDoUIBmQY8ZNYxeBEEIIIQJQgEQIIYQQIocCJEOiYf6EEEJIiUABkiFRgEQIIYSUCBQgGZBkqRFCCCGEmDYKkAghhBBC5FCAZEjUxEYIIYSUCEYNkE6cOIGuXbvC29sbIpEIu3btUps+MjISIpFI4VarVi1pmtmzZys8Xr16dT2fiUAUIBFCCCElglEDpJycHNSrVw/Lly8XlH7ZsmVISUmR3h4+fIjy5cujV69evHS1atXipfv333/1UXyt8fogMVpuhBBCCDFVFsY8eEREBCIiIgSnd3JygpOTk/T+rl278PLlSwwaNIiXzsLCAp6enjorp87IViAxRjVKhBBCiIkq0X2Q1q5di7CwMPj6+vK237lzB97e3qhSpQr69++P5ORkI5WQz0wke7mpBokQQggxVUatQSqOJ0+eYP/+/di0aRNve0hICGJiYhAUFISUlBTMmTMHLVq0wLVr1+Dg4KA0r9zcXOTm5krvZ2Vl6aXMIvkaJEIIIYSYpBIbIG3YsAHOzs7o3r07b7tsk13dunUREhICX19fbN26FUOGDFGaV3R0NObMmaPP4gIARPwISe/HI4QQQkjRlMgmNsYY1q1bh88++wxWVlZq0zo7O6NatWq4e/euyjRRUVHIzMyU3h4+fKjrIgOQC5CoBokQQggxWSUyQDp+/Dju3r2rskZIVnZ2Nu7duwcvLy+VaaytreHo6Mi76YOIOmUTQgghJYJRA6Ts7GwkJCQgISEBAJCUlISEhARpp+qoqCgMGDBAYb+1a9ciJCQEtWvXVnhs0qRJOH78OO7fv49Tp06hR48eMDc3R79+/fR6LkJQExshhBBSMhi1D9L58+fRpk0b6f0JEyYAAAYOHIiYmBikpKQojEDLzMzE9u3bsWzZMqV5Pnr0CP369cPz58/h5uaG5s2b4/Tp03Bzc9PfiQhkRp20CSGEkBLBqAFS69atwdQECjExMQrbnJyc8Pr1a5X7bN68WRdF0wsRaJg/IYQQUhKUyD5IJZVItgopO914BSGEEEKIWhQgGRCvC9Kjc0YrByGEEELUowDJgGgUGyGEEFIyUIBkQGInv/d3RHTpCSGEEFNF39IG9LZyy/d3qDaJEEIIMVkUIBmQmZns5aYAiRBCCDFVFCAZkBk1qxFCCCElAn1jG5CZ7DB/CpYIIYQQk0Xf0gbEm0nbXP0iu4QQQggxHgqQDMjc0ub9HUdv4xWEEEIIIWrpJEDKyMjQRTalnpmZCKnMBQDAWKGRS0MIIYQQVbQOkBYsWIAtW7ZI7/fu3RsVKlRAxYoVcfnyZZ0WrrQxE4nA3o1eU7cGHSGEEEKMS+sAaeXKlfDx8QEAHD58GIcPH8b+/fsRERGByZMn67yApYm5SCRdolZMARIhhBBisiy03SE1NVUaIO3Zswe9e/dGhw4d4Ofnh5CQEJ0XsDQRmeF9DVIhNbERQgghpkrrGiQXFxc8fPgQAHDgwAGEhYUB4JqMxGKxbktXypjLNLEVFlINEiGEEGKqtK5B6tmzJz755BNUrVoVz58/R0REBADg0qVLCAwM1HkBSxNzmXH+1EmbEEIIMV1a1yAtWbIEo0ePRs2aNXH48GHY29sDAFJSUjBy5EidF7A0EYkAxrggyfLoLODGbiOXiBBCCCHKiBgNp1KQlZUFJycnZGZmwtHRUWf5FogL8WRONVQ2e/p+4+xMneVPCCGElGW6/P7WugZpw4YN2Lt3r/T+lClT4OzsjKZNm+LBgwfFKkxpZyYS8YMjQgghhJgkrQOkb7/9Fra2tgCA+Ph4LF++HAsXLoSrqyu+/PJLnRewNOGtxUYIIYQQk6V1J+2HDx9KO2Pv2rULH330ET7//HM0a9YMrVu31nX5CCGEEEIMTusaJHt7ezx//hwAcOjQIbRv3x4AYGNjgzdv3ui2dIQQQgghRqB1DVL79u0xdOhQNGjQALdv30anTp0AANevX4efn5+uy0cIIYQQYnBa1yAtX74coaGhePr0KbZv344KFSoAAC5cuIB+/frpvICEEEIIIYZGw/yV0NcwfwDAbCe5+zTMnxBCCNEFXX5/a93EBgAZGRlYu3YtEhMTAQC1atXC4MGD4eTkpGFPQgghhBDTp3UT2/nz5xEQEIAlS5bgxYsXePHiBRYvXoyAgABcvHhRH2UkhBBCCDEorWuQvvzyS3z44YdYvXo1LCy43QsKCjB06FCMHz8eJ06c0HkhCSGEEEIMSesA6fz587zgCAAsLCwwZcoUNGzYUKeFI4QQQggxBq2b2BwdHZGcnKyw/eHDh3BwcNBJoQghhBBCjEnrAKlPnz4YMmQItmzZgocPH+Lhw4fYvHkzhg4dSsP8CSGEEFIqaN3EtmjRIohEIgwYMAAFBQUAAEtLS4wYMQLz58/XeQEJIYQQQgytyPMgvX79Gvfu3QMABAQEwM7OTqcFMyaaB4kQQggpeXT5/a11E5uEnZ0d6tSpgzp16hQ5ODpx4gS6du0Kb29viEQi7Nq1S236uLg4iEQihVtqaiov3fLly+Hn5wcbGxuEhITg7NmzRSofIYQQQsomQU1sPXv2FJzhjh07BKfNyclBvXr1MHjwYK2OcevWLV5k6O7uLv1/y5YtmDBhAlauXImQkBAsXboU4eHhuHXrFi8dIYQQQogqggIkfc2QHRERgYiICK33c3d3h7Ozs9LHFi9ejGHDhmHQoEEAgJUrV2Lv3r1Yt24dpk2bVpziEkIIIaSMEBQgrV+/Xt/l0Er9+vWRm5uL2rVrY/bs2WjWrBkAIC8vDxcuXEBUVJQ0rZmZGcLCwhAfH2+s4hJCCCGkhClyHyRj8PLywsqVK7F9+3Zs374dPj4+aN26tXSJk2fPnkEsFsPDw4O3n4eHh0I/JVm5ubnIysri3QghhBBSdhVpsVpjCQoKQlBQkPR+06ZNce/ePSxZsgS//vprkfONjo7GnDlzdFFEQgghhJQCJaoGSZnGjRvj7t27AABXV1eYm5sjLS2NlyYtLQ2enp4q84iKikJmZqb09vDhQ72WmRBCCCGmrcQHSAkJCfDy8gIAWFlZITg4GLGxsdLHCwsLERsbi9DQUJV5WFtbw9HRkXcjhBBCSNll1Ca27Oxsae0PACQlJSEhIQHly5dH5cqVERUVhcePH2Pjxo0AgKVLl8Lf3x+1atXC27dvsWbNGhw9ehSHDh2S5jFhwgQMHDgQDRs2ROPGjbF06VLk5ORIR7URQgghhGhSpAApNjYWsbGxSE9PR2FhIe+xdevWCc7n/PnzaNOmjfT+hAkTAAADBw5ETEwMUlJSeAvj5uXlYeLEiXj8+DHs7OxQt25dHDlyhJdHnz598PTpU8ycOROpqamoX78+Dhw4oNBxmxBCCCFEFa2XGpkzZw7mzp2Lhg0bwsvLCyKRiPf4zp07dVpAY6ClRgghhJCSR5ff31rXIK1cuRIxMTH47LPPinVgQgghhBBTpXUn7by8PDRt2lQfZSGEEEIIMQlaB0hDhw7Fpk2b9FEWQgghhBCTIKiJTdJ5GuCGza9atQpHjhxB3bp1YWlpyUu7ePFi3ZaQEEIIIcTABAVIly5d4t2vX78+AODatWu87fIdtgkhhBBCSiJBAdKxY8f0XQ5CCCGEEJOhdR+kzMxMvHjxQmH7ixcvaJHXosjLMXYJCCGEECJH6wCpb9++2Lx5s8L2rVu3om/fvjopVJnyloJKQgghxNRoHSCdOXOGN3O1ROvWrXHmzBmdFIoQQgghxJi0DpByc3NRUFCgsD0/Px9v3rzRSaFKtXqfGLsEhBBCCNFA6wCpcePGWLVqlcL2lStXIjg4WCeFKtWqtjd2CQghhBCigdZLjfzvf/9DWFgYLl++jHbt2gHgFq89d+4cDh06pPMClj7yS99ptRQeIYQQQgxA6xqkZs2aIT4+Hj4+Pti6dSv+/vtvBAYG4sqVK2jRooU+yli6yK8NrN1awYQQQggxAK1rkABuosjff/9d12Upk1ji3xA1+cLYxSCEEEKIDK1rkMzNzZGenq6w/fnz5zA3N9dJoUo1+RqjxL+NUw5CCCGEqKR1gMRUNAnl5ubCysqq2AUq9Vgh/66RikEIIYQQ1QQ3sf3www8AuPXW1qxZA3t7e+ljYrEYJ06cQPXq1XVfwlKHqblHCCGEEFMgOEBasmQJAK4GaeXKlbzmNCsrK/j5+WHlypW6L2Fpo9BJ2zjFIIQQQohqggOkpKQkAECbNm2wY8cOuLi46K1QpRo1sRFCCCEmT+tRbMeOHdNHOcoQmgeJEEIIMXVFGub/6NEj7N69G8nJycjLy+M9tnjxYp0UrNSSa2KjaZAIIYQQ06N1gBQbG4sPP/wQVapUwc2bN1G7dm3cv38fjDF88MEH+ihjKcOPiCyenAPOrQWqhQNOlYxUJkIIIYTI0nqYf1RUFCZNmoSrV6/CxsYG27dvx8OHD9GqVSv06tVLH2UsXeSqjETiPGDvBGBJLSAvx0iFIoQQQogsrQOkxMREDBgwAABgYWGBN2/ewN7eHnPnzsWCBQt0XsBSR66TNs8PDQxXDkIIIYSopHWAVK5cOWm/Iy8vL9y7d0/62LNnz3RXslJLTaej7DTDFYMQQgghKmndB6lJkyb4999/UaNGDXTq1AkTJ07E1atXsWPHDjRp0kQfZSxdqFc2IYQQYvK0DpAWL16M7OxsAMCcOXOQnZ2NLVu2oGrVqjSCTRAKkAghhBBTp3WAVKVKFen/5cqVo9mztUU1SIQQQojJK9I8SABw/vx5JCYmAgBq1qyJ4OBgnRWqVKva3tglIIQQQogGWgdIjx49Qr9+/XDy5Ek4OzsDADIyMtC0aVNs3rwZlSrRXD5qufgZuwSEEEII0UDrUWxDhw5Ffn4+EhMT8eLFC7x48QKJiYkoLCzE0KFD9VFGQgghhBCD0roG6fjx4zh16hSCgoKk24KCgvDjjz+iRYsWOi0cIYQQQogxaF2D5OPjg/z8fIXtYrEY3t7eOilUaZdiXUVzIgDIeQYU5Oq3MIQQQghRoHWA9N1332HMmDE4f/68dNv58+cxbtw4LFq0SKu8Tpw4ga5du8Lb2xsikQi7du1Sm37Hjh1o37493Nzc4OjoiNDQUBw8eJCXZvbs2RCJRLxb9erVtSqXvhW2nKI5UeYj4LsAYFl9vZeHEEIIIXyCmthcXFwgEomk93NychASEgILC273goICWFhYYPDgwejevbvgg+fk5KBevXoYPHgwevbsqTH9iRMn0L59e3z77bdwdnbG+vXr0bVrV5w5cwYNGrxfpqNWrVo4cuSI9L6knKaiYkUf1Q/OduL+RnzH/X31RP8FIoQQQgiPoMhh6dKlejl4REQEIiIiBKeXL8e3336Lv/76C3///TcvQLKwsICnp6euiql7QuZCStyt/3IQQgghRClBAdLAgQP1XY4iKSwsxKtXr1C+fHne9jt37sDb2xs2NjYIDQ1FdHQ0KleubKRSFpG6RW0JIYQQolda90GS1blzZ6SkpOiqLFpbtGgRsrOz0bt3b+m2kJAQxMTE4MCBA1ixYgWSkpLQokULvHr1SmU+ubm5yMrK4t30S8hs2iLNSQghhBCiF8XqnHPixAm8efNGV2XRyqZNmzBnzhz89ddfcHd3l26XbbKrW7cuQkJC4Ovri61bt2LIkCFK84qOjsacOXP0XmZCCCGElAzFqkEyls2bN2Po0KHYunUrwsLC1KZ1dnZGtWrVcPfuXZVpoqKikJmZKb09fPhQ10Xmq1BVcxoR1SARQgghxlKsAMnX1xeWlpa6Kosgf/zxBwYNGoQ//vgDnTt31pg+Ozsb9+7dg5eXl8o01tbWcHR05N30ylF1WQghhBBifMVqYrt27VqxDp6dnc2r2UlKSkJCQgLKly+PypUrIyoqCo8fP8bGjRsBcM1qAwcOxLJlyxASEoLU1FQAgK2tLZycuOHxkyZNQteuXeHr64snT55g1qxZMDc3R79+/YpVVkIIIYSUHYICpCtXrqB27dowMzPDlStX1KatW7eu4IOfP38ebdq0kd6fMGECAG7UXExMDFJSUpCcnCx9fNWqVSgoKMCoUaMwatQo6XZJeuD9YrrPnz+Hm5sbmjdvjtOnT8PNzU1wuUwCNbERQgghRiNiTPOkPGZmZkhNTYW7uzvMzMwgEokgu5vkvkgkglgs1muBDSErKwtOTk7IzMzUX3ObZEJIVfxbAUnH36XN1E8ZCCGEkFJEl9/fgmqQkpKSpDUwSUlJxTogIYQQQoipExQg+fr6Kv2f6BE1sRFCCCFGU6RO2nfu3MGxY8eQnp6OwkL+jM8zZ87UScEIBUiEEEKIsWgdIK1evRojRoyAq6srPD09eYvYikQiCpAIIYQQUuJpHSD973//wzfffIOpU6fqozxEgprYCCGEEKPReqLIly9folevXvooCyGEEEKISdA6QOrVqxcOHTqkj7IQHqpBIoQQQoxF6ya2wMBAzJgxA6dPn0adOnUUlhoZO3aszgpXplETGyGEEGI0giaKlOXv7686M5EI//33X7ELZWwmMVFkYBhw98i7tDRRJCGEEKKJwSeKlEUTRRoK1SARQgghxqJ1HyRiINTERgghhBiNoBqkCRMmYN68eShXrpx0QVlVFi9erJOCEQqQCCGEEGMRFCBdunQJ+fn50v9VEVGth+7cOfj+/9xswNreeGUhhBBCyhhBAdKxY8eU/k8Mg2WnQ0QBEiGEEGIw1AepBJjz93VjF4EQQggpU7Qexfb27Vv8+OOPKhervXjxos4KRzjHbqVjtrELQQghhJQhWgdIQ4YMwaFDh/Dxxx+jcePG1O+IEEIIIaWO1gHSnj17sG/fPjRr1kwf5SGEEEIIMTqt+yBVrFgRDg4O+igLIYQQQohJ0DpA+v777zF16lQ8ePBAH+UpO4Ye1X6fRxeAV2m6LwshhBBCeLRuYmvYsCHevn2LKlWqwM7OTmGx2hcvXuiscKVapWDBSV2RicwFteD05hG3gdZmI4QQQvRK6wCpX79+ePz4Mb799lt4eHhQJ20D2G49B3hj7FIQQgghZYfWAdKpU6cQHx+PevXq6aM8hBBCCCFGp3UfpOrVq+PNG6rOIIQQQkjppXWANH/+fEycOBFxcXF4/vw5srKyeDdCCCGEkJJO6ya2jh07AgDatWvH284Yg0gkglgs1k3JCCGEEEKMROsAiRarNUGp1wBLW6BCgLFLQgghhJQKWgdIrVq10kc5SFG9fgGsfDerOQ3/J4QQQnRC6z5IxPje5mQBme/mRMp6bNzCEN3LegKkXDF2KQghpEzTugaJGJ/Vj3WAtxnA6AvAls+MXRyia4trcH/HXgLKVzFuWQghpIyiGqQSyOxtBvfPwSjgZZLmHc6sAm4f1GuZiB6kXDZ2CQghpMyiGqSSLF9uPirGAPmZzR9fBPZP5v6nPkqEEEKIIFSDVJLJB0OMKaZ5lWKYshBCCCGliM4CpOnTp2Pw4MFa7XPixAl07doV3t7eEIlE2LVrl8Z94uLi8MEHH8Da2hqBgYGIiYlRSLN8+XL4+fnBxsYGISEhOHv2rFblKjloHTxCCCFEH3QWID1+/Bj379/Xap+cnBzUq1cPy5cvF5Q+KSkJnTt3Rps2bZCQkIDx48dj6NChOHjwff+aLVu2YMKECZg1axYuXryIevXqITw8HOnp6VqVzSA6Ly7e/iL5p09JDRIhhBBCtKazPkgbNmzQep+IiAhEREQITr9y5Ur4+/vj+++/BwDUqFED//77L5YsWYLw8HAAwOLFizFs2DAMGjRIus/evXuxbt06TJs2Tesy6lW1cGBvMfZ/KFczlpcNrOsI+LcEIhYIz4cx4OB0wMUfCPm8GAUihBBCSocS1QcpPj4eYWFhvG3h4eGIj48HAOTl5eHChQu8NGZmZggLC5OmUSY3N9dIa8oVs4ksP4d//85hIP0GcGaldsd4fAE4/fP7ztym4PIW4Oqfxi6FcSnrU0YIIcQgtK5B+uGHH5RuF4lEsLGxQWBgIFq2bAlzc/NiF05eamoqPDw8eNs8PDyQlZWFN2/e4OXLlxCLxUrT3Lx5U2W+0dHRmDNnjs7La2iFEBUt4s01sUWG37wEdr6ryaremVtGhRBCCDEgrQOkJUuW4OnTp3j9+jVcXFwAAC9fvoSdnR3s7e2Rnp6OKlWq4NixY/Dx8dF5gfUhKioKEyZMkN7PysoqMWWX9cfBE+gvuZOeyNUKsULdZM4YsONzwKkSEDareHndOwpY2AC+TZU/nidTMybOUx0gJf7NnV/NbsUrjxB5r7my2Drr/1gS8qMUCSGEGIzWFQ7ffvstGjVqhDt37uD58+d4/vw5bt++jZCQECxbtgzJycnw9PTEl19+qfPCenp6Ii0tjbctLS0Njo6OsLW1haurK8zNzZWm8fT0VJmvtbU1HB0deTeD0PEXYP/smPd3VrUBLm4ELv2mm8yfXAKubgX+LWbH8tcvgF97AOsjgEJx0fPJywG2fApsHQC8NcD8Tgv8gAW+QO4r/R/L1DxJAC7EUJMfIaRM0TpA+vrrr7FkyRIEBLxfOT4wMBCLFi1CVFQUKlWqhIULF+LkyZM6LSgAhIaGIjY2lrft8OHDCA0NBQBYWVkhODiYl6awsBCxsbHSNGVGwRvNaaQEBGrivCIXhef18/f/F6d2qyD3/f95r4uej1Did8d7ekv/xzI1q1oBf4/jauyKgzHFyU0JIcREaR0gpaSkoKCgQGF7QUEBUlNTAQDe3t549UrzL+3s7GwkJCQgISEBADeMPyEhAcnJyQC4pq8BAwZI03/xxRf477//MGXKFNy8eRM///wztm7dyqutmjBhAlavXo0NGzYgMTERI0aMQE5OjnRUm2kxcBOKITo9P7sLZDzU/3F4SlDNxrk1wP6pJbM2Jv2G4rb/jr9fOFmTHZ8D33gCz+/ptlxlCWPAqzTN6QghxaZ1gNSmTRsMHz4cly5dkm67dOkSRowYgbZt2wIArl69Cn9/f415nT9/Hg0aNECDBg0AcMFNgwYNMHPmTABcMCYJlgDA398fe/fuxeHDh1GvXj18//33WLNmjXSIPwD06dMHixYtwsyZM1G/fn0kJCTgwIEDCh23TYK1vWGPt32IbvPLfgpc3wWI3wXMb14CPwUDS2vr9jjKCG2evLABOL1SczpD2TuRG2WYrHpUZYmRdALY+CGwpJaw9Fe3cn/PmNDzUdIc+hr4vhpw8Vdjl4SQUk/rTtpr167FZ599huDgYFhaWgLgao/atWuHtWvXAgDs7e2lcxWp07p1azA1v6SVzZLdunVrXnCmzOjRozF69GiNxzc6awfAxhmQLD5b0iwKfPePCJidAWQkK6YpyAXMLAAz3Y9qlFL1GhLnA3+P5f6v1QNw0HOQfGUbkPUIaC6g/52Qvkzy51WQB5xeDgSGAZ51ilZGXbr/r7FLUPbE/8T9PfQV8MFnxi0LIaWc1gGSp6cnDh8+jJs3b+L27dsAgKCgIAQFBUnTtGnTRnclLO0C2gLXdxi7FMXEgIRN3Ag3WXmvgYVVgPJVgJGnlOxWnGYmATVIsn2c5OeMKiwEUhIA95qApU0xyiFjx1Dur5AApijnfno5cGQ2d6OFh8sWcT5oaSFCDEvrAOnff/9F8+bNUb16dVSvXl0fZSIl0a4RgF0F/rbH57nO4unXZTbq6ENe2xGA8gHJmZXAwSggoB3wmY4D1DcvdZOP/DmmXNZNvkS4/LfAs9tcwGusaRcKxcDSOoBIj7WwhBAFWvdBatu2Lfz9/TF9+nTcuKGk0yYppQR8OciOUFO5jz46Jxchz7O/cH/vxapPVxRCaodojqOS4dcewC8tuBpSY8lOA16lcM23hBCD0TpAevLkCSZOnIjjx4+jdu3aqF+/Pr777js8ekRv3qIx7GgmxhjXl0V2JJHsTNr35aZneHyB6+RclCH59/8pWiG1VaSAxMgBipAyl8SRbqVN8rum4QvrjVsObWQ+Bv5ZzM05ZgpO/QSc+cXYpSBEa1oHSK6urhg9ejROnjyJe/fuoVevXtiwYQP8/Pyko9iI6fr4fxuQs7Id8OMHwK393Mat76dSQEwnrllBYnVb4MBU4Oo27Q5UkAscX8C/fzdWh/PgFLOJTdvHtUG1Q0SntHw9xXQCYudwzd7GlvOc61C+f4ph5isjRIeKtVitv78/pk2bhvnz56NOnTo4fvy4rspVhhj2y3S7eBzKPbvC3bkQozyROFdxm7YTJBa85d8/EAX81hPY+YXMRl0FJe/yEedzsz4Xalnbtbk/sC5c+/1UFkdH50WBlnbE+cCGD7lO7KWemtfGy/vc33tHDVIStWQnrC1UnD9P6vJmIOEP/ZeHEC0UOUA6efIkRo4cCS8vL3zyySeoXbs29u7dq8uylREm2oxy9U9gTXuZDXLlzM3WkIHcB/h5bgoIfodtFYRMJCgbPEgCkh2fc7M+C1kORXb/m3uAh2eAp4ma9zMkdYHWo/PA5S3C88p5prvO41Iy1/DKNmBbpHFnyr59EEg6Dvy7hHstXN9pvLLonYl+biiQ/RxQUebcbGDncGDXF4ZZNogQgbQOkKKiouDv74+2bdsiOTkZy5YtQ2pqKn799Vd07NhRH2Uk+qLuC3j7EODR2ff3H8j0TRLnA9EV9VeuTb01p1FWdsl0Cad+eLehFNfArGkH7PwcSD6tOW1eDvBdALeenE77NcnktWMoF5AYs6+JbM3nlS1cwFaS5L7imqHF+fo/1vN7wP5pXH8lfRJSCyq7jFH+W9XpCDEwrQOkEydOYPLkyXj8+DH27NmDfv36wc7OTh9lI/p256CKBzR8qCmMVlOWhZB5iuS+rLOeAPum8JvnGOOq3tPUjZhU9aWvLhgoJcHT87ua06hbCqQgD8hO11153hioY3Bxm0PfZgK/tAT+0TyhrcH83ptrhpbtuweoeC8V8/W7riNwZgWwpX/x8tGGoOC8pNSMkbJA6wBJ0rTm6uqqj/IQU6ApuNk6UHMeRamp2Bb5fvi9ROLfXNX7CjWLDRflWIbu3/M2S/tyFqWMBXnA8YXAowvvt6k77opQYFFVA6+PVsxrHzcf+K4K8OK/oudxdhU3r1Ts3OKVRZckI+Yu/ab/Y+W8C4qfqF+VQKXUa8ADJZO/KhDQxCbU1T8Nc22EenkfeHzR2KUgeqT1RJESN27cQHJyMvLy+Ku8f/jhh8UuFDGcxJvXUUPbnR4KaNYRIi8H+HMQUONDoH4/bkoBeSkJKnbWwy9NfQ2rf3AKWB8BBEdqt59CeQQEFmd/AY59w91mPAfyXkHttZLUQN3cAzQbp135iqyY1zkumvt79H/Ax+uKlkdBnuY0Qv13nAu4On0HOHrrLl8pE6ztXNmM+zshUf056+qHiDj//VqS1ToC5VT8QC8sBMD0u7SRxLJ63N9xVwAXX/0fjxic1gHSf//9hx49euDq1asQiUTStdRE794IYrFYtyUkelVjc1PFjcX5ZS4h5IMx/ifg1j7ulnwKSr8IClW8niQjdZSRfP+qDXh0+KXzJgOwcVL9uOQLXdWoQQDISgE2fwI0GqrmQAICi3SZjua/tADSbwD9t8tkwXRYe2ZqX9xalEeXNYgb3/0oFOcB/eWmwzj1E/faKK3rpmU8FB4Uqno/KhtwIU92BFzuK9UB0uo2XBeAsZcAc0th5Squ9MTiBUj/LgEengV6/wqYF7nOguiB1k1s48aNg7+/P9LT02FnZ4fr16/jxIkTaNiwIeLi4vRQRGJwv7Qsfh7qhvRKyPZXubgRKFTWOVXFB+b6zprTKJRJrPtRVveOAgt8gT2yC9TKlUdIzdThGcCTi8BfI99vK+6XePq7flu39hUvH53TV2ClTc2UtmUQkD7rCf/+ywfcHEC7S8DC2Xoj5Dprm0bN85ySAGQ+5JaHKSmOzObeozf/NnZJiBytA6T4+HjMnTsXrq6uMDMzg5mZGZo3b47o6GiMHTtWH2UkJdG5tZrTFKdJK++V9vusaAp848X9AtVVDcLR/3F/izvTcq6S8ylKE5tSptbxVa484nxgy6eGHQEn+/w/iBewzl0RrqHsDPXFIfS1GjsPODRDN8cEgJQrwL1jxXuf8mqHhHSsF1DLJISpzEKf+Zibm02Iok6kmXYDiF8OnF3N9eNU13xckAe8SivacWRd2MDNOaZpWgZTeR6KSOsASSwWw8HBAQA3q/aTJ9yvJl9fX9y6peVkgqT0SrsmIJGQ5TbkPlRfvwCOfSuXRuAotqc3uW2PzkGrYOPiRjXlK8YHwL2j3CgqwXno4sNGRR7G/CC7uo3rjL9/SjEzUvKcvkjSnHZ9R93UmhpTbjbwzyKZKS6K6fULron21+4aRvpp8bo5OF35dl0FP0Z7Das57pKa3NxsxR0EUShW/iMK4AZaHJwO7JvETbVxWc2Em7+0AL6vpv3Ev/L+HsvNOXZymeo0xxcCi2vofyoJPdI6QKpduzYuX+Z+bYWEhGDhwoU4efIk5s6diypVqui8gKSEEvJrUVAauQ+fXSMVh0FrS+gHKWNczcLuMdof420WcHMft8SKKr/24EZRSZZ8MXW5r1T3CdOK3Beiqg9+XTj0tYoi6KGJTUJXM7Jrg+m472fmw/f/H52nmzyvaDGxabEVM1hKuQL8F6eTknD5aaqhBNSWeU0YEF2J66uoibpanac3ub/XdwkojxKFYiAjWeZYampJj33DLbIs6YNZAmndI+zrr79GTk4OAGDu3Lno0qULWrRogQoVKmDLFkO+AUoh91rCZpouCYR8kRZlXpQHJ5Un04cL6+X6FmlhU28gOR5oMkpz2s39lG8v0gK7StKous6ynfGFdqpPjgd6rlZTMyMn/w2wqQ8QGCYsva6pDMIFnG9ejmxGwo73/B43iWeTkUBQhMzuuuwcD+3yynsNWNpy/Vys7IEqrYQcQFje59dxfa3q9eHuF/c8lb1WGeNPJqnNvsrkZnP52ZVXneaXFtxfISPU9FlzlfAHcHkT1z8R4EabNh6mg4yLWOatA7gyaHWoktvMpnWAFB4eLv0/MDAQN2/exIsXL+Di4iIdyUaKqPl4YIcuXvwm4P6/uslH9s2Vdl15529lb8D8t6rfmPLrxKny7xJh6ZRJjuf+JvwGeNYtWh46+2CRyUc2z7+LMKz/8QVuoWMAqNJGc/qLv3JV8Ulq1mnU1WtFG0I+qi5seP//m5fcL3N1oxUB4MgsLu2xb/gBUrEUMTAW53Gjo9a2B7wbvJ/zaLaGfiP3jinO0P7wLFfT2WoqYGnzfvuVLdytzsdcP5j45cDgA0B5/+KVXdbGbvzXiJD3hbo0klUApj0EbBz5jxXkcs2LEi/vaw6Qnt/RXB5B3QmUpNn1heI2XRxLnROLgGs7gEF7AVsX/mMKwVHJDX6EKNZitRLly5en4EgXRDp5OkzD2wzNabT9oFvRFMhX1pGRcXPRSORmAt94qG4f3/wJ8ExDG/yR2fyqZFlXtgGHZxnulxFj3IK6kqVUdIVXQ1IEkl+16uQLOEbi7uKVo0gEfF7JBtLP7wLzK/Obzy79Jrx5NOOB+qbENxn8+4wBN/dyw+iL89m69t16irITQiqbWf3OEWBlc65p6dfuwPH5ivn8uxg49aPy4zDGjcTMTuX+SmhddiXvqaTjApsQtXw/KuuHs7wxsLi6dnkenqm4TbI2oVZ09Hmi7HMpO134a/XoPK4l49RPRTuWYiJhxzVBNOmCsbWeDiTuAZoU5ZdCCaerfkrA+xobWfIf8kK8SuNqANTVHu14N1eRkKaK/LfA/X+0L4esnGfaV2vLUvkhJmD+GbX5KtlW3AVxs54AtuX5tRT6IOSLW1kaJgZgxjVP/qWk+VTVdVxWD7C0A75S0YfkzmHZA3PB8J+DubuTlXTwlW/C1iYQWVJLcdvvH3F//+irft+LG4DmGpqdi/PDoahfuHmv5ZZAKmI+8vOrKSvP0f9pXgh5h9x8Zrr6MVXUfJaHaF4GSFzA73smVtN/soygAMnY3KoBX6VyE4Rd/dPYpTGsK5sFJCpmdbq2vq8mPO3rF1BaPtny6ORDRs35MQbcPsRdy84C1hVLOg4EtuP+L3aNpZJyKXQi1bIGYXENwLEiMEHF2nvyHVDTE7naF181S9FIFIq5X/u+TbUvl7ycZ9rvo7T28x1egMOApBMyd5VcZ3E+V+vz3zEgbLb2ZVFFviZLXuZDrhlRgUwZeeei4TrfPgikXhFYODUW19Bca/3yPr9W+N8lQD81I74AKH2Nn/hOy8KpcG4NcGWrzKH00KQuIR8cKTvWpt7AvdjiH0shCdUgkeKQzJ5qiOnxSxqhNUi6eBNKOmYKVZxV17N1MBcJwF2fTb24/22cNae/fUAmQJL58ipKM46+PviyHgMbunIzC9s68x/7ZzH//s9NuL9fChjccPVPrqN5/E9AYHsBBSnm8POXDxTTPL0FuAUpOVQRrr+k1qe8P1C3j/b7KyXgOY1X0vTCO3ct1l/b1FtIofhyngKuVfnb5IMjZa9NydIgEkImUNXnl/veifrLuyjkg6OinnvadbkRi0ryeZHE1cI1GqrYD8yElKJOL6VAUCdjl8D06OoDSsg8JEKDMYldXxRjsc+rwtIVFgpvtjq/lusUrkDFNdRHDZKu+iImneDm9ZGnagizqv5msq+fVzIzXd89rJhW1/ZNUty2fShX1g1d5WZ1l6t14S1Lo+E9cEJAzaFQRX6/yeyXuJu/WLI2zq3RnGaDgPU+89/oZskkffYLKsqxbuwC1ndSnLVd1nEhNVx6PK8VTdXPjwQAK5oBsXOAA9N0Uw49oQDJlFhYA/Yexi6FaSnO7LuyDLncBq8vhApCg7HNn3AdR/WhuAFScYLXO0eAbYP4I4bkKevUrCoAO7tKQHCm4XHZ83nzUvnQ8uMLVAe38sdX1gk+L5tr5ks68X5l+juHizeS79UTHTbPF/E5lX8txHQGbvwFnP5Zu3xOLtWcRumSRHLWdwR+aCB8FmtVDNk6JOT99OAkd9s/VXUaIQMjtHnvnvkF2DtJxT4C8lHWHC0poyGnbSkCamIjpq0ok0kqT1TsogimrMO4vPMClmIBgNs6nkRS9lrJBkiMcV9oZhZA9c6K+ynPTMk2mSChIFf1tZA0D6mrXk8+zU1FEDZbZrixmiBH2eugKDVabzKABX7KHzvxHXcbooMaqIK3XID4+8dF2FnuXPeML355AN3UIAFAwRtuzhxju7UP8K5f9P2PfQNU1cUcXjr+/BEySlidDCXNv6pIZriv1UN1mqt/cs3HbZTMlm6I2lo9oQCJmLYbu4Sl0zRizZAdBbVtqlMlO13IwTQnyZcZrq6qo/DbjPdfaF+lvR9Fpm7CT1V53T0CXN3OTXCnibqmz6c3uRtjwIc6WkJDHXE+YGHFLXhaFGnX+EvsaHrNicyENZ/GL1fcprfXs45qkEoLyVQWua+4Ob1qdC1efnk5XPOpsu4UFzcADQcVL3+hrmwBeq5Sn+ZtJn90ZV62YpoLMUD6TeDhu3mz/Ev4kj1yqInN1DT4zNglKIGEjKQw4PIPOus3dVc3+cg2SST8zjVvAfwaJNn1kiTp024Iay6U99tHwoIjQNgUCBffTdh4/1/FYdiy/tTw5aKpNun7atwsy8Ud4Sal4XVwZDY3iksTZc1O+no9FzlfEw2QdPVe3D8VOBgFrG6r/PFtg9TPc3VtO/c3di63btpPjRTTFLU/oyqvXxRvHbRLvwqr3XwoM6no6yKM7jRhFCCZmtbTgFo9jV2KkkXIh2B6om6O9UrAWkg6+/LS0RDah2f59yXNW7IBw1WZ4cYiM655a0UosEhutJCxxHTh+rVoOwz51r73605pulZvXr7LX59f9jLXXJzHfemaktJWE3R9h27WVLt3lPubo6JW9/oO9Yv63j7A/ZX0NRPSj6q4Fvpzi+VqmrpBsLI3GTQFSKbG3PL9MGwiyI1VkZoTPT6vm4Nt+VRAIiNPCicvS8WvSJUL6YqKNzGlPiiraVLXwVvWtoHAsWgV8/fIYYXAngkCMhWylpuSJgldBc96+4It4mvumsBZ3mWbe4tLnM8FHOryfH6XW6pElbdZ6hdclRLwfAtqEjcQ2ZqjFyqasc+vkxtJqYkegmcTD8gpQCIlXk2xhmVDSiohX6bF6Zyr6sMx9SqK/GtR6Dp3uvDfMeFphc6qfuMv1V8oPEX8YH+ZVLT9DKWoAdzu0cLS7RoBbB0I5BSh6Vbe4ZlcreKuEUXPY74Pd0vU8INASGf/K1vfN6Up88/3whbd1YUlNTWn2fMlsK6j+jLLKm4wI7/OXQlAARIhunZxo7FLUDzrOhR9PiND9vXSh6L0udI50/5VXSzXd3ADL5StX6YtyRQCulijcEt//nqORVGYzy0Po6pGK3Yu8Ox28Y4hkXQCiFtQ/HxSErgyC5kn7o9iTEZ6+xCwtA7X7Kcw277pogCJEJOlxy/K1GvKm4AMQXakl6kROjeUyuZJHTDxZgedeKVmokNj2ahiAkptm84M0b8IAOK+VT9oQWKPhrXzAGF9KwVR8cNqU6/3qwdc1rS8i+mgYf6EmCp91sasbKb+cU0z4RaHSU8OJ7DmbEMX/RXB0LVwScVcTLlIitnhV0iNh65oO1Dhrrbrmcl4EM81GVrbA50EzJAupA9RyuWil0drAoL72Dn6L4aOmEQN0vLly+Hn5wcbGxuEhITg7NmzKtO2bt0aIpFI4da58/vJ7SIjIxUe79ixoyFOhRDdkV1Ys6TQ2S9RI5HMe2NMhg6Q9BnsqVLcJWl2j9FNOfRh28Ci77u+I9dPLfUq19RtMGVvhJoQRq9B2rJlCyZMmICVK1ciJCQES5cuRXh4OG7dugV3d3eF9Dt27EBe3vuObs+fP0e9evXQq1cvXrqOHTti/fr10vvW1tb6OwlC9EEXw5MNTVdzNxmLqrXeDKmk9+MSQl1TJmPclAt25VWnETTyjAimq1qd3WN1k4+JMHqAtHjxYgwbNgyDBnGTvK1cuRJ79+7FunXrMG2a4kJ25cvz3zSbN2+GnZ2dQoBkbW0NT09P/RWcEEL04U3JGulTJOoCpB3DgKvbuP/r9FKeJk3gYs8Sz+5ol76seXhGN/nklq7A1ahNbHl5ebhw4QLCwt6vdWNmZoawsDDExwtYzwrA2rVr0bdvX5QrV463PS4uDu7u7ggKCsKIESPw/Lnq0Sm5ubnIysri3QghhOiLmiYdSXAk/39x/NRQN/mYmuMLjV2CUs2oAdKzZ88gFovh4cFfwd7DwwOpqaka9z979iyuXbuGoUOH8rZ37NgRGzduRGxsLBYsWIDjx48jIiICYrHydaWio6Ph5OQkvfn4+BT9pHTBycjHJ4QQfcpIBgoMNCdQaaaLKQ6MyrRHbJpEJ+2iWrt2LerUqYPGjRvztvft2xcffvgh6tSpg+7du2PPnj04d+4c4uLilOYTFRWFzMxM6e3hw4cGKL0a/i2BDt8YtwyEEKIv6deB/7kZuxSEqGXUAMnV1RXm5uZIS0vjbU9LS9PYfygnJwebN2/GkCFDNB6nSpUqcHV1xd27yjuQWltbw9HRkXczKpEIaCpwZlpCCCGE6JxRAyQrKysEBwcjNvb9vBGFhYWIjY1FaGio2n23bduG3NxcfPqp5rWxHj16hOfPn8PLy6vYZSaEEEJI6Wf0JrYJEyZg9erV2LBhAxITEzFixAjk5ORIR7UNGDAAUVGKK16vXbsW3bt3R4UKFXjbs7OzMXnyZJw+fRr3799HbGwsunXrhsDAQISHhxvknHRm7CVjl4AQQggpk4w+zL9Pnz54+vQpZs6cidTUVNSvXx8HDhyQdtxOTk6GmRk/jrt16xb+/fdfHDp0SCE/c3NzXLlyBRs2bEBGRga8vb3RoUMHzJs3r+TNhVS+irFLQAghhJRJIsbKwsI/2snKyoKTkxMyMzON3x9ptpNxj08IIYTog3NlYLyWc1ppoMvvb6M3sRFCCCGEmBoKkAghhBBC5FCARAghhBAihwKkkq5aR2OXgBBCCCl1KEAq6XpvNHYJCCGEkFKHAqSSzqKETV1ACCGEAED+W2OXQC0KkEoK12rGLgEhhBCiOznpxi6BWhQglWTDTxi7BIQQQkipRAFSSeZVz9glIIQQQkolCpAIIYQQQuRQgEQIIYQQIocCpJLks51ApUbGLgUhhBBS6lGAVFJUagQEtAVaTDR2SQghhJBSz8LYBSAajD4PXNsONBnB3WfMuOUhhBBCygAKkEyda1Wg9TRjl4IQQggpU6iJraQRiYxdAkIIIaTUowCJEEIIIUQOBUglDfVBIoQQQvSOAiRCCCGEEDkUIJU0XnWNXQJCCCGk1KNRbCWNUyVg1FnAxtnYJSGEEEJKLQqQSiK3IGOXgBBCCCnVqImtNPjipOI2M4p9CSGEkKKiAKk08KwNNB7O31Yh0DhlIYQQQkoBCpAI58MfjV0CQgghxGRQgFSa1e0LVGwIhEcrPjb4IP++T4hhykQIIYQAQMMhxi6BWtRRpdRQMoFkz1/e/38w6v3/1bvw0/XeSB2/CSGEGJaJL51FNUilhYMX/374N8rTWdgAfX7jb6vZTT9lIoQQQlQRmXYIQjVIpUWTEcCLe0BQZ6BKK8CqnPJ0lrbvonbTjtwJIYSUdqb9PUQBUmlhaQt0W27sUhBCCCHCmHgNkmmXjuie5AUppO3X2pF/P3S07stDCCGkbKIAiZiEnmsAO1eg7x/c/fJVNO/z2U7+fa96ui8XIYSQssnEO2lTE1tZUbcXUOfj9y/Icq7AyDOAlZ1iWgsbYHoKYGYGTLoLLCrmpJPl3ADfpsCNv4qXDyGEEGIgJlGDtHz5cvj5+cHGxgYhISE4e/asyrQxMTEQiUS8m42NDS8NYwwzZ86El5cXbG1tERYWhjt37uj7NEyffLTuXh1wrqw8rdm7l4a9m2wGRTuutSM3lQAhhBBSQhg9QNqyZQsmTJiAWbNm4eLFi6hXrx7Cw8ORnp6uch9HR0ekpKRIbw8ePOA9vnDhQvzwww9YuXIlzpw5g3LlyiE8PBxv377V9+mUbqZQHRo2G7ByMHYpCCGEFJcpfKeoYfQAafHixRg2bBgGDRqEmjVrYuXKlbCzs8O6detU7iMSieDp6Sm9eXh4SB9jjGHp0qX4+uuv0a1bN9StWxcbN27EkydPsGvXLgOcURmn735KTUYBo8/p9xiEEEIMgAIklfLy8nDhwgWEhYVJt5mZmSEsLAzx8fEq98vOzoavry98fHzQrVs3XL9+XfpYUlISUlNTeXk6OTkhJCREZZ65ubnIysri3YgWLGzf/x/yheLj8r8SXDXM2v3JVuCLk4rbbZwBCyvA0kbxMUIIISUL1SCp9uzZM4jFYl4NEAB4eHggNTVV6T5BQUFYt24d/vrrL/z2228oLCxE06ZN8ejRIwCQ7qdNntHR0XBycpLefHx8intqZYv8i9xSScdvWd1+Uv+4R23As7aa45j2m6rYqrQxdgkUFLJSfs0JIUZg2p8rRm9i01ZoaCgGDBiA+vXro1WrVtixYwfc3Nzwyy+/aN5ZhaioKGRmZkpvDx8+1GGJSxDJciV+LZQ/LhsIufi9/99ark/QkMNAjQ8V9x91Dui3BfBpXKxiqpwlHACs7Pn3gyO5UXklipJ19YxsZ2FzYxeBEFLKZL0tMHYR1DJqgOTq6gpzc3OkpaXxtqelpcHT01NQHpaWlmjQoAHu3r0LANL9tMnT2toajo6OvFuZNOQQ0OYroIeqYFMEfB7HLWfyyTbu5lYD+GQLP5lnbaDPr4q7u1UDgjqqL4NXPcV15eSZW3LB1gjVzbBSti4AM72AoyR5zCpAzErcbylCiIlLf5Vr7CKoZdRPPSsrKwQHByM2Nla6rbCwELGxsQgNDRWUh1gsxtWrV+HlxX2p+vv7w9PTk5dnVlYWzpw5IzjPMsu5MtBqClCuguo03g2Afpu4YKdaB2DUaW6bWgKrUccmAMPi3k8xoC4ft2qAR03lyer0EnY8IoiNhbmxi0AIKYXEJv7b1eg/CydMmIDVq1djw4YNSExMxIgRI5CTk4NBgwYBAAYMGICoqChp+rlz5+LQoUP477//cPHiRXz66ad48OABhg4dCoAb4TZ+/Hj873//w+7du3H16lUMGDAA3t7e6N69uzFOsfTQZ4c6x0pAeX81wZEWPlrDv1/UcrvVKH5ZSoHy5azQ84OKxi4GIaSUMfW+jUafSbtPnz54+vQpZs6cidTUVNSvXx8HDhyQdrJOTk6GmcyX5suXLzFs2DCkpqbCxcUFwcHBOHXqFGrWfF+bMGXKFOTk5ODzzz9HRkYGmjdvjgMHDihMKEm0JeDF7FSpiFkb+Y3i4g+8TOJvG/AX8H013R/LyQfIVNPPTb4flT7V7w8k/K42iQgMFuZG/y1FCCllmIl3fzCJT73Ro0fjwYMHyM3NxZkzZxASEiJ9LC4uDjExMdL7S5YskaZNTU3F3r170aABv4lHJBJh7ty5SE1Nxdu3b3HkyBFUq6aHLzry3mc7gfBo1R28dUGbIMq2PPe3WoSw9F2XAe1m8rc5eChPK8u/FdDma6BWT67GSdnM5HauQMRCwKky12/K1kV5XjbOgPcHQMQC5Y8P2K25PNpo8xXQMVq3eWpSqyfgUcewxyxJAtoZuwSEGIyJVyCZRoBESgg7NX2TAtoCoSONXxMkMe4yF4xUDtGcFgAcPIEWExW3t5qqfr+Bu4FWk4Fe64GR8YC5lfJ0IcOBL6+q7jcFANMeAJ8f42rhui1XfLxKK/VlUcZdzfFaTQFsnLTPU2JsgrB0ZjIV1TZOwIh/i37M0k7T681EJIiqG7sIpBQQmXgIYtqlI6ahxyqg+ZeAXxGHegsKmnSURjLHko2j+mAkbDYQuQ9oPR1oNBRwUzF5ZZvpAsolKZ4Og8P6/YFhR4uXh70HUL6K8sfKBxQvb4DrMybE8BPFP1ZpUrUD/76jTP8uM6P3ehCkmgct90OKj9E8SKTEq9eHCyhMpXZIlelPgFo9hKVt/iXg1wxoPRXo/L36tHV6A5UacQGHoYhEQMVgwNy66HnYu6ue4kB2uZZeG7hmwKII6qQ5jUetouVtapqM1E0+AW35981K3ihBO0slZfZvafiCkBLtiZWvsYugFgVIxDQ4eituq6zltAzqJpAsjo9WA0OPACIBX2RFbbJqNk77fYIji3YsgP+lXKs7MPku4Kai2cRTTZ+hj9e//79eP8BVQ18/ZUG2YxE79msi0vHHm4VcsCq7xI4qss3S/i2BBp8pppGNYU38N4haDQYYuwSkhJl2M9DYRVCLAiRifIFhQE8lk1P23sh1gJbQVwAklJAatB6rAK/6QJ/fZDYKGKnRfq725fFuAHyVprrTNyC81k8kUl7b1Phz4EM1S8PIrotnV4GrmfLVsil29Fnt0gsV0A4ImwM4y/1KbT5Bu3xCRwMf/qi4Xdsa1YF/C1hmp47miVJV8ayruK3rD0XLqyhYIf++xvnRSFlnpawm0oRQgESMQ1IbIzIDPt3OX7pEwt6d6wDd53dugVte0GEENbtrTuMaCAw/DtToqjqNLpsqLW3UzxRe3GG0EQsBezctd1JzzIrBitvkA9/6n2p5PBVEIqD5eMUmrbYztMsn/BvggwHqr6WyRZpVUchH5r6FFTD+mlbFk1LWlCkftOhK0LvRobI1pvKvk+I0D5NSr9bbtbC2MO0QxLRLR0oJJQHBkEOATwi3bpsmNbpwtQxeSn4hC1FO2y94FdrNBHqu0ZxOk4oNi58Hj8wX7Ge73v9fzr3o+YRHczVH2iwQbOusuK3FJO7vqLNcbUa9T9TnUc4dcNFzv4QiT0aqJkCSD8IkwuZwfxt/rnrfhoO5v/7vRimaq+ioXf9TbimenquVP65syoai9P+yF7DMU/3+QP8/gdHngSFHuDnD5PuxmXqfRWJUObCFnZVpD0qgAIkYR6WGXJBUqZjBgm8z7q+Tj+o0n2zhgrHisrQB6upgGZP2c7jRc7oi+WIt5w4EtOG+uALaAh/+UPQvqdCRwAdK+sso030ltz6fpBOzbA1Ju3e1NW5BQPBA1cHJ4IPcc/nZDtXHmVbURaR1NBldUfpKffAZMOEmVxOnSrNxwKADQL/NqtM0Hcs18w0/AXjUVp7G1gX4Op27lnX7cn3UfBpzwa42ZIMqz7rKR0KKzICq7blaXp9GQJXWSjLS/No7W6hi9CgpE8pZUxMbIfrTK4arpYjcqzqNRy0uGDO0wDDur3ztgbUDN3pOUCdiAV/uH/7A1W4Ne7f+YNX23MSdqmY1V9afBih6c1z9ftz6fNKmsiLkU7kJMGif+g7hNlouIq2umbMo5DvF86ZKUBMMOHrJBapy18fMHPANBazsVOfRYd774FLZ60bSLGlhzV3Lnr9wk58CXNAsoW5eLGXl+/w4V0tUFBVUTDFRijy00U2Ad0ispOm5FEsq5EYE21INEinz9FnVbu/O1VLou1lGVssp3N/WUerT9fkNGLQfaDlZv+WxdeEmuVQ2i7cyH5Sg0UbyE28Gdeb+SjqOK5vrydqRqzWRBA3qAj9VzZDKghALK2B6Cve8f/Ev0OdXrl/asGMaT0OnXKsBlZvyt3VXMrGoMp9u1+5YZmbKpyFQ+p6Wu87NxnN9swb+rTL7OhWdtSuPifH5sphzlb3zef4ENH4r8DksgjOF2k3s+UNBd/0U5J1kxgVIlmam3QxLARLRH0nH6+pdjFoMrUjKqmw4tkSb6cC4K5pnPba0BXybqp7nprgdqCU1VDqjo6YoXa6vJN+Bu89vwOR7XNPVlze4GdO7r+QHUhNvcU2E0uY8NeWp1YOrJZHvgK/qHKzsgNbTuJqu8v5A7w1AxQ+0Oych16fpGNWPmZkBg/dz5y2E5H0oMlc+nYa8So0UtznJBd/WSmrz5M/LwoZbNkfN/Ei2QkYxGbCzd46Hlk3+1sLXTVxa0FPNoyKkwwVZTMDUEQbwo9qycg6IlbxOtDSqLQ3zJ2XVkCPAR2tNcPkENb9aeq4CPtkKdFqkZncRV2NliE6oZpbKt1eoKmxhYG3mktJZYKPLBSjlrrGZGVDuXWdgp4pcEFo5BPgqlet/E/VYfVOVxPAT3HD/djMA7/pKAgcDLaLZ/0/l23W5pqGlLdd/K+qRsPTNJwAd/sd1rJfo/vP7/6c/Ud2RXJUeq7RLL1GjK9B4mNok/wUOFJaXgPdCOZkmn3Fm0zUENardKNRco62sVudUoYr+ZQBG5Y0VnI882Rmrm+cuE5BeucTC9309J+UP15iPuvJ826MOPqisZooSE0ABEtEfezegzsdc00RJYVUOqBbOn99HbwR8CX+6nRtV1Hsjf7tdeWGHCBkOdFmqdcmMyrep5jTyzMy5/jdCf9F71QPCZnH9wYDiB4daBcsyx6raXnkS+eVINOWjiY2jsMAR4F77Tcfwl9+RPT+h85HJ7lOvj+Y0ynRfwbt7uKFioPVf0FAsL/hQWJkkesVoTPLd9MkYNmO1wgSx+8SNNe6bBYHXWs7UfNXB4N7CJvipoBvSmLPKNCfEmheC3vVVv6IUDQBwXqZTfWExw4f2NQ24MkERUYBEiCnzDQUm3gRqduPuh83mZnDu9J2w/c0tgYaD1I/yE0L2i6zZeOCLk8XLTx2/5sCA3dx8QLqopdM2+GlQhHmYdNmsCHDnrWlKBF1o/iV/VJyqPkqCzk++iU1Ac5GySTEj98nc4U9g2r5LH2Dkad4PhhpeTsq/rOUnOLWUKU+tHsDgg1jtLDeDvczrzcrCDOWsLbh+hO98lT8YJwo1TzeSV02xW8G1QtVrFx6b1Bo7RzZFJtQH+IsK+iAkV3VfpYH5U/HB25VcTaoMkcxz42qvvMlSdkShsjXSCpgZ1okjZNIAT5mSplYBNXXNAl3h5mD682RRgETKnpI2P4tseZt/CUx/zNWAaKMoX3D8Qrz/t/0cwFN1U4CgY2lat6tKK8DZB4LmX9IJmTJ/+BNQ5d3IL2UTmBqKptepLoKysNlAu1nv76vs1ybgWLLl6fw9UK4C//GoR9wUBBJjLvJro744yXXodtYQzLvX4M3WXtHZDn0badjHt5niF3flJoh36Mjf5qBkDqjK76cIuSkKQPcGGvpxfbodLetUld79ueZvGJ83EkcK+X3VZIMQf9dyaFDZBQkzVdQoAjIBhUhu+/vabgYzWDu5a9U3SqKSs/qANjd0Ano2eh/kNfItj465CzA4b5LKfebkf4bEQh98ksef1sTSyvSDI4ACJFKW1P6I+6uuA2xJUKTFTQV8wdXpzf31UFJN32oqN+JLMoKvuMcKfPdFYKX9B7n2tAwkRCLgozVAm6/UTx8hv4+EdHSjigBH17VNhlBBy860jYYqbrN24C+LI9+HzrM2FzjLXh+VQSL/GrrJ1opYv5vdW7aptttypXnN6CIz7UH9/so7qMvYMrwJmvhpaN6W61Q+sndX7CpsDvnXg7JOzs52/O4Isk1mvYKV9zms4vo+yGwe6IoNgzU3ASrj7fy+WZBBhP62PwOdF0u3lbOxxJi27wO/jUMa4zmccLRQ9SCFv8VNkTP4BL6ZMJr/gLJJTU2QaU9CQIgudV/BzUmk85msS4mWk7j1s2R+MUs5VQQm3RZW++ZWHXh0Tn2aJiO4jtGa+hsZqrZPPmgp5wq0EhIMvmMh02etxSSu5knbxZYVaDp3A3aqd/TmpjMo6mLMSokEPr9KyicfRMnmM/EmkJctqK+Uv0xwgdDRQGG+2vQWyiY6/Wwn8PgCcPR/78ujwdi8UciF+r6Z921qolyjscA/XL+k8WHVULeSE5pUqQDw5h19f7zfhiqfEDdbfnRcxELg/HrgaeL7bX7NgORT0ruPzLyBRm2AvZK1C4W+F/npGsoHlI2HG7dmVgtUg0TKDskketqOwCkrzC2BoI6qF78VGqx0+B8QMgIYpmaOGHNLrgO/kGHnxVVHB7Ofa+LbjOvX0moa9/qq17f4c3NVfdfcpWqYu5BRjLpU8QOgQoCaBFo2w4lEQPV3k3mqWxZHWbOXvJAvAAdvrnbYyo6bH03+WG4aRnuJRFzT9fATwKS7qtPIC2irZK4z9dfilYBO3H4fRiHY931wYWVhho61vRRqmYQ0t68Rd+JvCBkOjDr9/n7FhkDtj6V3GYBC+R8NIhH/h4CqiW5lBrhM7ahkIs0S1MWBvikIKQsM2axj6wxEzNdRZjr4MK3SmgsyxLlqEhXz+piZCRoZpdWxanbnOk2rWlrEvxXQfp7A2bFl+DYDHpx8P9O4fyvuF72q4+iNCAhsx9VM8Sb7ZPw0jYcDz+4A1TrKZ/A+TbkKwIQb6r98q3fhpu/wbsDfV57GgEPT86cYjI1qE4Dlx+7xcrhSqGGmcSGBREBboHpn4LSaSSa7LMGT7RrKXLObwvGUfmTYu3M/AiysAEtb7BrVDA+e5wC7ZNJEfAf8xM0M3iu0muZzMGEUIBFSJpTAfi+65FoNSLtq7FJwhPbnEYnUTwYqEgHNlM+No1bf34Gbe4Ea74bGW9oAYy4V/5d9UV5iIpHiRJvyNT+WNkA3uRFpyg6mqfwikYY5lYScv0j5yDt53vW5tfXejR6d1CEI/UN8gaXcw/1DfHHOsiHQ+ILyRZ6FqttXwPMmgqN3NcxP7YuxXUOU113JB0cQKQmQ3qVp834Fgfo+zqjv4/w+QGoxCXANBD7ZBoC9n0ZDWT4lAAVIhJQFTccCB6N0vz6ZvhmqOr5uX+DsKsPUogR1AjrOB7zq6/9Yyti6KE5loGoRYa1oOVJS0HMroKO7oI7cAo4lpDxm5lxNVsspmmuagt4PiReJRPCWGSXWvqYX2letoalAQKV3Ha5dVEwRIPD9sWtUM+QVhMLWSs0AD7kBEwpNbEJI+n1VUzOPFzWxEUJMSpMRgH8Lzf0wTI6OPkw1ZVMpmJt3yd4Ak9eJRNzzUeYJG6FWZEKCKKFf1nX7AtmpgHstbp+2X6lOq6sAwNySm+Bz+pPiLbciEsHcTKQ+OIKIG4jRcQEm/30PgEhJHyQ1u3ecDyTuUVyYu4SjAImQskAk4tYPK2k+Xgf82gPo+G3x8rGroDmNpvl3iHqSvlB2rrrLU9+1DUxgLVPPX7TItJhlDh0NpF4BAtpx9zWNxhO6SLU6kuvc5At4Zt0Cjt7FnA+1qE1tMkKLoJ9qkAghpPj8mgFfpRRx7icZXX8Ado3gvnyIfljZcbUdqtYPBITV6ji+G51nYaMmL1NcN/Cd8qpnzJZSFyOEf6PFwUTcaMaBfwM2zkU4mKKJHYLwecsqcLCRv/YlJ7DRFQqQCCGmrbjBEcANuR+0T3M6Ujwa5x4SECBZWAHTU7hh5Kr6Rsl2/rVUNWReQO2QmQXX7+xtltxIuiIYcxHIzRI2LYGuSKbJUDczfRE6gSsGR+AP8S8K12rAs9vvJ+wtAShAIsRYPloLbB/CDT0mhLynaWFdq3LcPFsiM9ULS5vJfL1ZqOjDIxIBw/8BwIofiKudI0rhwMU7Vv8/gae3uBpWVbouAx6e46Y3KE552s4Abh/g1nQsjuH/ANlpxZ8fzIAoQCLEWOp8zM1hYilgUU9CSgNd9JeRqBis/nGrckC7mYA4n5u/RxWdjODTUnGDsartuZs6wZHcTQh1/e9aTuJuxWVpU6KCI4ACJEKMi4IjUpZYOwBf3lBdo6NrLSYa5jhCfTCQq/mRWWzXqPpv55ZJEVTLVPaIGCuJKyfqV1ZWFpycnJCZmQlHR0djF4cQQgghAujy+5vWYiOEEEIIkUMBEiGEEEKIHAqQCCGEEELkUIBECCGEECLHJAKk5cuXw8/PDzY2NggJCcHZs2dVpl29ejVatGgBFxcXuLi4ICwsTCF9ZGQkRCIR79axY0d9nwYhhBBCSgmjB0hbtmzBhAkTMGvWLFy8eBH16tVDeHg40tPTlaaPi4tDv379cOzYMcTHx8PHxwcdOnTA48ePeek6duyIlJQU6e2PP/4wxOkQQgghpBQw+jD/kJAQNGrUCD/99BMAoLCwED4+PhgzZgymTZumcX+xWAwXFxf89NNPGDBgAACuBikjIwO7du0qUplomD8hhBBS8pSaYf55eXm4cOECwsLCpNvMzMwQFhaG+Ph4QXm8fv0a+fn5KF++PG97XFwc3N3dERQUhBEjRuD58+cq88jNzUVWVhbvRgghhJCyy6gB0rNnzyAWi+Hh4cHb7uHhgdTUVEF5TJ06Fd7e3rwgq2PHjti4cSNiY2OxYMECHD9+HBERERCLxUrziI6OhpOTk/Tm46Nm2nVCCCGElHoleqmR+fPnY/PmzYiLi4ONzfsFC/v27Sv9v06dOqhbty4CAgIQFxeHdu3aKeQTFRWFCRMmSO9nZWVRkEQIIYSUYUatQXJ1dYW5uTnS0tJ429PS0uDp6al230WLFmH+/Pk4dOgQ6tatqzZtlSpV4Orqirt37yp93NraGo6OjrwbIYQQQsouowZIVlZWCA4ORmxsrHRbYWEhYmNjERoaqnK/hQsXYt68eThw4AAaNmyo8TiPHj3C8+fP4eXlpZNyE0IIIaR0M/ow/wkTJmD16tXYsGEDEhMTMWLECOTk5GDQoEEAgAEDBiAqKkqafsGCBZgxYwbWrVsHPz8/pKamIjU1FdnZ2QCA7OxsTJ48GadPn8b9+/cRGxuLbt26ITAwEOHh4UY5R0IIIYSULEbvg9SnTx88ffoUM2fORGpqKurXr48DBw5IO24nJyfDzOx9HLdixQrk5eXh448/5uUza9YszJ49G+bm5rhy5Qo2bNiAjIwMeHt7o0OHDpg3bx6sra0Nem6EEEIIKZmMPg+SKcrMzISzszMePnxI/ZEIIYSQEkIyyCojIwNOTk7FysvoNUim6NWrVwBAI9kIIYSQEujVq1fFDpCoBkmJwsJCPHnyBA4ODhCJRDrNWxLdUu2UftF1Ngy6zoZB19kw6Dobjr6uNWMMr169gre3N697TlFQDZISZmZmqFSpkl6PQdMJGAZdZ8Og62wYdJ0Ng66z4ejjWhe35kjC6KPYCCGEEEJMDQVIhBBCCCFyKEAyMGtra8yaNYumHNAzus6GQdfZMOg6GwZdZ8MpCdeaOmkTQgghhMihGiRCCCGEEDkUIBFCCCGEyKEAiRBCCCFEDgVIhBBCCCFyKEAyoOXLl8PPzw82NjYICQnB2bNnjV0kk3bixAl07doV3t7eEIlE2LVrF+9xxhhmzpwJLy8v2NraIiwsDHfu3OGlefHiBfr37w9HR0c4OztjyJAhyM7O5qW5cuUKWrRoARsbG/j4+GDhwoX6PjWTER0djUaNGsHBwQHu7u7o3r07bt26xUvz9u1bjBo1ChUqVIC9vT0++ugjpKWl8dIkJyejc+fOsLOzg7u7OyZPnoyCggJemri4OHzwwQewtrZGYGAgYmJi9H16JmXFihWoW7eudGK80NBQ7N+/X/o4XWf9mD9/PkQiEcaPHy/dRte6+GbPng2RSMS7Va9eXfp4qbjGjBjE5s2bmZWVFVu3bh27fv06GzZsGHN2dmZpaWnGLprJ2rdvH/vqq6/Yjh07GAC2c+dO3uPz589nTk5ObNeuXezy5cvsww8/ZP7+/uzNmzfSNB07dmT16tVjp0+fZv/88w8LDAxk/fr1kz6emZnJPDw8WP/+/dm1a9fYH3/8wWxtbdkvv/xiqNM0qvDwcLZ+/Xp27do1lpCQwDp16sQqV67MsrOzpWm++OIL5uPjw2JjY9n58+dZkyZNWNOmTaWPFxQUsNq1a7OwsDB26dIltm/fPubq6sqioqKkaf777z9mZ2fHJkyYwG7cuMF+/PFHZm5uzg4cOGDQ8zWm3bt3s71797Lbt2+zW7dusenTpzNLS0t27do1xhhdZ304e/Ys8/PzY3Xr1mXjxo2TbqdrXXyzZs1itWrVYikpKdLb06dPpY+XhmtMAZKBNG7cmI0aNUp6XywWM29vbxYdHW3EUpUc8gFSYWEh8/T0ZN999510W0ZGBrO2tmZ//PEHY4yxGzduMADs3Llz0jT79+9nIpGIPX78mDHG2M8//8xcXFxYbm6uNM3UqVNZUFCQns/INKWnpzMA7Pjx44wx7ppaWlqybdu2SdMkJiYyACw+Pp4xxgWyZmZmLDU1VZpmxYoVzNHRUXpdp0yZwmrVqsU7Vp8+fVh4eLi+T8mkubi4sDVr1tB11oNXr16xqlWrssOHD7NWrVpJAyS61roxa9YsVq9ePaWPlZZrTE1sBpCXl4cLFy4gLCxMus3MzAxhYWGIj483YslKrqSkJKSmpvKuqZOTE0JCQqTXND4+Hs7OzmjYsKE0TVhYGMzMzHDmzBlpmpYtW8LKykqaJjw8HLdu3cLLly8NdDamIzMzEwBQvnx5AMCFCxeQn5/Pu87Vq1dH5cqVede5Tp068PDwkKYJDw9HVlYWrl+/Lk0jm4ckTVl9/YvFYmzevBk5OTkIDQ2l66wHo0aNQufOnRWuB11r3blz5w68vb1RpUoV9O/fH8nJyQBKzzWmAMkAnj17BrFYzHshAICHhwdSU1ONVKqSTXLd1F3T1NRUuLu78x63sLBA+fLleWmU5SF7jLKisLAQ48ePR7NmzVC7dm0A3DWwsrKCs7MzL638ddZ0DVWlycrKwps3b/RxOibp6tWrsLe3h7W1Nb744gvs3LkTNWvWpOusY5s3b8bFixcRHR2t8Bhda90ICQlBTEwMDhw4gBUrViApKQktWrTAq1evSs01ttD7EQghJcKoUaNw7do1/Pvvv8YuSqkVFBSEhIQEZGZm4s8//8TAgQNx/PhxYxerVHn48CHGjRuHw4cPw8bGxtjFKbUiIiKk/9etWxchISHw9fXF1q1bYWtra8SS6Q7VIBmAq6srzM3NFXrwp6WlwdPT00ilKtkk103dNfX09ER6ejrv8YKCArx48YKXRlkesscoC0aPHo09e/bg2LFjqFSpknS7p6cn8vLykJGRwUsvf501XUNVaRwdHUvNh6kQVlZWCAwMRHBwMKKjo1GvXj0sW7aMrrMOXbhwAenp6fjggw9gYWEBCwsLHD9+HD/88AMsLCzg4eFB11oPnJ2dUa1aNdy9e7fUvJ4pQDIAKysrBAcHIzY2VrqtsLAQsbGxCA0NNWLJSi5/f394enryrmlWVhbOnDkjvaahoaHIyMjAhQsXpGmOHj2KwsJChISESNOcOHEC+fn50jSHDx9GUFAQXFxcDHQ2xsMYw+jRo7Fz504cPXoU/v7+vMeDg4NhaWnJu863bt1CcnIy7zpfvXqVF4wePnwYjo6OqFmzpjSNbB6SNGX99V9YWIjc3Fy6zjrUrl07XL16FQkJCdJbw4YN0b9/f+n/dK11Lzs7G/fu3YOXl1fpeT0bpCs4YZs3b2bW1tYsJiaG3bhxg33++efM2dmZ14Of8L169YpdunSJXbp0iQFgixcvZpcuXWIPHjxgjHHD/J2dndlff/3Frly5wrp166Z0mH+DBg3YmTNn2L///suqVq3KG+afkZHBPDw82GeffcauXbvGNm/ezOzs7MrMMP8RI0YwJycnFhcXxxuu+/r1a2maL774glWuXJkdPXqUnT9/noWGhrLQ0FDp45Lhuh06dGAJCQnswIEDzM3NTelw3cmTJ7PExES2fPnyMjUkmjHGpk2bxo4fP86SkpLYlStX2LRp05hIJGKHDh1ijNF11ifZUWyM0bXWhYkTJ7K4uDiWlJTETp48ycLCwpirqytLT09njJWOa0wBkgH9+OOPrHLlyszKyoo1btyYnT592thFMmnHjh1jABRuAwcOZIxxQ/1nzJjBPDw8mLW1NWvXrh27desWL4/nz5+zfv36MXt7e+bo6MgGDRrEXr16xUtz+fJl1rx5c2Ztbc0qVqzI5s+fb6hTNDpl1xcAW79+vTTNmzdv2MiRI5mLiwuzs7NjPXr0YCkpKbx87t+/zyIiIpitrS1zdXVlEydOZPn5+bw0x44dY/Xr12dWVlasSpUqvGOUBYMHD2a+vr7MysqKubm5sXbt2kmDI8boOuuTfIBE17r4+vTpw7y8vJiVlRWrWLEi69OnD7t796708dJwjUWMMWaYuipCCCGEkJKB+iARQgghhMihAIkQQgghRA4FSIQQQgghcihAIoQQQgiRQwESIYQQQogcCpAIIYQQQuRQgEQIIYQQIocCJEIIIYQQORQgEUIQFxcHkUiksLikOpGRkejevbvaNH5+fli6dGmxylYURTmf+/fvQyQSISEhoVjHnj17NurXr1+sPAghxkcBEiEETZs2RUpKCpycnATvs2zZMsTExOivUO/ExMTA2dlZ78fx8fFBSkoKateurfdj6cqgQYPw9ddfK31MLBZjxowZ8Pf3h62tLQICAjBv3jzILp4gEomU3r777jtDnQIhJsvC2AUghBiflZUVPD09tdpHm2CqJDA3N9f6GhiTWCzGnj17sHfvXqWPL1iwACtWrMCGDRtQq1YtnD9/HoMGDYKTkxPGjh0LAEhJSeHts3//fgwZMgQfffSR3stPiKmjGiRCSpnWrVtjzJgxGD9+PFxcXODh4YHVq1cjJycHgwYNgoODAwIDA7F//37pPvJNUpJam4MHD6JGjRqwt7dHx44deV+oQprYAODVq1fo168fypUrh4oVK2L58uW8xxcvXow6deqgXLly8PHxwciRI5GdnS0t16BBg5CZmSmt3Zg9ezYAIDc3F1OnToWPjw+sra0RGBiItWvX8vK+cOECGjZsCDs7OzRt2hS3bt1SWU75JjbJNYmNjVWbx/z58+Hh4QEHBwcMGTIEb9++Vch7zZo1qFGjBmxsbFC9enX8/PPP0scGDx6MunXrIjc3FwCQl5eHBg0aYMCAAWqv66lTp2BpaYlGjRqpfLxbt27o3Lkz/Pz88PHHH6NDhw44e/asNI2npyfv9tdff6FNmzaoUqWK2mMTUiYYbFlcQohBtGrVijk4OLB58+ax27dvs3nz5jFzc3MWERHBVq1axW7fvs1GjBjBKlSowHJychhj3IrZANjLly8ZY4ytX7+eWVpasrCwMHbu3Dl24cIFVqNGDfbJJ59IjzNw4EDWrVs3tWXx9fVlDg4OLDo6mt26dYv98MMPzNzcnLeK/ZIlS9jRo0dZUlISi42NZUFBQWzEiBGMMcZyc3PZ0qVLmaOjI0tJSWEpKSns1atXjDHGevfuzXx8fNiOHTvYvXv32JEjR9jmzZt55xMSEsLi4uLY9evXWYsWLVjTpk1VljUpKYkBYJcuXRKcx5YtW5i1tTVbs2YNu3nzJvvqq6+Yg4MDq1evnjTNb7/9xry8vNj27dvZf//9x7Zv387Kly/PYmJiGGOMvXr1ilWpUoWNHz+eMcbYpEmTmJ+fH8vMzFR7bSdNmsQ+//xzlY9/8803zNfXl926dYsxxlhCQgJzd3dnv/32m9L0qampzMLCgv3+++9qj0tIWUEBEiGlTKtWrVjz5s2l9wsKCli5cuXYZ599Jt2WkpLCALD4+HjGmPIACQC7e/eudJ/ly5czDw8P6X2hAVLHjh152/r06cMiIiJU7rNt2zZWoUIF6f3169czJycnXppbt24xAOzw4cNK85Ccz5EjR6Tb9u7dywCwN2/eKN1HVYCkLo/Q0FA2cuRIXj4hISG8ACkgIIBt2rSJl2bevHksNDRUev/UqVPM0tKSzZgxg1lYWLB//vlHaRllVa1ale3Zs0fl42KxmE2dOpWJRCJmYWHBRCIR+/bbb1WmX7BgAXNxcVF5fQgpa6iJjZBSqG7dutL/zc3NUaFCBdSpU0e6zcPDAwCQnp6uMg87OzsEBARI73t5ealM//vvv8Pe3l56++eff6SPhYaG8tKGhoYiMTFRev/IkSNo164dKlasCAcHB3z22Wd4/vw5Xr9+rbJsCQkJMDc3R6tWrVSmAfjXwcvLC4D6c9Y2j8TERISEhPDSy55vTk4O7t27hyFDhvCuz//+9z/cu3ePt8+kSZMwb948TJw4Ec2bN1dbpsTERDx58gTt2rVTmWbr1q34/fffsWnTJly8eBEbNmzAokWLsGHDBqXp161bh/79+8PGxkbtsQkpK6iTNiGlkKWlJe++SCTibROJRACAwsJCrfJgMiOgZH344Ye8QKFixYqCynn//n106dIFI0aMwDfffIPy5cvj33//xZAhQ5CXlwc7Ozul+9na2grKX9tz1nUekr5Uq1evVgikzM3Npf8XFhbi5MmTMDc3x927dzXmu3v3brRv///27R6kkSiKAvBZBQsbm4hgIQkEyaDDIBEREwgWizajFmIUlITgf2HAn2CjICrBSKYwhRZKbAJKbNRGEIsggQgDqQRthGks0giioojJFovizLpBcHV39XyQZriTvPuKcLi89z1vmJmYmMDk5CQ6OzsBAKIoQtM0BINBeDweXe3h4SFOT0+xubn5qr6IvgJOkIjozR4Pfj9+ngeYVCqlq02lUhAEAcDPQ9TZbBbhcBj19fWorKzE+fm5rr6oqAgPDw+6Z6IoIpvNIpFIvFNHryMIAo6OjnTPnvdbVlaG8vJynJ2d6fbHarXCYrE81S0uLuLk5ASJRAJ7e3uIRqN5f3d7exutra15a25ublBQoP+LLywsfDHcra2twW63Q5KkvN9J9JVwgkRE7yqZTCIUCqGtrQ37+/uIx+NPV9OtVivu7+8RiUQgyzKSySRWVlZ075vNZlxdXeHg4ACSJKG4uBhmsxkejwc+nw9LS0uQJAmapiGTyaCjo+PDevP7/fB6vaitrYXD4UAsFsPx8bHuFtjMzAxGRkZQUlKC5uZm3N3dQVVVXFxcYHR0FOl0GtPT09ja2oLD4YCiKPD7/XC5XC/eJstkMlBVFTs7O3nXJssy5ufnUVFRgaqqKqTTaSiKAp/Pp6u7vLxEPB5HOBz+M5tC9ElwgkRE72psbAyqqqKmpgZzc3NQFAVNTU0AAEmSoCgKFhYWUF1djVgshmAwqHu/oaEBg4ODcLvdKC0tRSgUAgAsLy+jvb0dw8PDsNls6Ovrw/X19Yf25na7MTU1hUAgALvdDk3TMDQ0pKvp7e3F6uoqotEoRFGEy+XC+vo6LBYLbm9v0d3dDa/XC1mWAQD9/f1obGxET0/PL5MzANjd3UVdXR1MJlPetUUikaf9EQQB4+PjGBgYwOzsrK5uY2MDuVwOXV1db9wNos/lW+53hwqIiOif09LSAqfTiUAg8LeXQvSpcYJERPQfcTqdnPYQfQBOkIiIiIgMOEEiIiIiMmBAIiIiIjJgQCIiIiIyYEAiIiIiMmBAIiIiIjJgQCIiIiIyYEAiIiIiMmBAIiIiIjJgQCIiIiIy+AFc2ojBQco6EQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_train_losses)\n",
    "plt.plot(avg_valid_losses)\n",
    "plt.title('DenseNet loss curve + plateau scheduling + l2 regularization')\n",
    "plt.xlabel('mini-batch index / {}'.format(iter_n_per_record))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.legend(['training loss', 'validation loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def moving_average(data, window_size):\n",
    "    \"\"\"Compute the moving average of the data using a specified window size.\"\"\"\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "window_size = 20  # Adjust this based on your preference\n",
    "train_losses_ma = moving_average(avg_train_losses, window_size)\n",
    "valid_losses_ma = moving_average(avg_valid_losses, window_size)\n",
    "\n",
    "# x_axis = np.arange(len(train_losses_ma))/100 \n",
    "x_axis = np.arange(window_size - 1, len(train_losses_ma) + window_size - 1)\n",
    "\n",
    "plt.plot(avg_train_losses)\n",
    "plt.plot(avg_valid_losses)\n",
    "plt.plot(x_axis, train_losses_ma, linewidth=2)\n",
    "plt.plot(x_axis, valid_losses_ma, linewidth=2)\n",
    "plt.title('DenseNet loss trend + exponential scheduling + l2 regularization')\n",
    "plt.xlabel('mini-batch index / {}'.format(iter_n_per_record))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.legend(['training loss', 'validation loss', 'training loss (moving avg)', 'validation loss (moving avg)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracies)\n",
    "plt.plot(valid_accuracies)\n",
    "plt.title('DenseMax accuracy curve for plateau scheduling + l2 regularization')\n",
    "plt.xlabel('epoch / {}'.format(iter_n_per_record))\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train accuracy', 'validation accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to show an image.\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # Unnormalize.\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "# Check several images.\n",
    "dataiter = iter(validloader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "outputs = dense_max(images.to(device))\n",
    "\n",
    "# max compare along the row, return the index of the max value, which is the predicted class\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 77.02 %\n"
     ]
    }
   ],
   "source": [
    "dense_max.to(device)\n",
    "dense_max.eval()\n",
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = dense_max(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 83 %\n",
      "Accuracy of   car : 91 %\n",
      "Accuracy of  bird : 69 %\n",
      "Accuracy of   cat : 65 %\n",
      "Accuracy of  deer : 79 %\n",
      "Accuracy of   dog : 73 %\n",
      "Accuracy of  frog : 85 %\n",
      "Accuracy of horse : 83 %\n",
      "Accuracy of  ship : 88 %\n",
      "Accuracy of truck : 90 %\n"
     ]
    }
   ],
   "source": [
    "dense_max.to(device)\n",
    "dense_max.eval()\n",
    "\n",
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in validloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = dense_max(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs181",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
