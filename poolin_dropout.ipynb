{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:19:23.381452Z",
     "start_time": "2019-05-05T20:19:22.875162Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T19:49:54.053090Z",
     "start_time": "2019-05-05T19:49:43.413Z"
    }
   },
   "source": [
    "#### Prepare for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T20:19:24.679448Z",
     "start_time": "2019-05-05T20:19:23.383032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "print(trainset.data.shape)\n",
    "print(testset.data.shape)\n",
    "print(len(trainset.data))\n",
    "\n",
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(device)  \n",
    "# If 'mps or cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Pooling + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgDropNet(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dp1): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "  (dp2): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AvgDropNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgDropNet, self).__init__()\n",
    "        \n",
    "        # input image shape = 3x32x32\n",
    "        # 3 input image channels, 10 output channels, 3x3 square convolution, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input image shape = 10x16x16\n",
    "        # 10 input image channels, 20 output channels, 3x3 square convolution, stride 1, padding 1\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, 1, 1)\n",
    "        \n",
    "        \n",
    "        # dropout layer before fully connected layer 1\n",
    "        self.dp1 = nn.Dropout(p=0.5)        \n",
    "                \n",
    "        # input image shape = 20x8x8\n",
    "        # affine operation to hidden layer with 100 neurons\n",
    "        self.fc1 = nn.Linear(20 * 8 * 8, 100)\n",
    "        \n",
    "        # dropout layer before fully connected layer 2\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # affine operation to output layer with 10 neurons\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        # conv1 then relu then max pool\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, (2, 2))\n",
    "        \n",
    "        # conv2 relu max pool\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, (2, 2))\n",
    "        \n",
    "        # flatten and pass through fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "avg_drop_net = AvgDropNet()     # Create the network instance.\n",
    "avg_drop_net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Pooling + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxDropNet(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dp1): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "  (dp2): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaxDropNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaxDropNet, self).__init__()\n",
    "        \n",
    "        # input image shape = 3x32x32\n",
    "        # 3 input image channels, 10 output channels, 3x3 square convolution, stride 1, padding 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # input image shape = 10x16x16\n",
    "        # 10 input image channels, 20 output channels, 3x3 square convolution, stride 1, padding 1\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, 1, 1)\n",
    "        \n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        # input image shape = 20x8x8\n",
    "        # affine operation to hidden layer with 100 neurons\n",
    "        self.fc1 = nn.Linear(20 * 8 * 8, 100)\n",
    "\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        # affine operation to output layer with 10 neurons\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        # conv1 then relu then max pool\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        \n",
    "        # conv2 relu max pool\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (2, 2))\n",
    "        \n",
    "        # flatten and pass through fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dp1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "max_drop_net = MaxDropNet()     # Create the network instance.\n",
    "max_drop_net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Adam for 6 different models: avg pooling, max pooling, avg pooling with dropout, max pooling with dropout, avg pooling with batch normalization, max pooling with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:  2499] avg-125-iter mini-batch train_loss: 0.863\n",
      "[epoch: 0, i:  4999] avg-125-iter mini-batch train_loss: 0.847\n",
      "[epoch: 0, i:  7499] avg-125-iter mini-batch train_loss: 0.896\n",
      "[epoch: 0, i:  9999] avg-125-iter mini-batch train_loss: 0.854\n",
      "[epoch: 0, i: 12499] avg-125-iter mini-batch train_loss: 0.881\n",
      "[epoch: 1, i:  2499] avg-125-iter mini-batch train_loss: 0.729\n",
      "[epoch: 1, i:  4999] avg-125-iter mini-batch train_loss: 0.833\n",
      "[epoch: 1, i:  7499] avg-125-iter mini-batch train_loss: 0.796\n",
      "[epoch: 1, i:  9999] avg-125-iter mini-batch train_loss: 0.765\n",
      "[epoch: 1, i: 12499] avg-125-iter mini-batch train_loss: 0.766\n",
      "[epoch: 2, i:  2499] avg-125-iter mini-batch train_loss: 0.507\n",
      "[epoch: 2, i:  4999] avg-125-iter mini-batch train_loss: 0.666\n",
      "[epoch: 2, i:  7499] avg-125-iter mini-batch train_loss: 0.699\n",
      "[epoch: 2, i:  9999] avg-125-iter mini-batch train_loss: 0.620\n",
      "[epoch: 2, i: 12499] avg-125-iter mini-batch train_loss: 0.669\n",
      "[epoch: 3, i:  2499] avg-125-iter mini-batch train_loss: 0.536\n",
      "[epoch: 3, i:  4999] avg-125-iter mini-batch train_loss: 0.601\n",
      "[epoch: 3, i:  7499] avg-125-iter mini-batch train_loss: 0.572\n",
      "[epoch: 3, i:  9999] avg-125-iter mini-batch train_loss: 0.478\n",
      "[epoch: 3, i: 12499] avg-125-iter mini-batch train_loss: 0.609\n",
      "[epoch: 4, i:  2499] avg-125-iter mini-batch train_loss: 0.385\n",
      "[epoch: 4, i:  4999] avg-125-iter mini-batch train_loss: 0.451\n",
      "[epoch: 4, i:  7499] avg-125-iter mini-batch train_loss: 0.471\n",
      "[epoch: 4, i:  9999] avg-125-iter mini-batch train_loss: 0.443\n",
      "[epoch: 4, i: 12499] avg-125-iter mini-batch train_loss: 0.592\n",
      "[epoch: 5, i:  2499] avg-125-iter mini-batch train_loss: 0.302\n",
      "[epoch: 5, i:  4999] avg-125-iter mini-batch train_loss: 0.379\n",
      "[epoch: 5, i:  7499] avg-125-iter mini-batch train_loss: 0.417\n",
      "[epoch: 5, i:  9999] avg-125-iter mini-batch train_loss: 0.430\n",
      "[epoch: 5, i: 12499] avg-125-iter mini-batch train_loss: 0.403\n",
      "[epoch: 6, i:  2499] avg-125-iter mini-batch train_loss: 0.255\n",
      "[epoch: 6, i:  4999] avg-125-iter mini-batch train_loss: 0.282\n",
      "[epoch: 6, i:  7499] avg-125-iter mini-batch train_loss: 0.399\n",
      "[epoch: 6, i:  9999] avg-125-iter mini-batch train_loss: 0.408\n",
      "[epoch: 6, i: 12499] avg-125-iter mini-batch train_loss: 0.417\n",
      "[epoch: 7, i:  2499] avg-125-iter mini-batch train_loss: 0.233\n",
      "[epoch: 7, i:  4999] avg-125-iter mini-batch train_loss: 0.202\n",
      "[epoch: 7, i:  7499] avg-125-iter mini-batch train_loss: 0.332\n",
      "[epoch: 7, i:  9999] avg-125-iter mini-batch train_loss: 0.344\n",
      "[epoch: 7, i: 12499] avg-125-iter mini-batch train_loss: 0.332\n",
      "[epoch: 8, i:  2499] avg-125-iter mini-batch train_loss: 0.280\n",
      "[epoch: 8, i:  4999] avg-125-iter mini-batch train_loss: 0.228\n",
      "[epoch: 8, i:  7499] avg-125-iter mini-batch train_loss: 0.308\n",
      "[epoch: 8, i:  9999] avg-125-iter mini-batch train_loss: 0.298\n",
      "[epoch: 8, i: 12499] avg-125-iter mini-batch train_loss: 0.227\n",
      "[epoch: 9, i:  2499] avg-125-iter mini-batch train_loss: 0.225\n",
      "[epoch: 9, i:  4999] avg-125-iter mini-batch train_loss: 0.212\n",
      "[epoch: 9, i:  7499] avg-125-iter mini-batch train_loss: 0.284\n",
      "[epoch: 9, i:  9999] avg-125-iter mini-batch train_loss: 0.256\n",
      "[epoch: 9, i: 12499] avg-125-iter mini-batch train_loss: 0.336\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(avg_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "avg_avg_train_losses = []   # Avg. losses.\n",
    "avg_train_accuracies, avg_test_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "epochs = 10             # Total epochs.\n",
    "\n",
    "iter_n = len(trainset.data) // 4  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 5 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    test_total = 0   \n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = avg_net(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        # Record training loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            avg_avg_train_losses.append(avg_train_loss)\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}] avg-{}-iter mini-batch train_loss: {:.3f}'.format(\n",
    "                    epoch, i, record_freq, avg_train_loss))\n",
    "        \n",
    "    # Set the model to evaluation mode.\n",
    "    avg_net.eval() \n",
    "    \n",
    "    # calculating a train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    avg_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:  \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            test_output = avg_net(inputs)\n",
    "            # get the class which has the maximum probability\n",
    "            _, predicted = torch.max(test_output.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    avg_test_accuracies.append(test_accuracy)\n",
    "    # Set the model back to training mode.\n",
    "    avg_net.train()     \n",
    "              \n",
    "\n",
    "print('Finished Training.')\n",
    "PATH = './cifar_avg_net_adam.pth'\n",
    "torch.save(avg_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:  2499] avg-125-iter mini-batch train_loss: 1.703\n",
      "[epoch: 0, i:  4999] avg-125-iter mini-batch train_loss: 1.591\n",
      "[epoch: 0, i:  7499] avg-125-iter mini-batch train_loss: 1.644\n",
      "[epoch: 0, i:  9999] avg-125-iter mini-batch train_loss: 1.569\n",
      "[epoch: 0, i: 12499] avg-125-iter mini-batch train_loss: 1.463\n",
      "[epoch: 1, i:  2499] avg-125-iter mini-batch train_loss: 1.446\n",
      "[epoch: 1, i:  4999] avg-125-iter mini-batch train_loss: 1.479\n",
      "[epoch: 1, i:  7499] avg-125-iter mini-batch train_loss: 1.462\n",
      "[epoch: 1, i:  9999] avg-125-iter mini-batch train_loss: 1.340\n",
      "[epoch: 1, i: 12499] avg-125-iter mini-batch train_loss: 1.360\n",
      "[epoch: 2, i:  2499] avg-125-iter mini-batch train_loss: 1.307\n",
      "[epoch: 2, i:  4999] avg-125-iter mini-batch train_loss: 1.328\n",
      "[epoch: 2, i:  7499] avg-125-iter mini-batch train_loss: 1.319\n",
      "[epoch: 2, i:  9999] avg-125-iter mini-batch train_loss: 1.352\n",
      "[epoch: 2, i: 12499] avg-125-iter mini-batch train_loss: 1.364\n",
      "[epoch: 3, i:  2499] avg-125-iter mini-batch train_loss: 1.294\n",
      "[epoch: 3, i:  4999] avg-125-iter mini-batch train_loss: 1.362\n",
      "[epoch: 3, i:  7499] avg-125-iter mini-batch train_loss: 1.243\n",
      "[epoch: 3, i:  9999] avg-125-iter mini-batch train_loss: 1.285\n",
      "[epoch: 3, i: 12499] avg-125-iter mini-batch train_loss: 1.283\n",
      "[epoch: 4, i:  2499] avg-125-iter mini-batch train_loss: 1.253\n",
      "[epoch: 4, i:  4999] avg-125-iter mini-batch train_loss: 1.260\n",
      "[epoch: 4, i:  7499] avg-125-iter mini-batch train_loss: 1.115\n",
      "[epoch: 4, i:  9999] avg-125-iter mini-batch train_loss: 1.188\n",
      "[epoch: 4, i: 12499] avg-125-iter mini-batch train_loss: 1.185\n",
      "[epoch: 5, i:  2499] avg-125-iter mini-batch train_loss: 1.257\n",
      "[epoch: 5, i:  4999] avg-125-iter mini-batch train_loss: 1.187\n",
      "[epoch: 5, i:  7499] avg-125-iter mini-batch train_loss: 1.176\n",
      "[epoch: 5, i:  9999] avg-125-iter mini-batch train_loss: 1.255\n",
      "[epoch: 5, i: 12499] avg-125-iter mini-batch train_loss: 1.188\n",
      "[epoch: 6, i:  2499] avg-125-iter mini-batch train_loss: 1.228\n",
      "[epoch: 6, i:  4999] avg-125-iter mini-batch train_loss: 1.141\n",
      "[epoch: 6, i:  7499] avg-125-iter mini-batch train_loss: 1.233\n",
      "[epoch: 6, i:  9999] avg-125-iter mini-batch train_loss: 1.166\n",
      "[epoch: 6, i: 12499] avg-125-iter mini-batch train_loss: 1.084\n",
      "[epoch: 7, i:  2499] avg-125-iter mini-batch train_loss: 1.039\n",
      "[epoch: 7, i:  4999] avg-125-iter mini-batch train_loss: 1.117\n",
      "[epoch: 7, i:  7499] avg-125-iter mini-batch train_loss: 1.145\n",
      "[epoch: 7, i:  9999] avg-125-iter mini-batch train_loss: 1.152\n",
      "[epoch: 7, i: 12499] avg-125-iter mini-batch train_loss: 1.125\n",
      "[epoch: 8, i:  2499] avg-125-iter mini-batch train_loss: 1.223\n",
      "[epoch: 8, i:  4999] avg-125-iter mini-batch train_loss: 1.187\n",
      "[epoch: 8, i:  7499] avg-125-iter mini-batch train_loss: 1.090\n",
      "[epoch: 8, i:  9999] avg-125-iter mini-batch train_loss: 1.127\n",
      "[epoch: 8, i: 12499] avg-125-iter mini-batch train_loss: 1.125\n",
      "[epoch: 9, i:  2499] avg-125-iter mini-batch train_loss: 1.166\n",
      "[epoch: 9, i:  4999] avg-125-iter mini-batch train_loss: 1.137\n",
      "[epoch: 9, i:  7499] avg-125-iter mini-batch train_loss: 1.129\n",
      "[epoch: 9, i:  9999] avg-125-iter mini-batch train_loss: 1.152\n",
      "[epoch: 9, i: 12499] avg-125-iter mini-batch train_loss: 1.104\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(avg_bn_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "avg_bn_avg_train_losses = []   # Avg. losses.\n",
    "avg_bn_train_accuracies, avg_bn_test_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "epochs = 10             # Total epochs.\n",
    "\n",
    "iter_n = len(trainset.data) // 4  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 5 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    test_total = 0   \n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = avg_bn_net(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        # Record training loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            avg_bn_avg_train_losses.append(avg_train_loss)\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}] avg-{}-iter mini-batch train_loss: {:.3f}'.format(\n",
    "                    epoch, i, record_freq, avg_train_loss))\n",
    "        \n",
    "    # Set the model to evaluation mode.\n",
    "    avg_bn_net.eval() \n",
    "    \n",
    "    # calculating a train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    avg_bn_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:  \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            test_output = avg_bn_net(inputs)\n",
    "            # get the class which has the maximum probability\n",
    "            _, predicted = torch.max(test_output.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    avg_bn_test_accuracies.append(test_accuracy)\n",
    "    # Set the model back to training mode.\n",
    "    avg_bn_net.train()     \n",
    "              \n",
    "\n",
    "print('Finished Training.')\n",
    "PATH = './cifar_avg_bn_net_adam.pth'\n",
    "torch.save(avg_bn_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:  2499] avg-125-iter mini-batch train_loss: 1.751\n",
      "[epoch: 0, i:  4999] avg-125-iter mini-batch train_loss: 1.728\n",
      "[epoch: 0, i:  7499] avg-125-iter mini-batch train_loss: 1.588\n",
      "[epoch: 0, i:  9999] avg-125-iter mini-batch train_loss: 1.536\n",
      "[epoch: 0, i: 12499] avg-125-iter mini-batch train_loss: 1.453\n",
      "[epoch: 1, i:  2499] avg-125-iter mini-batch train_loss: 1.467\n",
      "[epoch: 1, i:  4999] avg-125-iter mini-batch train_loss: 1.393\n",
      "[epoch: 1, i:  7499] avg-125-iter mini-batch train_loss: 1.488\n",
      "[epoch: 1, i:  9999] avg-125-iter mini-batch train_loss: 1.511\n",
      "[epoch: 1, i: 12499] avg-125-iter mini-batch train_loss: 1.414\n",
      "[epoch: 2, i:  2499] avg-125-iter mini-batch train_loss: 1.359\n",
      "[epoch: 2, i:  4999] avg-125-iter mini-batch train_loss: 1.445\n",
      "[epoch: 2, i:  7499] avg-125-iter mini-batch train_loss: 1.484\n",
      "[epoch: 2, i:  9999] avg-125-iter mini-batch train_loss: 1.324\n",
      "[epoch: 2, i: 12499] avg-125-iter mini-batch train_loss: 1.440\n",
      "[epoch: 3, i:  2499] avg-125-iter mini-batch train_loss: 1.339\n",
      "[epoch: 3, i:  4999] avg-125-iter mini-batch train_loss: 1.310\n",
      "[epoch: 3, i:  7499] avg-125-iter mini-batch train_loss: 1.361\n",
      "[epoch: 3, i:  9999] avg-125-iter mini-batch train_loss: 1.314\n",
      "[epoch: 3, i: 12499] avg-125-iter mini-batch train_loss: 1.336\n",
      "[epoch: 4, i:  2499] avg-125-iter mini-batch train_loss: 1.274\n",
      "[epoch: 4, i:  4999] avg-125-iter mini-batch train_loss: 1.324\n",
      "[epoch: 4, i:  7499] avg-125-iter mini-batch train_loss: 1.286\n",
      "[epoch: 4, i:  9999] avg-125-iter mini-batch train_loss: 1.403\n",
      "[epoch: 4, i: 12499] avg-125-iter mini-batch train_loss: 1.382\n",
      "[epoch: 5, i:  2499] avg-125-iter mini-batch train_loss: 1.275\n",
      "[epoch: 5, i:  4999] avg-125-iter mini-batch train_loss: 1.312\n",
      "[epoch: 5, i:  7499] avg-125-iter mini-batch train_loss: 1.265\n",
      "[epoch: 5, i:  9999] avg-125-iter mini-batch train_loss: 1.294\n",
      "[epoch: 5, i: 12499] avg-125-iter mini-batch train_loss: 1.286\n",
      "[epoch: 6, i:  2499] avg-125-iter mini-batch train_loss: 1.226\n",
      "[epoch: 6, i:  4999] avg-125-iter mini-batch train_loss: 1.270\n",
      "[epoch: 6, i:  7499] avg-125-iter mini-batch train_loss: 1.319\n",
      "[epoch: 6, i:  9999] avg-125-iter mini-batch train_loss: 1.376\n",
      "[epoch: 6, i: 12499] avg-125-iter mini-batch train_loss: 1.317\n",
      "[epoch: 7, i:  2499] avg-125-iter mini-batch train_loss: 1.153\n",
      "[epoch: 7, i:  4999] avg-125-iter mini-batch train_loss: 1.241\n",
      "[epoch: 7, i:  7499] avg-125-iter mini-batch train_loss: 1.324\n",
      "[epoch: 7, i:  9999] avg-125-iter mini-batch train_loss: 1.367\n",
      "[epoch: 7, i: 12499] avg-125-iter mini-batch train_loss: 1.219\n",
      "[epoch: 8, i:  2499] avg-125-iter mini-batch train_loss: 1.212\n",
      "[epoch: 8, i:  4999] avg-125-iter mini-batch train_loss: 1.215\n",
      "[epoch: 8, i:  7499] avg-125-iter mini-batch train_loss: 1.245\n",
      "[epoch: 8, i:  9999] avg-125-iter mini-batch train_loss: 1.287\n",
      "[epoch: 8, i: 12499] avg-125-iter mini-batch train_loss: 1.304\n",
      "[epoch: 9, i:  2499] avg-125-iter mini-batch train_loss: 1.208\n",
      "[epoch: 9, i:  4999] avg-125-iter mini-batch train_loss: 1.295\n",
      "[epoch: 9, i:  7499] avg-125-iter mini-batch train_loss: 1.254\n",
      "[epoch: 9, i:  9999] avg-125-iter mini-batch train_loss: 1.271\n",
      "[epoch: 9, i: 12499] avg-125-iter mini-batch train_loss: 1.203\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(avg_drop_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "avg_drop_avg_train_losses = []   # Avg. losses.\n",
    "avg_drop_train_accuracies, avg_drop_test_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "epochs = 10             # Total epochs.\n",
    "\n",
    "iter_n = len(trainset.data) // 4  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 5 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    test_total = 0   \n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = avg_drop_net(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        # Record training loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            avg_drop_avg_train_losses.append(avg_train_loss)\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}] avg-{}-iter mini-batch train_loss: {:.3f}'.format(\n",
    "                    epoch, i, record_freq, avg_train_loss))\n",
    "        \n",
    "    # Set the model to evaluation mode.\n",
    "    avg_drop_net.eval() \n",
    "    \n",
    "    # calculating a train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    avg_drop_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:  \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            test_output = avg_drop_net(inputs)\n",
    "            # get the class which has the maximum probability\n",
    "            _, predicted = torch.max(test_output.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    avg_drop_test_accuracies.append(test_accuracy)\n",
    "    # Set the model back to training mode.\n",
    "    avg_drop_net.train()     \n",
    "              \n",
    "\n",
    "print('Finished Training.')\n",
    "PATH = './cifar_avg_drop_net_adam.pth'\n",
    "torch.save(avg_drop_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:  2499] avg-125-iter mini-batch train_loss: 1.535\n",
      "[epoch: 0, i:  4999] avg-125-iter mini-batch train_loss: 1.383\n",
      "[epoch: 0, i:  7499] avg-125-iter mini-batch train_loss: 1.318\n",
      "[epoch: 0, i:  9999] avg-125-iter mini-batch train_loss: 1.216\n",
      "[epoch: 0, i: 12499] avg-125-iter mini-batch train_loss: 1.020\n",
      "[epoch: 1, i:  2499] avg-125-iter mini-batch train_loss: 1.031\n",
      "[epoch: 1, i:  4999] avg-125-iter mini-batch train_loss: 1.089\n",
      "[epoch: 1, i:  7499] avg-125-iter mini-batch train_loss: 1.024\n",
      "[epoch: 1, i:  9999] avg-125-iter mini-batch train_loss: 1.100\n",
      "[epoch: 1, i: 12499] avg-125-iter mini-batch train_loss: 0.962\n",
      "[epoch: 2, i:  2499] avg-125-iter mini-batch train_loss: 0.856\n",
      "[epoch: 2, i:  4999] avg-125-iter mini-batch train_loss: 0.904\n",
      "[epoch: 2, i:  7499] avg-125-iter mini-batch train_loss: 0.903\n",
      "[epoch: 2, i:  9999] avg-125-iter mini-batch train_loss: 0.905\n",
      "[epoch: 2, i: 12499] avg-125-iter mini-batch train_loss: 0.839\n",
      "[epoch: 3, i:  2499] avg-125-iter mini-batch train_loss: 0.928\n",
      "[epoch: 3, i:  4999] avg-125-iter mini-batch train_loss: 0.851\n",
      "[epoch: 3, i:  7499] avg-125-iter mini-batch train_loss: 0.839\n",
      "[epoch: 3, i:  9999] avg-125-iter mini-batch train_loss: 0.904\n",
      "[epoch: 3, i: 12499] avg-125-iter mini-batch train_loss: 0.869\n",
      "[epoch: 4, i:  2499] avg-125-iter mini-batch train_loss: 0.712\n",
      "[epoch: 4, i:  4999] avg-125-iter mini-batch train_loss: 0.762\n",
      "[epoch: 4, i:  7499] avg-125-iter mini-batch train_loss: 0.872\n",
      "[epoch: 4, i:  9999] avg-125-iter mini-batch train_loss: 0.863\n",
      "[epoch: 4, i: 12499] avg-125-iter mini-batch train_loss: 0.919\n",
      "[epoch: 5, i:  2499] avg-125-iter mini-batch train_loss: 0.704\n",
      "[epoch: 5, i:  4999] avg-125-iter mini-batch train_loss: 0.765\n",
      "[epoch: 5, i:  7499] avg-125-iter mini-batch train_loss: 0.711\n",
      "[epoch: 5, i:  9999] avg-125-iter mini-batch train_loss: 0.761\n",
      "[epoch: 5, i: 12499] avg-125-iter mini-batch train_loss: 0.741\n",
      "[epoch: 6, i:  2499] avg-125-iter mini-batch train_loss: 0.681\n",
      "[epoch: 6, i:  4999] avg-125-iter mini-batch train_loss: 0.711\n",
      "[epoch: 6, i:  7499] avg-125-iter mini-batch train_loss: 0.679\n",
      "[epoch: 6, i:  9999] avg-125-iter mini-batch train_loss: 0.668\n",
      "[epoch: 6, i: 12499] avg-125-iter mini-batch train_loss: 0.789\n",
      "[epoch: 7, i:  2499] avg-125-iter mini-batch train_loss: 0.614\n",
      "[epoch: 7, i:  4999] avg-125-iter mini-batch train_loss: 0.575\n",
      "[epoch: 7, i:  7499] avg-125-iter mini-batch train_loss: 0.631\n",
      "[epoch: 7, i:  9999] avg-125-iter mini-batch train_loss: 0.674\n",
      "[epoch: 7, i: 12499] avg-125-iter mini-batch train_loss: 0.670\n",
      "[epoch: 8, i:  2499] avg-125-iter mini-batch train_loss: 0.579\n",
      "[epoch: 8, i:  4999] avg-125-iter mini-batch train_loss: 0.653\n",
      "[epoch: 8, i:  7499] avg-125-iter mini-batch train_loss: 0.558\n",
      "[epoch: 8, i:  9999] avg-125-iter mini-batch train_loss: 0.664\n",
      "[epoch: 8, i: 12499] avg-125-iter mini-batch train_loss: 0.684\n",
      "[epoch: 9, i:  2499] avg-125-iter mini-batch train_loss: 0.548\n",
      "[epoch: 9, i:  4999] avg-125-iter mini-batch train_loss: 0.622\n",
      "[epoch: 9, i:  7499] avg-125-iter mini-batch train_loss: 0.668\n",
      "[epoch: 9, i:  9999] avg-125-iter mini-batch train_loss: 0.689\n",
      "[epoch: 9, i: 12499] avg-125-iter mini-batch train_loss: 0.620\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(max_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "max_avg_train_losses = []   # Avg. losses.\n",
    "max_train_accuracies, max_test_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "epochs = 10             # Total epochs.\n",
    "\n",
    "iter_n = len(trainset.data) // 4  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 5 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    test_total = 0   \n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = max_net(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        # Record training loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            max_avg_train_losses.append(avg_train_loss)\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}] avg-{}-iter mini-batch train_loss: {:.3f}'.format(\n",
    "                    epoch, i, record_freq, avg_train_loss))\n",
    "        \n",
    "    # Set the model to evaluation mode.\n",
    "    max_net.eval() \n",
    "    \n",
    "    # calculating a train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    max_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:  \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            test_output = max_net(inputs)\n",
    "            # get the class which has the maximum probability\n",
    "            _, predicted = torch.max(test_output.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    max_test_accuracies.append(test_accuracy)\n",
    "    # Set the model back to training mode.\n",
    "    max_net.train()     \n",
    "              \n",
    "\n",
    "print('Finished Training.')\n",
    "PATH = './cifar_max_net_adam.pth'\n",
    "torch.save(max_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:  2499] avg-125-iter mini-batch train_loss: 1.700\n",
      "[epoch: 0, i:  4999] avg-125-iter mini-batch train_loss: 1.493\n",
      "[epoch: 0, i:  7499] avg-125-iter mini-batch train_loss: 1.527\n",
      "[epoch: 0, i:  9999] avg-125-iter mini-batch train_loss: 1.554\n",
      "[epoch: 0, i: 12499] avg-125-iter mini-batch train_loss: 1.442\n",
      "[epoch: 1, i:  2499] avg-125-iter mini-batch train_loss: 1.550\n",
      "[epoch: 1, i:  4999] avg-125-iter mini-batch train_loss: 1.358\n",
      "[epoch: 1, i:  7499] avg-125-iter mini-batch train_loss: 1.346\n",
      "[epoch: 1, i:  9999] avg-125-iter mini-batch train_loss: 1.414\n",
      "[epoch: 1, i: 12499] avg-125-iter mini-batch train_loss: 1.410\n",
      "[epoch: 2, i:  2499] avg-125-iter mini-batch train_loss: 1.218\n",
      "[epoch: 2, i:  4999] avg-125-iter mini-batch train_loss: 1.441\n",
      "[epoch: 2, i:  7499] avg-125-iter mini-batch train_loss: 1.344\n",
      "[epoch: 2, i:  9999] avg-125-iter mini-batch train_loss: 1.254\n",
      "[epoch: 2, i: 12499] avg-125-iter mini-batch train_loss: 1.339\n",
      "[epoch: 3, i:  2499] avg-125-iter mini-batch train_loss: 1.181\n",
      "[epoch: 3, i:  4999] avg-125-iter mini-batch train_loss: 1.297\n",
      "[epoch: 3, i:  7499] avg-125-iter mini-batch train_loss: 1.229\n",
      "[epoch: 3, i:  9999] avg-125-iter mini-batch train_loss: 1.293\n",
      "[epoch: 3, i: 12499] avg-125-iter mini-batch train_loss: 1.181\n",
      "[epoch: 4, i:  2499] avg-125-iter mini-batch train_loss: 1.172\n",
      "[epoch: 4, i:  4999] avg-125-iter mini-batch train_loss: 1.277\n",
      "[epoch: 4, i:  7499] avg-125-iter mini-batch train_loss: 1.178\n",
      "[epoch: 4, i:  9999] avg-125-iter mini-batch train_loss: 1.242\n",
      "[epoch: 4, i: 12499] avg-125-iter mini-batch train_loss: 1.207\n",
      "[epoch: 5, i:  2499] avg-125-iter mini-batch train_loss: 1.140\n",
      "[epoch: 5, i:  4999] avg-125-iter mini-batch train_loss: 1.118\n",
      "[epoch: 5, i:  7499] avg-125-iter mini-batch train_loss: 1.093\n",
      "[epoch: 5, i:  9999] avg-125-iter mini-batch train_loss: 1.292\n",
      "[epoch: 5, i: 12499] avg-125-iter mini-batch train_loss: 1.144\n",
      "[epoch: 6, i:  2499] avg-125-iter mini-batch train_loss: 1.158\n",
      "[epoch: 6, i:  4999] avg-125-iter mini-batch train_loss: 1.108\n",
      "[epoch: 6, i:  7499] avg-125-iter mini-batch train_loss: 1.202\n",
      "[epoch: 6, i:  9999] avg-125-iter mini-batch train_loss: 1.183\n",
      "[epoch: 6, i: 12499] avg-125-iter mini-batch train_loss: 1.154\n",
      "[epoch: 7, i:  2499] avg-125-iter mini-batch train_loss: 1.109\n",
      "[epoch: 7, i:  4999] avg-125-iter mini-batch train_loss: 1.147\n",
      "[epoch: 7, i:  7499] avg-125-iter mini-batch train_loss: 1.113\n",
      "[epoch: 7, i:  9999] avg-125-iter mini-batch train_loss: 1.195\n",
      "[epoch: 7, i: 12499] avg-125-iter mini-batch train_loss: 1.240\n",
      "[epoch: 8, i:  2499] avg-125-iter mini-batch train_loss: 1.131\n",
      "[epoch: 8, i:  4999] avg-125-iter mini-batch train_loss: 1.168\n",
      "[epoch: 8, i:  7499] avg-125-iter mini-batch train_loss: 1.213\n",
      "[epoch: 8, i:  9999] avg-125-iter mini-batch train_loss: 1.101\n",
      "[epoch: 8, i: 12499] avg-125-iter mini-batch train_loss: 1.163\n",
      "[epoch: 9, i:  2499] avg-125-iter mini-batch train_loss: 1.256\n",
      "[epoch: 9, i:  4999] avg-125-iter mini-batch train_loss: 1.113\n",
      "[epoch: 9, i:  7499] avg-125-iter mini-batch train_loss: 1.136\n",
      "[epoch: 9, i:  9999] avg-125-iter mini-batch train_loss: 1.150\n",
      "[epoch: 9, i: 12499] avg-125-iter mini-batch train_loss: 1.149\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(max_bn_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "max_bn_avg_train_losses = []   # Avg. losses.\n",
    "max_bn_train_accuracies, max_bn_test_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "epochs = 10             # Total epochs.\n",
    "\n",
    "iter_n = len(trainset.data) // 4  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 5 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    test_total = 0   \n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = max_bn_net(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        # Record training loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            max_bn_avg_train_losses.append(avg_train_loss)\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}] avg-{}-iter mini-batch train_loss: {:.3f}'.format(\n",
    "                    epoch, i, record_freq, avg_train_loss))\n",
    "        \n",
    "    # Set the model to evaluation mode.\n",
    "    max_bn_net.eval() \n",
    "    \n",
    "    # calculating a train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    max_bn_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:  \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            test_output = max_bn_net(inputs)\n",
    "            # get the class which has the maximum probability\n",
    "            _, predicted = torch.max(test_output.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    max_bn_test_accuracies.append(test_accuracy)\n",
    "    # Set the model back to training mode.\n",
    "    max_bn_net.train()     \n",
    "              \n",
    "\n",
    "print('Finished Training.')\n",
    "PATH = './cifar_max_bn_net_adam.pth'\n",
    "torch.save(max_bn_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 0, i:  2499] avg-125-iter mini-batch train_loss: 1.669\n",
      "[epoch: 0, i:  4999] avg-125-iter mini-batch train_loss: 1.564\n",
      "[epoch: 0, i:  7499] avg-125-iter mini-batch train_loss: 1.541\n",
      "[epoch: 0, i:  9999] avg-125-iter mini-batch train_loss: 1.609\n",
      "[epoch: 0, i: 12499] avg-125-iter mini-batch train_loss: 1.506\n",
      "[epoch: 1, i:  2499] avg-125-iter mini-batch train_loss: 1.589\n",
      "[epoch: 1, i:  4999] avg-125-iter mini-batch train_loss: 1.396\n",
      "[epoch: 1, i:  7499] avg-125-iter mini-batch train_loss: 1.520\n",
      "[epoch: 1, i:  9999] avg-125-iter mini-batch train_loss: 1.352\n",
      "[epoch: 1, i: 12499] avg-125-iter mini-batch train_loss: 1.434\n",
      "[epoch: 2, i:  2499] avg-125-iter mini-batch train_loss: 1.451\n",
      "[epoch: 2, i:  4999] avg-125-iter mini-batch train_loss: 1.405\n",
      "[epoch: 2, i:  7499] avg-125-iter mini-batch train_loss: 1.416\n",
      "[epoch: 2, i:  9999] avg-125-iter mini-batch train_loss: 1.315\n",
      "[epoch: 2, i: 12499] avg-125-iter mini-batch train_loss: 1.424\n",
      "[epoch: 3, i:  2499] avg-125-iter mini-batch train_loss: 1.282\n",
      "[epoch: 3, i:  4999] avg-125-iter mini-batch train_loss: 1.351\n",
      "[epoch: 3, i:  7499] avg-125-iter mini-batch train_loss: 1.425\n",
      "[epoch: 3, i:  9999] avg-125-iter mini-batch train_loss: 1.415\n",
      "[epoch: 3, i: 12499] avg-125-iter mini-batch train_loss: 1.273\n",
      "[epoch: 4, i:  2499] avg-125-iter mini-batch train_loss: 1.327\n",
      "[epoch: 4, i:  4999] avg-125-iter mini-batch train_loss: 1.176\n",
      "[epoch: 4, i:  7499] avg-125-iter mini-batch train_loss: 1.232\n",
      "[epoch: 4, i:  9999] avg-125-iter mini-batch train_loss: 1.312\n",
      "[epoch: 4, i: 12499] avg-125-iter mini-batch train_loss: 1.384\n",
      "[epoch: 5, i:  2499] avg-125-iter mini-batch train_loss: 1.313\n",
      "[epoch: 5, i:  4999] avg-125-iter mini-batch train_loss: 1.249\n",
      "[epoch: 5, i:  7499] avg-125-iter mini-batch train_loss: 1.388\n",
      "[epoch: 5, i:  9999] avg-125-iter mini-batch train_loss: 1.284\n",
      "[epoch: 5, i: 12499] avg-125-iter mini-batch train_loss: 1.417\n",
      "[epoch: 6, i:  2499] avg-125-iter mini-batch train_loss: 1.270\n",
      "[epoch: 6, i:  4999] avg-125-iter mini-batch train_loss: 1.188\n",
      "[epoch: 6, i:  7499] avg-125-iter mini-batch train_loss: 1.319\n",
      "[epoch: 6, i:  9999] avg-125-iter mini-batch train_loss: 1.381\n",
      "[epoch: 6, i: 12499] avg-125-iter mini-batch train_loss: 1.342\n",
      "[epoch: 7, i:  2499] avg-125-iter mini-batch train_loss: 1.197\n",
      "[epoch: 7, i:  4999] avg-125-iter mini-batch train_loss: 1.329\n",
      "[epoch: 7, i:  7499] avg-125-iter mini-batch train_loss: 1.308\n",
      "[epoch: 7, i:  9999] avg-125-iter mini-batch train_loss: 1.206\n",
      "[epoch: 7, i: 12499] avg-125-iter mini-batch train_loss: 1.272\n",
      "[epoch: 8, i:  2499] avg-125-iter mini-batch train_loss: 1.284\n",
      "[epoch: 8, i:  4999] avg-125-iter mini-batch train_loss: 1.112\n",
      "[epoch: 8, i:  7499] avg-125-iter mini-batch train_loss: 1.231\n",
      "[epoch: 8, i:  9999] avg-125-iter mini-batch train_loss: 1.328\n",
      "[epoch: 8, i: 12499] avg-125-iter mini-batch train_loss: 1.314\n",
      "[epoch: 9, i:  2499] avg-125-iter mini-batch train_loss: 1.321\n",
      "[epoch: 9, i:  4999] avg-125-iter mini-batch train_loss: 1.346\n",
      "[epoch: 9, i:  7499] avg-125-iter mini-batch train_loss: 1.315\n",
      "[epoch: 9, i:  9999] avg-125-iter mini-batch train_loss: 1.335\n",
      "[epoch: 9, i: 12499] avg-125-iter mini-batch train_loss: 1.268\n",
      "Finished Training.\n"
     ]
    }
   ],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "\n",
    "# We use Adam as optimizer.\n",
    "opt = optim.Adam(max_drop_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "max_drop_avg_train_losses = []   # Avg. losses.\n",
    "max_drop_train_accuracies, max_drop_test_accuracies = [], []  # Train and test accuracies.\n",
    "\n",
    "epochs = 10             # Total epochs.\n",
    "\n",
    "iter_n = len(trainset.data) // 4  # number of iteration per epoch\n",
    "record_freq = iter_n // 100  # Record frequency.\n",
    "print_freq = iter_n // 5 # Print frequency, need to be multiple of record_freq.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_train_loss = 0.0       # Initialize running train_loss for training set.\n",
    "    \n",
    "    # Initialize running total and correct for computing train accuracy.\n",
    "    train_correct = 0 \n",
    "    train_total = 0\n",
    "    # Initialize running total and correct for computing test accuracy.\n",
    "    test_total = 0   \n",
    "    test_correct = 0\n",
    "    \n",
    "    for i, data in enumerate(iterable=trainloader, start=0):\n",
    "        \n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step\n",
    "        train_output = max_drop_net(inputs)\n",
    "        train_loss = loss_func(train_output, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # record statistics.\n",
    "        running_train_loss += train_loss.item()\n",
    "        \n",
    "        # this is for recording training accuracy\n",
    "        _, predicted = torch.max(train_output.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        # Record training loss every several mini-batches.\n",
    "        if i % record_freq == record_freq - 1: \n",
    "            avg_train_loss = running_train_loss / record_freq\n",
    "            max_drop_avg_train_losses.append(avg_train_loss)\n",
    "            running_train_loss = 0.0\n",
    "            \n",
    "            # only print traing training loss once in a while to avoid cluster output\n",
    "            if i % print_freq == print_freq - 1:\n",
    "                print('[epoch: {}, i: {:5d}] avg-{}-iter mini-batch train_loss: {:.3f}'.format(\n",
    "                    epoch, i, record_freq, avg_train_loss))\n",
    "        \n",
    "    # Set the model to evaluation mode.\n",
    "    max_drop_net.eval() \n",
    "    \n",
    "    # calculating a train accuracy\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    max_drop_train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:  \n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            test_output = max_drop_net(inputs)\n",
    "            # get the class which has the maximum probability\n",
    "            _, predicted = torch.max(test_output.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    max_drop_test_accuracies.append(test_accuracy)\n",
    "    # Set the model back to training mode.\n",
    "    max_drop_net.train()     \n",
    "              \n",
    "\n",
    "print('Finished Training.')\n",
    "PATH = './cifar_max_drop_net_adam.pth'\n",
    "torch.save(max_drop_net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(avg_avg_train_losses)\n",
    "# plt.plot(avg_bn_avg_train_losses)\n",
    "plt.plot(avg_drop_avg_train_losses)\n",
    "# plt.plot(max_avg_train_losses)\n",
    "# plt.plot(max_bn_avg_train_losses)\n",
    "plt.plot(max_drop_avg_train_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(record_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "# plt.legend(['avg', 'avg_bn', 'avg_drop', 'max', 'max_bn', 'max_drop'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(max_bn_train_accuracies)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(max_bn_test_accuracies)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmini-batch index / \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(record_freq))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(max_bn_train_accuracies)\n",
    "plt.plot(max_bn_test_accuracies)\n",
    "plt.xlabel('mini-batch index / {}'.format(record_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all models in a list\n",
    "models = [avg_net, avg_bn_net, avg_drop_net, max_net, max_bn_net, max_drop_net]\n",
    "\n",
    "# set all models to eval mode\n",
    "for model in models:\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the AvgNet network on the 10000 test images: 64.42 %\n",
      "Accuracy of the AvgBNNet network on the 10000 test images: 68.29 %\n",
      "Accuracy of the AvgDropNet network on the 10000 test images: 64.94 %\n",
      "Accuracy of the MaxNet network on the 10000 test images: 64.33 %\n",
      "Accuracy of the MaxBNNet network on the 10000 test images: 69.33 %\n",
      "Accuracy of the MaxDropNet network on the 10000 test images: 63.91 %\n"
     ]
    }
   ],
   "source": [
    "corrects = [0] * 6\n",
    "totals = [0] * 6\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        for i, model in enumerate(iterable=models, start=0):\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            totals[i] += labels.size(0)\n",
    "            corrects[i] += (predicted == labels).sum().item()\n",
    "\n",
    "# print all the accuracies\n",
    "for i in range(len(models)):\n",
    "    print('Accuracy of the %s network on the 10000 test images: %.2f %%' % (models[i].__class__.__name__,\n",
    "        100 * corrects[i] / totals[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxNet(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1280, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model explicitly\n",
    "# max_net = MaxNet()\n",
    "# max_net.to(device)\n",
    "# PATH = './cifar_max_net_adam.pth'\n",
    "# max_net.load_state_dict(torch.load(PATH))\n",
    "# max_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the essembled network on the 10000 test images: 73.70 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = [model(images).data for model in models]\n",
    "        enssembled_outputs = torch.stack(outputs, dim=0).sum(dim=0)\n",
    "        _, predicted = torch.max(enssembled_outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print('Accuracy of the essembled network on the 10000 test images: %.2f %%' % (\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.4967, -4.9822, -4.5038,  0.0880, -3.8759, -1.4940, -3.0071, -4.3399,\n",
      "         -0.2131, -4.1152],\n",
      "        [ 0.0711,  3.4113, -3.8370, -3.7963, -5.6577, -5.9947, -8.0490, -2.8024,\n",
      "          0.7028, -2.0797],\n",
      "        [ 0.1010, -0.6433, -3.5087, -2.8251, -3.0741, -5.4893, -5.5182, -2.0182,\n",
      "         -0.1710, -1.3593],\n",
      "        [ 2.2307,  0.0133, -3.0063, -2.6697, -2.6974, -5.9213, -4.1817, -3.8934,\n",
      "         -1.4629, -3.6291]], device='mps:0', grad_fn=<LinearBackward0>)\n",
      "tensor([[-3.4967, -4.9822, -4.5038,  0.0880, -3.8759, -1.4940, -3.0071, -4.3399,\n",
      "         -0.2131, -4.1152],\n",
      "        [ 0.0711,  3.4113, -3.8370, -3.7963, -5.6577, -5.9947, -8.0490, -2.8024,\n",
      "          0.7028, -2.0797],\n",
      "        [ 0.1010, -0.6433, -3.5087, -2.8251, -3.0741, -5.4893, -5.5182, -2.0182,\n",
      "         -0.1710, -1.3593],\n",
      "        [ 2.2307,  0.0133, -3.0063, -2.6697, -2.6974, -5.9213, -4.1817, -3.8934,\n",
      "         -1.4629, -3.6291]], device='mps:0')\n",
      "tensor([3, 8, 8, 0], device='mps:0')\n",
      "tensor([3, 1, 0, 0], device='mps:0')\n",
      "tensor([ True, False, False,  True], device='mps:0')\n",
      "tensor([ True, False, False,  True], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# just a script to understand what .data does\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs1 = avg_bn_net(images)\n",
    "print(outputs1)\n",
    "print(outputs1.data)\n",
    "_, predicted = torch.max(outputs1.data, 1)\n",
    "print(labels)\n",
    "print(predicted)\n",
    "print(predicted == labels)\n",
    "c = (predicted == labels).squeeze()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m outputs1 \u001b[38;5;241m=\u001b[39m avg_bn_net(images)\n\u001b[0;32m----> 9\u001b[0m outputs2 \u001b[38;5;241m=\u001b[39m \u001b[43mmax_bn_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m enssembled_outputs \u001b[38;5;241m=\u001b[39m outputs1\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m+\u001b[39m outputs2\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m     11\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(enssembled_outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cogs181/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cogs181/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[68], line 32\u001b[0m, in \u001b[0;36mMaxBNNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# conv2 relu max pool\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x)\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/cogs181/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cogs181/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cogs181/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cogs181/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = [model(images).data for model in models]\n",
    "        enssembled_outputs = torch.stack(outputs, dim=0).sum(dim=0)\n",
    "        _, predicted = torch.max(enssembled_outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
